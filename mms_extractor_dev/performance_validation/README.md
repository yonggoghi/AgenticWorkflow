# ì„±ëŠ¥ ê²€ì¦ ì‹œìŠ¤í…œ

ì´ ë””ë ‰í† ë¦¬ëŠ” 5ê°œ ëª¨ë¸ (gemma, gemini, claude, ax, gpt)ì˜ MMS ì¶”ì¶œ ì„±ëŠ¥ì„ ë¹„êµí•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸ“‹ ì‹¤í—˜ ê°œìš”

### ëª©ì 
- 5ê°œ LLM ëª¨ë¸ì˜ MMS ë©”ì‹œì§€ ì¶”ì¶œ ì„±ëŠ¥ ë¹„êµ
- ê° ëª¨ë¸ì´ ìƒì„±í•˜ëŠ” "7ë‹¨ê³„: ì—”í‹°í‹° ë§¤ì¹­ ë° ìµœì¢… ê²°ê³¼ êµ¬ì„±" ì „ì˜ json_objects ë¶„ì„
- ì •ë‹µ ë°ì´í„°ì…‹ ê¸°ë°˜ ê°ê´€ì  ì„±ëŠ¥ í‰ê°€

### ë¹„êµ ëª¨ë¸
1. **gemma**: `skt/gemma3-12b-it`
2. **gemini**: `gcp/gemini-2.5-flash` 
3. **claude**: `amazon/anthropic/claude-sonnet-4-20250514`
4. **ax**: `skt/ax4`
5. **gpt**: `azure/openai/gpt-4o-2024-08-06`

### ì‹¤í—˜ ì„¤ì •
- `extract-entity-dag=false`
- `product-info-extraction-mode='rag'`
- `entity-matching-mode='llm'`

## ğŸš€ ì‹¤í–‰ ë°©ë²•

### 1. ì „ì²´ ì‹¤í—˜ ìë™ ì‹¤í–‰ (ê¶Œì¥)

**âš ï¸ ì¤‘ìš”: mms_extractor_unified ë””ë ‰í† ë¦¬ì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”**

```bash
# mms_extractor_unified ë””ë ‰í† ë¦¬ë¡œ ì´ë™
cd /path/to/mms_extractor_unified

# ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰ (ë°°ì¹˜ í¬ê¸° 100, ìµœì†Œ ë©”ì‹œì§€ ê¸¸ì´ 300ì)
python performance_validation/run_validation.py

# ì‚¬ìš©ì ì„¤ì •ìœ¼ë¡œ ì‹¤í–‰
python performance_validation/run_validation.py --batch-size 50 --output-dir my_results --similarity-threshold 0.85 --min-message-length 400
```

### 2. ê°œë³„ ë‹¨ê³„ ì‹¤í–‰

#### ë‹¨ê³„ 1: ëª¨ë¸ ì¶”ì¶œ ì‹¤í—˜
```bash
# mms_extractor_unified ë””ë ‰í† ë¦¬ì—ì„œ
python performance_validation/model_comparison_experiment.py --batch-size 100 --output-dir results --min-message-length 300
```

#### ë‹¨ê³„ 2: ì„±ëŠ¥ í‰ê°€
```bash
# mms_extractor_unified ë””ë ‰í† ë¦¬ì—ì„œ
python performance_validation/model_performance_evaluator.py --results-dir results --similarity-threshold 0.9 --min-message-length 300
```

### 3. ê¸°ì¡´ ê²°ê³¼ í™œìš©

ì´ë¯¸ ì¶”ì¶œ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° í‰ê°€ë§Œ ì‹¤í–‰:
```bash
# mms_extractor_unified ë””ë ‰í† ë¦¬ì—ì„œ
python performance_validation/run_validation.py --skip-extraction
```

## ğŸ“ ê²°ê³¼ êµ¬ì¡°

ì‹¤í—˜ ì‹¤í–‰ í›„ ë‹¤ìŒê³¼ ê°™ì€ ë””ë ‰í† ë¦¬ êµ¬ì¡°ê°€ ìƒì„±ë©ë‹ˆë‹¤:

```
results/
â”œâ”€â”€ combined_extraction_results.json    # ì „ì²´ ëª¨ë¸ ê²°ê³¼ (JSON)
â”œâ”€â”€ combined_extraction_results.pkl     # ì „ì²´ ëª¨ë¸ ê²°ê³¼ (í”¼í´)
â”œâ”€â”€ experiment_metadata.json            # ì‹¤í—˜ ë©”íƒ€ë°ì´í„°
â”œâ”€â”€ gemma_extraction_results.json       # gemma ëª¨ë¸ ê°œë³„ ê²°ê³¼
â”œâ”€â”€ gemini_extraction_results.json      # gemini ëª¨ë¸ ê°œë³„ ê²°ê³¼
â”œâ”€â”€ claude_extraction_results.json      # claude ëª¨ë¸ ê°œë³„ ê²°ê³¼
â”œâ”€â”€ ax_extraction_results.json          # ax ëª¨ë¸ ê°œë³„ ê²°ê³¼
â”œâ”€â”€ gpt_extraction_results.json         # gpt ëª¨ë¸ ê°œë³„ ê²°ê³¼
â””â”€â”€ evaluation/
    â”œâ”€â”€ ground_truth_dataset.json       # ì •ë‹µ ë°ì´í„°ì…‹
    â”œâ”€â”€ model_evaluation_results.json   # ìƒì„¸ í‰ê°€ ê²°ê³¼
    â”œâ”€â”€ performance_summary.json        # ì„±ëŠ¥ ìš”ì•½
    â””â”€â”€ performance_report.txt          # í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸
```

## ğŸ“Š í‰ê°€ ë°©ë²•

### ì •ë‹µ ë°ì´í„°ì…‹ ìƒì„±
1. gemini, gpt, claude 3ê°œ ëª¨ë¸ì´ ëª¨ë‘ ì„±ê³µí•œ ë©”ì‹œì§€ ì„ ë³„
2. **ì¶”ê°€ í•„í„°ë§ ì¡°ê±´ ì ìš©**:
   - ë©”ì‹œì§€ ê¸¸ì´ê°€ ìµœì†Œ 300ì ì´ìƒ
   - 1st depth íƒœê·¸ë“¤(title, purpose, product, channel, pgm)ì˜ ê°’ì´ ëª¨ë‘ ìœ íš¨í•˜ê²Œ ì±„ì›Œì ¸ ìˆì–´ì•¼ í•¨
3. 3ê°œ ëª¨ë¸ ê²°ê³¼ ê°„ ìœ ì‚¬ë„ ê³„ì‚° (ê¸°ë³¸ ì„ê³„ê°’: 90%)
4. ì„ê³„ê°’ ì´ìƒì˜ ë©”ì‹œì§€ì—ì„œ claude ê²°ê³¼ë¥¼ ì •ë‹µìœ¼ë¡œ ì„¤ì •

### ì„±ëŠ¥ í‰ê°€ ì§€í‘œ
- **ì „ì²´ ìœ ì‚¬ë„** (Overall Similarity): ê°€ì¤‘í‰ê·  ì ìˆ˜
  - title: 20%
  - purpose: 15% 
  - product: 35%
  - channel: 15%
  - pgm: 15%

### ìœ ì‚¬ë„ ê³„ì‚° ì„¸ë¶€ì‚¬í•­
- **í…ìŠ¤íŠ¸ ìœ ì‚¬ë„**: SequenceMatcher ì‚¬ìš©
- **ë¦¬ìŠ¤íŠ¸ ìœ ì‚¬ë„**: Jaccard ìœ ì‚¬ë„
- **ì œí’ˆ ìœ ì‚¬ë„**: ë‹¤ì¤‘ í•„ë“œ ê°€ì¤‘í‰ê· 
- **ì±„ë„/í”„ë¡œê·¸ë¨ ìœ ì‚¬ë„**: í•„ë“œë³„ í‰ê· 

## ğŸ“ˆ ê²°ê³¼ í•´ì„

### ì„±ëŠ¥ ë“±ê¸‰
- **A+ (Excellent)**: 0.9 ì´ìƒ
- **A (Very Good)**: 0.8 ì´ìƒ
- **B+ (Good)**: 0.7 ì´ìƒ  
- **B (Fair)**: 0.6 ì´ìƒ
- **C+ (Below Average)**: 0.5 ì´ìƒ
- **C (Poor)**: 0.5 ë¯¸ë§Œ

### ì£¼ìš” ì¶œë ¥ íŒŒì¼

#### 1. performance_report.txt
í…ìŠ¤íŠ¸ í˜•íƒœì˜ ì¢…í•© ë¦¬í¬íŠ¸
- ëª¨ë¸ë³„ ì„±ëŠ¥ ìš”ì•½
- í•„ë“œë³„ ìƒì„¸ ë¶„ì„
- ì„±ëŠ¥ ìˆœìœ„

#### 2. performance_summary.json  
í”„ë¡œê·¸ë˜ë°ì  ì ‘ê·¼ì„ ìœ„í•œ ìš”ì•½ ë°ì´í„°
- ëª¨ë¸ë³„ í†µê³„
- ì„±ëŠ¥ ìˆœìœ„
- ë©”íƒ€ë°ì´í„°

#### 3. model_evaluation_results.json
ìƒì„¸í•œ í‰ê°€ ê²°ê³¼
- ë©”ì‹œì§€ë³„ ìœ ì‚¬ë„ ì ìˆ˜
- í•„ë“œë³„ ë¶„ì„ ê²°ê³¼
- í†µê³„ ì •ë³´

## âš™ï¸ ì„¤ì • ì˜µì…˜

### ëª…ë ¹í–‰ ì˜µì…˜

#### run_validation.py
- `--batch-size`: ì‹¤í—˜í•  ë©”ì‹œì§€ ìˆ˜ (ê¸°ë³¸ê°’: 100)
- `--output-dir`: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: results)
- `--similarity-threshold`: ì •ë‹µ ìƒì„± ìœ ì‚¬ë„ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.9)
- `--min-message-length`: ì •ë‹µìš© ë©”ì‹œì§€ ìµœì†Œ ê¸¸ì´ (ê¸°ë³¸ê°’: 300)
- `--skip-extraction`: ì¶”ì¶œ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°
- `--skip-evaluation`: í‰ê°€ ë‹¨ê³„ ê±´ë„ˆë›°ê¸°

#### model_comparison_experiment.py
- `--batch-size`: ë°°ì¹˜ í¬ê¸°
- `--output-dir`: ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
- `--min-message-length`: ìµœì†Œ ë©”ì‹œì§€ ê¸¸ì´ (ì¶”ì¶œ ë‹¨ê³„ì—ì„œ ì‚¬ì „ í•„í„°ë§)

#### model_performance_evaluator.py  
- `--results-dir`: ê²°ê³¼ ë””ë ‰í† ë¦¬
- `--similarity-threshold`: ìœ ì‚¬ë„ ì„ê³„ê°’
- `--min-message-length`: ì •ë‹µìš© ë©”ì‹œì§€ ìµœì†Œ ê¸¸ì´

## ğŸ”§ ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

1. **API í‚¤ ì˜¤ë¥˜**
   - `.env` íŒŒì¼ì— í•„ìš”í•œ API í‚¤ë“¤ì´ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
   - `OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, `CUSTOM_API_KEY` ë“±

2. **ë©”ëª¨ë¦¬ ë¶€ì¡±**
   - ë°°ì¹˜ í¬ê¸°ë¥¼ ì¤„ì—¬ì„œ ì‹¤í–‰: `--batch-size 50`

3. **ëª¨ë¸ ì´ˆê¸°í™” ì‹¤íŒ¨**
   - ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
   - API í‚¤ ê¶Œí•œ í™•ì¸

4. **ê²°ê³¼ íŒŒì¼ ì—†ìŒ**
   - ì¶”ì¶œ ë‹¨ê³„ê°€ ì„±ê³µí–ˆëŠ”ì§€ í™•ì¸
   - `combined_extraction_results.json` ë˜ëŠ” `.pkl` íŒŒì¼ ì¡´ì¬ í™•ì¸

### ë¡œê·¸ í™•ì¸
ê° ì‹¤í–‰ ì‹œ ë¡œê·¸ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤:
- `validation_run_YYYYMMDD_HHMMSS.log`
- `model_comparison_YYYYMMDD_HHMMSS.log`  
- `model_evaluation_YYYYMMDD_HHMMSS.log`

## ğŸ“ ì˜ˆì œ ì‹¤í–‰

### ì†Œê·œëª¨ í…ŒìŠ¤íŠ¸
```bash
# 10ê°œ ë©”ì‹œì§€ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸
python run_validation.py --batch-size 10 --output-dir test_results
```

### ëŒ€ê·œëª¨ ì‹¤í—˜
```bash
# 500ê°œ ë©”ì‹œì§€ë¡œ ë³¸ê²©ì ì¸ ì‹¤í—˜
python run_validation.py --batch-size 500 --output-dir large_experiment
```

### ê¸°ì¡´ ê²°ê³¼ ì¬í‰ê°€
```bash
# ë‹¤ë¥¸ ìœ ì‚¬ë„ ì„ê³„ê°’ê³¼ ë©”ì‹œì§€ ê¸¸ì´ ì¡°ê±´ìœ¼ë¡œ ì¬í‰ê°€
python model_performance_evaluator.py --results-dir results --similarity-threshold 0.85 --min-message-length 500
```

## ğŸ—ï¸ ì‹œìŠ¤í…œ êµ¬ì¡°

### í•µì‹¬ íŠ¹ì§•
- **ìµœì†Œ ì›ë³¸ ìˆ˜ì •**: ê¸°ì¡´ MMSExtractor ì½”ë“œë¥¼ ìµœëŒ€í•œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
- **ë…ë¦½ì  ì‹¤í–‰**: mms_extractor_unified ë””ë ‰í† ë¦¬ ë‚´ì—ì„œ ì™„ì „íˆ ì‹¤í–‰
- **ëª¨ë“ˆí™” ì„¤ê³„**: ê° ë‹¨ê³„ë³„ë¡œ ë…ë¦½ ì‹¤í–‰ ê°€ëŠ¥
- **í™•ì¥ ê°€ëŠ¥ì„±**: ìƒˆë¡œìš´ ëª¨ë¸ ì¶”ê°€ ìš©ì´

### ì£¼ìš” ì»´í¬ë„ŒíŠ¸
1. **model_comparison_experiment.py**: ëª¨ë¸ë³„ ì¶”ì¶œ ì‹¤í—˜
2. **model_performance_evaluator.py**: ì„±ëŠ¥ í‰ê°€ ë° ë¶„ì„
3. **run_validation.py**: í†µí•© ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
4. **README.md**: ì‚¬ìš© ê°€ì´ë“œ (ì´ ë¬¸ì„œ)

## ğŸ“š ì°¸ê³  ì •ë³´

### ì›ë³¸ ì½”ë“œ ì˜ì¡´ì„±
- `mms_extractor.py`: ë©”ì¸ ì¶”ì¶œê¸° (ê¸°ì¡´ ë©”ì†Œë“œ í™œìš©)
- `config/settings.py`: ì„¤ì • ì •ë³´
- ë°ì´í„° íŒŒì¼ë“¤: MMS ë©”ì‹œì§€, ìƒí’ˆ ì •ë³´ ë“±

### ì‹¤í—˜ ì¬í˜„ì„±
- ë©”ì‹œì§€ ìƒ˜í”Œë§ì— `random_state=42` ì‚¬ìš©
- ëª¨ë“  ì„¤ì •ê³¼ ë©”íƒ€ë°ì´í„°ê°€ ì €ì¥ë¨
- ë™ì¼í•œ ì„¤ì •ìœ¼ë¡œ ì¬ì‹¤í–‰ ê°€ëŠ¥

### í™•ì¥ ê°€ëŠ¥ì„±
- ìƒˆë¡œìš´ ëª¨ë¸ ì¶”ê°€: `models` ë”•ì…”ë„ˆë¦¬ ìˆ˜ì •
- í‰ê°€ ì§€í‘œ ì¶”ê°€: `calculate_dictionary_similarity` í•¨ìˆ˜ ìˆ˜ì •
- ìƒˆë¡œìš´ ìœ ì‚¬ë„ í•¨ìˆ˜: í‰ê°€ê¸° í´ë˜ìŠ¤ í™•ì¥

## ğŸ“… ê²°ê³¼ ë””ë ‰í† ë¦¬ ìë™ íƒ€ì„ìŠ¤íƒ¬í”„

ëª¨ë“  ì‹¤í—˜ ê²°ê³¼ëŠ” ì‹¤í–‰ ì‹œê°„ì— ë”°ë¼ ìë™ìœ¼ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤:

```bash
# ì…ë ¥: --output-dir results
# ì‹¤ì œ ìƒì„±: results_202501031430

# ì…ë ¥: --output-dir my_experiment  
# ì‹¤ì œ ìƒì„±: my_experiment_202501031430
```

**íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹**: `YYYYMMDDHHmm` (ë…„ì›”ì¼ì‹œë¶„)

ì´ë¥¼ í†µí•´ ì—¬ëŸ¬ ì‹¤í—˜ì„ ë™ì‹œì— ì‹¤í–‰í•˜ê±°ë‚˜ ê¸°ë¡ì„ ë³´ê´€í•  ë•Œ ì¶©ëŒ ì—†ì´ ê´€ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
