"""
MMS Workflow Steps - MMS ì¶”ì¶œê¸° ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ êµ¬í˜„
===================================================

ì´ ëª¨ë“ˆì€ MMS ë©”ì‹œì§€ ì²˜ë¦¬ì˜ ê° ë‹¨ê³„ë¥¼ ë…ë¦½ì ì¸ í´ë˜ìŠ¤ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.
ê° ë‹¨ê³„ëŠ” WorkflowStepì„ ìƒì†ë°›ì•„ execute ë©”ì„œë“œë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤.
"""

import logging
import copy
from typing import Any, Dict
from .workflow_core import WorkflowStep, WorkflowState
from utils import (
    validate_text_input,
    safe_check_empty,
    extract_json_objects
)
from utils import PromptManager, validate_extraction_result, detect_schema_response


logger = logging.getLogger(__name__)


class InputValidationStep(WorkflowStep):
    """
    ì…ë ¥ ë©”ì‹œì§€ ê²€ì¦ ë‹¨ê³„
    
    - ë©”ì‹œì§€ ìœ íš¨ì„± ê²€ì‚¬
    - ì¶”ì¶œê¸° ì„¤ì • ìƒíƒœ ë¡œê¹…
    """
    
    def execute(self, state: WorkflowState) -> WorkflowState:
        mms_msg = state.get("mms_msg")
        extractor = state.get("extractor")
        
        self._log_message_info(mms_msg)
        self._log_extractor_config(extractor)
        
        try:
            msg = validate_text_input(mms_msg)
            state.set("msg", msg)
        except Exception as e:
            logger.error(f"ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨: {e}")
            state.add_error(f"ì…ë ¥ ê²€ì¦ ì‹¤íŒ¨: {e}")
            state.set("is_fallback", True)
        
        return state
    
    def _log_message_info(self, mms_msg: str):
        """ë©”ì‹œì§€ ì •ë³´ ë¡œê¹…"""
        logger.info(f"ë©”ì‹œì§€ ë‚´ìš©: {mms_msg[:200]}...")
        logger.info(f"ë©”ì‹œì§€ ê¸¸ì´: {len(mms_msg)} ë¬¸ì")
    
    def _log_extractor_config(self, extractor):
        """ì¶”ì¶œê¸° ì„¤ì • ë¡œê¹…"""
        logger.info("=== í˜„ì¬ ì¶”ì¶œê¸° ì„¤ì • ===")
        logger.info(f"ë°ì´í„° ì†ŒìŠ¤: {extractor.offer_info_data_src}")
        logger.info(f"ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ëª¨ë“œ: {extractor.product_info_extraction_mode}")
        logger.info(f"ì—”í‹°í‹° ì¶”ì¶œ ëª¨ë“œ: {extractor.entity_extraction_mode}")
        logger.info(f"LLM ëª¨ë¸: {extractor.llm_model_name}")
        logger.info(f"ìƒí’ˆ ë°ì´í„° í¬ê¸°: {extractor.item_pdf_all.shape}")
        logger.info(f"í”„ë¡œê·¸ë¨ ë°ì´í„° í¬ê¸°: {extractor.pgm_pdf.shape}")


class EntityExtractionStep(WorkflowStep):
    """
    ì—”í‹°í‹° ì¶”ì¶œ ë‹¨ê³„
    
    - Kiwi í˜•íƒœì†Œ ë¶„ì„
    - ì„ë² ë”© ìœ ì‚¬ë„ ë§¤ì¹­
    - DB ëª¨ë“œ ì§„ë‹¨
    """
    
    def __init__(self, entity_recognizer):
        self.entity_recognizer = entity_recognizer

    def execute(self, state: WorkflowState) -> WorkflowState:
        if state.has_error():
            return state
        
        msg = state.get("msg")
        extractor = state.get("extractor")
        
        # DB ëª¨ë“œ ì§„ë‹¨
        if extractor.offer_info_data_src == "db":
            self._diagnose_db_mode(extractor)
        
        # ì—”í‹°í‹° ì¶”ì¶œ
        entities_from_kiwi, cand_item_list, extra_item_pdf = self.entity_recognizer.extract_entities_from_kiwi(msg)
        
        self._log_extraction_results(entities_from_kiwi, cand_item_list, extra_item_pdf)
        
        # DB ëª¨ë“œ ê²°ê³¼ ë¶„ì„
        if extractor.offer_info_data_src == "db":
            self._analyze_db_results(cand_item_list)
        
        state.set("entities_from_kiwi", entities_from_kiwi)
        state.set("cand_item_list", cand_item_list)
        state.set("extra_item_pdf", extra_item_pdf)
        
        return state
    
    def _diagnose_db_mode(self, extractor):
        """DB ëª¨ë“œ ì§„ë‹¨"""
        logger.info("ğŸ” DB ëª¨ë“œ íŠ¹ë³„ ì§„ë‹¨ ì‹œì‘")
        logger.info(f"ìƒí’ˆ ë°ì´í„° ìƒíƒœ: {extractor.item_pdf_all.shape}")
        
        required_columns = ['item_nm', 'item_id', 'item_nm_alias']
        missing_columns = [col for col in required_columns if col not in extractor.item_pdf_all.columns]
        if missing_columns:
            logger.error(f"ğŸš¨ DB ëª¨ë“œì—ì„œ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing_columns}")
        
        if 'item_nm_alias' in extractor.item_pdf_all.columns:
            null_aliases = extractor.item_pdf_all['item_nm_alias'].isnull().sum()
            total_aliases = len(extractor.item_pdf_all)
            logger.info(f"DB ëª¨ë“œ ë³„ì¹­ ë°ì´í„° í’ˆì§ˆ: {total_aliases - null_aliases}/{total_aliases} ìœ íš¨")
    
    def _log_extraction_results(self, entities_from_kiwi, cand_item_list, extra_item_pdf):
        """ì¶”ì¶œ ê²°ê³¼ ë¡œê¹…"""
        logger.info(f"ì¶”ì¶œëœ Kiwi ì—”í‹°í‹°: {entities_from_kiwi}")
        logger.info(f"ì¶”ì¶œëœ í›„ë³´ ì—”í‹°í‹°: {cand_item_list}")
        logger.info(f"ë§¤ì¹­ëœ ìƒí’ˆ ì •ë³´: {extra_item_pdf.shape}")
    
    def _analyze_db_results(self, cand_item_list):
        """DB ëª¨ë“œ ê²°ê³¼ ë¶„ì„"""
        logger.info("ğŸ” DB ëª¨ë“œ ì—”í‹°í‹° ì¶”ì¶œ ê²°ê³¼ ë¶„ì„")
        if safe_check_empty(cand_item_list):
            logger.error("ğŸš¨ DB ëª¨ë“œì—ì„œ í›„ë³´ ì—”í‹°í‹°ê°€ ì „í˜€ ì¶”ì¶œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            logger.error("ê°€ëŠ¥í•œ ì›ì¸:")
            logger.error("1. ìƒí’ˆ ë°ì´í„°ë² ì´ìŠ¤ì— í•´ë‹¹ ìƒí’ˆì´ ì—†ìŒ")
            logger.error("2. ë³„ì¹­ ê·œì¹™ ì ìš© ì‹¤íŒ¨")
            logger.error("3. ìœ ì‚¬ë„ ì„ê³„ê°’ì´ ë„ˆë¬´ ë†’ìŒ")
            logger.error("4. Kiwi í˜•íƒœì†Œ ë¶„ì„ ì‹¤íŒ¨")


class ProgramClassificationStep(WorkflowStep):
    """
    í”„ë¡œê·¸ë¨ ë¶„ë¥˜ ë‹¨ê³„
    
    - ë©”ì‹œì§€ë¥¼ í”„ë¡œê·¸ë¨ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜
    """
    
    def __init__(self, program_classifier):
        self.program_classifier = program_classifier

    def execute(self, state: WorkflowState) -> WorkflowState:
        if state.has_error():
            return state
        
        msg = state.get("msg")
        extractor = state.get("extractor")
        
        pgm_info = self.program_classifier.classify(msg)
        logger.info(f"í”„ë¡œê·¸ë¨ ë¶„ë¥˜ ê²°ê³¼ í‚¤: {list(pgm_info.keys())}")
        
        state.set("pgm_info", pgm_info)
        
        return state


class ContextPreparationStep(WorkflowStep):
    """
    RAG ì»¨í…ìŠ¤íŠ¸ ë° ì œí’ˆ ì •ë³´ ì¤€ë¹„ ë‹¨ê³„
    
    - RAG ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
    - ì œí’ˆ ì •ë³´ ì¤€ë¹„ (ëª¨ë“œë³„: nlp/llm/rag)
    """
    
    def execute(self, state: WorkflowState) -> WorkflowState:
        if state.has_error():
            return state
        
        extractor = state.get("extractor")
        pgm_info = state.get("pgm_info")
        cand_item_list = state.get("cand_item_list")
        extra_item_pdf = state.get("extra_item_pdf")
        
        # RAG ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        rag_context = self._build_rag_context(extractor, pgm_info)
        
        # ì œí’ˆ ì •ë³´ ì¤€ë¹„
        product_element = None
        
        if not safe_check_empty(cand_item_list):
            self._log_candidate_items(cand_item_list, extra_item_pdf)
            rag_context, product_element = self._prepare_product_info(
                extractor, rag_context, cand_item_list, extra_item_pdf
            )
        else:
            self._log_no_candidates()
        
        state.set("rag_context", rag_context)
        state.set("product_element", product_element)
        
        return state
    
    def _build_rag_context(self, extractor, pgm_info) -> str:
        """RAG ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±"""
        rag_context = f"\n### ê´‘ê³  ë¶„ë¥˜ ê¸°ì¤€ ì •ë³´ ###\n\t{pgm_info['pgm_cand_info']}" if extractor.num_cand_pgms > 0 else ""
        logger.info(f"í”„ë¡œê·¸ë¨ ë¶„ë¥˜ ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´: {len(rag_context)} ë¬¸ì")
        return rag_context
    
    def _log_candidate_items(self, cand_item_list, extra_item_pdf):
        """í›„ë³´ ì•„ì´í…œ ë¡œê¹…"""
        logger.info(f"í›„ë³´ ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸ í¬ê¸°: {len(cand_item_list)}ê°œ")
        logger.info(f"í›„ë³´ ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸: {cand_item_list}")
        logger.info(f"extra_item_pdf í¬ê¸°: {extra_item_pdf.shape}")
        if not extra_item_pdf.empty:
            logger.info(f"extra_item_pdf ì»¬ëŸ¼ë“¤: {list(extra_item_pdf.columns)}")
            logger.info(f"extra_item_pdf ìƒ˜í”Œ: {extra_item_pdf.head(2).to_dict('records')}")
    
    def _prepare_product_info(self, extractor, rag_context, cand_item_list, extra_item_pdf):
        """ì œí’ˆ ì •ë³´ ì¤€ë¹„ (ëª¨ë“œë³„)"""
        product_element = None
        
        if extractor.product_info_extraction_mode == 'rag':
            rag_context += f"\n\n### í›„ë³´ ìƒí’ˆ ì´ë¦„ ëª©ë¡ ###\n\t{cand_item_list}"
            logger.info("RAG ëª¨ë“œ: í›„ë³´ ìƒí’ˆ ëª©ë¡ì„ RAG ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€")
        elif extractor.product_info_extraction_mode == 'llm':
            rag_context += f"\n\n### ì°¸ê³ ìš© í›„ë³´ ìƒí’ˆ ì´ë¦„ ëª©ë¡ ###\n\t{cand_item_list}"
            logger.info("LLM ëª¨ë“œ: ì°¸ê³ ìš© í›„ë³´ ìƒí’ˆ ëª©ë¡ì„ RAG ì»¨í…ìŠ¤íŠ¸ì— ì¶”ê°€")
        elif extractor.product_info_extraction_mode == 'nlp':
            product_element = self._prepare_nlp_product_element(extractor, extra_item_pdf)
        
        return rag_context, product_element
    
    def _prepare_nlp_product_element(self, extractor, extra_item_pdf):
        """NLP ëª¨ë“œ ì œí’ˆ ìš”ì†Œ ì¤€ë¹„"""
        if not extra_item_pdf.empty and 'item_nm' in extra_item_pdf.columns:
            product_df = extra_item_pdf.rename(columns={'item_nm': 'name'}).query(
                "not name in @extractor.stop_item_names"
            )[['name']]
            product_df['action'] = 'ê¸°íƒ€'
            product_element = product_df.to_dict(orient='records') if product_df.shape[0] > 0 else None
            logger.info(f"NLP ëª¨ë“œ: ì œí’ˆ ìš”ì†Œ ì¤€ë¹„ ì™„ë£Œ - {len(product_element) if product_element else 0}ê°œ")
            if product_element:
                logger.info(f"NLP ëª¨ë“œ ì œí’ˆ ìš”ì†Œ ìƒ˜í”Œ: {product_element[:2]}")
            return product_element
        else:
            logger.warning("NLP ëª¨ë“œ: extra_item_pdfê°€ ë¹„ì–´ìˆê±°ë‚˜ item_nm ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            return None
    
    def _log_no_candidates(self):
        """í›„ë³´ ì•„ì´í…œ ì—†ìŒ ê²½ê³ """
        logger.warning("í›„ë³´ ì•„ì´í…œì´ ì—†ìŠµë‹ˆë‹¤!")
        logger.warning("ì´ëŠ” ë‹¤ìŒ ì¤‘ í•˜ë‚˜ì˜ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        logger.warning("1. ìƒí’ˆ ë°ì´í„° ë¡œë”© ì‹¤íŒ¨")
        logger.warning("2. ì—”í‹°í‹° ì¶”ì¶œ ì‹¤íŒ¨")
        logger.warning("3. ìœ ì‚¬ë„ ë§¤ì¹­ ì„ê³„ê°’ ë¬¸ì œ")


class LLMExtractionStep(WorkflowStep):
    """
    LLM í˜¸ì¶œ ë° ì¶”ì¶œ ë‹¨ê³„
    
    - í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    - LLM í˜¸ì¶œ
    - í”„ë¡¬í”„íŠ¸ ì €ì¥ (ë””ë²„ê¹…ìš©)
    """
    
    def execute(self, state: WorkflowState) -> WorkflowState:
        if state.has_error():
            return state
        
        msg = state.get("msg")
        extractor = state.get("extractor")
        rag_context = state.get("rag_context")
        product_element = state.get("product_element")
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = extractor._build_extraction_prompt(msg, rag_context, product_element)
        logger.info(f"êµ¬ì„±ëœ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ë¬¸ì")
        logger.info(f"RAG ì»¨í…ìŠ¤íŠ¸ í¬í•¨ ì—¬ë¶€: {'í›„ë³´ ìƒí’ˆ' in rag_context}")
        
        # í”„ë¡¬í”„íŠ¸ ì €ì¥ (helpers ëª¨ë“ˆ ì‚¬ìš©)
        PromptManager.store_prompt_for_preview(prompt, "main_extraction")
        
        # LLM í˜¸ì¶œ
        result_json_text = extractor._safe_llm_invoke(prompt)
        logger.info(f"LLM ì‘ë‹µ ê¸¸ì´: {len(result_json_text)} ë¬¸ì")
        logger.info(f"LLM ì‘ë‹µ ë‚´ìš© (ì²˜ìŒ 500ì): {result_json_text[:500]}...")
        
        state.set("result_json_text", result_json_text)
        
        return state


class ResponseParsingStep(WorkflowStep):
    """
    LLM ì‘ë‹µ JSON íŒŒì‹± ë‹¨ê³„
    
    - JSON íŒŒì‹±
    - ìŠ¤í‚¤ë§ˆ ì‘ë‹µ ê°ì§€ (helpers ëª¨ë“ˆ ì‚¬ìš©)
    """
    
    def execute(self, state: WorkflowState) -> WorkflowState:
        if state.has_error():
            return state
        
        result_json_text = state.get("result_json_text")
        # extractor = state.get("extractor") # No longer needed for detect_schema_response
        # msg = state.get("msg") # No longer needed
        
        # JSON íŒŒì‹±
        json_objects_list = extract_json_objects(result_json_text)
        logger.info(f"ì¶”ì¶œëœ JSON ê°ì²´ ìˆ˜: {len(json_objects_list)}ê°œ")
        
        if not json_objects_list:
            logger.warning("LLMì´ ìœ íš¨í•œ JSON ê°ì²´ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            logger.warning(f"LLM ì›ë³¸ ì‘ë‹µ: {result_json_text}")
            state.add_error("JSON íŒŒì‹± ì‹¤íŒ¨")
            state.set("is_fallback", True)
            return state
        
        json_objects = json_objects_list[-1]
        logger.info(f"íŒŒì‹±ëœ JSON ê°ì²´ í‚¤: {list(json_objects.keys())}")
        logger.info(f"íŒŒì‹±ëœ JSON ë‚´ìš©: {json_objects}")
        
        # ìŠ¤í‚¤ë§ˆ ì‘ë‹µ ê°ì§€ (helpers ëª¨ë“ˆ ì‚¬ìš©)
        if detect_schema_response(json_objects):
            logger.error("ğŸš¨ LLMì´ ìŠ¤í‚¤ë§ˆ ì •ì˜ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤! ì‹¤ì œ ë°ì´í„°ê°€ ì•„ë‹™ë‹ˆë‹¤.")
            logger.error("ì¬ì‹œë„ ë˜ëŠ” fallback ê²°ê³¼ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
            state.add_error("ìŠ¤í‚¤ë§ˆ ì‘ë‹µ ê°ì§€")
            state.set("is_fallback", True)
            return state
        
        raw_result = copy.deepcopy(json_objects)
        
        state.set("json_objects", json_objects)
        state.set("raw_result", raw_result)
        
        return state


class ResultConstructionStep(WorkflowStep):
    """
    ìµœì¢… ê²°ê³¼ êµ¬ì„± ë‹¨ê³„
    
    - ì—”í‹°í‹° ë§¤ì¹­
    - ì±„ë„ ì¶”ì¶œ
    - í”„ë¡œê·¸ë¨ ë§¤í•‘
    """
    
    def __init__(self, result_builder):
        self.result_builder = result_builder

    def execute(self, state: WorkflowState) -> WorkflowState:
        if state.has_error():
            return state
        
        json_objects = state.get("json_objects")
        msg = state.get("msg")
        pgm_info = state.get("pgm_info")
        entities_from_kiwi = state.get("entities_from_kiwi")
        extractor = state.get("extractor")
        
        # ìµœì¢… ê²°ê³¼ êµ¬ì„±
        final_result = self.result_builder.build_final_result(json_objects, msg, pgm_info, entities_from_kiwi)
        
        state.set("final_result", final_result)
        
        return state


class ValidationStep(WorkflowStep):
    """
    ê²°ê³¼ ê²€ì¦ ë‹¨ê³„
    
    - ê²°ê³¼ ìœ íš¨ì„± ê²€ì¦ (helpers ëª¨ë“ˆ ì‚¬ìš©)
    - ìµœì¢… ê²°ê³¼ ìš”ì•½ ë¡œê¹…
    """
    
    def execute(self, state: WorkflowState) -> WorkflowState:
        if state.has_error():
            return state
        
        final_result = state.get("final_result")
        # extractor = state.get("extractor") # No longer needed for validate_extraction_result
        
        # ê²°ê³¼ ê²€ì¦ (helpers ëª¨ë“ˆ ì‚¬ìš©)
        validated_result = validate_extraction_result(final_result)
        
        # ìµœì¢… ê²°ê³¼ ìš”ì•½ ë¡œê¹…
        self._log_final_summary(validated_result)
        
        state.set("final_result", validated_result)
        
        return state
    
    def _log_final_summary(self, result: Dict[str, Any]):
        """ìµœì¢… ê²°ê³¼ ìš”ì•½ ë¡œê¹…"""
        logger.info("=== ìµœì¢… ê²°ê³¼ ìš”ì•½ ===")
        logger.info(f"ì œëª©: {result.get('title', 'N/A')}")
        logger.info(f"ëª©ì : {result.get('purpose', [])}")
        
        sales_script = result.get('sales_script', '')
        if sales_script:
            preview = sales_script[:100] + "..." if len(sales_script) > 100 else sales_script
            logger.info(f"íŒë§¤ ìŠ¤í¬ë¦½íŠ¸: {preview}")
        
        logger.info(f"ìƒí’ˆ ìˆ˜: {len(result.get('product', []))}ê°œ")
        logger.info(f"ì±„ë„ ìˆ˜: {len(result.get('channel', []))}ê°œ")
        logger.info(f"í”„ë¡œê·¸ë¨ ìˆ˜: {len(result.get('pgm', []))}ê°œ")
        
        offer_info = result.get('offer', {})
        logger.info(f"ì˜¤í¼ íƒ€ì…: {offer_info.get('type', 'N/A')}")
        logger.info(f"ì˜¤í¼ í•­ëª© ìˆ˜: {len(offer_info.get('value', []))}ê°œ")


class DAGExtractionStep(WorkflowStep):
    """
    DAG ì¶”ì¶œ ë‹¨ê³„ (ì„ íƒì )
    
    í˜„ì¬ëŠ” process_message_with_dagì—ì„œ ë³„ë„ë¡œ ì²˜ë¦¬ë¨
    í–¥í›„ workflowì— í†µí•© ê°€ëŠ¥
    """
    
    def execute(self, state: WorkflowState) -> WorkflowState:
        # DAG ì¶”ì¶œì€ process_message_with_dagì—ì„œ ë³„ë„ë¡œ ì²˜ë¦¬ë˜ë¯€ë¡œ
        # ì—¬ê¸°ì„œëŠ” ìŠ¤í‚µ
        # í•„ìš”ì‹œ ë‚˜ì¤‘ì— êµ¬í˜„ ê°€ëŠ¥
        return state
