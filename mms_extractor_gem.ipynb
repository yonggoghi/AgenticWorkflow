{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import configfrom concurrent.futures import ThreadPoolExecutorimport timefrom langchain_anthropic import ChatAnthropicfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_core.output_parsers import JsonOutputParserimport jsonimport refrom pygments import highlightfrom pygments.lexers import JsonLexerfrom pygments.formatters import HtmlFormatterfrom IPython.display import HTMLimport pandas as pd# from langchain.chat_models import ChatOpenAIfrom langchain_openai import ChatOpenAIfrom langchain_anthropic import ChatAnthropicfrom langchain.schema import AIMessage, HumanMessage, SystemMessagefrom openai import OpenAIfrom typing import List, Tuple, Union, Dict, Anyimport astfrom rapidfuzz import fuzz, processimport reimport jsonimport globimport ospd.set_option('display.max_colwidth', 500)llm_api_key = config.CUSTOM_API_KEY\"https://api.platform.a15t.com/v1\"client = OpenAI(    api_key = llm_api_key,    base_url = llm_api_url)# from langchain.chat_models import ChatOpenAIfrom langchain_openai import ChatOpenAIfrom langchain_anthropic import ChatAnthropicfrom langchain.schema import AIMessage, HumanMessage, SystemMessagedef ChatAnthropicSKT(model=\"skt/claude-3-7-sonnet-20250219\", max_tokens=4000):    llm_api_key = config.CUSTOM_API_KEY\"https://api.platform.a15t.com/v1\"        # llm_api_url = \"https://43.203.77.11:443/v1\"    # model = \"anthropic/claude-3-5-sonnet-20240620\"    model = ChatOpenAI(        temperature=0,          openai_api_key=llm_api_key,         openai_api_base=llm_api_url,         model=model,        max_tokens=max_tokens        )    return modelllm_cld37 = ChatAnthropicSKT()llm_gem3 = ChatAnthropicSKT(model='skt/gemma3-12b-it')# llm_ax = ChatAnthropicSKT(model='skt/a.x-3-lg')# llm_cld37 = ChatAnthropic(#     api_key=os.getenv(\"ANTHROPIC_API_KEY\"),#     model=\"claude-3-7-sonnet-20250219\",#     max_tokens=3000# )llm_chat = ChatOpenAI(        temperature=0,          model=\"gpt-4.1\",        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),        max_tokens=2000,)llm_cld40 = ChatAnthropic(    api_key=os.getenv(\"ANTHROPIC_API_KEY\"),    model=\"claude-sonnet-4-20250514\",    max_tokens=3000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import List, Tuple, Union, Dict, Any",
        "import ast",
        "",
        "import re",
        "import json",
        "import glob",
        "",
        "def dataframe_to_markdown_prompt(df, max_rows=None):",
        "    # Limit rows if needed",
        "    if max_rows is not None and len(df) > max_rows:",
        "        display_df = df.head(max_rows)",
        "        truncation_note = f\"\\n[Note: Only showing first {max_rows} of {len(df)} rows]\"",
        "    else:",
        "        display_df = df",
        "        truncation_note = \"\"",
        "    ",
        "    # Convert to markdown",
        "    df_markdown = display_df.to_markdown()",
        "    ",
        "    prompt = f\"\"\"",
        "",
        "    {df_markdown}",
        "    {truncation_note}",
        "",
        "    \"\"\"",
        "    ",
        "    return prompt",
        "",
        "def replace_strings(text, replacements):",
        "    for old, new in replacements.items():",
        "        text = text.replace(old, new)",
        "        ",
        "    return text",
        "",
        "def clean_segment(segment):",
        "    \"\"\"",
        "    Given a segment that is expected to be quoted (i.e. begins and ends with",
        "    the same single or double quote), remove any occurrences of that quote",
        "    from the inner content.",
        "    For example, if segment is:",
        "         \"에이닷 T 멤버십 쿠폰함에 \"에이닷은통화요약된닷\" 입력\"",
        "    then the outer quotes are preserved but the inner double quotes are removed.",
        "    \"\"\"",
        "    segment = segment.strip()",
        "    if len(segment) >= 2 and segment[0] in ['\"', \"'\"] and segment[-1] == segment[0]:",
        "        q = segment[0]",
        "        # Remove inner occurrences of the quote character.",
        "        inner = segment[1:-1].replace(q, '')",
        "        return q + inner + q",
        "    return segment",
        "",
        "def split_key_value(text):",
        "    \"\"\"",
        "    Splits text into key and value based on the first colon that appears",
        "    outside any quoted region.",
        "    If no colon is found outside quotes, the value will be returned empty.",
        "    \"\"\"",
        "    in_quote = False",
        "    quote_char = ''",
        "    for i, char in enumerate(text):",
        "        if char in ['\"', \"'\"]:",
        "            # Toggle quote state (assumes well-formed starting/ending quotes for each token)",
        "            if in_quote:",
        "                if char == quote_char:",
        "                    in_quote = False",
        "                    quote_char = ''",
        "            else:",
        "                in_quote = True",
        "                quote_char = char",
        "        elif char == ':' and not in_quote:",
        "            return text[:i], text[i+1:]",
        "    return text, ''",
        "",
        "def split_outside_quotes(text, delimiter=','):",
        "    \"\"\"",
        "    Splits the input text on the given delimiter (default comma) but only",
        "    if the delimiter occurs outside of quoted segments.",
        "    Returns a list of parts.",
        "    \"\"\"",
        "    parts = []",
        "    current = []",
        "    in_quote = False",
        "    quote_char = ''",
        "    for char in text:",
        "        if char in ['\"', \"'\"]:",
        "            # When encountering a quote, toggle our state",
        "            if in_quote:",
        "                if char == quote_char:",
        "                    in_quote = False",
        "                    quote_char = ''",
        "            else:",
        "                in_quote = True",
        "                quote_char = char",
        "            current.append(char)",
        "        elif char == delimiter and not in_quote:",
        "            parts.append(''.join(current).strip())",
        "            current = []",
        "        else:",
        "            current.append(char)",
        "    if current:",
        "        parts.append(''.join(current).strip())",
        "    return parts",
        "",
        "def clean_ill_structured_json(text):",
        "    \"\"\"",
        "    Given a string that is intended to represent a JSON-like structure",
        "    but may be ill-formed (for example, it might contain nested quotes that",
        "    break standard JSON rules), attempt to “clean” it by processing each",
        "    key–value pair.",
        "    ",
        "    The function uses the following heuristics:",
        "      1. Split the input text into comma-separated parts (only splitting",
        "         when the comma is not inside a quoted string).",
        "      2. For each part, split on the first colon (that is outside quotes) to separate key and value.",
        "      3. For any segment that begins and ends with a quote, remove any inner occurrences",
        "         of that same quote.",
        "      4. Rejoin the cleaned key and value.",
        "    ",
        "    Note: This approach does not build a fully robust JSON parser. For very complex",
        "          or deeply nested ill-structured inputs further refinement would be needed.",
        "    \"\"\"",
        "    # First, split the text by commas outside of quotes.",
        "    parts = split_outside_quotes(text, delimiter=',')",
        "    ",
        "    cleaned_parts = []",
        "    for part in parts:",
        "        # Try to split into key and value on the first colon not inside quotes.",
        "        key, value = split_key_value(part)",
        "        key_clean = clean_segment(key)",
        "        value_clean = clean_segment(value) if value.strip() != \"\" else \"\"",
        "        if value_clean:",
        "            cleaned_parts.append(f\"{key_clean}: {value_clean}\")",
        "        else:",
        "            cleaned_parts.append(key_clean)",
        "    ",
        "    # Rejoin the cleaned parts with commas (or you can use another format if desired)",
        "    return ', '.join(cleaned_parts)",
        "",
        "def repair_json(broken_json):",
        "    \"\"\"",
        "    More advanced JSON repair that handles edge cases better",
        "    \"\"\"",
        "    json_str = broken_json",
        "    ",
        "    # Fix unquoted keys",
        "    json_str = re.sub(r'([{,])\\s*([a-zA-Z0-9_]+)\\s*:', r'\\1 \"\\2\":', json_str)",
        "    ",
        "    # Fix unquoted values more carefully",
        "    # Split on quotes to avoid modifying content inside strings",
        "    parts = json_str.split('\"')",
        "    ",
        "    for i in range(0, len(parts), 2):  # Only process parts outside quotes (even indices)",
        "        # Fix unquoted values in this part",
        "        parts[i] = re.sub(r':\\s*([a-zA-Z0-9_]+)(?=\\s*[,\\]\\}])', r': \"\\1\"', parts[i])",
        "    ",
        "    json_str = '\"'.join(parts)",
        "    ",
        "    # Fix trailing commas",
        "    json_str = re.sub(r',\\s*([}\\]])', r'\\1', json_str)",
        "    ",
        "    return json_str",
        "",
        "def extract_json_objects(text):",
        "    # More sophisticated pattern that tries to match proper JSON syntax",
        "    pattern = r'(\\{(?:[^{}]|(?:\\{(?:[^{}]|(?:\\{[^{}]*\\}))*\\}))*\\})'",
        "    ",
        "    result = []",
        "    for match in re.finditer(pattern, text):",
        "        potential_json = match.group(0)",
        "        try:",
        "            # Try to parse and validate",
        "            # json_obj = json.loads(repair_json(potential_json))",
        "            json_obj = ast.literal_eval(clean_ill_structured_json(repair_json(potential_json)))",
        "            result.append(json_obj)",
        "        except json.JSONDecodeError:",
        "            # Not valid JSON, skip",
        "            pass",
        "    ",
        "    return result",
        "",
        "def extract_between(text, start_marker, end_marker):",
        "    start_index = text.find(start_marker)",
        "    if start_index == -1:",
        "        return None",
        "    ",
        "    start_index += len(start_marker)",
        "    end_index = text.find(end_marker, start_index)",
        "    if end_index == -1:",
        "        return None",
        "    ",
        "    return text[start_index:end_index]",
        "",
        "def extract_content(text: str, tag_name: str) -> List[str]:",
        "    pattern = f'<{tag_name}>(.*?)</{tag_name}>'",
        "    matches = re.findall(pattern, text, re.DOTALL)",
        "    return matches",
        "",
        "def clean_bad_text(text):",
        "    import re",
        "    ",
        "    if not isinstance(text, str):",
        "        return \"\"",
        "    ",
        "    # Remove URLs and emails",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)",
        "    text = re.sub(r'\\S+@\\S+', ' ', text)",
        "    ",
        "    # Keep Korean, alphanumeric, spaces, and specific punctuation",
        "    text = re.sub(r'[^\\uAC00-\\uD7A3\\u1100-\\u11FF\\w\\s\\.\\?!,]', ' ', text)",
        "    ",
        "    # Normalize whitespace",
        "    text = re.sub(r'\\s+', ' ', text).strip()",
        "    ",
        "    return text",
        "",
        "def clean_text(text):",
        "    \"\"\"",
        "    Cleans text by removing special characters that don't affect fine-tuning.",
        "    Preserves important structural elements like quotes, brackets, and JSON syntax.",
        "    Specifically handles Korean text (Hangul) properly.",
        "    ",
        "    Args:",
        "        text (str): The input text to clean",
        "        ",
        "    Returns:",
        "        str: Cleaned text ready for fine-tuning",
        "    \"\"\"",
        "    import re",
        "    ",
        "    # Preserve the basic structure by temporarily replacing important characters",
        "    # with placeholder tokens that won't be affected by cleanup",
        "    ",
        "    # Step 1: Temporarily replace JSON structural elements",
        "    placeholders = {",
        "        '\"': \"DQUOTE_TOKEN\",",
        "        \"'\": \"SQUOTE_TOKEN\",",
        "        \"{\": \"OCURLY_TOKEN\",",
        "        \"}\": \"CCURLY_TOKEN\",",
        "        \"[\": \"OSQUARE_TOKEN\",",
        "        \"]\": \"CSQUARE_TOKEN\",",
        "        \":\": \"COLON_TOKEN\",",
        "        \",\": \"COMMA_TOKEN\"",
        "    }",
        "    ",
        "    for char, placeholder in placeholders.items():",
        "        text = text.replace(char, placeholder)",
        "    ",
        "    # Step 2: Remove problematic characters",
        "    ",
        "    # Remove control characters (except newlines, carriage returns, and tabs which can be meaningful)",
        "    text = re.sub(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]', '', text)",
        "    ",
        "    # Normalize all types of newlines to \\n",
        "    text = re.sub(r'\\r\\n|\\r', '\\n', text)",
        "    ",
        "    # Remove zero-width characters and other invisible unicode",
        "    text = re.sub(r'[\\u200B-\\u200D\\uFEFF\\u00A0]', '', text)",
        "    ",
        "    # MODIFIED: Keep Korean characters (Hangul) along with other useful character sets",
        "    # This regex keeps:",
        "    # - ASCII (Basic Latin): \\x00-\\x7F",
        "    # - Latin-1 Supplement: \\u0080-\\u00FF",
        "    # - Latin Extended A & B: \\u0100-\\u017F\\u0180-\\u024F",
        "    # - Greek and Coptic: \\u0370-\\u03FF",
        "    # - Cyrillic: \\u0400-\\u04FF",
        "    # - Korean Hangul Syllables: \\uAC00-\\uD7A3",
        "    # - Hangul Jamo (Korean alphabet): \\u1100-\\u11FF",
        "    # - Hangul Jamo Extended-A: \\u3130-\\u318F",
        "    # - Hangul Jamo Extended-B: \\uA960-\\uA97F",
        "    # - Hangul Compatibility Jamo: \\u3130-\\u318F",
        "    # - CJK symbols and punctuation: \\u3000-\\u303F",
        "    # - Full-width forms (often used with CJK): \\uFF00-\\uFFEF",
        "    # - CJK Unified Ideographs (Basic common Chinese/Japanese characters): \\u4E00-\\u9FFF",
        "    ",
        "    # Instead of removing characters, we'll define which ones to keep",
        "    allowed_chars_pattern = r'[^\\x00-\\x7F\\u0080-\\u00FF\\u0100-\\u024F\\u0370-\\u03FF\\u0400-\\u04FF' + \\",
        "                           r'\\u1100-\\u11FF\\u3130-\\u318F\\uA960-\\uA97F\\u3000-\\u303F' + \\",
        "                           r'\\uAC00-\\uD7A3\\uFF00-\\uFFEF\\u4E00-\\u9FFF\\n\\r\\t ]'",
        "    text = re.sub(allowed_chars_pattern, '', text)",
        "    ",
        "    # Step 3: Normalize whitespace (but preserve deliberate line breaks)",
        "    text = re.sub(r'[ \\t]+', ' ', text)  # Convert multiple spaces/tabs to single space",
        "    ",
        "    # First ensure all newlines are standardized",
        "    text = re.sub(r'\\r\\n|\\r', '\\n', text)  # Convert all newline variants to \\n",
        "    ",
        "    # Then normalize multiple blank lines to at most two",
        "    text = re.sub(r'\\n\\s*\\n+', '\\n\\n', text)  # Convert multiple newlines to at most two",
        "    ",
        "    # Step 4: Restore original JSON structural elements",
        "    for char, placeholder in placeholders.items():",
        "        text = text.replace(placeholder, char)",
        "    ",
        "    # Step 5: Fix common JSON syntax issues that might remain",
        "    # Fix spaces between quotes and colons in JSON",
        "    text = re.sub(r'\"\\s+:', r'\":', text)",
        "    ",
        "    # Fix trailing commas in arrays",
        "    text = re.sub(r',\\s*]', r']', text)",
        "    ",
        "    # Fix trailing commas in objects",
        "    text = re.sub(r',\\s*}', r'}', text)",
        "    ",
        "    return text",
        "",
        "def remove_control_characters(text):",
        "    if isinstance(text, str):",
        "        # Remove control characters except commonly used whitespace",
        "        return re.sub(r'[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F\\x7F]', '', text)",
        "    return text",
        "",
        "import openai",
        "from langchain.chains import RetrievalQA",
        "from langchain.llms.openai import OpenAIChat  # For compatibility with newer setup",
        "",
        "# Create a custom LLM class that uses the OpenAI client directly",
        "class CustomOpenAI:",
        "    def __init__(self, model=\"skt/a.x-3-lg\"):",
        "        self.model = model",
        "        ",
        "    def __call__(self, prompt):",
        "        response = client.chat.completions.create(",
        "            model=self.model,",
        "            messages=[",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},",
        "                {\"role\": \"user\", \"content\": prompt}",
        "            ],",
        "            temperature=0.1",
        "        )",
        "        return response.choices[0].message.content",
        "",
        "# Create a simple retrieval function",
        "def get_relevant_context(query, vectorstore, topk=5):",
        "    docs = vectorstore.similarity_search(query, k=topk)",
        "    context = \"\\n\\n\".join([doc.page_content for doc in docs])",
        "    titles = \", \".join(set([doc.metadata['title'] for doc in docs if 'title' in doc.metadata.keys()]))",
        "    return {'title':titles, 'context':context}",
        "",
        "# Create a function to combine everything",
        "def answer_question(query, vectorstore):",
        "    # Get relevant context",
        "    context = get_relevant_context(query, vectorstore)",
        "    ",
        "    # Create combined prompt",
        "    prompt = f\"Answer the following question based on the provided context:\\n\\nContext: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"",
        "    ",
        "    # Use OpenAI directly",
        "    custom_llm = CustomOpenAI()  # Or your preferred model",
        "    response = custom_llm(prompt)",
        "    ",
        "    return response",
        "",
        "def is_list_of_dicts(var):",
        "    # Check if the variable is a list",
        "    if not isinstance(var, list):",
        "        return False",
        "    ",
        "    # Check if the list is not empty and all elements are dictionaries",
        "    if not var:  # Empty list",
        "        return False",
        "        ",
        "    # Check that all elements are dictionaries",
        "    return all(isinstance(item, dict) for item in var)",
        "",
        "def remove_duplicate_dicts(dict_list):",
        "    result = []",
        "    seen = set()",
        "    for d in dict_list:",
        "        # Convert dictionary to a hashable tuple of items",
        "        t = tuple(sorted(d.items()))",
        "        if t not in seen:",
        "            seen.add(t)",
        "            result.append(d)",
        "    return result",
        "",
        "def convert_to_custom_format(json_items):",
        "    custom_format = []",
        "    ",
        "    for item in json_items:",
        "        item_name = item.get(\"item_name_in_message\", \"\")",
        "        item_id = item.get(\"item_id\", \"\")",
        "        category = item.get(\"category\", \"\")",
        "        ",
        "        # Create custom format for each item",
        "        custom_line = f\"[Item Name] {item_name} [Item ID] {item_id} [Item Category] {category}\"",
        "        custom_format.append(custom_line)",
        "    ",
        "    return \"\\n\".join(custom_format)",
        "",
        "def remove_urls(text):",
        "    # Regular expression pattern to match URLs",
        "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')",
        "    ",
        "    # Replace URLs with an empty string",
        "    return url_pattern.sub('', text)",
        "",
        "def remove_custom_pattern(text, keyword=\"바로가기\"):",
        "    # Create a pattern that matches any text followed by the specified keyword",
        "    # We escape the keyword to handle any special regex characters it might contain",
        "    escaped_keyword = re.escape(keyword)",
        "    pattern = re.compile(r'.*? ' + escaped_keyword)",
        "    ",
        "    # Replace the matched pattern with an empty string",
        "    return pattern.sub('', text)",
        "",
        "def select_most_comprehensive(strings):",
        "    \"\"\"",
        "    Select the most comprehensive string from a list of overlapping strings.",
        "    Returns the longest string that contains other strings as substrings.",
        "    ",
        "    Args:",
        "        strings: List of strings to filter",
        "        ",
        "    Returns:",
        "        List of most comprehensive strings (usually one, but could be multiple if no containment)",
        "    \"\"\"",
        "    if not strings:",
        "        return []",
        "    ",
        "    # Remove duplicates and sort by length (longest first)",
        "    unique_strings = list(set(strings))",
        "    unique_strings.sort(key=len, reverse=True)",
        "    ",
        "    result = []",
        "    ",
        "    for current in unique_strings:",
        "        # Check if current string contains any of the strings already in result",
        "        is_contained = any(current in existing for existing in result)",
        "        ",
        "        # Check if current string contains other strings not yet in result",
        "        contains_others = any(other in current for other in unique_strings if other != current and other not in result)",
        "        ",
        "        # If current is not contained by existing results and either:",
        "        # 1. It contains other strings, or ",
        "        # 2. No strings contain each other (keep all unique)",
        "        if not is_contained:",
        "            # Remove any strings from result that are contained in current",
        "            result = [r for r in result if r not in current]",
        "            result.append(current)",
        "    ",
        "    return result",
        "",
        "def replace_special_chars_comprehensive(text):",
        "    \"\"\"",
        "    More comprehensive: Handle various types of special characters.",
        "    \"\"\"",
        "    # Replace common punctuation with space",
        "    punctuation_pattern = r'[!@#$%^&*()_+\\-=\\[\\]{};\\':\"\\\\|,.<>?/~`]'",
        "    text = re.sub(punctuation_pattern, ' ', text)",
        "    ",
        "    # Replace other special symbols",
        "    symbol_pattern = r'[₩＄￦※◆▲▼◀▶★☆♪♫♬♩♭♯]'",
        "    text = re.sub(symbol_pattern, ' ', text)",
        "    ",
        "    # Replace various dashes and quotes",
        "    dash_quote_pattern = r'[—–‒―\"\"''‚„‹›«»]'",
        "    text = re.sub(dash_quote_pattern, ' ', text)",
        "    ",
        "    # Clean up multiple spaces",
        "    text = re.sub(r'\\s+', ' ', text).strip()",
        "    ",
        "    return text",
        "",
        "def preprocess_text(text):",
        "    # 특수문자를 공백으로 변환",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)",
        "    # 여러 공백을 하나로 통일",
        "    text = re.sub(r'\\s+', ' ', text)",
        "    # 앞뒤 공백 제거",
        "    return text.strip()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from difflib import SequenceMatcher\n",
        "def advanced_sequential_similarity(str1, str2, metrics=None, visualize=False):\n",
        "    \"\"\"\n",
        "    Calculate multiple character-level similarity metrics between two strings.\n",
        "    Parameters:\n",
        "    -----------\n",
        "    str1 : str\n",
        "        First string\n",
        "    str2 : str\n",
        "        Second string\n",
        "    metrics : list\n",
        "        List of metrics to compute. Options:\n",
        "        ['ngram', 'lcs', 'subsequence', 'difflib']\n",
        "        If None, all metrics will be computed\n",
        "    visualize : bool\n",
        "        If True, visualize the differences between strings\n",
        "    Returns:\n",
        "    --------\n",
        "    dict\n",
        "        Dictionary containing similarity scores for each metric\n",
        "    \"\"\"\n",
        "    if metrics is None:\n",
        "        metrics = ['ngram', 'lcs', 'subsequence', 'difflib']\n",
        "    results = {}\n",
        "    # Handle empty strings\n",
        "    if not str1 or not str2:\n",
        "        return {metric: 0.0 for metric in metrics+['overall']}\n",
        "    # Prepare strings\n",
        "    s1, s2 = str1.lower(), str2.lower()\n",
        "    # 1. N-gram similarity (with multiple window sizes)\n",
        "    if 'ngram' in metrics:\n",
        "        ngram_scores = {}\n",
        "        for window in range(min([len(s1),len(s2),2]), min([5,max([len(s1),len(s2)])+1])):\n",
        "            # Skip if strings are shorter than window\n",
        "            if len(s1) < window or len(s2) < window:\n",
        "                ngram_scores[f'window_{window}'] = 0.0\n",
        "                continue\n",
        "            # Generate character n-grams\n",
        "            ngrams1 = [s1[i:i+window] for i in range(len(s1) - window + 1)]\n",
        "            ngrams2 = [s2[i:i+window] for i in range(len(s2) - window + 1)]\n",
        "            # Count matches\n",
        "            matches = sum(1 for ng in ngrams1 if ng in ngrams2)\n",
        "            max_possible = max(len(ngrams1), len(ngrams2))\n",
        "            # Normalize\n",
        "            score = matches / max_possible if max_possible > 0 else 0.0\n",
        "            ngram_scores[f'window_{window}'] = score\n",
        "        # Average of all n-gram scores\n",
        "        results['ngram'] = max(ngram_scores.values())#sum(ngram_scores.values()) / len(ngram_scores)\n",
        "        results['ngram_details'] = ngram_scores\n",
        "    # 2. Longest Common Substring (LCS)\n",
        "    if 'lcs' in metrics:\n",
        "        def longest_common_substring(s1, s2):\n",
        "            # Dynamic programming approach\n",
        "            m, n = len(s1), len(s2)\n",
        "            dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "            max_length = 0\n",
        "            for i in range(1, m + 1):\n",
        "                for j in range(1, n + 1):\n",
        "                    if s1[i-1] == s2[j-1]:\n",
        "                        dp[i][j] = dp[i-1][j-1] + 1\n",
        "                        max_length = max(max_length, dp[i][j])\n",
        "            return max_length\n",
        "        lcs_length = longest_common_substring(s1, s2)\n",
        "        max_length = max(len(s1), len(s2))\n",
        "        results['lcs'] = lcs_length / max_length if max_length > 0 else 0.0\n",
        "    # 3. Longest Common Subsequence\n",
        "    if 'subsequence' in metrics:\n",
        "        def longest_common_subsequence(s1, s2):\n",
        "            # Dynamic programming approach for subsequence\n",
        "            m, n = len(s1), len(s2)\n",
        "            dp = [[0] * (n + 1) for _ in range(m + 1)]\n",
        "            for i in range(1, m + 1):\n",
        "                for j in range(1, n + 1):\n",
        "                    if s1[i-1] == s2[j-1]:\n",
        "                        dp[i][j] = dp[i-1][j-1] + 1\n",
        "                    else:\n",
        "                        dp[i][j] = max(dp[i-1][j], dp[i][j-1])\n",
        "            return dp[m][n]\n",
        "        subseq_length = longest_common_subsequence(s1, s2)\n",
        "        max_length = max(len(s1), len(s2))\n",
        "        results['subsequence'] = subseq_length / max_length if max_length > 0 else 0.0\n",
        "    # 4. SequenceMatcher from difflib\n",
        "    if 'difflib' in metrics:\n",
        "        sm = SequenceMatcher(None, s1, s2)\n",
        "        results['difflib'] = sm.ratio()\n",
        "    # Visualization of differences\n",
        "    if visualize:\n",
        "        try:\n",
        "            # Only works in notebooks or environments that support plotting\n",
        "            sm = SequenceMatcher(None, s1, s2)\n",
        "            matches = sm.get_matching_blocks()\n",
        "            # Prepare for visualization\n",
        "            fig, ax = plt.subplots(figsize=(10, 3))\n",
        "            # Draw strings as horizontal bars\n",
        "            ax.barh(0, len(s1), height=0.4, left=0, color='lightgray', alpha=0.3)\n",
        "            ax.barh(1, len(s2), height=0.4, left=0, color='lightgray', alpha=0.3)\n",
        "            # Draw matching parts\n",
        "            for match in matches:\n",
        "                i, j, size = match\n",
        "                if size > 0:  # Ignore zero-length matches\n",
        "                    ax.barh(0, size, height=0.4, left=i, color='green', alpha=0.5)\n",
        "                    ax.barh(1, size, height=0.4, left=j, color='green', alpha=0.5)\n",
        "                    # Draw connection lines between matches\n",
        "                    ax.plot([i + size/2, j + size/2], [0.2, 0.8], 'k-', alpha=0.3)\n",
        "            # Add string texts\n",
        "            for i, c in enumerate(s1):\n",
        "                ax.text(i + 0.5, 0, c, ha='center', va='center')\n",
        "            for i, c in enumerate(s2):\n",
        "                ax.text(i + 0.5, 1, c, ha='center', va='center')\n",
        "            ax.set_yticks([0, 1])\n",
        "            ax.set_yticklabels(['String 1', 'String 2'])\n",
        "            ax.set_xlabel('Character Position')\n",
        "            ax.set_title('Character-Level String Comparison')\n",
        "            ax.grid(False)\n",
        "            plt.tight_layout()\n",
        "            # plt.show()  # Uncomment to display\n",
        "        except Exception as e:\n",
        "            print(f\"Visualization error: {e}\")\n",
        "    # Calculate overall similarity score (average of all metrics)\n",
        "    metrics_to_average = [m for m in results.keys() if not m.endswith('_details')]\n",
        "    results['overall'] = sum(results[m] for m in metrics_to_average) / len(metrics_to_average)\n",
        "    return results\n",
        "# advanced_sequential_similarity('시크릿', '시크릿', metrics='ngram')\n",
        "# advanced_sequential_similarity('에이닷_자사', '에이닷')['overall']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import difflib",
        "from difflib import SequenceMatcher",
        "import re",
        "",
        "def longest_common_subsequence_ratio(s1, s2, normalizaton_value):",
        "    \"\"\"",
        "    Calculate similarity based on longest common subsequence (LCS).",
        "    Preserves order and gives high scores for substring relationships.",
        "    \"\"\"",
        "    def lcs_length(x, y):",
        "        m, n = len(x), len(y)",
        "        dp = [[0] * (n + 1) for _ in range(m + 1)]",
        "        ",
        "        for i in range(1, m + 1):",
        "            for j in range(1, n + 1):",
        "                if x[i-1] == y[j-1]:",
        "                    dp[i][j] = dp[i-1][j-1] + 1",
        "                else:",
        "                    dp[i][j] = max(dp[i-1][j], dp[i][j-1])",
        "        ",
        "        return dp[m][n]",
        "    ",
        "    lcs_len = lcs_length(s1, s2)",
        "    if normalizaton_value == 'max':",
        "        max_len = max(len(s1), len(s2))",
        "        return lcs_len / max_len if max_len > 0 else 1.0",
        "    elif normalizaton_value == 'min':",
        "        min_len = min(len(s1), len(s2))",
        "        return lcs_len / min_len if min_len > 0 else 1.0",
        "    elif normalizaton_value == 's1':",
        "        return lcs_len / len(s1) if len(s1) > 0 else 1.0",
        "    elif normalizaton_value == 's2':",
        "        return lcs_len / len(s2) if len(s2) > 0 else 1.0",
        "    else:",
        "        raise ValueError(f\"Invalid normalization value: {normalizaton_value}\")",
        "",
        "# def sequence_matcher_similarity(s1, s2):",
        "#     \"\"\"",
        "#     Use Python's built-in SequenceMatcher which considers sequence order.",
        "#     \"\"\"",
        "#     return SequenceMatcher(None, s1, s2).ratio()",
        "",
        "def sequence_matcher_similarity(s1, s2, normalizaton_value):",
        "    \"\"\"Normalize by minimum length (favors shorter strings)\"\"\"",
        "    matcher = difflib.SequenceMatcher(None, s1, s2)",
        "    matches = sum(triple.size for triple in matcher.get_matching_blocks())",
        "",
        "    normalization_length = min(len(s1), len(s2))",
        "    if normalizaton_value == 'max':",
        "        normalization_length = max(len(s1), len(s2))",
        "    elif normalizaton_value == 's1':",
        "        normalization_length = len(s1)",
        "    elif normalizaton_value == 's2':",
        "        normalization_length = len(s2)",
        "        ",
        "    if normalization_length == 0: ",
        "        return 0.0",
        "    ",
        "    return matches / normalization_length",
        "",
        "def substring_aware_similarity(s1, s2, normalizaton_value):",
        "    \"\"\"",
        "    Custom similarity that heavily weights substring relationships",
        "    while considering sequence order.",
        "    \"\"\"",
        "    # Check if one is a substring of the other",
        "    if s1 in s2 or s2 in s1:",
        "        shorter = min(s1, s2, key=len)",
        "        longer = max(s1, s2, key=len)",
        "        # High base score for substring relationship",
        "        base_score = len(shorter) / len(longer)",
        "        # Bonus for exact substring match",
        "        return min(0.95 + base_score * 0.05, 1.0)",
        "    ",
        "    # Use LCS ratio for non-substring cases",
        "    return longest_common_subsequence_ratio(s1, s2, normalizaton_value)",
        "",
        "def token_sequence_similarity(s1, s2, normalizaton_value, separator_pattern=r'[\\s_\\-]+'):",
        "    \"\"\"",
        "    Tokenize strings and calculate similarity based on token sequence overlap.",
        "    Good for product names with separators.",
        "    \"\"\"",
        "    tokens1 = re.split(separator_pattern, s1.strip())",
        "    tokens2 = re.split(separator_pattern, s2.strip())",
        "    ",
        "    # Remove empty tokens",
        "    tokens1 = [t for t in tokens1 if t]",
        "    tokens2 = [t for t in tokens2 if t]",
        "    ",
        "    if not tokens1 or not tokens2:",
        "        return 0.0",
        "    ",
        "    # Find longest common subsequence of tokens",
        "    def token_lcs_length(t1, t2):",
        "        m, n = len(t1), len(t2)",
        "        dp = [[0] * (n + 1) for _ in range(m + 1)]",
        "        ",
        "        for i in range(1, m + 1):",
        "            for j in range(1, n + 1):",
        "                if t1[i-1] == t2[j-1]:",
        "                    dp[i][j] = dp[i-1][j-1] + 1",
        "                else:",
        "                    dp[i][j] = max(dp[i-1][j], dp[i][j-1])",
        "        ",
        "        return dp[m][n]",
        "    ",
        "    lcs_tokens = token_lcs_length(tokens1, tokens2)",
        "    normalization_tokens = max(len(tokens1), len(tokens2))",
        "    if normalizaton_value == 'min':",
        "        normalization_tokens = min(len(tokens1), len(tokens2))",
        "    elif normalizaton_value == 's1':",
        "        normalization_tokens = len(tokens1)",
        "    elif normalizaton_value == 's2':",
        "        normalization_tokens = len(tokens2)",
        "    ",
        "    # print(normalizaton_value, normalization_tokens, lcs_tokens)",
        "        ",
        "    return lcs_tokens / normalization_tokens  ",
        "",
        "def combined_sequence_similarity(s1, s2, weights=None, normalizaton_value='max'):",
        "    \"\"\"",
        "    Combine multiple sequence-aware similarity measures.",
        "    \"\"\"",
        "    if weights is None:",
        "        weights = {",
        "            'substring': 0.4,",
        "            'sequence_matcher': 0.4,",
        "            'token_sequence': 0.2",
        "        }",
        "    ",
        "    similarities = {",
        "        'substring': substring_aware_similarity(s1, s2, normalizaton_value),",
        "        'sequence_matcher': sequence_matcher_similarity(s1, s2, normalizaton_value),",
        "        'token_sequence': token_sequence_similarity(s1, s2, normalizaton_value)",
        "    }",
        "    ",
        "    combined = sum(similarities[key] * weights[key] for key in weights)",
        "    return combined, similarities",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "from joblib import Parallel, delayed",
        "",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"true\"",
        "",
        "def fuzzy_similarities(text, entities):",
        "    results = []",
        "    for entity in entities:",
        "        scores = {",
        "            'ratio': fuzz.ratio(text, entity) / 100,",
        "            'partial_ratio': fuzz.partial_ratio(text, entity) / 100,",
        "            'token_sort_ratio': fuzz.token_sort_ratio(text, entity) / 100,",
        "            'token_set_ratio': fuzz.token_set_ratio(text, entity) / 100",
        "        }",
        "        max_score = max(scores.values())",
        "        results.append((entity, max_score))",
        "    return results",
        "",
        "def get_fuzzy_similarities(args_dict):",
        "    text = args_dict['text']",
        "    entities = args_dict['entities']",
        "    threshold = args_dict['threshold']",
        "    text_col_nm = args_dict['text_col_nm']",
        "    item_col_nm = args_dict['item_col_nm']",
        "",
        "    # Get similarities using auto method selection",
        "    text_processed = preprocess_text(text.lower())",
        "    similarities = fuzzy_similarities(text_processed, entities)",
        "    ",
        "    # Filter by threshold and create DataFrame",
        "    filtered_results = [",
        "        {",
        "            text_col_nm: text,",
        "            item_col_nm: entity, ",
        "            \"sim\": score",
        "        } ",
        "        for entity, score in similarities ",
        "        if score >= threshold",
        "    ]",
        "    ",
        "    return filtered_results",
        "",
        "def parallel_fuzzy_similarity(texts, entities, threshold=0.5, text_col_nm='sent', item_col_nm='item_nm_alias', n_jobs=None, batch_size=None):",
        "    \"\"\"",
        "    Batched version for better performance with large datasets.",
        "    \"\"\"",
        "    if n_jobs is None:",
        "        n_jobs = min(os.cpu_count()-1, 8)  # Limit to 8 jobs max",
        "",
        "    if batch_size is None:",
        "        batch_size = max(1, len(entities) // (n_jobs * 2))",
        "        ",
        "    # Create batches",
        "    batches = []",
        "    for text in texts:",
        "        for i in range(0, len(entities), batch_size):",
        "            batch = entities[i:i + batch_size]",
        "            batches.append({\"text\": text, \"entities\": batch, \"threshold\": threshold, \"text_col_nm\": text_col_nm, \"item_col_nm\": item_col_nm})",
        "    ",
        "    # print(f\"Processing {len(item_list)} items in {len(batches)|} batches with {n_jobs} jobs...\")",
        "    ",
        "    # Run parallel jobs",
        "    with Parallel(n_jobs=n_jobs) as parallel:",
        "        batch_results = parallel(delayed(get_fuzzy_similarities)(args) for args in batches)",
        "    ",
        "    # # Flatten results",
        "    # similarities = []",
        "    # for batch_result in batch_results:",
        "    #     similarities.extend(batch_result)",
        "    ",
        "    return pd.DataFrame(sum(batch_results, []))",
        "",
        "def calculate_seq_similarity(args_dict):",
        "    \"\"\"",
        "    Process a batch of items in one job for better efficiency.",
        "    \"\"\"",
        "    sent_item_batch = args_dict['sent_item_batch']",
        "    text_col_nm = args_dict['text_col_nm']",
        "    item_col_nm = args_dict['item_col_nm']",
        "    normalizaton_value = args_dict['normalizaton_value']",
        "    ",
        "    results = []",
        "    for sent_item in sent_item_batch:",
        "        sent = sent_item[text_col_nm]",
        "        item = sent_item[item_col_nm]",
        "        try:",
        "            sent_processed = preprocess_text(sent.lower())",
        "            item_processed = preprocess_text(item.lower())",
        "            similarity = combined_sequence_similarity(sent_processed, item_processed, normalizaton_value=normalizaton_value)[0]",
        "            results.append({text_col_nm:sent, item_col_nm:item, \"sim\":similarity})",
        "        except Exception as e:",
        "            print(f\"Error processing {item}: {e}\")",
        "            results.append({text_col_nm:sent, item_col_nm:item, \"sim\":0.0})",
        "    ",
        "    return results",
        "",
        "def parallel_seq_similarity(sent_item_pdf, text_col_nm='sent', item_col_nm='item_nm_alias', n_jobs=None, batch_size=None, normalizaton_value='s2'):",
        "    \"\"\"",
        "    Batched version for better performance with large datasets.",
        "    \"\"\"",
        "    if n_jobs is None:",
        "        n_jobs = min(os.cpu_count()-1, 8)  # Limit to 8 jobs max",
        "",
        "    if batch_size is None:",
        "        batch_size = max(1, sent_item_pdf.shape[0] // (n_jobs * 2))",
        "        ",
        "    # Create batches",
        "    batches = []",
        "    for i in range(0, sent_item_pdf.shape[0], batch_size):",
        "        batch = sent_item_pdf.iloc[i:i + batch_size].to_dict(orient='records')",
        "        batches.append({\"sent_item_batch\": batch, 'text_col_nm': text_col_nm, 'item_col_nm': item_col_nm, 'normalizaton_value': normalizaton_value})",
        "    ",
        "    # print(f\"Processing {len(item_list)} items in {len(batches)|} batches with {n_jobs} jobs...\")",
        "    ",
        "    # Run parallel jobs",
        "    with Parallel(n_jobs=n_jobs) as parallel:",
        "        batch_results = parallel(delayed(calculate_seq_similarity)(args) for args in batches)",
        "    ",
        "    # Flatten results",
        "    # similarities = []",
        "    # for batch_result in batch_results:",
        "    #     similarities.extend(batch_result)",
        "    ",
        "    return pd.DataFrame(sum(batch_results, []))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from datetime import datetime\n",
        "def save_embeddings_numpy(embeddings, texts, filename):\n",
        "    \"\"\"\n",
        "    Save embeddings as NumPy arrays (.npz format).\n",
        "    Most common and efficient method.\n",
        "    \"\"\"\n",
        "    if torch.is_tensor(embeddings):\n",
        "        embeddings = embeddings.cpu().numpy()\n",
        "    np.savez_compressed(\n",
        "        filename,\n",
        "        embeddings=embeddings,\n",
        "        texts=texts,\n",
        "        timestamp=str(datetime.now())\n",
        "    )\n",
        "    print(f\"✅ Saved embeddings to {filename}\")\n",
        "def load_embeddings_numpy(filename):\n",
        "    \"\"\"Load embeddings from NumPy .npz file.\"\"\"\n",
        "    data = np.load(filename, allow_pickle=True)\n",
        "    embeddings = data['embeddings']\n",
        "    texts = data['texts']\n",
        "    timestamp = data['timestamp'] if 'timestamp' in data else None\n",
        "    print(f\"✅ Loaded {len(embeddings)} embeddings from {filename}\")\n",
        "    if timestamp:\n",
        "        print(f\"   Created: {timestamp}\")\n",
        "    return embeddings, texts\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading jhgan/ko-sbert-nli...\n",
            "Model saved to ./models/ko-sbert-nli\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import torch\n",
        "def save_sentence_transformer(model_name, save_path):\n",
        "    \"\"\"Download and save SentenceTransformer model locally\"\"\"\n",
        "    print(f\"Downloading {model_name}...\")\n",
        "    model = SentenceTransformer(model_name)\n",
        "    # Create directory if it doesn't exist\n",
        "    os.makedirs(save_path, exist_ok=True)\n",
        "    # Save the model\n",
        "    model.save(save_path)\n",
        "    print(f\"Model saved to {save_path}\")\n",
        "    return model\n",
        "def load_sentence_transformer(model_path, device=None):\n",
        "    \"\"\"Load SentenceTransformer model from local path\"\"\"\n",
        "    if device is None:\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"Loading model from {model_path}...\")\n",
        "    model = SentenceTransformer(model_path).to(device)\n",
        "    print(f\"Model loaded on {device}\")\n",
        "    return model\n",
        "# Usage\n",
        "# Save model (do this once)\n",
        "model = save_sentence_transformer('jhgan/ko-sbert-nli', './models/ko-sbert-nli')\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.2.2\n",
            "MPS available: True\n",
            "MPS built: True\n",
            "✅ MPS is available and ready to use!\n",
            "Loading model from ./models/ko-sbert-nli...\n",
            "Model loaded on mps\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer",
        "",
        "def check_mps_availability():",
        "    \"\"\"Check if MPS is available on this Mac.\"\"\"",
        "    print(f\"PyTorch version: {torch.__version__}\")",
        "    print(f\"MPS available: {torch.backends.mps.is_available()}\")",
        "    print(f\"MPS built: {torch.backends.mps.is_built()}\")",
        "    ",
        "    if torch.backends.mps.is_available():",
        "        print(\"✅ MPS is available and ready to use!\")",
        "        return True",
        "    else:",
        "        print(\"❌ MPS is not available. Using CPU instead.\")",
        "        return False",
        "",
        "mps_available = check_mps_availability()",
        "    ",
        "# Determine device",
        "if mps_available:",
        "    device = \"mps\"",
        "elif torch.cuda.is_available():",
        "    device = \"cuda\"",
        "else:",
        "    device = \"cpu\"",
        "",
        "# emb_model = SentenceTransformer('jhgan/ko-sbert-nli').to(device)",
        "emb_model = load_sentence_transformer('./models/ko-sbert-nli', device)",
        "# emb_model = SentenceTransformer('jhgan/ko-sroberta-multitask').to(device)",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "",
        "item_pdf_raw = pd.read_csv(\"./data/item_info_all_250527.csv\")",
        "",
        "item_pdf_all = item_pdf_raw.drop_duplicates(['item_nm','item_id'])[['item_nm','item_id','item_desc','domain','start_dt','end_dt','rank']].copy()",
        "",
        "# item_pdf_all.query(\"rank<1000\")[['item_nm']].drop_duplicates().to_csv(\"./data/item_nm_1000.csv\", index=False)",
        "alias_pdf = pd.read_csv(\"./data/alias_rules.csv\")",
        "alia_rule_set = list(zip(alias_pdf['alias_1'], alias_pdf['alias_2']))",
        "",
        "def apply_alias_rule(item_nm):",
        "    item_nm_list = [item_nm]",
        "",
        "    for r in alia_rule_set:",
        "        if r[0] in item_nm:",
        "            item_nm_list.append(item_nm.replace(r[0], r[1]))",
        "        if r[1] in item_nm:",
        "            item_nm_list.append(item_nm.replace(r[1], r[0]))",
        "    return item_nm_list",
        "",
        "item_pdf_all['item_nm_alias'] = item_pdf_all['item_nm'].apply(apply_alias_rule)",
        "",
        "item_pdf_all = item_pdf_all.explode('item_nm_alias')",
        "",
        "item_pdf_all.query(\"rank<1000 and item_nm.str.contains('넷플릭스', case=False) or item_nm.str.contains('웨이브', case=False)\")[['item_nm','item_nm_alias','item_id']]",
        "",
        "user_defined_entity = ['AIA Vitality' , '부스트 파크 건대입구' , 'Boost Park 건대입구']",
        "item_pdf_ext = pd.DataFrame([{'item_nm':e,'item_id':e,'item_desc':e, 'domain':'user_defined', 'start_dt':20250101, 'end_dt':99991231, 'rank':1, 'item_nm_alias':e} for e in user_defined_entity])",
        "item_pdf_all = pd.concat([item_pdf_all,item_pdf_ext])",
        "",
        "stop_item_names = pd.read_csv(\"./data/stop_words.csv\")['stop_words'].to_list()",
        "",
        "entity_vocab = []",
        "for row in item_pdf_all.to_dict('records'):",
        "    if row['item_nm_alias'] in stop_item_names:",
        "        continue",
        "    entity_vocab.append((row['item_nm_alias'], {'item_nm':row['item_nm'], 'item_id':row['item_id'], 'description':row['item_desc'], 'domain':row['domain'],'item_nm_alias':row['item_nm_alias']}))",
        "",
        "entity_list_for_fuzzy = []",
        "for row in item_pdf_all.to_dict('records'):",
        "    entity_list_for_fuzzy.append((row['item_nm_alias'], {'item_nm':row['item_nm'], 'item_id':row['item_id'], 'description':row['item_desc'], 'domain':row['domain'], 'start_dt':row['start_dt'], 'end_dt':row['end_dt'], 'rank':1, 'item_nm_alias':row['item_nm_alias']}))",
        "",
        "# text_list_item = [preprocess_text(x).lower() for x in item_pdf_all['item_nm_alias'].tolist()]",
        "# item_embeddings = emb_model.encode(text_list_item",
        "#                             # ,batch_size=64  # Optimal for MPS",
        "#                             ,convert_to_tensor=True",
        "#                             ,show_progress_bar=True)",
        "",
        "# save_embeddings_numpy(item_embeddings, text_list_item, './data/item_embeddings_250527.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "mms_pdf = pd.read_csv(\"./data/mms_data_250408.csv\")\n",
        "mms_pdf['msg'] = mms_pdf['msg_nm']+\"\\n\"+mms_pdf['mms_phrs']\n",
        "mms_pdf = mms_pdf.groupby([\"msg_nm\",\"mms_phrs\",\"msg\"])['offer_dt'].min().reset_index(name=\"offer_dt\")\n",
        "mms_pdf = mms_pdf.reset_index()\n",
        "mms_pdf = mms_pdf.astype('str')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab38e09876bc4cda9790ae860f19e923",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "import re\n",
        "num_cand_pgms = 5\n",
        "pgm_pdf = pd.read_csv(\"./data/pgm_tag_ext_250516.csv\")\n",
        "clue_embeddings = emb_model.encode(pgm_pdf[[\"pgm_nm\",\"clue_tag\"]].apply(lambda x: preprocess_text(x['pgm_nm'].lower())+\" \"+x['clue_tag'].lower(), axis=1).tolist()\n",
        "                            # ,batch_size=64  # Optimal for MPS\n",
        "                            ,convert_to_tensor=True\n",
        "                            ,show_progress_bar=True)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "org_pdf = pd.read_csv(\"./data/org_info_all_250605.csv\", encoding='cp949')\n",
        "org_pdf['sub_org_cd'] = org_pdf['sub_org_cd'].apply(lambda x: x.zfill(4))\n",
        "# text_list_org_all = org_pdf[[\"org_abbr_nm\",\"bas_addr\",\"dtl_addr\"]].apply(lambda x: preprocess_text(x['org_abbr_nm'].lower())+\" \"+x['bas_addr'].lower()+\" \"+x['dtl_addr'].lower(), axis=1).tolist()\n",
        "# org_all_embeddings = emb_model.encode(text_list_org_all\n",
        "#                     # ,batch_size=32  # Optimal for MPS\n",
        "#                     ,convert_to_tensor=True\n",
        "#                     ,show_progress_bar=True)\n",
        "# save_embeddings_numpy(org_all_embeddings, text_list_org_all, './data/org_all_embeddings_250605.npz')\n",
        "# text_list_org_nm = org_pdf[[\"org_abbr_nm\"]].apply(lambda x: preprocess_text(x['org_abbr_nm'].lower()), axis=1).tolist()\n",
        "# org_nm_embeddings = emb_model.encode(text_list_org_nm\n",
        "#                     # ,batch_size=32  # Optimal for MPS\n",
        "#                     ,convert_to_tensor=True\n",
        "#                     ,show_progress_bar=True)\n",
        "# save_embeddings_numpy(org_nm_embeddings, text_list_org_nm, './data/org_nm_embeddings_250605.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# item_embeddings, text_list_item = load_embeddings_numpy('./data/item_embeddings_250527.npz')\n",
        "# org_all_embeddings, text_list_org_all = load_embeddings_numpy('./data/org_all_embeddings_250605.npz')\n",
        "# org_nm_embeddings, text_list_org_nm = load_embeddings_numpy('./data/org_nm_embeddings_250605.npz')\n",
        "# item_embeddings = torch.from_numpy(item_embeddings).to(device)\n",
        "# org_all_embeddings = torch.from_numpy(org_all_embeddings).to(device)\n",
        "# org_nm_embeddings = torch.from_numpy(org_nm_embeddings).to(device)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_df_to_json_list(df):\n",
        "    \"\"\"\n",
        "    Convert DataFrame to the specific JSON structure you want\n",
        "    \"\"\"\n",
        "    result = []\n",
        "    # Group by 'item_name_in_msg' to create the main structure\n",
        "    grouped = df.groupby('item_name_in_msg')\n",
        "    for item_name_in_msg, group in grouped:\n",
        "        # Create the main item dictionary\n",
        "        item_dict = {\n",
        "            'item_name_in_msg': item_name_in_msg,\n",
        "            'item_in_voca': []\n",
        "        }\n",
        "        # Group by item_nm within each item_name_in_msg to collect item_ids\n",
        "        item_nm_groups = group.groupby('item_nm')\n",
        "        for item_nm, item_group in item_nm_groups:\n",
        "            # Collect all item_ids for this item_nm\n",
        "            item_ids = list(item_group['item_id'].unique())\n",
        "            voca_item = {\n",
        "                'item_nm': item_nm,\n",
        "                'item_id': item_ids\n",
        "            }\n",
        "            item_dict['item_in_voca'].append(voca_item)\n",
        "        result.append(item_dict)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h2 style=\"color: #006600; font-size: 1.5em;\">개채명 추출기 (Kiwi)</h2>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from kiwipiepy import Kiwi\n",
        "# Simple approach\n",
        "kiwi = Kiwi()\n",
        "entity_list_for_kiwi = list(item_pdf_all['item_nm_alias'].unique())\n",
        "for w in entity_list_for_kiwi:\n",
        "    kiwi.add_user_word(w, \"NNP\")\n",
        "# for w in stop_item_names:\n",
        "#     kiwi.add_user_word(w, \"NNG\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_text_by_exc_patterns(sentence, exc_tag_patterns):",
        "    \"\"\"",
        "    Create a new text by replacing tokens that match exclusion tag patterns with whitespace.",
        "    Handles both individual tags and consecutive tag sequences.",
        "    Preserves original whitespace from the source text.",
        "    \"\"\"",
        "    ",
        "    # Separate individual tags from sequences",
        "    individual_tags = set()",
        "    sequences = []",
        "    ",
        "    for pattern in exc_tag_patterns:",
        "        if isinstance(pattern, list):",
        "            if len(pattern) == 1:",
        "                individual_tags.add(pattern[0])",
        "            else:",
        "                sequences.append(pattern)",
        "        else:",
        "            individual_tags.add(pattern)",
        "    ",
        "    # Track which tokens to exclude",
        "    tokens_to_exclude = set()",
        "    ",
        "    # Check for individual tag matches",
        "    for i, token in enumerate(sentence.tokens):",
        "        if token.tag in individual_tags:",
        "            tokens_to_exclude.add(i)",
        "    ",
        "    # Check for sequence matches",
        "    for sequence in sequences:",
        "        seq_len = len(sequence)",
        "        for i in range(len(sentence.tokens) - seq_len + 1):",
        "            # Check if consecutive tokens match the sequence",
        "            if all(sentence.tokens[i + j].tag == sequence[j] for j in range(seq_len)):",
        "                # Mark all tokens in this sequence for exclusion",
        "                for j in range(seq_len):",
        "                    tokens_to_exclude.add(i + j)",
        "    ",
        "    # Create a character array from the original text",
        "    result_chars = list(sentence.text)",
        "    ",
        "    # Replace excluded tokens with whitespace while preserving original whitespace",
        "    for i, token in enumerate(sentence.tokens):",
        "        if i in tokens_to_exclude:",
        "            # Replace token characters with spaces, but keep original whitespace intact",
        "            start_pos = token.start - sentence.start  # Adjust for sentence start offset",
        "            end_pos = start_pos + token.len",
        "            for j in range(start_pos, end_pos):",
        "                if j < len(result_chars) and result_chars[j] != ' ':",
        "                    result_chars[j] = ' '",
        "    ",
        "    # Join the character array to create filtered text",
        "    filtered_text = ''.join(result_chars)",
        "",
        "    #Replace consecutive whitespaces with a single whitespace",
        "    filtered_text = re.sub(r'\\s+', ' ', filtered_text)",
        "    ",
        "    return filtered_text",
        "",
        "# Define Token and Sentence classes",
        "class Token:",
        "    def __init__(self, form, tag, start, length):",
        "        self.form = form",
        "        self.tag = tag",
        "        self.start = start",
        "        self.len = length",
        "",
        "class Sentence:",
        "    def __init__(self, text, start, end, tokens, subs=None):",
        "        self.text = text",
        "        self.start = start",
        "        self.end = end",
        "        self.tokens = tokens",
        "        self.subs = subs or []",
        "",
        "exc_tag_patterns = [['SN', 'NNB'],",
        " ['W_SERIAL'],",
        " ['JKO'],",
        " ['W_URL'],",
        " ['W_EMAIL'],",
        " ['XSV', 'EC'],",
        " ['VV', 'EC'],",
        " ['VCP', 'ETM'],",
        " ['XSA', 'ETM'],",
        " ['VV', 'ETN'],",
        " ['W_SERIAL'],",
        " ['W_URL'],",
        " ['JKO'],",
        " ['SSO'],",
        " ['SSC'],",
        " ['SW'],",
        " ['SF'],",
        " ['SP'],",
        " ['SS'],",
        " ['SE'],",
        " ['SO'],",
        " ['SB'],",
        " ['SH'],",
        " ['W_HASHTAG']",
        " ]",
        "",
        "# sentence = sentences[1]",
        "",
        "# Apply the filtering",
        "# filtered_text = filter_text_by_exc_patterns(sentence, exc_tag_patterns)",
        "",
        "# print(\"Original text:\", repr(sentence.text))",
        "# print(\"Filtered text:\", repr(filtered_text))",
        "",
        "# # Show which tokens were excluded",
        "# print(\"\\nToken analysis:\")",
        "# individual_tags = set()",
        "# sequences = []",
        "",
        "# for pattern in exc_tag_patterns:",
        "#     if isinstance(pattern, list):",
        "#         if len(pattern) == 1:",
        "#             individual_tags.add(pattern[0])",
        "#         else:",
        "#             sequences.append(pattern)",
        "#     else:",
        "#         individual_tags.add(pattern)",
        "",
        "# print(\"Individual exclusion tags:\", individual_tags)",
        "# print(\"Sequence exclusion patterns:\", sequences)",
        "# print()",
        "",
        "# for i, token in enumerate(sentence.tokens):",
        "#     status = \"EXCLUDED\" if token.tag in individual_tags else \"KEPT\"",
        "#     print(f\"Token {i}: '{token.form}' ({token.tag}) at pos {token.start}-{token.start + token.len - 1} - {status}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "msg_text_list = [\"\"\"\n",
        "광고 제목:[SK텔레콤] 2월 0 day 혜택 안내\n",
        "광고 내용:(광고)[SKT] 2월 0 day 혜택 안내__[2월 10일(토) 혜택]_만 13~34세 고객이라면_베어유 모든 강의 14일 무료 수강 쿠폰 드립니다!_(선착순 3만 명 증정)_▶ 자세히 보기: http://t-mms.kr/t.do?m=#61&s=24589&a=&u=https://bit.ly/3SfBjjc__■ 에이닷 X T 멤버십 시크릿코드 이벤트_에이닷 T 멤버십 쿠폰함에 ‘에이닷이빵쏜닷’을 입력해보세요!_뚜레쥬르 데일리우유식빵 무료 쿠폰을 드립니다._▶ 시크릿코드 입력하러 가기: https://bit.ly/3HCUhLM__■ 문의: SKT 고객센터(1558, 무료)_무료 수신거부 1504\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "광고 제목:통화 부가서비스를 패키지로 저렴하게!\n",
        "광고 내용:(광고)[SKT] 콜링플러스 이용 안내  #04 고객님, 안녕하세요. <콜링플러스>에 가입하고 콜키퍼, 컬러링, 통화가능통보플러스까지 총 3가지의 부가서비스를 패키지로 저렴하게 이용해보세요.  ■ 콜링플러스 - 이용요금: 월 1,650원, 부가세 포함 - 콜키퍼(550원), 컬러링(990원), 통화가능통보플러스(770원)를 저렴하게 이용할 수 있는 상품  ■ 콜링플러스 가입 방법 - T월드 앱: 오른쪽 위에 있는 돋보기를 눌러 콜링플러스 검색 > 가입  ▶ 콜링플러스 가입하기: http://t-mms.kr/t.do?m=#61&u=https://skt.sh/17tNH  ■ 유의 사항 - 콜링플러스에 가입하면 기존에 이용 중인 콜키퍼, 컬러링, 통화가능통보플러스 서비스는 자동으로 해지됩니다. - 기존에 구매한 컬러링 음원은 콜링플러스 가입 후에도 계속 이용할 수 있습니다.(시간대, 발신자별 설정 정보는 다시 설정해야 합니다.)  * 최근 다운로드한 음원은 보관함에서 무료로 재설정 가능(다운로드한 날로부터 1년 이내)   ■ 문의: SKT 고객센터(114)  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\\n    ',\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "(광고)[SKT] 1월 0 day 혜택 안내_ _[1월 20일(토) 혜택]_만 13~34세 고객이라면 _CU에서 핫바 1,000원에 구매 하세요!_(선착순 1만 명 증정)_▶ 자세히 보기 : http://t-mms.kr/t.do?m=#61&s=24264&a=&u=https://bit.ly/3H2OHSs__■ 에이닷 X T 멤버십 구독캘린더 이벤트_0 day 일정을 에이닷 캘린더에 등록하고 혜택 날짜에 알림을 받아보세요! _알림 설정하면 추첨을 통해 [스타벅스 카페 라떼tall 모바일쿠폰]을 드립니다. _▶ 이벤트 참여하기 : https://bit.ly/3RVSojv_ _■ 문의: SKT 고객센터(1558, 무료)_무료 수신거부 1504\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "'[T 우주] 넷플릭스와 웨이브를 월 9,900원에! \\n(광고)[SKT] 넷플릭스+웨이브 월 9,900원, 이게 되네! __#04 고객님,_넷플릭스와 웨이브 둘 다 보고 싶었지만, 가격 때문에 망설이셨다면 지금이 바로 기회! __오직 T 우주에서만, _2개월 동안 월 9,900원에 넷플릭스와 웨이브를 모두 즐기실 수 있습니다.__8월 31일까지만 드리는 혜택이니, 지금 바로 가입해 보세요! __■ 우주패스 Netflix 런칭 프로모션 _- 기간 : 2024년 8월 31일(토)까지_- 혜택 : 우주패스 Netflix(광고형 스탠다드)를 2개월 동안 월 9,900원에 이용 가능한 쿠폰 제공_▶ 프로모션 자세히 보기: http://t-mms.kr/jAs/#74__■ 우주패스 Netflix(월 12,000원)  _- 기본 혜택 : Netflix 광고형 스탠다드 멤버십_- 추가 혜택 : Wavve 콘텐츠 팩 _* 추가 요금을 내시면 Netflix 스탠다드와 프리미엄 멤버십 상품으로 가입 가능합니다.  __■ 유의 사항_-  프로모션 쿠폰은 1인당 1회 다운로드 가능합니다. _-  쿠폰 할인 기간이 끝나면 정상 이용금액으로 자동 결제 됩니다. __■ 문의: T 우주 고객센터 (1505, 무료)__나만의 구독 유니버스, T 우주 __무료 수신거부 1504'\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "광고 제목:[SK텔레콤] T건강습관 X AIA Vitality, 우리 가족의 든든한 보험!\n",
        "광고 내용:(광고)[SKT] 가족의 든든한 보험 (무배당)AIA Vitality 베스트핏 보장보험 안내  고객님, 안녕하세요. 4인 가족 표준생계비, 준비하고 계시나요? (무배당)AIA Vitality 베스트핏 보장보험(디지털 전용)으로 최대 20% 보험료 할인과 가족의 든든한 보험 보장까지 누려 보세요.   ▶ 자세히 보기: http://t-mms.kr/t.do?m=#61&u=https://bit.ly/36oWjgX  ■ AIA Vitality  혜택 - 매달 리워드 최대 12,000원 - 등급 업그레이드 시 특별 리워드 - T건강습관 제휴 할인 최대 40% ※ 제휴사별 할인 조건과 주간 미션 달성 혜택 등 자세한 내용은 AIA Vitality 사이트에서 확인하세요. ※ 이 광고는 AIA생명의 광고이며 SK텔레콤은 모집 행위를 하지 않습니다.  - 보험료 납입 기간 중 피보험자가 장해분류표 중 동일한 재해 또는 재해 이외의 동일한 원인으로 여러 신체 부위의 장해지급률을 더하여 50% 이상인 장해 상태가 된 경우 차회 이후의 보험료 납입 면제 - 사망보험금은 계약일(부활일/효력회복일)로부터 2년 안에 자살한 경우 보장하지 않음 - 일부 특약 갱신 시 보험료 인상 가능 - 기존 계약 해지 후 신계약 체결 시 보험인수 거절, 보험료 인상, 보장 내용 변경 가능 - 해약 환급금(또는 만기 시 보험금이나 사고보험금)에 기타 지급금을 합해 5천만 원까지(본 보험 회사 모든 상품 합산) 예금자 보호 - 계약 체결 전 상품 설명서 및 약관 참조 - 월 보험료 5,500원(부가세 포함)  * 생명보험협회 심의필 제2020-03026호(2020-09-22) COM-2020-09-32426  ■문의: 청약 관련(1600-0880)  무료 수신거부 1504\n",
        "\"\"\",\n",
        "\"\"\"\n",
        "[SK텔레콤]추석맞이 추가할인 쿠폰 증정\n",
        "(광고)[SKT]공식인증매장 고촌점 추석맞이 행사__안녕하세요 고객님!_고촌역 1번 출구 고촌파출소 방향 100m SK텔레콤 대리점 입니다._스마트폰 개통, 인터넷/TV 설치 시 조건 없이 추가 할인 행사를 진행합니다.__■삼성 갤럭시 Z플립5/Z폴드5는_  9월 내내 즉시개통 가능!!_1.갤럭시 워치6 개통 시 추가 할인_2.삼성케어+ 파손보장 1년권_3.삼성 정품 악세사리 30% 할인 쿠폰_4.정품 보호필름 1회 무료 부착__■새로운 아이폰15 출시 전_  아이폰14 재고 대방출!!_1.투명 범퍼 케이스 증정_2.방탄 유리 필름 부착_3.25W C타입 PD 충전기__여기에 5만원 추가 할인 적용!!__■기가인터넷+IPTV 가입 시_1.최대 36만원 상당 상품권 지급_2.스마트폰 개통 시 10만원 할인_3.매장 특별 사은품 지급_(특별 사은품은 매장 상황에 따라 변경될 수 있습니다)__■SKT 공식인증매장 고촌점_- 주소: 경기 김포시 고촌읍 장차로 3, SK텔레콤_- 연락처: 0507-1480-7833_- 네이버 예약하기: http://t-mms.kr/bSo/#74_- 매장 홈페이지: http://t-mms.kr/bSt/#74__■ 문의 : SKT 고객센터(1558, 무료)_무료 수신거부 1504_\n",
        "\"\"\"\n",
        "]\n",
        "message_idx = -1\n",
        "mms_msg = msg_text_list[message_idx]\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_specific_terms(strings: List[str]) -> List[str]:",
        "    unique_strings = list(set(strings))  # 중복 제거",
        "    unique_strings.sort(key=len, reverse=True)  # 길이 기준 내림차순 정렬",
        "",
        "    filtered = []",
        "    for s in unique_strings:",
        "        if not any(s in other for other in filtered):",
        "            filtered.append(s)",
        "",
        "    return filtered",
        "",
        "def extract_entities_from_kiwi(mms_msg, item_pdf_all, stop_item_names):",
        "    sentences = sum(kiwi.split_into_sents(re.split(r\"_+\",mms_msg), return_tokens=True, return_sub_sents=True), [])",
        "    # sentence_list = [sent.text.strip() for sent in sentences if sent.text.strip()]",
        "",
        "    sentences_all = []",
        "    for sent in sentences:",
        "        # print(sent.text.strip())",
        "        # print(\"-\"*100)",
        "        if sent.subs:",
        "            for sub_sent in sent.subs:",
        "                sentences_all.append(sub_sent)",
        "        else:",
        "            sentences_all.append(sent)",
        "",
        "    sentence_list = []",
        "    for sent in sentences_all:",
        "        # print(sent.text, \" --> \", filter_text_by_exc_patterns(sent, exc_tag_patterns))",
        "        sentence_list.append(filter_text_by_exc_patterns(sent, exc_tag_patterns))",
        "",
        "    result_msg = kiwi.tokenize(mms_msg, normalize_coda=True, z_coda=False, split_complex=False)",
        "    entities_from_kiwi = []",
        "    for token in result_msg:  # 첫 번째 분석 결과의 토큰 리스트",
        "        if token.tag == 'NNP' and token.form not in stop_item_names+['-'] and len(token.form)>=2 and not token.form.lower() in stop_item_names:  # 고유명사인 경우",
        "        # if token.tag == 'NNG' and token.form in stop_item_names_ext:  # 고유명사인 경우",
        "            entities_from_kiwi.append(token.form)",
        "",
        "    from typing import List",
        "",
        "    entities_from_kiwi = filter_specific_terms(entities_from_kiwi)",
        "",
        "    print(\"추출된 개체명:\", list(set(entities_from_kiwi)))",
        "",
        "    similarities_fuzzy = parallel_fuzzy_similarity(",
        "        sentence_list, ",
        "        item_pdf_all['item_nm_alias'].unique(), ",
        "        threshold=0.4,",
        "        text_col_nm='sent',",
        "        item_col_nm='item_nm_alias',",
        "        n_jobs=6,",
        "        batch_size=30",
        "    )",
        "",
        "    similarities_seq = parallel_seq_similarity(",
        "        sent_item_pdf=similarities_fuzzy,",
        "        text_col_nm='sent',",
        "        item_col_nm='item_nm_alias',",
        "        n_jobs=6,",
        "        batch_size=100",
        "    )",
        "",
        "    cand_items = similarities_seq.query(\"sim>=0.7 and item_nm_alias.str.contains('', case=False) and item_nm_alias not in @stop_item_names\")",
        "",
        "    entities_from_kiwi_pdf = item_pdf_all.query(\"item_nm_alias in @entities_from_kiwi\")[['item_nm','item_nm_alias']]",
        "    entities_from_kiwi_pdf['sim'] = 1.0",
        "",
        "    cand_item_pdf = pd.concat([cand_items,entities_from_kiwi_pdf])",
        "    cand_item_list = cand_item_pdf.sort_values('sim', ascending=False).groupby([\"item_nm_alias\"])['sim'].max().reset_index(name='final_sim').sort_values('final_sim', ascending=False).query(\"final_sim>=0.2\")['item_nm_alias'].unique()",
        "",
        "    # product_tag = [{\"item_name_in_msg\":d['item_nm'], \"item_in_voca\":[{\"item_name_in_voca\":d['item_nm'], \"item_id\":d['item_id']}]} for d in item_pdf_all.query(\"item_nm_alias in @cand_item_list\")[['item_nm','item_nm_alias','item_id']].groupby([\"item_nm\"])['item_id'].apply(list).reset_index().to_dict(orient='records')]",
        "",
        "    # product_tag    ",
        "",
        "    extra_item_pdf = item_pdf_all.query(\"item_nm_alias in @cand_item_list\")[['item_nm','item_nm_alias','item_id']].groupby([\"item_nm\"])['item_id'].apply(list).reset_index()",
        "",
        "    # extra_item_pdf",
        "",
        "    return cand_item_list, extra_item_pdf",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test text: '[SK텔레콤] 큰사랑대리점 하남직영3호점 3월 특별 이벤트 안내드립니다.\n",
            "(광고)[SKT] 큰사랑대리점 하남직영3호점 3월 특별 이벤트 안내__고객님, 안녕하세요. 하남 1등 매장 최대 가입매장, 하남3호 덕풍점에서 3월 특별 이벤트를 안내드립니다.__■ 2월 출시된, 갤럭시 S25 즉시개통 최대 혜택_- 제휴 카드 이용 시 최대 할인_- 기존 쓰던 폰 반납 시 최대 보상_- 삼성 노트북, 워치7, 태블릿PC 중 택1 증정 (프라임요금제 사용)__■ 새학기 어린이/청소년 이벤트_- 할부원금 최저, 초특가폰 대방출_- 월 요금 14,850원 부터 (ZEM플랜 스마트+ 선택약정 가입조건)_- 가족결합 시 월 요금 최저_- 아이폰 16e 최대 할인_- 새학기 특별 사은품, 노트북 증정__■ 갤럭시 S24 선착순 재고 할인 이벤트_- S24 최대할인_- 재고 소진 시 마감__■ 인터넷 +TV 가입 사은품 최대 증정_- 55인치 TV 증정_- 하남에서 사은품 최대 제공__■ 큰사랑대리점 하남직영3호점_- 주소 : 경기도 하남시 덕풍동 418-1, 신장사거리에서 국민은행 가기 전 투썸플레이스 옆 (매장 앞 주차 가능)_- 연락처 : 031-8028-7010, 031-8028-7012_▶매장 홈페이지 : http://t-mms.kr/t.do?m=#61&s=30861&a=&u=https://tworldfriends.co.kr/D134220127__■ 문의: SKT 고객센터(1558, 무료)_SKT와 함께 해주셔서 감사합니다.__무료 수신거부 1504'\n",
            "추출된 개체명: ['아이폰 16', '태블릿', 'ZEM플랜 스마트', '하남시', '국민은행', '갤럭시 S25', '신장', '투썸플레이스', '경기도', '덕풍동']\n",
            "\n",
            "Entity from extractor: ['ZEM플랜 베스트', 'ZEM플랜 스마트', '못된사랑 이벤트', '갤럭시 S24 FE', '(LGU)갤럭시 S25', '국민은행', '갤럭시 S25+', '갤럭시 S25 울트라', '갤럭시 S21', '갤럭시 J4+', 'T 연락처', '(KTF)갤럭시 S25', 'ZEM플랜 라이트', '갤럭시S5', '레이', '갤럭시S4', '갤럭시 S21+', '갤럭시 S22', '아이폰 15', '(LGU)갤럭시 S25+', '(N)스마트', '갤럭시 A24', '갤럭시 S22+', '아이폰 12', '도서할인 이벤트', '갤럭시 S25', '리안', '갤럭시S2', '투썸플레이스', '갤럭시 S25 엣지', '아이폰 14', 'SK텔레콤(주)', '갤럭시S', '갤럭시 북S', '갤럭시S2 화이트', '아이폰 16', '투썸플레이스 할인', '아이폰 13', '갤럭시 A25', '아이폰 16E', '(KTF)갤럭시 S25+']\n",
            "Entity from LLM: ['갤럭시 S25', '갤럭시 S24', '아이폰 16e', 'ZEM플랜 스마트', '인터넷+TV', '삼성 노트북', '워치7', '태블릿PC', '55인치 TV', '노트북']\n",
            "{\n",
            "    \"title\": \"SK텔레콤 하남직영3호점 3월 특별 이벤트 - 갤럭시S25 출시 및 새학기 할인 혜택\",\n",
            "    \"purpose\": [\n",
            "        \"상품 가입 유도\",\n",
            "        \"대리점/매장 방문 유도\",\n",
            "        \"혜택 안내\",\n",
            "        \"경품 제공 안내\"\n",
            "    ],\n",
            "    \"product\": [\n",
            "        {\n",
            "            \"item_name_in_msg\": \"ZEM플랜 스마트\",\n",
            "            \"item_in_voca\": [\n",
            "                {\n",
            "                    \"item_nm\": \"ZEM플랜 스마트\",\n",
            "                    \"item_id\": [\n",
            "                        \"NA00004891\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"스마트\",\n",
            "                    \"item_id\": [\n",
            "                        \"NT00000103\",\n",
            "                        \"T000009135\"\n",
            "                    ]\n",
            "                }\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"item_name_in_msg\": \"갤럭시 S24\",\n",
            "            \"item_in_voca\": [\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S24 FE\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5V7\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)삼성 갤럭시 S24 울트라_256G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5G6\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)삼성 갤럭시 S24 울트라_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5G7\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)삼성 갤럭시 S24+_256G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5G4\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)삼성 갤럭시 S24+_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5G5\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)삼성 갤럭시 S24_256G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5G2\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)삼성 갤럭시 S24_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5G3\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)갤럭시 S24 FE\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5V8\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)삼성 갤럭시 S24 울트라 PE\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5JF\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)삼성 갤럭시 S24 울트라_256G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5GG\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)삼성 갤럭시 S24 울트라_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5GH\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)삼성 갤럭시 S24+_256G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5GE\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)삼성 갤럭시 S24+_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5GF\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)삼성 갤럭시 S24_256G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5GC\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)삼성 갤럭시 S24_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5GD\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S24 FE\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5V2\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S24 울트라_1T\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5JN\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S24 울트라_256G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5CV\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S24 울트라_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5JM\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S24+_256G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5CU\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S24+_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5JL\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S24_256G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5CT\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S24_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5JK\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S24 FE\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5VS\",\n",
            "                        \"A5VR\",\n",
            "                        \"A5VM\",\n",
            "                        \"A5VQ\",\n",
            "                        \"A5VT\",\n",
            "                        \"A5UX\",\n",
            "                        \"A5VP\",\n",
            "                        \"A5VN\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S24 울트라_1T\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5J1\",\n",
            "                        \"A5J5\",\n",
            "                        \"A5J4\",\n",
            "                        \"A5J2\",\n",
            "                        \"A5J6\",\n",
            "                        \"A5HZ\",\n",
            "                        \"A5J7\",\n",
            "                        \"A5J3\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S24 울트라_256G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5EM\",\n",
            "                        \"A5EN\",\n",
            "                        \"A5EH\",\n",
            "                        \"A5EP\",\n",
            "                        \"A5CM\",\n",
            "                        \"A5EJ\",\n",
            "                        \"A5EL\",\n",
            "                        \"A5EK\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S24 울트라_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5EV\",\n",
            "                        \"A5EX\",\n",
            "                        \"A5EU\",\n",
            "                        \"A5ET\",\n",
            "                        \"A5EW\",\n",
            "                        \"A5ES\",\n",
            "                        \"A5EQ\",\n",
            "                        \"A5ER\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S24+_256G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5EZ\",\n",
            "                        \"A5F4\",\n",
            "                        \"A5F3\",\n",
            "                        \"A5F2\",\n",
            "                        \"A5F1\",\n",
            "                        \"A5EY\",\n",
            "                        \"A5F5\",\n",
            "                        \"A5CL\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S24+_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5F9\",\n",
            "                        \"A5FE\",\n",
            "                        \"A5FC\",\n",
            "                        \"A5FA\",\n",
            "                        \"A5F8\",\n",
            "                        \"A5F7\",\n",
            "                        \"A5F6\",\n",
            "                        \"A5FD\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S24_256G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5FM\",\n",
            "                        \"A5FG\",\n",
            "                        \"A5FK\",\n",
            "                        \"A5FJ\",\n",
            "                        \"A5FF\",\n",
            "                        \"A5CK\",\n",
            "                        \"A5FH\",\n",
            "                        \"A5FL\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S24_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5FP\",\n",
            "                        \"A5FV\",\n",
            "                        \"A5FT\",\n",
            "                        \"A5FR\",\n",
            "                        \"A5FN\",\n",
            "                        \"A5FU\",\n",
            "                        \"A5FQ\",\n",
            "                        \"A5FS\"\n",
            "                    ]\n",
            "                }\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"item_name_in_msg\": \"갤럭시 S25\",\n",
            "            \"item_in_voca\": [\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66R\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25 AS\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66S\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25 엣지\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6AV\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25 엣지 AS\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6AW\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25 엣지_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6AX\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25 엣지_512G AS\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6AY\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25 울트라\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66Z\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25 울트라 AS\",\n",
            "                    \"item_id\": [\n",
            "                        \"A671\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25 울트라_1T\",\n",
            "                    \"item_id\": [\n",
            "                        \"A674\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25 울트라_1T AS\",\n",
            "                    \"item_id\": [\n",
            "                        \"A675\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25 울트라_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A672\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25 울트라_512G AS\",\n",
            "                    \"item_id\": [\n",
            "                        \"A673\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25+\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66V\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25+ AS\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66W\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25+_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66X\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25+_512G AS\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66Y\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66T\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 S25_512G AS\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66U\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)갤럭시 S25\",\n",
            "                    \"item_id\": [\n",
            "                        \"A676\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)갤럭시 S25 엣지\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6AZ\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)갤럭시 S25 엣지_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6C2\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)갤럭시 S25 울트라\",\n",
            "                    \"item_id\": [\n",
            "                        \"A67A\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)갤럭시 S25 울트라_1T\",\n",
            "                    \"item_id\": [\n",
            "                        \"A67D\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)갤럭시 S25 울트라_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A67C\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)갤럭시 S25+\",\n",
            "                    \"item_id\": [\n",
            "                        \"A678\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)갤럭시 S25+_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A679\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)갤럭시 S25_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A677\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S25\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66H\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S25 시리즈 해외향\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6DU\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S25 시리즈 해외향_NON\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6DV\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S25 엣지\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6C3\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S25 엣지_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6C6\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S25 울트라\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66M\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S25 울트라_1T\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66P\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S25 울트라_1T_16RAM\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6AT\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S25 울트라_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66N\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S25+\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66K\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S25+_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66L\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 S25_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A66J\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S25\",\n",
            "                    \"item_id\": [\n",
            "                        \"A683\",\n",
            "                        \"A682\",\n",
            "                        \"A684\",\n",
            "                        \"A685\",\n",
            "                        \"A687\",\n",
            "                        \"A686\",\n",
            "                        \"A688\",\n",
            "                        \"A65Y\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S25 엣지\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6DG\",\n",
            "                        \"A6DH\",\n",
            "                        \"A6DF\",\n",
            "                        \"A6AS\",\n",
            "                        \"A6DK\",\n",
            "                        \"A6DJ\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S25 엣지_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6DR\",\n",
            "                        \"A6DL\",\n",
            "                        \"A6DP\",\n",
            "                        \"A6DN\",\n",
            "                        \"A6DQ\",\n",
            "                        \"A6DM\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S25 울트라\",\n",
            "                    \"item_id\": [\n",
            "                        \"A693\",\n",
            "                        \"A692\",\n",
            "                        \"A691\",\n",
            "                        \"A68Z\",\n",
            "                        \"A694\",\n",
            "                        \"A696\",\n",
            "                        \"A65X\",\n",
            "                        \"A695\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S25 울트라_1T\",\n",
            "                    \"item_id\": [\n",
            "                        \"A69G\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S25 울트라_1T_미사용\",\n",
            "                    \"item_id\": [\n",
            "                        \"A69P\",\n",
            "                        \"A69M\",\n",
            "                        \"A69J\",\n",
            "                        \"A69L\",\n",
            "                        \"A69H\",\n",
            "                        \"A69N\",\n",
            "                        \"A69K\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S25 울트라_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A69A\",\n",
            "                        \"A697\",\n",
            "                        \"A69E\",\n",
            "                        \"A69D\",\n",
            "                        \"A699\",\n",
            "                        \"A69F\",\n",
            "                        \"A698\",\n",
            "                        \"A69C\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S25+\",\n",
            "                    \"item_id\": [\n",
            "                        \"A65Z\",\n",
            "                        \"A68M\",\n",
            "                        \"A68N\",\n",
            "                        \"A68L\",\n",
            "                        \"A68J\",\n",
            "                        \"A68P\",\n",
            "                        \"A68K\",\n",
            "                        \"A68Q\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S25+_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A68V\",\n",
            "                        \"A68U\",\n",
            "                        \"A68S\",\n",
            "                        \"A68W\",\n",
            "                        \"A68T\",\n",
            "                        \"A68R\",\n",
            "                        \"A68X\",\n",
            "                        \"A68Y\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 S25_512G\",\n",
            "                    \"item_id\": [\n",
            "                        \"A68H\",\n",
            "                        \"A689\",\n",
            "                        \"A68E\",\n",
            "                        \"A68C\",\n",
            "                        \"A68D\",\n",
            "                        \"A68F\",\n",
            "                        \"A68A\",\n",
            "                        \"A68G\"\n",
            "                    ]\n",
            "                }\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"item_name_in_msg\": \"삼성 노트북\",\n",
            "            \"item_in_voca\": [\n",
            "                {\n",
            "                    \"item_nm\": \"삼성\",\n",
            "                    \"item_id\": [\n",
            "                        \"T000005327\"\n",
            "                    ]\n",
            "                }\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"item_name_in_msg\": \"아이폰 16e\",\n",
            "            \"item_in_voca\": [\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)IPHONE 16E\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6D7\",\n",
            "                        \"A6D9\",\n",
            "                        \"A6D3\",\n",
            "                        \"A6D5\",\n",
            "                        \"A6CZ\",\n",
            "                        \"A6D6\",\n",
            "                        \"A6D1\",\n",
            "                        \"A6D4\",\n",
            "                        \"A6D2\",\n",
            "                        \"A6D8\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)IPHONE 16E\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6DC\",\n",
            "                        \"A6DD\",\n",
            "                        \"A6DA\",\n",
            "                        \"A6DE\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"IPHONE 16E\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6CC\",\n",
            "                        \"A6CV\",\n",
            "                        \"A6CM\",\n",
            "                        \"A6CN\",\n",
            "                        \"A6CU\",\n",
            "                        \"A6CQ\",\n",
            "                        \"A6CL\",\n",
            "                        \"A6CJ\",\n",
            "                        \"A6CP\",\n",
            "                        \"A6CT\",\n",
            "                        \"A6CD\",\n",
            "                        \"A6CK\",\n",
            "                        \"A6CE\",\n",
            "                        \"A6CA\",\n",
            "                        \"A6CR\",\n",
            "                        \"A6CS\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD IPHONE 16E\",\n",
            "                    \"item_id\": [\n",
            "                        \"A6CG\",\n",
            "                        \"A6CF\"\n",
            "                    ]\n",
            "                }\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"item_name_in_msg\": \"워치7\",\n",
            "            \"item_in_voca\": [\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 워치7 40MM\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5MA\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 워치7 40MM AS\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5MC\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 워치7 44MM\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5MD\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(KTF)갤럭시 워치7 44MM AS\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5ME\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)갤럭시 워치7 40MM\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5LS\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"(LGU)갤럭시 워치7 44MM\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5LQ\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 워치7 40MM\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5MH\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"OMD 삼성 갤럭시 워치7 44MM\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5MJ\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 워치7 40MM\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5LC\",\n",
            "                        \"A5RQ\",\n",
            "                        \"A5RR\",\n",
            "                        \"A5RP\"\n",
            "                    ]\n",
            "                },\n",
            "                {\n",
            "                    \"item_nm\": \"갤럭시 워치7 44MM\",\n",
            "                    \"item_id\": [\n",
            "                        \"A5RT\",\n",
            "                        \"A5LD\",\n",
            "                        \"A5RU\",\n",
            "                        \"A5RS\"\n",
            "                    ]\n",
            "                }\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"item_name_in_msg\": \"인터넷+TV\",\n",
            "            \"item_in_voca\": [\n",
            "                {\n",
            "                    \"item_nm\": \"인터넷\",\n",
            "                    \"item_id\": [\n",
            "                        \"NI00000861\"\n",
            "                    ]\n",
            "                }\n",
            "            ]\n",
            "        }\n",
            "    ],\n",
            "    \"channel\": [\n",
            "        {\n",
            "            \"type\": \"대리점\",\n",
            "            \"value\": \"큰사랑대리점 하남직영3호점\",\n",
            "            \"action\": \"가입\",\n",
            "            \"store_info\": [\n",
            "                {\n",
            "                    \"org_nm\": \"큰사랑대리점 하남직영3호점\",\n",
            "                    \"org_cd\": [\n",
            "                        \"D134220127\"\n",
            "                    ]\n",
            "                }\n",
            "            ]\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"전화번호\",\n",
            "            \"value\": \"031-8028-7010\",\n",
            "            \"action\": \"문의\",\n",
            "            \"store_info\": []\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"전화번호\",\n",
            "            \"value\": \"031-8028-7012\",\n",
            "            \"action\": \"문의\",\n",
            "            \"store_info\": []\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"URL\",\n",
            "            \"value\": \"https://tworldfriends.co.kr/D134220127\",\n",
            "            \"action\": \"추가 정보\",\n",
            "            \"store_info\": []\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"전화번호\",\n",
            "            \"value\": \"1558\",\n",
            "            \"action\": \"문의\",\n",
            "            \"store_info\": []\n",
            "        },\n",
            "        {\n",
            "            \"type\": \"전화번호\",\n",
            "            \"value\": \"1504\",\n",
            "            \"action\": \"수신 거부\",\n",
            "            \"store_info\": []\n",
            "        }\n",
            "    ],\n",
            "    \"pgm\": [\n",
            "        {\n",
            "            \"pgm_nm\": \"[마케팅_Sales]상품및부가서비스가입유도_단말\",\n",
            "            \"pgm_id\": \"2019SCTDH04\"\n",
            "        },\n",
            "        {\n",
            "            \"pgm_nm\": \"[마케팅_Sales]매장오픈안내및방문유도\",\n",
            "            \"pgm_id\": \"2020SCEET11\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "schema_prd = {",
        "    \"title\": {",
        "        \"type\": \"string\", ",
        "        'description': '광고 제목. 광고의 핵심 주제와 가치 제안을 명확하게 설명할 수 있도록 생성'",
        "    },",
        "    'purpose': {",
        "        'type': 'array', ",
        "        'description': '광고의 주요 목적을 다음 중에서 선택(복수 가능): [상품 가입 유도, 대리점/매장 방문 유도, 웹/앱 접속 유도, 이벤트 응모 유도, 혜택 안내, 쿠폰 제공 안내, 경품 제공 안내, 수신 거부 안내, 기타 정보 제공]'",
        "    },",
        "    'product': {",
        "        'type': 'array',",
        "        'items': {",
        "            'type': 'object',",
        "            'properties': {",
        "            'name': {'type': 'string', 'description': '광고하는 제품이나 서비스 이름'},",
        "            # 'category': {'type': 'string', 'description': '광고 상품의 카테고리. [요금제, 부가서비스, 구독서비스, 제휴서비스, 모바일 단말기, 기타] 중에서 선택'},",
        "            'position': {'type': 'string', 'description': '광고 상품의 분류. [main, sub] 중에서 선택'},",
        "            'action': {'type': 'string', 'description': '고객에게 기대하는 행동: [구매, 가입, 사용, 방문, 참여, 코드입력, 쿠폰다운로드, 기타] 중에서 선택'}",
        "            }",
        "        }",
        "    },",
        "    'channel': {",
        "        'type': 'array', ",
        "        'items': {",
        "            'type': 'object', ",
        "            'properties': {",
        "                'type': {'type': 'string', 'description': '채널 종류: [URL, 전화번호, 앱, 대리점] 중에서 선택'},",
        "                'value': {'type': 'string', 'description': '실제 URL, 전화번호, 앱 이름, 대리점 이름 등 구체적 정보'},",
        "                'action': {'type': 'string', 'description': '채널 목적: [가입, 추가 정보, 문의, 수신, 수신 거부] 중에서 선택'},",
        "                # 'store_code': {'type': 'string', 'description': \"매장 코드 - tworldfriends.co.kr URL에서 D+숫자 9자리(D[0-9]{9}) 패턴의 코드 추출하여 대리점 채널에 설정\"}",
        "            }",
        "        }",
        "    },",
        "    'pgm':{",
        "        'type': 'array', ",
        "        'description': '아래 광고 분류 기준 정보에서 선택. 메세지 내용과 광고 분류 기준을 참고하여, 광고 메세지에 가장 부합하는 2개의 pgm_nm을 적합도 순서대로 제공'",
        "    },",
        "}",
        "",
        "prompt_template = ChatPromptTemplate.from_messages([",
        "    (\"system\", \"당신은 광고 메시지에서 구조화된 정보를 추출하는 전문가이다.\"),",
        "    (\"user\", \"\"\"",
        "    아래 광고 메시지에서 광고 목적과 상품 이름을 추출해 주세요. ",
        "",
        "    ### 광고 메시지 ###",
        "    {msg}",
        "",
        "    ### 추출 작업 순서 ###",
        "    1. 광고 목적을 먼저 파악한다.",
        "    2. 파악된 목적에 기반하여 Main 상품을 추출한다.",
        "    3. 추출한 Main 상품에 관련되는 Sub 상품을 추출한다.",
        "    4. 추출된 상품 정보를 고려하여 채널 정보를 제공한다.",
        "",
        "    ### 추출 작업 가이드 ###",
        "    * 상품 추출시 정확도(precision) 보다는 재현율(recall)에 중심을 두어라.",
        "    * 광고 목적에 대리점 방문이 포함되어 있으면 대리점 채널 정보를 제공해라.",
        "    {prd_ext_guide}",
        "    * Only generate the json object, do not include any other text to save as a json file",
        "",
        "    {schema_prompt}",
        "",
        "    {rag_context}",
        "     \"\"\"),",
        "])",
        "",
        "product_info_extraction_mode = 'rag' # options: 'rag', 'llm', 'nlp'",
        "",
        "# for test_text in mms_pdf.query(\"msg.str.contains('대리점')\").sample(10)['msg'].tolist():",
        "",
        "test_text = \"\"\"",
        "[SK텔레콤] ZEM폰 포켓몬에디션3 안내\\n(광고)[SKT] 우리 아이 첫 번째 스마트폰, ZEM 키즈폰__#04 고객님, 안녕하세요!_우리 아이 스마트폰 고민 중이셨다면, _자녀 스마트폰 관리 앱 ZEM이 설치된 SKT만의 안전한 키즈폰,_ZEM폰 포켓몬에디션3으로 우리 아이 취향을 저격해 보세요!__신학기를 맞이하여 SK텔레콤 공식 인증 대리점에서 풍성한 혜택을 제공해 드리고 있습니다!__■ 주요 기능_1. 실시간 위치 조회_2. 모르는 회선 자동 차단_3. 스마트폰 사용 시간 제한_4. IP68 방수 방진_5. 수업 시간 자동 무음모드_6. 유해 콘텐츠 차단__■ 가까운 SK텔레콤 공식 인증 대리점 찾기_http://t-mms.kr/t.do?m=#61&s=30684&a=&u=https://bit.ly/3yQF2hx__■ 문의 : SKT 고객센터(1558, 무료)__무료 수신거부 1504",
        "\"\"\"",
        "",
        "test_text = \"\"\"",
        "'[SK텔레콤] 큰사랑대리점 하남직영3호점 3월 특별 이벤트 안내드립니다.\\n(광고)[SKT] 큰사랑대리점 하남직영3호점 3월 특별 이벤트 안내__고객님, 안녕하세요. 하남 1등 매장 최대 가입매장, 하남3호 덕풍점에서 3월 특별 이벤트를 안내드립니다.__■ 2월 출시된, 갤럭시 S25 즉시개통 최대 혜택_- 제휴 카드 이용 시 최대 할인_- 기존 쓰던 폰 반납 시 최대 보상_- 삼성 노트북, 워치7, 태블릿PC 중 택1 증정 (프라임요금제 사용)__■ 새학기 어린이/청소년 이벤트_- 할부원금 최저, 초특가폰 대방출_- 월 요금 14,850원 부터 (ZEM플랜 스마트+ 선택약정 가입조건)_- 가족결합 시 월 요금 최저_- 아이폰 16e 최대 할인_- 새학기 특별 사은품, 노트북 증정__■ 갤럭시 S24 선착순 재고 할인 이벤트_- S24 최대할인_- 재고 소진 시 마감__■ 인터넷 +TV 가입 사은품 최대 증정_- 55인치 TV 증정_- 하남에서 사은품 최대 제공__■ 큰사랑대리점 하남직영3호점_- 주소 : 경기도 하남시 덕풍동 418-1, 신장사거리에서 국민은행 가기 전 투썸플레이스 옆 (매장 앞 주차 가능)_- 연락처 : 031-8028-7010, 031-8028-7012_▶매장 홈페이지 : http://t-mms.kr/t.do?m=#61&s=30861&a=&u=https://tworldfriends.co.kr/D134220127__■ 문의: SKT 고객센터(1558, 무료)_SKT와 함께 해주셔서 감사합니다.__무료 수신거부 1504'",
        "\"\"\"",
        "",
        "print(f\"Test text: {test_text.strip()}\")",
        "msg = test_text.strip()",
        "",
        "cand_item_list, extra_item_pdf = extract_entities_from_kiwi(msg, item_pdf_all, stop_item_names)",
        "",
        "product_df = extra_item_pdf.rename(columns={'item_nm':'name'}).query(\"not name in @stop_item_names\")[['name']]",
        "product_df['action'] = '고객에게 기대하는 행동: [구매, 가입, 사용, 방문, 참여, 코드입력, 쿠폰다운로드, 기타] 중에서 선택'",
        "product_df['position'] = '광고 상품의 분류. [main, sub, etc] 중에서 선택'",
        "product_element = product_df.to_dict(orient='records') if product_df.shape[0]>0 else schema_prd['product']",
        "",
        "# print(cand_item_list)",
        "",
        "mms_embedding = emb_model.encode([msg.lower()], convert_to_tensor=True)",
        "",
        "similarities = torch.nn.functional.cosine_similarity(",
        "    mms_embedding,  ",
        "    clue_embeddings,  ",
        "    dim=1 ",
        ").cpu().numpy()",
        "",
        "pgm_pdf_tmp = pgm_pdf.copy()",
        "pgm_pdf_tmp['sim'] = similarities",
        "",
        "pgm_pdf_tmp = pgm_pdf_tmp.sort_values('sim', ascending=False)",
        "",
        "pgm_cand_info = \"\\n\\t\".join(pgm_pdf_tmp.iloc[:num_cand_pgms][['pgm_nm','clue_tag']].apply(lambda x: re.sub(r'\\[.*?\\]', '', x['pgm_nm'])+\" : \"+x['clue_tag'], axis=1).to_list())",
        "rag_context = f\"\\n### 광고 분류 기준 정보 ###\\n\\t{pgm_cand_info}\" if num_cand_pgms>0 else \"\"",
        "",
        "chain_of_thought = \"\"\"",
        "1. 광고 목적을 먼저 파악한다.",
        "2. 파악된 목적에 기반하여 Main 상품을 추출한다.",
        "3. 추출한 Main 상품에 관련되는 Sub 상품을 추출한다.",
        "4. 추출된 상품 정보를 고려하여 채널 정보를 제공한다.",
        "\"\"\"",
        "",
        "prd_ext_guide = \"* 상품 추출시 정확도(precision) 보다는 재현율(recall)에 중심을 두어라.\"",
        "if len(cand_item_list)>0: ",
        "    if product_info_extraction_mode == 'rag':",
        "        rag_context += f\"\\n\\n### 후보 상품 이름 목록 ###\\n\\t{cand_item_list}\"",
        "        prd_ext_guide = f\"\"\"* 상품 추출시 정확도(precision) 보다는 재현율(recall)에 중심을 두어라.",
        "* 후보 상품 이름 목록에 포함된 상품 이름은 참고하여 Product 정보를 추출하라.",
        "        \"\"\"",
        "    elif product_info_extraction_mode == 'nlp':",
        "        schema_prd['product'] = product_element",
        "        chain_of_thought = \"\"\"1. 광고 목적을 먼저 파악한다.",
        "2. 파악된 목적에 기반하여 Product 정보를 추출한다.",
        "3. 주어진 name 정보에 기반하여, position과 action 필드의 정보를 추출한다.",
        "4. 추출된 상품 정보를 고려하여 채널 정보를 제공한다.",
        "        \"\"\"",
        "        prd_ext_guide = f\"\"\"* Product 정보에서 position, action 필드의 정보를 추출하라.",
        "        \"\"\"",
        "",
        "schema_prompt = f\"\"\"",
        "아래와 같은 스키마로 결과를 제공해 주세요.",
        "",
        "{schema_prd}",
        "\"\"\"",
        "",
        "prompt = f\"\"\"",
        "아래 광고 메시지에서 광고 목적과 상품 이름을 추출해 주세요.",
        "",
        "### 광고 메시지 ###",
        "{msg}",
        "",
        "### 추출 작업 순서 ###",
        "{chain_of_thought}",
        "",
        "### 추출 작업 가이드 ###",
        "* 광고 목적에 대리점 방문이 포함되어 있으면 대리점 채널 정보를 제공해라.",
        "{prd_ext_guide}",
        "",
        "{schema_prompt}",
        "",
        "{rag_context}",
        "",
        "\"\"\"",
        "",
        "print()",
        "",
        "# prompt = prompt_template.format(msg=msg, prd_ext_guide=prd_ext_guide, rag_context=rag_context, schema_prompt=schema_prompt)",
        "",
        "result_json_text = llm_cld40.invoke(prompt).content",
        "# result_json_text = llm_gem3.invoke(prompt).content",
        "",
        "json_objects = extract_json_objects(result_json_text)[0]",
        "",
        "similarities_fuzzy = parallel_fuzzy_similarity(",
        "[item['name'] for item in json_objects['product']['items']] if isinstance(json_objects['product'], dict) else [item['name'] for item in json_objects['product']], ",
        "item_pdf_all['item_nm_alias'].unique(), ",
        "threshold=0.8,",
        "text_col_nm='item_name_in_msg',",
        "item_col_nm='item_nm_alias',",
        "n_jobs=6,",
        "batch_size=30",
        ")",
        "",
        "if similarities_fuzzy.shape[0]>0:",
        "    similarities_fuzzy = parallel_seq_similarity(",
        "        sent_item_pdf=similarities_fuzzy,",
        "        text_col_nm='item_name_in_msg',",
        "        item_col_nm='item_nm_alias',",
        "        n_jobs=6,",
        "        batch_size=100,",
        "        normalizaton_value='min'",
        "    )",
        "",
        "final_result = json_objects.copy()",
        "",
        "if num_cand_pgms>0:",
        "    pgm_json = pgm_pdf[pgm_pdf['pgm_nm'].apply(lambda x: re.sub(r'\\[.*?\\]', '', x) in ' '.join(json_objects['pgm']))][['pgm_nm','pgm_id']].to_dict('records')",
        "    final_result['pgm'] = pgm_json",
        "",
        "# print(\"===\"*15+\"claude sonnet (emb)\"+\"===\"*15+\"\\n\")",
        "# print(json.dumps(final_result, indent=4, ensure_ascii=False))",
        "",
        "print(\"Entity from extractor:\", list(set(cand_item_list)))",
        "print(\"Entity from LLM:\", [x['name'] for x in ([item for item in json_objects['product']['items']] if isinstance(json_objects['product'], dict) else json_objects['product']) ])",
        "",
        "if similarities_fuzzy.shape[0]>0:",
        "    product_tag = convert_df_to_json_list(",
        "        item_pdf_all.merge(similarities_fuzzy.query(\"item_nm_alias in @similarities_fuzzy.query('sim>=0.95')['item_nm_alias'].unique() and not item_nm_alias.str.contains('test', case=False) and item_name_in_msg not in @stop_item_names\"), on=['item_nm_alias'])",
        "    )",
        "",
        "    final_result = {",
        "        \"title\":json_objects['title'],",
        "        \"purpose\":json_objects['purpose'],",
        "        \"product\":product_tag,",
        "        \"channel\":json_objects['channel'],",
        "        \"pgm\":json_objects['pgm']",
        "    }",
        "",
        "else:",
        "    final_result = json_objects.copy()",
        "    product_tag = [item for item in json_objects['product']['items']] if isinstance(json_objects['product'], dict) else json_objects['product']",
        "    final_result['product'] = [{'item_name_in_msg':d['name'], 'item_in_voca':[{'item_name_in_voca':d['name'], 'item_id': ['#']}]} for d in product_tag if d['name'] not in stop_item_names]",
        "",
        "if num_cand_pgms>0:",
        "    pgm_json = pgm_pdf[pgm_pdf['pgm_nm'].apply(lambda x: re.sub(r'\\[.*?\\]', '', x) in ' '.join(json_objects['pgm']))][['pgm_nm','pgm_id']].to_dict('records')",
        "    final_result['pgm'] = pgm_json",
        "",
        "channel_tag = []",
        "for d in [item for item in json_objects['channel']['items']] if isinstance(json_objects['channel'], dict) else json_objects['channel']:",
        "    if d['type']=='대리점':",
        "",
        "        # _embedding = emb_model.encode([preprocess_text(d['value'].lower())], convert_to_tensor=True)",
        "",
        "        # similarities = torch.nn.functional.cosine_similarity(",
        "        #     _embedding,  ",
        "        #     org_all_embeddings,  ",
        "        #     dim=1 ",
        "        # ).cpu().numpy()",
        "",
        "        # org_pdf_tmp = org_pdf.copy()",
        "        # org_pdf_tmp['sim'] = similarities.round(5)",
        "",
        "        org_pdf_cand = parallel_fuzzy_similarity(",
        "            [preprocess_text(d['value'].lower())], ",
        "            org_pdf['org_abbr_nm'].unique(), ",
        "            threshold=0.5,",
        "            text_col_nm='org_nm_in_msg',",
        "            item_col_nm='org_abbr_nm',",
        "            n_jobs=6,",
        "            batch_size=100",
        "        ).drop('org_nm_in_msg', axis=1)",
        "",
        "        org_pdf_cand = org_pdf.merge(org_pdf_cand, on=['org_abbr_nm'])",
        "",
        "        org_pdf_cand['sim'] = org_pdf_cand['sim'].round(5)",
        "        ",
        "        org_pdf_tmp = org_pdf_cand.query(\"org_cd.str.startswith('D')\").sort_values('sim', ascending=False).query(\"sim>=0.7\")",
        "        if org_pdf_tmp.shape[0]<1:",
        "            org_pdf_tmp = org_pdf_cand.sort_values('sim', ascending=False).query(\"sim>=0.7\")",
        "",
        "        org_pdf_tmp['sim'] = org_pdf_tmp.apply(lambda x: combined_sequence_similarity(d['value'], x['org_nm'])[0], axis=1)",
        "        org_pdf_tmp['rank'] = org_pdf_tmp['sim'].rank(method='dense',ascending=False)",
        "        org_pdf_tmp['org_cd'] = org_pdf_tmp.apply(lambda x: x['org_cd']+x['sub_org_cd'], axis=1)",
        "",
        "        org_pdf_tmp = org_pdf_tmp.query(\"rank==1\").groupby('org_nm')['org_cd'].apply(list).reset_index(name='org_cd').to_dict('records')",
        "",
        "        # org_nm_id_list =  list(zip(org_pdf_tmp['org_nm'], org_pdf_tmp['org_id']))",
        "",
        "        d['store_info'] = org_pdf_tmp",
        "    else:",
        "        d['store_info'] = []",
        "",
        "    channel_tag.append(d)",
        "",
        "final_result['channel'] = channel_tag",
        "",
        "# print(\"===\"*15+\"claude sonnet (fuzzy)\"+\"===\"*15+\"\\n\")",
        "print(json.dumps(final_result, indent=4, ensure_ascii=False))",
        "",
        "print(\"\\n\\n\")",
        "",
        "# break",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>org_abbr_nm</th>\n",
              "      <th>sim</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [org_abbr_nm, sim]\n",
              "Index: []"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# org_pdf_tmp = parallel_fuzzy_similarity(\n",
        "#             [preprocess_text(d['value'].lower())],\n",
        "#             org_pdf['org_abbr_nm'].unique(),\n",
        "#             threshold=0.5,\n",
        "#             text_col_nm='org_nm_in_msg',\n",
        "#             item_col_nm='org_abbr_nm',\n",
        "#             n_jobs=6,\n",
        "#             batch_size=100\n",
        "#         ).drop('org_nm_in_msg', axis=1)\n",
        "# org_pdf_tmp = org_pdf.merge(org_pdf_tmp, on=['org_abbr_nm'])\n",
        "# org_pdf_tmp['sim'] = org_pdf_tmp['sim'].round(5)\n",
        "# org_pdf_tmp.query(\"org_cd.str.startswith('D')\").sort_values('sim', ascending=False).query(\"sim>=0.6\")\n",
        "parallel_fuzzy_similarity(\n",
        "            [preprocess_text(d['value'].lower())],\n",
        "            org_pdf['org_abbr_nm'].unique(),\n",
        "            threshold=0.3,\n",
        "            text_col_nm='org_nm_in_msg',\n",
        "            item_col_nm='org_abbr_nm',\n",
        "            n_jobs=6,\n",
        "            batch_size=100\n",
        "        ).drop('org_nm_in_msg', axis=1).query(\"org_abbr_nm.str.contains('고촌')\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>org_id</th>\n",
              "      <th>org_cd</th>\n",
              "      <th>sub_org_cd</th>\n",
              "      <th>sup_org_cd</th>\n",
              "      <th>org_nm</th>\n",
              "      <th>org_abbr_nm</th>\n",
              "      <th>bas_addr</th>\n",
              "      <th>dtl_addr</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>1000156925</td>\n",
              "      <td>J25021</td>\n",
              "      <td>7995</td>\n",
              "      <td>J25021</td>\n",
              "      <td>스피드메이트 고촌제일점</td>\n",
              "      <td>스피드메이트 고촌제일점</td>\n",
              "      <td>경기 김포시 장차로13번길</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4897</th>\n",
              "      <td>1000209680</td>\n",
              "      <td>J00039</td>\n",
              "      <td>A839</td>\n",
              "      <td>J00039</td>\n",
              "      <td>김포고촌</td>\n",
              "      <td>김포고촌</td>\n",
              "      <td>경기 김포시 고촌읍 은행영사정로5번길 11</td>\n",
              "      <td>()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10256</th>\n",
              "      <td>1000189586</td>\n",
              "      <td>J33733</td>\n",
              "      <td>2857</td>\n",
              "      <td>J33733</td>\n",
              "      <td>도미노피자 고촌점</td>\n",
              "      <td>도미노피자 고촌점</td>\n",
              "      <td>경기 김포시 고촌읍 은행영사정로 41</td>\n",
              "      <td>#</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11805</th>\n",
              "      <td>1430446485</td>\n",
              "      <td>J60549</td>\n",
              "      <td>E696</td>\n",
              "      <td>J00039</td>\n",
              "      <td>고촌힐스테이트</td>\n",
              "      <td>고촌힐스테이트</td>\n",
              "      <td>경기 김포시 고촌읍 인향로244번길 56</td>\n",
              "      <td>()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16653</th>\n",
              "      <td>1430572703</td>\n",
              "      <td>JA0053</td>\n",
              "      <td>8927</td>\n",
              "      <td>JA0053</td>\n",
              "      <td>고촌제일</td>\n",
              "      <td>고촌제일</td>\n",
              "      <td>경기도 김포시 고촌읍 장차로13번길?9</td>\n",
              "      <td>(신곡리)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241060</th>\n",
              "      <td>1430482898</td>\n",
              "      <td>J00039</td>\n",
              "      <td>F357</td>\n",
              "      <td>J00039</td>\n",
              "      <td>고촌</td>\n",
              "      <td>고촌</td>\n",
              "      <td>경기 김포시 고촌읍 장차로 13</td>\n",
              "      <td>1층</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250858</th>\n",
              "      <td>1430488754</td>\n",
              "      <td>J00175</td>\n",
              "      <td>Z678</td>\n",
              "      <td>J00175</td>\n",
              "      <td>고촌행복점</td>\n",
              "      <td>고촌행복점</td>\n",
              "      <td>경기도 김포시 고촌읍 장차로 30</td>\n",
              "      <td>1층 101호</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255561</th>\n",
              "      <td>1430502828</td>\n",
              "      <td>JA0053</td>\n",
              "      <td>1248</td>\n",
              "      <td>JA0053</td>\n",
              "      <td>고촌제일</td>\n",
              "      <td>고촌제일</td>\n",
              "      <td>경기도 김포시</td>\n",
              "      <td>고촌읍 장차로13번길 9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255679</th>\n",
              "      <td>1430466100</td>\n",
              "      <td>J96299</td>\n",
              "      <td>1709</td>\n",
              "      <td>J94964</td>\n",
              "      <td>김포고촌</td>\n",
              "      <td>김포고촌</td>\n",
              "      <td>경기 김포시 고촌읍 김포대로 334-1</td>\n",
              "      <td>(조선일보고촌지국)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258177</th>\n",
              "      <td>1000244383</td>\n",
              "      <td>J00175</td>\n",
              "      <td>R138</td>\n",
              "      <td>J00175</td>\n",
              "      <td>고촌행복점</td>\n",
              "      <td>고촌행복점</td>\n",
              "      <td>경기 김포시 고촌읍 장차로 30</td>\n",
              "      <td>(장천슈퍼)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            org_id  org_cd sub_org_cd sup_org_cd        org_nm   org_abbr_nm  \\\n",
              "79      1000156925  J25021       7995     J25021  스피드메이트 고촌제일점  스피드메이트 고촌제일점   \n",
              "4897    1000209680  J00039       A839     J00039          김포고촌          김포고촌   \n",
              "10256   1000189586  J33733       2857     J33733     도미노피자 고촌점     도미노피자 고촌점   \n",
              "11805   1430446485  J60549       E696     J00039       고촌힐스테이트       고촌힐스테이트   \n",
              "16653   1430572703  JA0053       8927     JA0053          고촌제일          고촌제일   \n",
              "...            ...     ...        ...        ...           ...           ...   \n",
              "241060  1430482898  J00039       F357     J00039            고촌            고촌   \n",
              "250858  1430488754  J00175       Z678     J00175         고촌행복점         고촌행복점   \n",
              "255561  1430502828  JA0053       1248     JA0053          고촌제일          고촌제일   \n",
              "255679  1430466100  J96299       1709     J94964          김포고촌          김포고촌   \n",
              "258177  1000244383  J00175       R138     J00175         고촌행복점         고촌행복점   \n",
              "\n",
              "                       bas_addr       dtl_addr  \n",
              "79               경기 김포시 장차로13번길              9  \n",
              "4897    경기 김포시 고촌읍 은행영사정로5번길 11             ()  \n",
              "10256      경기 김포시 고촌읍 은행영사정로 41              #  \n",
              "11805    경기 김포시 고촌읍 인향로244번길 56             ()  \n",
              "16653     경기도 김포시 고촌읍 장차로13번길?9          (신곡리)  \n",
              "...                         ...            ...  \n",
              "241060        경기 김포시 고촌읍 장차로 13             1층  \n",
              "250858       경기도 김포시 고촌읍 장차로 30        1층 101호  \n",
              "255561                  경기도 김포시  고촌읍 장차로13번길 9  \n",
              "255679    경기 김포시 고촌읍 김포대로 334-1     (조선일보고촌지국)  \n",
              "258177        경기 김포시 고촌읍 장차로 30         (장천슈퍼)  \n",
              "\n",
              "[72 rows x 8 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "org_pdf.query(\"org_abbr_nm.str.contains('고촌') and sup_org_cd.str.startswith('J')\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'title': 'SK텔레콤 고촌점 추석맞이 스마트폰 개통 및 인터넷/TV 설치 특별 할인 행사',\n",
              " 'purpose': ['상품 가입 유도', '대리점/매장 방문 유도', '혜택 안내', '쿠폰 제공 안내'],\n",
              " 'product': [{'name': '갤럭시 Z 플립5', 'action': '구매', 'position': 'main'},\n",
              "  {'name': '갤럭시 Z 폴드5', 'action': '구매', 'position': 'main'},\n",
              "  {'name': 'IPHONE 14', 'action': '구매', 'position': 'main'},\n",
              "  {'name': '기가인터넷', 'action': '가입', 'position': 'main'}],\n",
              " 'channel': [{'type': '대리점',\n",
              "   'value': 'SKT 공식인증매장 고촌점 (경기 김포시 고촌읍 장차로 3)',\n",
              "   'action': '가입',\n",
              "   'store_info': [{'org_nm': '고촌점',\n",
              "     'org_cd': ['J300261634',\n",
              "      'J002004913',\n",
              "      'J316081332',\n",
              "      'J089511440',\n",
              "      'J393661639',\n",
              "      'J083481022']}]},\n",
              "  {'type': '전화번호',\n",
              "   'value': '0507-1480-7833',\n",
              "   'action': '문의',\n",
              "   'store_info': []},\n",
              "  {'type': 'URL',\n",
              "   'value': 'http://t-mms.kr/bSo/#74',\n",
              "   'action': '추가 정보',\n",
              "   'store_info': []},\n",
              "  {'type': 'URL',\n",
              "   'value': 'http://t-mms.kr/bSt/#74',\n",
              "   'action': '추가 정보',\n",
              "   'store_info': []},\n",
              "  {'type': '전화번호', 'value': '1558', 'action': '문의', 'store_info': []},\n",
              "  {'type': '전화번호', 'value': '1504', 'action': '수신 거부', 'store_info': []}],\n",
              " 'pgm': ['상품및부가서비스가입유도_단말', '기변유도및해지방어']}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "json_objects"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "ConnectionError",
          "evalue": "HTTPConnectionPool(host='127.0.0.1', port=8080): Max retries exceeded with url: /extract (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1b9f20c20>: Failed to establish a new connection: [Errno 61] Connection refused'))",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/urllib3/connection.py:174\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 174\u001b[0m     conn \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mcreate_connection(\n\u001b[1;32m    175\u001b[0m         (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dns_host, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mextra_kw\n\u001b[1;32m    176\u001b[0m     )\n\u001b[1;32m    178\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/urllib3/util/connection.py:95\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 85\u001b[0m sock\u001b[38;5;241m.\u001b[39mconnect(sa)\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
            "\u001b[0;31mConnectionRefusedError\u001b[0m: [Errno 61] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/urllib3/connectionpool.py:716\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 716\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    717\u001b[0m     conn,\n\u001b[1;32m    718\u001b[0m     method,\n\u001b[1;32m    719\u001b[0m     url,\n\u001b[1;32m    720\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    721\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    722\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    723\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    724\u001b[0m )\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/urllib3/connectionpool.py:416\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m         conn\u001b[38;5;241m.\u001b[39mrequest(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhttplib_request_kw)\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/urllib3/connection.py:244\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers)\u001b[0m\n\u001b[1;32m    243\u001b[0m     headers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser-Agent\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m _get_default_user_agent()\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28msuper\u001b[39m(HTTPConnection, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mrequest(method, url, body\u001b[38;5;241m=\u001b[39mbody, headers\u001b[38;5;241m=\u001b[39mheaders)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/http/client.py:1336\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1335\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/http/client.py:1382\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[0;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[1;32m   1381\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 1382\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/http/client.py:1331\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[0;32m-> 1331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/http/client.py:1091\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[0;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[0;32m-> 1091\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1094\u001b[0m \n\u001b[1;32m   1095\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/http/client.py:1035\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[0;32m-> 1035\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[1;32m   1036\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/urllib3/connection.py:205\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 205\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_conn()\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_conn(conn)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/urllib3/connection.py:186\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    187\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
            "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x1b9f20c20>: Failed to establish a new connection: [Errno 61] Connection refused",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    679\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/urllib3/connectionpool.py:802\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    800\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 802\u001b[0m retries \u001b[38;5;241m=\u001b[39m retries\u001b[38;5;241m.\u001b[39mincrement(\n\u001b[1;32m    803\u001b[0m     method, url, error\u001b[38;5;241m=\u001b[39me, _pool\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, _stacktrace\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    804\u001b[0m )\n\u001b[1;32m    805\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/urllib3/util/retry.py:594\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    596\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=8080): Max retries exceeded with url: /extract (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1b9f20c20>: Failed to establish a new connection: [Errno 61] Connection refused'))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Extract information\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp://127.0.0.1:8080/extract\u001b[39m\u001b[38;5;124m'\u001b[39m, json\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m광고 제목:[SK텔레콤] 2월 0 day 혜택 안내\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124m광고 내용:(광고)[SKT] 2월 0 day 혜택 안내__[2월 10일(토) 혜택]_만 13~34세 고객이라면_베어유 모든 강의 14일 무료 수강 쿠폰 드립니다!_(선착순 3만 명 증정)_▶ 자세히 보기: http://t-mms.kr/t.do?m=#61&s=24589&a=&u=https://bit.ly/3SfBjjc__■ 에이닷 X T 멤버십 시크릿코드 이벤트_에이닷 T 멤버십 쿠폰함에 ‘에이닷이빵쏜닷’을 입력해보세요!_뚜레쥬르 데일리우유식빵 무료 쿠폰을 드립니다._▶ 시크릿코드 입력하러 가기: https://bit.ly/3HCUhLM__■ 문의: SKT 고객센터(1558, 무료)_무료 수신거부 1504\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgemma_3\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mextraction_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnlp\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_loading_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m })\n\u001b[1;32m     12\u001b[0m result \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(json\u001b[38;5;241m.\u001b[39mdumps(result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m], indent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m, ensure_ascii\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/requests/api.py:115\u001b[0m, in \u001b[0;36mpost\u001b[0;34m(url, data, json, **kwargs)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(url, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, json\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    104\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, data\u001b[38;5;241m=\u001b[39mdata, json\u001b[38;5;241m=\u001b[39mjson, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m session\u001b[38;5;241m.\u001b[39mrequest(method\u001b[38;5;241m=\u001b[39mmethod, url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
            "\u001b[0;31mConnectionError\u001b[0m: HTTPConnectionPool(host='127.0.0.1', port=8080): Max retries exceeded with url: /extract (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x1b9f20c20>: Failed to establish a new connection: [Errno 61] Connection refused'))"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import json\n",
        "# Extract information\n",
        "response = requests.post('http://127.0.0.1:8080/extract', json={\n",
        "    \"message\": \"\"\"광고 제목:[SK텔레콤] 2월 0 day 혜택 안내\n",
        "광고 내용:(광고)[SKT] 2월 0 day 혜택 안내__[2월 10일(토) 혜택]_만 13~34세 고객이라면_베어유 모든 강의 14일 무료 수강 쿠폰 드립니다!_(선착순 3만 명 증정)_▶ 자세히 보기: http://t-mms.kr/t.do?m=#61&s=24589&a=&u=https://bit.ly/3SfBjjc__■ 에이닷 X T 멤버십 시크릿코드 이벤트_에이닷 T 멤버십 쿠폰함에 ‘에이닷이빵쏜닷’을 입력해보세요!_뚜레쥬르 데일리우유식빵 무료 쿠폰을 드립니다._▶ 시크릿코드 입력하러 가기: https://bit.ly/3HCUhLM__■ 문의: SKT 고객센터(1558, 무료)_무료 수신거부 1504\"\"\",\n",
        "    \"model\": \"gemma_3\",\n",
        "    \"extraction_mode\": \"nlp\",\n",
        "    \"model_loading_mode\": \"local\"\n",
        "})\n",
        "result = response.json()\n",
        "print(json.dumps(result['result'], indent=4, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}