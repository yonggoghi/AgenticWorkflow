# HDFS Transfer Script Configuration

# HDFS 경로 (다운로드할 데이터가 있는 경로)
HDFS_PATH=/user/hive/warehouse/your_table_name

# 원격 서버 접속 정보
REMOTE_USER=your_username
REMOTE_PASSWORD=your_password
REMOTE_IP=192.168.1.100
REMOTE_PATH=/home/your_username/data

# 로컬 임시 디렉토리 (다운로드 및 처리용)
LOCAL_TMP_PATH=/home/skinet/myfiles/aos_ost/tmp/

# 압축 파일명 (선택사항, 명령행 옵션으로도 지정 가능)
# 이것은 tar.gz 압축 파일명입니다
# ARCHIVE_NAME=data.tar.gz

# 파티션 통합 후 출력 Parquet 파일명 (선택사항, 명령행 옵션으로도 지정 가능)
# --merge-partitions 옵션 사용 시에만 적용됩니다
# OUTPUT_FILENAME=merged.parquet
# 예: OUTPUT_FILENAME=mth_mms_rcv_ract_score_202601.parquet

# 사용 예제:
# 1. 이 파일을 .env로 복사: cp .env.example .env
# 2. 위의 값들을 실제 환경에 맞게 수정
# 3. 스크립트 실행: python hdfs_transfer.py
