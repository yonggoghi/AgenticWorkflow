// =============================================================================
// MMS Click Prediction - Model Training and Service Data Generation
// =============================================================================
// ì´ ì½”ë“œëŠ” data_transformation.scalaì—ì„œ ìƒì„±ëœ transformed ë°ì´í„°ë¥¼ ì½ì–´ì„œ:
// 1. Transformed Train/Test ë°ì´í„° ë¡œë”©
// 2. í•™ìŠµ, í…ŒìŠ¤íŠ¸, ì„œë¹„ìŠ¤ìš© ë°ì´í„° ì¤€ë¹„
// 3. Click ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
// 4. Gap ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ
// 5. í•™ìŠµëœ ëª¨ë¸ ì €ì¥
//
// [ì‹¤í–‰ ë°©ë²•]
// 1. data_transformation.scala ì™„ë£Œ í›„ ì‹¤í–‰
// 2. Paragraph 1-8: ìˆœì°¨ ì‹¤í–‰
// =============================================================================


// ===== Paragraph 1: Imports and Configuration =====

import com.microsoft.azure.synapse.ml.causal
import ml.dmlc.xgboost4j.scala.spark.{XGBoostClassificationModel, XGBoostClassifier, XGBoostRegressor}
import org.apache.spark.ml.classification._
import org.apache.spark.ml.regression._
import org.apache.spark.ml.feature._
import org.apache.spark.ml.linalg.Vectors
import org.apache.spark.ml.{Pipeline, PipelineModel, linalg}
import org.apache.spark.mllib.evaluation.MulticlassMetrics
import org.apache.spark.sql.expressions.Window
import org.apache.spark.sql.functions.explode
import org.apache.spark.sql.types.{DateType, StringType, TimestampType}
import org.apache.spark.sql.{DataFrame, SparkSession, functions => F}
import org.apache.spark.storage.StorageLevel
import org.apache.spark.ml.evaluation.{BinaryClassificationEvaluator, MulticlassClassificationEvaluator, RegressionEvaluator}

import java.sql.Date
import java.text.DecimalFormat
import java.time.format.DateTimeFormatter
import java.time.{ZoneId, ZonedDateTime}
import com.microsoft.azure.synapse.{ml => sml}
import com.microsoft.azure.synapse.ml.lightgbm.LightGBMClassifier

import collection.JavaConverters._
import scala.collection.JavaConverters._
import org.apache.spark.ml.linalg.Vector

// ëŒ€ìš©ëŸ‰ ì²˜ë¦¬ ìµœì í™”ë¥¼ ìœ„í•œ Spark ì„¤ì •
spark.conf.set("spark.sql.sources.partitionOverwriteMode", "dynamic")
spark.conf.set("spark.sql.adaptive.enabled", "true")
spark.conf.set("spark.sql.adaptive.coalescePartitions.enabled", "true")
spark.conf.set("spark.sql.adaptive.skewJoin.enabled", "true")
spark.conf.set("spark.sql.adaptive.advisoryPartitionSizeInBytes", "128MB")
spark.conf.set("spark.sql.autoBroadcastJoinThreshold", "50m")

// // ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì • (OOM ë°©ì§€)
// spark.conf.set("spark.executor.memoryOverhead", "4g")
// spark.conf.set("spark.memory.fraction", "0.8")
// spark.conf.set("spark.memory.storageFraction", "0.3")

// ë™ì  íŒŒí‹°ì…˜ ê°œìˆ˜ ê³„ì‚°
val executorInstances = spark.sparkContext.getConf.getInt("spark.executor.instances", 10)
val executorCores = spark.sparkContext.getConf.getInt("spark.executor.cores", 5)
val optimalPartitions = executorInstances * executorCores
spark.conf.set("spark.sql.shuffle.partitions", (optimalPartitions * 4).toString)

println(s"Spark configuration set for model training")
println(s"  Optimal partitions: $optimalPartitions (Executors: $executorInstances Ã— Cores: $executorCores)")


// ===== Paragraph 2: Configuration Variables =====

// =============================================================================
// ë°ì´í„° ë²„ì „ ë° ê²½ë¡œ ì„¤ì •
// =============================================================================

// âš ï¸  ì¤‘ìš”: data_transformation.scalaì—ì„œ ì €ì¥í•œ ë²„ì „ê³¼ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.
val transformedDataVersion = "1"  // data_transformation.scalaì˜ transformedDataVersionê³¼ ì¼ì¹˜

// data_transformation.scalaì—ì„œ ì‚¬ìš©í•œ ë‚ ì§œ ì„¤ì • (ì¬í˜„ì„ ìœ„í•´ ë™ì¼í•˜ê²Œ ì„¤ì •)
val predictionDTSta = "20251201"  // í…ŒìŠ¤íŠ¸ ì‹œì‘ì¼
val predictionDTEnd = "20260101"  // í…ŒìŠ¤íŠ¸ ì¢…ë£Œì¼

// í•™ìŠµ ê¸°ê°„ ì •ë³´ (data_transformation.scalaì™€ ë™ì¼)
val trainPeriod = 3  // í•™ìŠµ ê°œì›” ìˆ˜
val trainSendMonth = "202511"  // í•™ìŠµ ê¸°ì¤€ ì›”

// Helper functions (data_transformation.scalaì—ì„œ ì‚¬ìš©í•œ ê²ƒê³¼ ë™ì¼)
def getPreviousMonths(startMonthStr: String, periodM: Int): Array[String] = {
  val formatter = DateTimeFormatter.ofPattern("yyyyMM")
  val startMonth = java.time.YearMonth.parse(startMonthStr, formatter)
  var resultMonths = scala.collection.mutable.ListBuffer[String]()
  var currentMonth = startMonth

  for (i <- 0 until periodM) {
    resultMonths.prepend(currentMonth.format(formatter))
    currentMonth = currentMonth.minusMonths(1)
  }
  resultMonths.toArray
}

val trainSendYmList = getPreviousMonths(trainSendMonth, trainPeriod)

spark.udf.register("vector_to_array", (v: Vector) => v.toArray)

// ê²½ë¡œ êµ¬ì„± (data_transformation.scalaì™€ ì¼ì¹˜)
val transformerClickPath = s"aos/sto/transformPipelineClick_v${transformedDataVersion}_${trainSendYmList.head}-${trainSendYmList.last}"
val transformerGapPath = s"aos/sto/transformPipelineGap_v${transformedDataVersion}_${trainSendYmList.head}-${trainSendYmList.last}"
val trainDataPath = s"aos/sto/transformedTrainDF_v${transformedDataVersion}_${trainSendYmList.head}-${trainSendYmList.last}"
val testDataPath = s"aos/sto/transformedTestDF_v${transformedDataVersion}_${predictionDTSta}-${predictionDTEnd}"

// ëª¨ë¸ ì €ì¥ ë²„ì „
val modelVersion = "1"  // ëª¨ë¸ ì €ì¥ ë²„ì „ ë²ˆí˜¸

// Feature column ì´ë¦„ (data_transformation.scalaì™€ ì¼ì¹˜)
val indexedLabelColClick = "click_yn"
val indexedLabelColGap = "hour_gap"
val indexedLabelColReg = "res_utility"

val indexedFeatureColClick = "indexedFeaturesClick"
val scaledFeatureColClick = "scaledFeaturesClick"
val selectedFeatureColClick = "selectedFeaturesClick"

val indexedFeatureColGap = "indexedFeaturesGap"
val scaledFeatureColGap = "scaledFeaturesGap"
val selectedFeatureColGap = "selectedFeaturesGap"

println("=" * 80)
println("Configuration Summary")
println("=" * 80)
println(s"Data Configuration:")
println(s"  - Transformed Data Version: $transformedDataVersion")
println(s"  - Model Version: $modelVersion")
println(s"  - Training Period: ${trainSendYmList.head} ~ ${trainSendYmList.last} ($trainPeriod months)")
println(s"  - Test Period: $predictionDTSta ~ $predictionDTEnd")
println()
println(s"Data Paths:")
println(s"  - Click Transformer: $transformerClickPath")
println(s"  - Gap Transformer: $transformerGapPath")
println(s"  - Training Data: $trainDataPath")
println(s"  - Test Data: $testDataPath")
println("=" * 80)


// ===== Paragraph 3: Load Transformers and Transformed Data =====

println("=" * 80)
println("Loading Transformers and Transformed Data")
println("=" * 80)

// 1. Transformer ë¡œë”©
println(s"Loading Click transformer from: $transformerClickPath")
val transformerClick = PipelineModel.load(transformerClickPath)
println("Click transformer loaded successfully")

println(s"Loading Gap transformer from: $transformerGapPath")
val transformerGap = PipelineModel.load(transformerGapPath)
println("Gap transformer loaded successfully")

// 2. Transformed training data ë¡œë”©
// âœ… persist í•„ìš”: Click/Gap/Reg ëª¨ë¸ì—ì„œ ì—¬ëŸ¬ ë²ˆ ì¬ì‚¬ìš© (3íšŒ)
println(s"Loading transformed training data from: $trainDataPath")
val transformedTrainDF = spark.read.parquet(trainDataPath)
    .persist(StorageLevel.MEMORY_AND_DISK_SER)

println("Transformed training data loaded and cached")

// 3. Transformed test data ë¡œë”©
// âœ… persist í•„ìš”: Paragraph 9ì—ì„œ ì˜ˆì¸¡ ìƒì„± ì‹œ ì¬ì‚¬ìš© (2íšŒ)
println(s"Loading transformed test data from: $testDataPath")
val transformedTestDF = spark.read.parquet(testDataPath)
    .persist(StorageLevel.MEMORY_AND_DISK_SER)

println("Transformed test data loaded and cached")
println("=" * 80)


// ===== Paragraph 4: ML Model Definitions =====

println("=" * 80)
println("Defining ML Models")
println("=" * 80)

// ========================================
// Click ì˜ˆì¸¡ ëª¨ë¸ ì •ì˜
// ========================================

// GBTClassifier for Click
val gbtc = new GBTClassifier("gbtc_click")
  .setLabelCol(indexedLabelColClick)
  .setFeaturesCol(indexedFeatureColClick)
  .setMaxIter(100)
  .setMaxDepth(4)
  .setFeatureSubsetStrategy("auto")
  .setPredictionCol("pred_gbtc_click")
  .setProbabilityCol("prob_gbtc_click")
  .setRawPredictionCol("pred_raw_gbtc_click")

println("GBT Click model defined")

// FMClassifier for Click
val fmc = new FMClassifier("fmc_click")
  .setLabelCol(indexedLabelColClick)
  .setFeaturesCol(indexedFeatureColClick)
  .setStepSize(0.01)
  .setPredictionCol("pred_fmc_click")
  .setProbabilityCol("prob_fmc_click")
  .setRawPredictionCol("pred_raw_fmc_click")

println("FM Click model defined")

// XGBoost for Click
val xgbc = new XGBoostClassifier("xgbc_click")
    .setLabelCol(indexedLabelColClick)
    .setFeaturesCol(indexedFeatureColClick)
    .setMissing(0)
    .setSeed(0)
    .setMaxDepth(4)
    .setObjective("binary:logistic")
    .setNumRound(50)
    .setWeightCol("sample_weight")
    .setNumWorkers(10)
    .setEvalMetric("auc")
    .setProbabilityCol("prob_xgbc_click")
    .setPredictionCol("pred_xgbc_click")
    .setRawPredictionCol("pred_raw_xgbc_click")

println("XGBoost Click model defined")

// LightGBM for Click
val lgbmc = new LightGBMClassifier("lgbmc_click")
  .setLabelCol(indexedLabelColClick)
  .setFeaturesCol(indexedFeatureColClick)
  .setObjective("binary")
  .setNumIterations(50)
  .setMaxDepth(4)
  .setNumLeaves(63)
  .setNumTasks(10)
  .setSeed(0)
  .setProbabilityCol("prob_lgbmc_click")
  .setPredictionCol("pred_lgbmc_click")
  .setRawPredictionCol("pred_raw_lgbmc_click")
  .setMetric("binary_error")
  .setBoostingType("gbdt")
  .setFeatureFraction(0.8)
  .setBaggingFraction(0.8)
  .setBaggingFreq(5)

println("LightGBM Click model defined")

// ========================================
// Gap ì˜ˆì¸¡ ëª¨ë¸ ì •ì˜
// ========================================

// GBT for Gap
val gbtg = new GBTClassifier("gbtc_gap")
  .setLabelCol(indexedLabelColGap)
  .setFeaturesCol(indexedFeatureColGap)
  .setMaxIter(100)
  .setMaxDepth(6)
  .setStepSize(0.1)
  .setSubsamplingRate(0.8)
  .setFeatureSubsetStrategy("sqrt")
  .setMinInstancesPerNode(10)
  .setMinInfoGain(0.001)
  .setPredictionCol("pred_gbtc_gap")
  .setProbabilityCol("prob_gbtc_gap")
  .setRawPredictionCol("pred_raw_gbtc_gap")

println("GBT Gap model defined")

// XGBoost for Gap
val xgbg = new XGBoostClassifier("xgbc_gap")
    .setLabelCol(indexedLabelColGap)
    .setFeaturesCol(indexedFeatureColGap)
    .setMissing(0)
    .setSeed(0)
    .setMaxDepth(4)
    .setObjective("binary:logistic")
    .setNumRound(50)
    .setNumWorkers(10)
    .setEvalMetric("auc")
    .setProbabilityCol("prob_xgbc_gap")
    .setPredictionCol("pred_xgbc_gap")
    .setRawPredictionCol("pred_raw_xgbc_gap")

println("XGBoost Gap model defined")

// ========================================
// Response Utility Regression ëª¨ë¸ ì •ì˜
// ========================================

// XGBoost for Regression
val xgbr = new XGBoostRegressor("xgbr")
  .setLabelCol(indexedLabelColReg)
  .setFeaturesCol(indexedFeatureColGap)
  .setMissing(0)
  .setSeed(0)
  .setMaxDepth(6)
  .setObjective("reg:squarederror")
  .setNumRound(100)
  .setNumWorkers(10)
  .setEvalMetric("rmse")
  .setPredictionCol("pred_xgbr")

println("XGBoost Regression model defined")

println("=" * 80)
println("All models defined successfully")
println("=" * 80)


// ===== Paragraph 5: Click Prediction Model Training =====

println("=" * 80)
println("Training Click Prediction Model")
println("=" * 80)

// í•™ìŠµì— ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ (gbtc, xgbc, fmc, lgbmc ì¤‘ ì„ íƒ)
val modelClickforCV = gbtc  // ê¸°ë³¸ê°’: GBT

val pipelineMLClick = new Pipeline().setStages(Array(modelClickforCV))

// í•™ìŠµ ë°ì´í„° ìƒ˜í”Œë§ ìµœì í™”
// ìƒ˜í”Œë§ ë¹„ìœ¨ ì„¤ì • (neg:pos)
// - 0.3 (3:1) = ê¶Œì¥ (F1 ìµœì )
val negSampleRatioClick = 0.3

println(s"Preparing training samples for Click model...")
println(s"  - Negative sampling ratio: $negSampleRatioClick")
println(s"  - Campaign type filter: Sales")

// âŒ repartition ì œê±°: ML fit ì „ repartitionì€ AQEê°€ ìë™ ìµœì í™”
// âŒ count() ì œê±°: ë“œë¼ì´ë²„ ì•¡ì…˜ ë¶ˆí•„ìš” (ë¡œê¹…ìš©)
val trainSampleClick = transformedTrainDF
    .filter("cmpgn_typ=='Sales'")
    .stat.sampleBy(
        F.col(indexedLabelColClick),
        Map(
            0.0 -> negSampleRatioClick,  // Negative ìƒ˜í”Œë§
            1.0 -> 1.0                   // Positive ì „ì²´ ì‚¬ìš©
        ),
        42L
    )
    .withColumn("sample_weight", F.expr(s"case when $indexedLabelColClick>0.0 then 10.0 else 1.0 end"))

println("Training samples prepared")

println("Training Click prediction model...")
val startTimeClick = System.currentTimeMillis()

val pipelineModelClick = pipelineMLClick.fit(trainSampleClick)

val elapsedClick = (System.currentTimeMillis() - startTimeClick) / 1000
println(s"Click model training completed in ${elapsedClick}s")

println("=" * 80)


// ===== Paragraph 6: Click-to-Action Gap Model Training =====

println("=" * 80)
println("Training Gap Prediction Model")
println("=" * 80)

// í•™ìŠµì— ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ
val modelGapforCV = xgbg  // ê¸°ë³¸ê°’: XGBoost

val pipelineMLGap = new Pipeline().setStages(Array(modelGapforCV))

// Gap ëª¨ë¸ í•™ìŠµ ë°ì´í„° ìƒ˜í”Œë§
val posSampleRatioGap = 0.45

println(s"Preparing training samples for Gap model...")
println(s"  - Positive sampling ratio: $posSampleRatioGap")
println(s"  - Click filter: click_yn > 0")

// âŒ repartition ì œê±°: AQEê°€ ìë™ ìµœì í™”
// âŒ count() ì œê±°: ë“œë¼ì´ë²„ ì•¡ì…˜ ë¶ˆí•„ìš”
val trainSampleGap = transformedTrainDF
    .filter("click_yn>0")
    .stat.sampleBy(
        F.col("hour_gap"),
        Map(
            0.0 -> 1.0,                  // Negative ì „ì²´ ì‚¬ìš©
            1.0 -> posSampleRatioGap     // Positive ìƒ˜í”Œë§
        ),
        42L
    )

println("Training samples prepared")

println("Training Gap prediction model...")
val startTimeGap = System.currentTimeMillis()

val pipelineModelGap = pipelineMLGap.fit(trainSampleGap)

val elapsedGap = (System.currentTimeMillis() - startTimeGap) / 1000
println(s"Gap model training completed in ${elapsedGap}s")

println("=" * 80)


// ===== Paragraph 7: Response Utility Regression Model Training =====

println("=" * 80)
println("Training Response Utility Regression Model")
println("=" * 80)

// í•™ìŠµì— ì‚¬ìš©í•  ëª¨ë¸ ì„ íƒ
val modelRegforCV = xgbr  // ê¸°ë³¸ê°’: XGBoost Regressor

val pipelineMLReg = new Pipeline().setStages(Array(modelRegforCV))

println(s"Preparing training samples for Regression model...")
println(s"  - Click filter: click_yn > 0")

// âœ… persist í•„ìš”: fit()ì—ì„œ ì—¬ëŸ¬ ë²ˆ ì½ìŒ (2íšŒ)
// âŒ repartition ì œê±°: AQEê°€ ìë™ ìµœì í™”
// âŒ count() ì œê±°: ë“œë¼ì´ë²„ ì•¡ì…˜ ë¶ˆí•„ìš”
val trainSampleReg = transformedTrainDF
    .filter("click_yn>0")
    .persist(StorageLevel.MEMORY_AND_DISK_SER)

println("Training samples prepared")

println("Training Regression model...")
val startTimeReg = System.currentTimeMillis()

val pipelineModelReg = pipelineMLReg.fit(trainSampleReg)

val elapsedReg = (System.currentTimeMillis() - startTimeReg) / 1000
println(s"Regression model training completed in ${elapsedReg}s")

trainSampleReg.unpersist()

println("=" * 80)


// ===== Paragraph 8: Save Trained Models =====

println("=" * 80)
println("Saving Trained Models")
println("=" * 80)

// ëª¨ë¸ ì €ì¥ ê²½ë¡œ
val modelClickPath = s"aos/sto/pipelineModelClick_${modelClickforCV.uid}_v${modelVersion}_${trainSendYmList.head}-${trainSendYmList.last}"
val modelGapPath = s"aos/sto/pipelineModelGap_${modelGapforCV.uid}_v${modelVersion}_${trainSendYmList.head}-${trainSendYmList.last}"
// val modelRegPath = s"aos/sto/pipelineModelReg_${modelRegforCV.uid}_v${modelVersion}_${trainSendYmList.head}-${trainSendYmList.last}"

println(s"Saving Click model to: $modelClickPath")
pipelineModelClick.write.overwrite().save(modelClickPath)
println("Click model saved successfully")

println(s"Saving Gap model to: $modelGapPath")
pipelineModelGap.write.overwrite().save(modelGapPath)
println("Gap model saved successfully")

// println(s"Saving Regression model to: $modelRegPath")
// pipelineModelReg.write.overwrite().save(modelRegPath)
// println("Regression model saved successfully")

println("=" * 80)
println("All models saved successfully")
println("=" * 80)


// ===== Paragraph 9: Model Prediction on Test Dataset =====

// í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ë³µ ì œê±° í›„ ì˜ˆì¸¡ - íŒŒí‹°ì…˜ ìµœì í™”
val testDataForPred = transformedTestDF
    .filter("cmpgn_typ=='Sales'")
    .dropDuplicates("svc_mgmt_num", "chnl_typ", "cmpgn_typ", "send_ym", "send_hournum_cd", "click_yn")
    .repartition(400)
    .persist(StorageLevel.MEMORY_AND_DISK_SER)

println("Test data for prediction prepared and cached")

println("Generating Click predictions...")
val predictionsClickDev = pipelineModelClick.transform(testDataForPred)
    .persist(StorageLevel.MEMORY_AND_DISK_SER)

println("Click predictions cached")

println("Generating Gap predictions...")
val predictionsGapDev = pipelineModelGap.transform(testDataForPred)
    .persist(StorageLevel.MEMORY_AND_DISK_SER)

println("Gap predictions cached")


// ===== Paragraph 10: Click Model Performance Evaluation (Precision@K per Hour & MAP) =====

val stagesClick = pipelineModelClick.stages

stagesClick.foreach { stage => 

    val evalModelName = stage.uid  // í•™ìŠµì— ì‚¬ìš©ëœ ëª¨ë¸ì˜ UID ìë™ ì¶”ì¶œ
    val evalModelShortName = evalModelName.replace("_click", "").toUpperCase
        
    println("\n" + "=" * 80)
    println(s"ì‹¤ì œ ì„œë¹„ìŠ¤ í‰ê°€: Precision@K per Hour & MAP")
    println("-" * 80)
    println(s"í‰ê°€ ëª¨ë¸: $evalModelShortName (UID: $evalModelName)")
    
    // ëª¨ë¸ë³„ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶œë ¥
    evalModelName match {
        case "gbtc_click" =>
            println(s"  - maxIter: ${gbtc.getMaxIter}")
            println(s"  - maxDepth: ${gbtc.getMaxDepth}")
            println(s"  - featureSubsetStrategy: ${gbtc.getFeatureSubsetStrategy}")
        case "xgbc_click" =>
            println(s"  - numRound: ${xgbc.getNumRound}")
            println(s"  - maxDepth: ${xgbc.getMaxDepth}")
            println(s"  - objective: ${xgbc.getObjective}")
        case "fmc_click" =>
            println(s"  - stepSize: ${fmc.getStepSize}")
        case "lgbmc_click" =>
            println(s"  - numIterations: ${lgbmc.getNumIterations}")
            println(s"  - learningRate: ${lgbmc.getLearningRate}")
        case _ =>
            println(s"  - Model: $evalModelName")
    }
    println("=" * 80 + "\n")
    
    // ========================================
    // Part 1: Precision@K per Hour (ì‹œê°„ëŒ€ë³„ í‰ê°€)
    // ========================================
    
    println("=" * 80)
    println("Part 1: Precision@K per Hour (ì‹œê°„ëŒ€ë³„ ìƒìœ„ Këª… ì„ íƒ ì‹œ í´ë¦­ë¥ )")
    println("=" * 80)
    
    // ì‹œê°„ëŒ€ë³„ ì‚¬ìš©ì í™•ë¥  ìƒì„±
    // suffix ê¸°ë°˜ ìƒ˜í”Œë§ (shuffle ì—†ì´ ë¹ ë¥´ê²Œ ì²˜ë¦¬)
    val suffixRange = (0 to 8).map(_.toHexString)  // 0~9: ì•½ 62.5% ìƒ˜í”Œë§, 0~f: 100%
    
    val hourlyUserPredictions = predictionsClickDev
        .filter("click_yn >= 0")
        .withColumn("suffix", F.substring(F.col("svc_mgmt_num"), -1, 1))  // ë§ˆì§€ë§‰ ìë¦¬ ì¶”ì¶œ
        .where(s"""suffix in ('${suffixRange.mkString("', '")}')""")  // suffix í•„í„°ë§ (shuffle ì—†ìŒ!)
        .repartition(400)  // íŒŒí‹°ì…˜ ì¦ê°€ë¡œ ë©”ëª¨ë¦¬ ë¶„ì‚°
        .select(
            F.col("svc_mgmt_num"),
            F.col("send_ym"),
            F.col("send_hournum_cd").cast("int").alias("hour"),
            F.col(indexedLabelColClick).alias("actual_click"),
            F.expr(s"vector_to_array(prob_$evalModelName)[1]").alias("click_prob")
        )
        .groupBy("svc_mgmt_num", "send_ym", "hour")
        .agg(
            F.max("click_prob").alias("click_prob"),
            F.max("actual_click").alias("actual_click")
        )
        .repartition(200)  // ì§‘ê³„ í›„ íŒŒí‹°ì…˜ ì¡°ì •
        .persist(StorageLevel.MEMORY_AND_DISK_SER)  // cache â†’ persistë¡œ ë³€ê²½
    
    // K ê°’ë“¤
    val kValues = Array(100, 500, 1000, 2000, 5000, 10000)
    
    println("\nì‹œê°„ëŒ€ë³„ Precision@K:")
    println("-" * 100)
    println(f"Hour | ${"K=100"}%8s | ${"K=500"}%8s | ${"K=1000"}%9s | ${"K=2000"}%9s | ${"K=5000"}%9s | ${"K=10000"}%10s |")
    println("-" * 100)
    
    // ê° ì‹œê°„ëŒ€ë³„ë¡œ ê³„ì‚°
    val hours = (9 to 18).toArray
    
    hours.foreach { hour =>
        val hourData = hourlyUserPredictions.filter(s"hour = $hour")
        
        val precisions = kValues.map { k =>
            // í™•ë¥  ìƒìœ„ Këª… ì„ íƒ
            val topK = hourData
                .orderBy(F.desc("click_prob"))
                .limit(k)
            
            val totalK = topK.count().toDouble
            val clickedK = topK.filter("actual_click > 0").count().toDouble
            
            if (totalK > 0) clickedK / totalK else 0.0
        }
        
        println(f"$hour%4d | ${precisions(0) * 100}%7.2f%% | ${precisions(1) * 100}%7.2f%% | ${precisions(2) * 100}%8.2f%% | ${precisions(3) * 100}%8.2f%% | ${precisions(4) * 100}%8.2f%% | ${precisions(5) * 100}%9.2f%% |")
    }
    
    println("-" * 100)
    
    // ì „ì²´ í‰ê·  (ì‹œê°„ëŒ€ë³„ í‰ê· )
    println("\nì „ì²´ í‰ê·  Precision@K (ì‹œê°„ëŒ€ë³„ í‰ê· ):")
    kValues.foreach { k =>
        val avgPrecision = hours.map { hour =>
            val hourData = hourlyUserPredictions.filter(s"hour = $hour")
            val topK = hourData.orderBy(F.desc("click_prob")).limit(k)
            val totalK = topK.count().toDouble
            val clickedK = topK.filter("actual_click > 0").count().toDouble
            if (totalK > 0) clickedK / totalK else 0.0
        }.sum / hours.length
        
        println(f"  Precision@$k%5d: $avgPrecision%.4f (${avgPrecision * 100}%.2f%%)")
    }
    
    // ========================================
    // Part 1.5: Recall@K per Hour (ì‹œê°„ëŒ€ë³„ ì»¤ë²„ë¦¬ì§€)
    // ========================================
    
    println("\n" + "=" * 80)
    println("Part 1.5: Recall@K per Hour (ì‹œê°„ëŒ€ë³„ ìƒìœ„ Këª…ì´ ì „ì²´ í´ë¦­ì ì¤‘ ì°¨ì§€í•˜ëŠ” ë¹„ìœ¨)")
    println("=" * 80)
    
    println("\nì‹œê°„ëŒ€ë³„ Recall@K:")
    println("-" * 100)
    println(f"Hour | ${"K=100"}%8s | ${"K=500"}%8s | ${"K=1000"}%9s | ${"K=2000"}%9s | ${"K=5000"}%9s | ${"K=10000"}%10s |")
    println("-" * 100)
    
    hours.foreach { hour =>
        val hourData = hourlyUserPredictions.filter(s"hour = $hour")
        val totalClicked = hourData.filter("actual_click > 0").count().toDouble
        
        val recalls = kValues.map { k =>
            // í™•ë¥  ìƒìœ„ Këª… ì„ íƒ
            val topK = hourData
                .orderBy(F.desc("click_prob"))
                .limit(k)
            
            val clickedK = topK.filter("actual_click > 0").count().toDouble
            
            if (totalClicked > 0) clickedK / totalClicked else 0.0
        }
        
        println(f"$hour%4d | ${recalls(0) * 100}%7.2f%% | ${recalls(1) * 100}%7.2f%% | ${recalls(2) * 100}%8.2f%% | ${recalls(3) * 100}%8.2f%% | ${recalls(4) * 100}%8.2f%% | ${recalls(5) * 100}%9.2f%% |")
    }
    
    println("-" * 100)
    
    // ì „ì²´ í‰ê·  Recall
    println("\nì „ì²´ í‰ê·  Recall@K (ì‹œê°„ëŒ€ë³„ í‰ê· ):")
    kValues.foreach { k =>
        val avgRecall = hours.map { hour =>
            val hourData = hourlyUserPredictions.filter(s"hour = $hour")
            val totalClicked = hourData.filter("actual_click > 0").count().toDouble
            val topK = hourData.orderBy(F.desc("click_prob")).limit(k)
            val clickedK = topK.filter("actual_click > 0").count().toDouble
            if (totalClicked > 0) clickedK / totalClicked else 0.0
        }.sum / hours.length
        
        println(f"  Recall@$k%5d: $avgRecall%.4f (${avgRecall * 100}%.2f%%)")
    }
    
    // Precision-Recall íŠ¸ë ˆì´ë“œì˜¤í”„ ë¶„ì„
    println("\n" + "=" * 80)
    println("Precision-Recall íŠ¸ë ˆì´ë“œì˜¤í”„ (ì‹œê°„ëŒ€ë³„ í‰ê· )")
    println("=" * 80)
    println(f"${"K"}%8s | ${"Precision"}%10s | ${"Recall"}%8s | ${"F1-Score"}%10s | ${"í´ë¦­ì/ë°œì†¡"}%12s |")
    println("-" * 80)
    
    kValues.foreach { k =>
        val (avgPrec, avgRec, avgClicked) = hours.map { hour =>
            val hourData = hourlyUserPredictions.filter(s"hour = $hour")
            val totalClicked = hourData.filter("actual_click > 0").count().toDouble
            val topK = hourData.orderBy(F.desc("click_prob")).limit(k)
            val totalK = topK.count().toDouble
            val clickedK = topK.filter("actual_click > 0").count().toDouble
            
            val prec = if (totalK > 0) clickedK / totalK else 0.0
            val rec = if (totalClicked > 0) clickedK / totalClicked else 0.0
            
            (prec, rec, clickedK)
        }.reduce((a, b) => (a._1 + b._1, a._2 + b._2, a._3 + b._3))
        
        val finalPrec = avgPrec / hours.length
        val finalRec = avgRec / hours.length
        val f1 = if (finalPrec + finalRec > 0) 2 * (finalPrec * finalRec) / (finalPrec + finalRec) else 0.0
        val avgClickedPerHour = avgClicked / hours.length
        
        println(f"$k%8d | ${finalPrec * 100}%9.2f%% | ${finalRec * 100}%7.2f%% | $f1%10.4f | ${avgClickedPerHour}%12.1f |")
    }
    
    println("-" * 80)
    println("\nğŸ’¡ í•´ì„:")
    println("- K ì¦ê°€ â†’ Precision ê°ì†Œ, Recall ì¦ê°€ (ì •ìƒ)")
    println("- F1-Score ìµœëŒ€ ì§€ì  = ìµœì  K ê°’")
    println("- ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì— ë”°ë¼ K ì„ íƒ:")
    println("  â€¢ íš¨ìœ¨ ìš°ì„  (ë†’ì€ Precision): ì‘ì€ K")
    println("  â€¢ ì»¤ë²„ë¦¬ì§€ ìš°ì„  (ë†’ì€ Recall): í° K")
    
    // ========================================
    // Part 2: MAP (Mean Average Precision) - IR í‘œì¤€ ë°©ì‹
    // ========================================
    
    println("\n" + "=" * 80)
    println("Part 2: MAP (ì •ë³´ê²€ìƒ‰ í‘œì¤€ ë°©ì‹) - ì‹œê°„ëŒ€ë³„ AP â†’ í‰ê· ")
    println("=" * 80)
    
    println("\nê° ì‹œê°„ëŒ€(ì§ˆì˜ì–´)ë³„ Average Precision:")
    println("-" * 80)
    println(f"${"Hour"}%5s | ${"í´ë¦­ì ìˆ˜"}%10s | ${"AP"}%8s | ${"ì„¤ëª…"}%40s")
    println("-" * 80)
    
    // ê° ì‹œê°„ëŒ€ë³„ë¡œ AP ê³„ì‚°
    val hourlyAPs = hours.map { hour =>
        val hourData = hourlyUserPredictions
            .filter(s"hour = $hour")
            .orderBy(F.desc("click_prob"))  // í™•ë¥  ìˆœ ì •ë ¬
            .withColumn("rank", F.row_number().over(Window.orderBy(F.desc("click_prob"))).cast("long"))
            .cache()
        
        val totalClicked = hourData.filter("actual_click > 0").count()
        
        if (totalClicked > 0) {
            // í´ë¦­í•œ ì‚¬ìš©ìë“¤ì˜ ìˆœìœ„
            val clickedRanks = hourData
                .filter("actual_click > 0")
                .select("rank")
                .collect()
                .map { row =>
                    // íƒ€ì… ì•ˆì „í•˜ê²Œ ì²˜ë¦¬
                    val rank = row.get(0) match {
                        case i: Int => i.toLong
                        case l: Long => l
                        case _ => row.getLong(0)
                    }
                    rank.toDouble
                }
            
            // AP ê³„ì‚°: sum(precision@rank) / total_relevant
            val ap = clickedRanks.zipWithIndex.map { case (rank, idx) =>
                (idx + 1).toDouble / rank  // precision@rank = (idx+1) / rank
            }.sum / totalClicked
            
            hourData.unpersist()
            (hour, totalClicked, ap)
        } else {
            hourData.unpersist()
            (hour, 0L, 0.0)
        }
    }
    
    // ì‹œê°„ëŒ€ë³„ AP ì¶œë ¥
    hourlyAPs.foreach { case (hour, clicked, ap) =>
        val desc = if (clicked > 0) {
            f"ìƒìœ„ ìˆœìœ„ì— í´ë¦­ì ë°°ì¹˜ í’ˆì§ˆ"
        } else {
            "í´ë¦­ ì—†ìŒ"
        }
        println(f"$hour%5d | $clicked%10d | $ap%8.4f | $desc%-40s")
    }
    
    println("-" * 80)
    
    // MAP ê³„ì‚° (í´ë¦­ì´ ìˆëŠ” ì‹œê°„ëŒ€ë§Œ)
    val validAPs = hourlyAPs.filter(_._2 > 0)
    val map = if (validAPs.nonEmpty) {
        validAPs.map(_._3).sum / validAPs.length
    } else {
        0.0
    }
    
    println(f"\nâ˜… MAP (Mean Average Precision): $map%.4f")
    println(f"   í‰ê°€ ëŒ€ìƒ ì‹œê°„ëŒ€: ${validAPs.length}/10")
    println(f"   í•´ì„: ê° ì‹œê°„ëŒ€ë³„ë¡œ í´ë¦­ìë¥¼ ì–¼ë§ˆë‚˜ ìƒìœ„ì— ë­í‚¹í–ˆëŠ”ì§€ í‰ê· ")
    println(f"   ê¸°ì¤€: MAP > 0.3 (ì–‘í˜¸), > 0.5 (ìš°ìˆ˜), > 0.7 (ë§¤ìš° ìš°ìˆ˜)")
    
    // ========================================
    // Part 2.5: ì‚¬ìš©ìë³„ MAP (ë³´ì¡° ì§€í‘œ - ë¹„í‘œì¤€)
    // ========================================
    
    println("\n" + "=" * 80)
    println("Part 2.5: ì‚¬ìš©ìë³„ MAP (ë³´ì¡° ì§€í‘œ - ì‚¬ìš©ì ê´€ì )")
    println("=" * 80)
    
    // ê° ì‚¬ìš©ìë³„ ì‹œê°„ëŒ€ë³„ í™•ë¥  ë° í´ë¦­ ì—¬ë¶€
    val userAPData = predictionsClickDev
        .filter("click_yn >= 0")
        .select(
            F.col("svc_mgmt_num"),
            F.col("send_ym"),
            F.col("send_hournum_cd").cast("int").alias("hour"),
            F.col(indexedLabelColClick).alias("actual_click"),
            F.expr("vector_to_array(prob_gbtc_click)[1]").alias("click_prob")
        )
        .groupBy("svc_mgmt_num", "send_ym")
        .agg(
            F.collect_list(
                F.struct(
                    F.col("hour"),
                    F.col("click_prob"),
                    F.col("actual_click")
                )
            ).alias("hourly_data")
        )
        .withColumn("hourly_data_sorted", 
            F.expr("array_sort(hourly_data, (left, right) -> case when left.click_prob > right.click_prob then -1 when left.click_prob < right.click_prob then 1 else 0 end)")
        )
        .withColumn("clicked_hours_count",
            F.expr("size(filter(hourly_data, x -> x.actual_click > 0))")
        )
        .filter("clicked_hours_count > 0")  // ì‹¤ì œ í´ë¦­ì´ ìˆëŠ” ì‚¬ìš©ìë§Œ
        .withColumn("ap", 
            F.expr("""
                aggregate(
                    sequence(0, size(hourly_data_sorted) - 1),
                    cast(0.0 as double),
                    (acc, i) -> case 
                        when element_at(hourly_data_sorted, i + 1).actual_click > 0 
                        then acc + (
                            size(filter(slice(hourly_data_sorted, 1, i + 1), x -> x.actual_click > 0)) 
                            / cast(i + 1 as double)
                        )
                        else acc
                    end
                ) / clicked_hours_count
            """)
        )
        .cache()
    
    val userMAP = userAPData
        .agg(F.avg("ap"))
        .first()
        .getDouble(0)
    
    val totalUsersMAP = userAPData.count()
    
    println(f"\nì‚¬ìš©ìë³„ MAP: $userMAP%.4f")
    println(f"  â†’ í‰ê°€ ëŒ€ìƒ ì‚¬ìš©ì ìˆ˜: $totalUsersMAP")
    println(f"  â†’ ì˜ë¯¸: ê° ì‚¬ìš©ìë³„ë¡œ í´ë¦­ ì‹œê°„ëŒ€ë¥¼ ì–¼ë§ˆë‚˜ ìƒìœ„ì— ì˜ˆì¸¡í–ˆëŠ”ì§€")
    println(f"  â†’ ì£¼ì˜: IR í‘œì¤€ MAPê³¼ ë‹¤ë¦„! ë³´ì¡° ì§€í‘œë¡œë§Œ í™œìš©")
    
    // AP ë¶„í¬
    println("\nì‚¬ìš©ìë³„ AP ë¶„í¬:")
    userAPData
        .selectExpr("floor(ap * 10) / 10 as ap_bucket")
        .groupBy("ap_bucket")
        .count()
        .orderBy("ap_bucket")
        .withColumn("percentage", F.expr(s"count * 100.0 / $totalUsersMAP"))
        .show(10, false)
    
    // ========================================
    // Part 3: ë³´ì¡° ì§€í‘œ (ì°¸ê³ ìš©)
    // ========================================
    
    println("\n" + "=" * 80)
    println("Part 3: ë³´ì¡° ì§€í‘œ (ì‚¬ìš©ìë³„ Top-K Accuracy - ì°¸ê³ ìš©)")
    println("=" * 80)
    
    val userMetrics = userAPData
        .withColumn("top1_hour", F.expr("hourly_data_sorted[0].hour"))
        .withColumn("actual_click_hours", 
            F.expr("transform(filter(hourly_data, x -> x.actual_click > 0), x -> x.hour)")
        )
        .withColumn("top1_match", 
            F.expr("array_contains(actual_click_hours, top1_hour)")
        )
        .withColumn("top3_hours",
            F.expr("transform(slice(hourly_data_sorted, 1, 3), x -> x.hour)")
        )
        .withColumn("top3_match",
            F.expr("size(array_intersect(top3_hours, actual_click_hours)) > 0")
        )
        .cache()
    
    val top1Acc = userMetrics.filter("top1_match").count().toDouble / totalUsersMAP
    val top3Acc = userMetrics.filter("top3_match").count().toDouble / totalUsersMAP
    
    println(f"Top-1 Accuracy: $top1Acc%.4f (${top1Acc * 100}%.2f%%)")
    println(f"  â†’ ëœë¤ ëŒ€ë¹„: ${top1Acc / 0.1}%.2fë°°")
    println(f"Top-3 Accuracy: $top3Acc%.4f (${top3Acc * 100}%.2f%%)")
    
    println("\n" + "=" * 80)
    println("ğŸ’¡ ì¢…í•© í•´ì„ ê°€ì´ë“œ (ì •ë³´ê²€ìƒ‰ ê´€ì )")
    println("=" * 80)
    println("\nâ˜… ì •ë³´ê²€ìƒ‰ ì‹œìŠ¤í…œ ë§¤í•‘:")
    println("  ì§ˆì˜ì–´(Query)  â†’ ì‹œê°„ëŒ€ (9ì‹œ, 10ì‹œ, ..., 18ì‹œ)")
    println("  ë¬¸ì„œ(Document) â†’ ì‚¬ìš©ì")
    println("  ê´€ë ¨ì„±         â†’ í•´ë‹¹ ì‹œê°„ëŒ€ í´ë¦­ ì—¬ë¶€")
    println("  ê²€ìƒ‰ ê²°ê³¼      â†’ í™•ë¥  ìˆœ ì‚¬ìš©ì ë¦¬ìŠ¤íŠ¸")
    
    println("\n1. Precision@K per Hour (IR í‘œì¤€ âœ“):")
    println("   - ì˜ë¯¸: ì§ˆì˜ì–´(ì‹œê°„ëŒ€) qì— ëŒ€í•´ ìƒìœ„ Kê°œ ë¬¸ì„œ(ì‚¬ìš©ì) ì¤‘ ê´€ë ¨ ë¬¸ì„œ ë¹„ìœ¨")
    println("   - í™œìš©: ê° ì‹œê°„ëŒ€ë³„ ë°œì†¡ ì¸ì›(K) ê²°ì •")
    println("   - ì „ëµ: ë†’ì€ Precision ì‹œê°„ëŒ€ì— ë” ë§ì€ ì˜ˆì‚°")
    
    println("\n2. Recall@K per Hour (IR í‘œì¤€ âœ“):")
    println("   - ì˜ë¯¸: ì§ˆì˜ì–´(ì‹œê°„ëŒ€) qì— ëŒ€í•´ ì „ì²´ ê´€ë ¨ ë¬¸ì„œ ì¤‘ ìƒìœ„ Kê°œì— í¬í•¨ëœ ë¹„ìœ¨")
    println("   - í™œìš©: Kì— ë”°ë¥¸ ì»¤ë²„ë¦¬ì§€ íŒŒì•…")
    println("   - ì „ëµ: ëª©í‘œ Recall ë‹¬ì„±ì„ ìœ„í•œ ìµœì†Œ K ê²°ì •")
    
    println("\n3. Precision-Recall íŠ¸ë ˆì´ë“œì˜¤í”„:")
    println("   - F1-Score ìµœëŒ€ ì§€ì  = íš¨ìœ¨ê³¼ ì»¤ë²„ë¦¬ì§€ ê· í˜•ì ")
    println("   - ë¹„ì¦ˆë‹ˆìŠ¤ ëª©í‘œì— ë”°ë¼ K ì„ íƒ")
    
    println("\n4. MAP - ì‹œê°„ëŒ€ë³„ (IR í‘œì¤€ âœ“):")
    println("   - ì˜ë¯¸: ê° ì§ˆì˜ì–´(ì‹œê°„ëŒ€)ë³„ APë¥¼ í‰ê· ")
    println("   - AP = ê° ê´€ë ¨ ë¬¸ì„œ(í´ë¦­ì)ì˜ ìˆœìœ„ì—ì„œ precision í‰ê· ")
    println("   - í™œìš©: ì „ì²´ ëª¨ë¸ í’ˆì§ˆ í‰ê°€, ëª¨ë¸ ê°„ ë¹„êµ")
    println("   - ê¸°ì¤€: MAP > 0.3 (ì–‘í˜¸), > 0.5 (ìš°ìˆ˜), > 0.7 (ë§¤ìš° ìš°ìˆ˜)")
    
    println("\n5. ì‚¬ìš©ìë³„ MAP (ë¹„í‘œì¤€, ë³´ì¡°):")
    println("   - ì˜ë¯¸: ê° ì‚¬ìš©ìë³„ë¡œ í´ë¦­ ì‹œê°„ëŒ€ë¥¼ ì–¼ë§ˆë‚˜ ìƒìœ„ì— ì˜ˆì¸¡í–ˆëŠ”ì§€")
    println("   - ì£¼ì˜: IR í‘œì¤€ê³¼ ë‹¤ë¦„! ê´€ì ì´ ë°˜ëŒ€ (ì‚¬ìš©ì ì¤‘ì‹¬)")
    println("   - í™œìš©: Top-K Accuracyì™€ ìœ ì‚¬, ë³´ì¡° ì§€í‘œë¡œë§Œ ì‚¬ìš©")
    
    println("\n6. Top-K Accuracy (ë³´ì¡°):")
    println("   - ì‚¬ìš©ì ê´€ì  í‰ê°€")
    println("   - ëœë¤ ëŒ€ë¹„ ì„±ëŠ¥ í™•ì¸")
    
    println("\nâ˜… í‘œì¤€ IR í‰ê°€ vs ìš°ë¦¬ í‰ê°€:")
    println("  âœ“ Precision@K per Hour: ì™„ë²½íˆ ì¼ì¹˜")
    println("  âœ“ Recall@K per Hour: ì™„ë²½íˆ ì¼ì¹˜")
    println("  âœ“ MAP (ì‹œê°„ëŒ€ë³„): ì™„ë²½íˆ ì¼ì¹˜")
    println("  âš  ì‚¬ìš©ìë³„ MAP: ë¹„í‘œì¤€ (ë³´ì¡°ìš©)")
    
    println("\nì‹¤ì „ í™œìš© ì˜ˆì‹œ:")
    println("  ëª©í‘œ: ì‹œê°„ë‹¹ 1000ëª… ë°œì†¡, ìµœì†Œ Recall 20%")
    println("  â†’ Recall@1000 >= 20%ì¸ ì‹œê°„ëŒ€ ì„ íƒ")
    println("  â†’ í•´ë‹¹ ì‹œê°„ëŒ€ì˜ Precision@1000 í™•ì¸ (ì˜ˆìƒ í´ë¦­ë¥ )")
    println("  â†’ MAPìœ¼ë¡œ ì „ì²´ ëª¨ë¸ í’ˆì§ˆ ì¶”ì ")
    
    // ========================================
    // ë¡œê·¸ ì €ì¥ìš© ë°ì´í„° ì‚¬ì „ ìˆ˜ì§‘ (unpersist ì „ì— ëª¨ë“  ê³„ì‚° ì™„ë£Œ)
    // ========================================
    println("\në¡œê·¸ ì €ì¥ì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘ ì¤‘...")
    
    // Precision@Kì™€ Recall@Kë¥¼ í•œ ë²ˆì— ê³„ì‚°í•˜ì—¬ ë¡œì»¬ë¡œ ìˆ˜ì§‘
    val precisionRecallResults = hours.map { hour =>
        val hourData = hourlyUserPredictions.filter(s"hour = $hour")
        val totalClicked = hourData.filter("actual_click > 0").count().toDouble
        
        val metricsPerK = kValues.map { k =>
            val topK = hourData.orderBy(F.desc("click_prob")).limit(k)
            val totalK = topK.count().toDouble
            val clickedK = topK.filter("actual_click > 0").count().toDouble
            
            val precision = if (totalK > 0) clickedK / totalK else 0.0
            val recall = if (totalClicked > 0) clickedK / totalClicked else 0.0
            
            (precision, recall)
        }
        
        (hour, metricsPerK)
    }
    
    // MAP ë° User Metricsë¥¼ ë¡œì»¬ ë³€ìˆ˜ë¡œ ì €ì¥
    val mapValue = map
    val validAPsLength = validAPs.length
    val userMAPValue = userMAP
    val totalUsersMAPValue = totalUsersMAP
    
    println("ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ. ë©”ëª¨ë¦¬ í•´ì œ ì¤‘...")
    
    // ì´ì œ ì•ˆì „í•˜ê²Œ unpersist
    hourlyUserPredictions.unpersist()
    userAPData.unpersist()
    userMetrics.unpersist()
    
    println("ë©”ëª¨ë¦¬ í•´ì œ ì™„ë£Œ. ë¡œê·¸ ì €ì¥ ì‹œì‘...")
    
    // ========================================
    // í‰ê°€ ê²°ê³¼ ë¡œê·¸ ì €ì¥ (ìˆ˜ì§‘ëœ ë¡œì»¬ ë°ì´í„° ì‚¬ìš©)
    // ========================================
    import java.io.{File, PrintWriter}
    import java.time.LocalDateTime
    import java.time.format.DateTimeFormatter
    
    val logDir = new File("/data/myfiles/aos_ost/predict")
    if (!logDir.exists()) logDir.mkdirs()
    
    val timestamp = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyyMMdd_HHmmss"))
    val logFile = new File(logDir, s"click_model_eval_${evalModelName}_${timestamp}.log")
    val writer = new PrintWriter(logFile)
    
    try {
        writer.println("=" * 80)
        writer.println(s"Click Model Evaluation Log - $timestamp")
        writer.println("=" * 80)
        writer.println()
        
        // ëª¨ë¸ ì •ë³´
        writer.println("[Model Information]")
        writer.println(s"Model: $evalModelShortName (UID: $evalModelName)")
        evalModelName match {
            case "gbtc_click" =>
                writer.println(s"  - maxIter: ${gbtc.getMaxIter}")
                writer.println(s"  - maxDepth: ${gbtc.getMaxDepth}")
                writer.println(s"  - featureSubsetStrategy: ${gbtc.getFeatureSubsetStrategy}")
            case "xgbc_click" =>
                writer.println(s"  - numRound: ${xgbc.getNumRound}")
                writer.println(s"  - maxDepth: ${xgbc.getMaxDepth}")
                writer.println(s"  - objective: ${xgbc.getObjective}")
            case "fmc_click" =>
                writer.println(s"  - stepSize: ${fmc.getStepSize}")
            case "lgbmc_click" =>
                writer.println(s"  - numIterations: ${lgbmc.getNumIterations}")
                writer.println(s"  - learningRate: ${lgbmc.getLearningRate}")
            case _ =>
                writer.println(s"  - Model: $evalModelName")
        }
        writer.println()
        
        // í•™ìŠµ ë°ì´í„° ì •ë³´
        writer.println("[Training Data Information]")
        writer.println(s"Negative Sample Ratio: $negSampleRatioClick")
        writer.println(s"Positive Sample Ratio: 1.0 (ì „ì²´ ì‚¬ìš©)")
        writer.println(s"Sample Strategy: stat.sampleBy")
        writer.println(s"Estimated neg:pos ratio: ${(negSampleRatioClick * 100).toInt}:100")
        writer.println()
        
        // Precision@K ê²°ê³¼ ì €ì¥ (ìˆ˜ì§‘ëœ ë°ì´í„° ì‚¬ìš©)
        writer.println("[Precision@K per Hour]")
        writer.println(f"${"Hour"}%5s | ${"K=100"}%7s | ${"K=500"}%7s | ${"K=1000"}%8s | ${"K=2000"}%8s | ${"K=5000"}%8s | ${"K=10000"}%9s")
        writer.println("-" * 75)
        
        precisionRecallResults.foreach { case (hour, metricsPerK) =>
            val precisions = metricsPerK.map(_._1)
            writer.println(f"$hour%5d | ${precisions(0)*100}%6.2f%% | ${precisions(1)*100}%6.2f%% | ${precisions(2)*100}%7.2f%% | ${precisions(3)*100}%7.2f%% | ${precisions(4)*100}%7.2f%% | ${precisions(5)*100}%8.2f%%")
        }
        
        // í‰ê·  Precision@K
        writer.println("-" * 75)
        val avgPrecisions = kValues.indices.map { idx =>
            precisionRecallResults.map(_._2(idx)._1).sum / precisionRecallResults.length
        }
        writer.print(f"${"Avg"}%5s")
        avgPrecisions.foreach { avg =>
            writer.print(f" | ${avg*100}%6.2f%%")
        }
        writer.println()
        writer.println()
        
        // Recall@K ê²°ê³¼ ì €ì¥ (ìˆ˜ì§‘ëœ ë°ì´í„° ì‚¬ìš©)
        writer.println("[Recall@K per Hour]")
        writer.println(f"${"Hour"}%5s | ${"K=100"}%7s | ${"K=500"}%7s | ${"K=1000"}%8s | ${"K=2000"}%8s | ${"K=5000"}%8s | ${"K=10000"}%9s")
        writer.println("-" * 75)
        
        precisionRecallResults.foreach { case (hour, metricsPerK) =>
            val recalls = metricsPerK.map(_._2)
            writer.println(f"$hour%5d | ${recalls(0)*100}%6.2f%% | ${recalls(1)*100}%6.2f%% | ${recalls(2)*100}%7.2f%% | ${recalls(3)*100}%7.2f%% | ${recalls(4)*100}%7.2f%% | ${recalls(5)*100}%8.2f%%")
        }
        
        // í‰ê·  Recall@K
        writer.println("-" * 75)
        val avgRecalls = kValues.indices.map { idx =>
            precisionRecallResults.map(_._2(idx)._2).sum / precisionRecallResults.length
        }
        writer.print(f"${"Avg"}%5s")
        avgRecalls.foreach { avg =>
            writer.print(f" | ${avg*100}%6.2f%%")
        }
        writer.println()
        writer.println()
        
        // MAP ê²°ê³¼ ì €ì¥ (ìˆ˜ì§‘ëœ ë°ì´í„° ì‚¬ìš©)
        writer.println("[MAP - Mean Average Precision]")
        writer.println(f"MAP (ì‹œê°„ëŒ€ë³„): $mapValue%.4f")
        writer.println(f"Evaluated Hours: $validAPsLength/10")
        writer.println(f"User-based MAP: $userMAPValue%.4f")
        writer.println(f"Evaluated Users: $totalUsersMAPValue")
        writer.println()
        
        // í•´ì„ ê°€ì´ë“œ
        writer.println("[Interpretation Guide]")
        writer.println("- Precision@K: ìƒìœ„ Këª… ë°œì†¡ ì‹œ í´ë¦­ë¥ ")
        writer.println("- Recall@K: ì „ì²´ í´ë¦­ì ì¤‘ ìƒìœ„ Këª…ì— í¬í•¨ëœ ë¹„ìœ¨")
        writer.println("- MAP > 0.3: ì–‘í˜¸, > 0.5: ìš°ìˆ˜, > 0.7: ë§¤ìš° ìš°ìˆ˜")
        writer.println()
        
        writer.println("=" * 80)
        writer.println("Log saved successfully!")
        
        println(s"\nâœ… Click Model í‰ê°€ ê²°ê³¼ ë¡œê·¸ ì €ì¥: ${logFile.getAbsolutePath}")
        
    } finally {
        writer.close()
    }
}


// ===== Paragraph 11: Gap Model Performance Evaluation (Precision, Recall, F1) =====

val stagesGap = pipelineModelGap.stages

stagesGap.foreach { stage => 
    
    val modelName = stage.uid
    
    println(s"Evaluating model: $modelName")
    
    // ì§‘ê³„ ë° í‰ê°€ìš© ë°ì´í„° ì¤€ë¹„ - íŒŒí‹°ì…˜ ìµœì í™”
    val aggregatedPredictionsGap = predictionsGapDev
        .filter("click_yn>0")
        .withColumn("prob", F.expr(s"vector_to_array(prob_$modelName)[1]"))
        .repartition(100, F.col("svc_mgmt_num"))  // GroupBy ì „ íŒŒí‹°ì…”ë‹
        .groupBy("svc_mgmt_num", "send_ym", "send_hournum_cd")
        .agg(F.sum(indexedLabelColGap).alias(indexedLabelColGap), F.max("prob").alias("prob"))
        .withColumn(indexedLabelColGap, F.expr(s"case when $indexedLabelColGap>0 then cast(1.0 AS DOUBLE) else cast(0.0 AS DOUBLE) end"))
        .withColumn("prediction_gap", F.expr("case when prob>=0.5 then cast(1.0 AS DOUBLE) else cast(0.0 AS DOUBLE) end"))
        .sample(false, 0.3, 42)  // â† 30% ìƒ˜í”Œë§ ì¶”ê°€
        .repartition(50)  // ìƒ˜í”Œë§ í›„ íŒŒí‹°ì…˜ ì¬ì¡°ì •
        .persist(StorageLevel.MEMORY_AND_DISK_SER)
    
    // ========================================
    // ì™„ì „ ë¶„ì‚° í‰ê°€ (Driver ìˆ˜ì§‘ ì—†ìŒ, ë§¤ìš° ë¹ ë¦„!)
    // ========================================
    
    println(s"######### $modelName ì˜ˆì¸¡ ê²°ê³¼ #########")
    
    // 1. DataFrame ì—°ì‚°ìœ¼ë¡œ Confusion Matrix ê³„ì‚° (ì™„ì „ ë¶„ì‚°)
    val confusionDF = aggregatedPredictionsGap
        .groupBy(indexedLabelColGap, "prediction_gap")
        .count()
        .cache()
    
    // 2. TP, FP, TN, FN ê³„ì‚° (ë¶„ì‚° ì—°ì‚°)
    val tp = confusionDF.filter(s"$indexedLabelColGap = 1.0 AND prediction_gap = 1.0").select("count").first().getLong(0).toDouble
    val fp = confusionDF.filter(s"$indexedLabelColGap = 0.0 AND prediction_gap = 1.0").select("count").first().getLong(0).toDouble
    val tn = confusionDF.filter(s"$indexedLabelColGap = 0.0 AND prediction_gap = 0.0").select("count").first().getLong(0).toDouble
    val fn = confusionDF.filter(s"$indexedLabelColGap = 1.0 AND prediction_gap = 0.0").select("count").first().getLong(0).toDouble
    
    // 3. ì§€í‘œ ê³„ì‚° (Driverì—ì„œ ê°„ë‹¨í•œ ê³„ì‚°ë§Œ)
    val precision_1 = if (tp + fp > 0) tp / (tp + fp) else 0.0
    val recall_1 = if (tp + fn > 0) tp / (tp + fn) else 0.0
    val f1_1 = if (precision_1 + recall_1 > 0) 2 * (precision_1 * recall_1) / (precision_1 + recall_1) else 0.0
    
    val precision_0 = if (tn + fn > 0) tn / (tn + fn) else 0.0
    val recall_0 = if (tn + fp > 0) tn / (tn + fp) else 0.0
    val f1_0 = if (precision_0 + recall_0 > 0) 2 * (precision_0 * recall_0) / (precision_0 + recall_0) else 0.0
    
    val accuracy = (tp + tn) / (tp + tn + fp + fn)
    val total = tp + tn + fp + fn
    
    val weightedPrecision = (precision_1 * (tp + fn) + precision_0 * (tn + fp)) / total
    val weightedRecall = (recall_1 * (tp + fn) + recall_0 * (tn + fp)) / total
    
    // 4. BinaryClassificationEvaluatorë¡œ AUC ê³„ì‚° (ë¶„ì‚°)
    val binaryEvaluator = new BinaryClassificationEvaluator()
        .setLabelCol(indexedLabelColGap)
        .setRawPredictionCol("prob")
        .setMetricName("areaUnderROC")
    val auc = binaryEvaluator.evaluate(aggregatedPredictionsGap)
    
    // 5. ê²°ê³¼ ì¶œë ¥
    println("--- ë ˆì´ë¸”ë³„ ì„±ëŠ¥ ì§€í‘œ ---")
    println(f"Label 0.0 (í´ë˜ìŠ¤): Precision = $precision_0%.4f, Recall = $recall_0%.4f, F1 = $f1_0%.4f")
    println(f"Label 1.0 (í´ë˜ìŠ¤): Precision = $precision_1%.4f, Recall = $recall_1%.4f, F1 = $f1_1%.4f")
    
    println(f"\nWeighted Precision (ì „ì²´ í‰ê· ): $weightedPrecision%.4f")
    println(f"Weighted Recall (ì „ì²´ í‰ê· ): $weightedRecall%.4f")
    println(f"Accuracy (ì „ì²´ ì •í™•ë„): $accuracy%.4f")
    println(f"AUC (Area Under ROC): $auc%.4f")
    
    println("\n--- Confusion Matrix (í˜¼ë™ í–‰ë ¬) ---")
    println(f"              Predicted 0    Predicted 1")
    println(f"Actual 0:     ${tn}%.0f         ${fp}%.0f")
    println(f"Actual 1:     ${fn}%.0f         ${tp}%.0f")
    
    // ========================================
    // ë¡œê·¸ ì €ì¥ìš© ë°ì´í„° ì‚¬ì „ ìˆ˜ì§‘ (unpersist ì „ì— ëª¨ë“  ê°’ì„ ë¡œì»¬ë¡œ)
    // ========================================
    
    // ì„±ëŠ¥ ì§€í‘œë“¤ì„ ë¡œì»¬ ë³€ìˆ˜ë¡œ ì €ì¥
    val precision_0_local = precision_0
    val recall_0_local = recall_0
    val f1_0_local = f1_0
    val precision_1_local = precision_1
    val recall_1_local = recall_1
    val f1_1_local = f1_1
    val weightedPrecision_local = weightedPrecision
    val weightedRecall_local = weightedRecall
    val accuracy_local = accuracy
    val auc_local = auc
    val tp_local = tp
    val fp_local = fp
    val tn_local = tn
    val fn_local = fn
    val total_local = total
    
    // ë©”ëª¨ë¦¬ í•´ì œ
    confusionDF.unpersist()
    aggregatedPredictionsGap.unpersist()
    
    // ========================================
    // Gap Model í‰ê°€ ê²°ê³¼ ë¡œê·¸ ì €ì¥ (ìˆ˜ì§‘ëœ ë¡œì»¬ ë°ì´í„° ì‚¬ìš©)
    // ========================================
    import java.io.{File, PrintWriter}
    import java.time.LocalDateTime
    import java.time.format.DateTimeFormatter
    
    val logDir = new File("/data/myfiles/aos_ost/predict")
    if (!logDir.exists()) logDir.mkdirs()
    
    val timestamp = LocalDateTime.now().format(DateTimeFormatter.ofPattern("yyyyMMdd_HHmmss"))
    val logFile = new File(logDir, s"gap_model_eval_${modelName}_${timestamp}.log")
    val writer = new PrintWriter(logFile)
    
    try {
        writer.println("=" * 80)
        writer.println(s"Gap Model Evaluation Log - $timestamp")
        writer.println("=" * 80)
        writer.println()
        
        // ëª¨ë¸ ì •ë³´
        writer.println("[Model Information]")
        writer.println(s"Model: ${modelName.replace("_gap", "").toUpperCase} (UID: $modelName)")
        modelName match {
            case "gbtc_gap" =>
                writer.println(s"  - maxIter: ${gbtg.getMaxIter}")
                writer.println(s"  - maxDepth: ${gbtg.getMaxDepth}")
                writer.println(s"  - featureSubsetStrategy: ${gbtg.getFeatureSubsetStrategy}")
            case "xgbc_gap" =>
                writer.println(s"  - numRound: ${xgbg.getNumRound}")
                writer.println(s"  - maxDepth: ${xgbg.getMaxDepth}")
                writer.println(s"  - objective: ${xgbg.getObjective}")
            case _ =>
                writer.println(s"  - Model: $modelName")
        }
        writer.println()
        
        // í•™ìŠµ ë°ì´í„° ì •ë³´
        writer.println("[Training Data Information]")
        writer.println(s"Data Filter: click_yn > 0 (í´ë¦­ ë°œìƒ ì¼€ì´ìŠ¤ë§Œ)")
        writer.println(s"Positive Sample Ratio (hour_gap > 0): $posSampleRatioGap")
        writer.println(s"Negative Sample Ratio (hour_gap = 0): 1.0")
        writer.println(s"Sample Strategy: stat.sampleBy")
        writer.println()
        
        // ì„±ëŠ¥ ì§€í‘œ (ë¡œì»¬ ë³€ìˆ˜ ì‚¬ìš©)
        writer.println("[Performance Metrics]")
        writer.println(f"Precision (Label 0): $precision_0_local%.4f")
        writer.println(f"Recall (Label 0): $recall_0_local%.4f")
        writer.println(f"F1-Score (Label 0): $f1_0_local%.4f")
        writer.println()
        writer.println(f"Precision (Label 1): $precision_1_local%.4f")
        writer.println(f"Recall (Label 1): $recall_1_local%.4f")
        writer.println(f"F1-Score (Label 1): $f1_1_local%.4f")
        writer.println()
        writer.println(f"Weighted Precision: $weightedPrecision_local%.4f")
        writer.println(f"Weighted Recall: $weightedRecall_local%.4f")
        writer.println(f"Accuracy: $accuracy_local%.4f")
        writer.println(f"AUC: $auc_local%.4f")
        writer.println()
        
        // Confusion Matrix (ë¡œì»¬ ë³€ìˆ˜ ì‚¬ìš©)
        writer.println("[Confusion Matrix]")
        writer.println(f"              Predicted 0    Predicted 1")
        writer.println(f"Actual 0:     ${tn_local}%.0f         ${fp_local}%.0f")
        writer.println(f"Actual 1:     ${fn_local}%.0f         ${tp_local}%.0f")
        writer.println()
        
        // í•´ì„
        writer.println("[Interpretation]")
        writer.println("- Label 0: ì¦‰ì‹œ í´ë¦­ (hour_gap = 0)")
        writer.println("- Label 1: ì§€ì—° í´ë¦­ (hour_gap > 0)")
        writer.println(s"- ì´ í‰ê°€ ìƒ˜í”Œ: ${total_local.toLong}")
        writer.println()
        
        writer.println("=" * 80)
        writer.println("Log saved successfully!")
        
        println(s"\nâœ… Gap Model í‰ê°€ ê²°ê³¼ ë¡œê·¸ ì €ì¥: ${logFile.getAbsolutePath}")
        
    } finally {
        writer.close()
    }
}

