{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[1], line 1360\u001b[0m\n\u001b[1;32m   1358\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[1;32m   1359\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m-> 1360\u001b[0m model \u001b[38;5;241m=\u001b[39m SentenceTransformer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjhgan/ko-sbert-nli\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1362\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m   1364\u001b[0m num_cand_pgms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:308\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    299\u001b[0m         model_name_or_path \u001b[38;5;241m=\u001b[39m __MODEL_HUB_ORGANIZATION__ \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m model_name_or_path\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_sentence_transformer_model(\n\u001b[1;32m    302\u001b[0m     model_name_or_path,\n\u001b[1;32m    303\u001b[0m     token,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    306\u001b[0m     local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    307\u001b[0m ):\n\u001b[0;32m--> 308\u001b[0m     modules, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_sbert_model(\n\u001b[1;32m    309\u001b[0m         model_name_or_path,\n\u001b[1;32m    310\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m    311\u001b[0m         cache_folder\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[1;32m    312\u001b[0m         revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m    313\u001b[0m         trust_remote_code\u001b[38;5;241m=\u001b[39mtrust_remote_code,\n\u001b[1;32m    314\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m    315\u001b[0m         model_kwargs\u001b[38;5;241m=\u001b[39mmodel_kwargs,\n\u001b[1;32m    316\u001b[0m         tokenizer_kwargs\u001b[38;5;241m=\u001b[39mtokenizer_kwargs,\n\u001b[1;32m    317\u001b[0m         config_kwargs\u001b[38;5;241m=\u001b[39mconfig_kwargs,\n\u001b[1;32m    318\u001b[0m     )\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    320\u001b[0m     modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_auto_model(\n\u001b[1;32m    321\u001b[0m         model_name_or_path,\n\u001b[1;32m    322\u001b[0m         token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m         config_kwargs\u001b[38;5;241m=\u001b[39mconfig_kwargs,\n\u001b[1;32m    330\u001b[0m     )\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/sentence_transformers/SentenceTransformer.py:1747\u001b[0m, in \u001b[0;36mSentenceTransformer._load_sbert_model\u001b[0;34m(self, model_name_or_path, token, cache_folder, revision, trust_remote_code, local_files_only, model_kwargs, tokenizer_kwargs, config_kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m         module_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1747\u001b[0m         module_path \u001b[38;5;241m=\u001b[39m load_dir_path(\n\u001b[1;32m   1748\u001b[0m             model_name_or_path,\n\u001b[1;32m   1749\u001b[0m             module_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1750\u001b[0m             token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   1751\u001b[0m             cache_folder\u001b[38;5;241m=\u001b[39mcache_folder,\n\u001b[1;32m   1752\u001b[0m             revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   1753\u001b[0m             local_files_only\u001b[38;5;241m=\u001b[39mlocal_files_only,\n\u001b[1;32m   1754\u001b[0m         )\n\u001b[1;32m   1755\u001b[0m     module \u001b[38;5;241m=\u001b[39m module_class\u001b[38;5;241m.\u001b[39mload(module_path)\n\u001b[1;32m   1757\u001b[0m modules[module_config[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m module\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/sentence_transformers/util.py:1411\u001b[0m, in \u001b[0;36mload_dir_path\u001b[0;34m(model_name_or_path, directory, token, cache_folder, revision, local_files_only)\u001b[0m\n\u001b[1;32m   1409\u001b[0m \u001b[38;5;66;03m# Try to download from the remote\u001b[39;00m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1411\u001b[0m     repo_path \u001b[38;5;241m=\u001b[39m snapshot_download(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mdownload_kwargs)\n\u001b[1;32m   1412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1413\u001b[0m     \u001b[38;5;66;03m# Otherwise, try local (i.e. cache) only\u001b[39;00m\n\u001b[1;32m   1414\u001b[0m     download_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocal_files_only\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/huggingface_hub/_snapshot_download.py:155\u001b[0m, in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;66;03m# if we have internet connection we want to list files to download\u001b[39;00m\n\u001b[1;32m    148\u001b[0m     api \u001b[38;5;241m=\u001b[39m HfApi(\n\u001b[1;32m    149\u001b[0m         library_name\u001b[38;5;241m=\u001b[39mlibrary_name,\n\u001b[1;32m    150\u001b[0m         library_version\u001b[38;5;241m=\u001b[39mlibrary_version,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m         headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    154\u001b[0m     )\n\u001b[0;32m--> 155\u001b[0m     repo_info \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mrepo_info(repo_id\u001b[38;5;241m=\u001b[39mrepo_id, repo_type\u001b[38;5;241m=\u001b[39mrepo_type, revision\u001b[38;5;241m=\u001b[39mrevision, token\u001b[38;5;241m=\u001b[39mtoken)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mSSLError, requests\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mProxyError):\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# Actually raise for those subclasses of ConnectionError\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2704\u001b[0m, in \u001b[0;36mHfApi.repo_info\u001b[0;34m(self, repo_id, revision, repo_type, timeout, files_metadata, expand, token)\u001b[0m\n\u001b[1;32m   2702\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported repo type.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2704\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\n\u001b[1;32m   2705\u001b[0m     repo_id,\n\u001b[1;32m   2706\u001b[0m     revision\u001b[38;5;241m=\u001b[39mrevision,\n\u001b[1;32m   2707\u001b[0m     token\u001b[38;5;241m=\u001b[39mtoken,\n\u001b[1;32m   2708\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m   2709\u001b[0m     expand\u001b[38;5;241m=\u001b[39mexpand,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m   2710\u001b[0m     files_metadata\u001b[38;5;241m=\u001b[39mfiles_metadata,\n\u001b[1;32m   2711\u001b[0m )\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/huggingface_hub/hf_api.py:2488\u001b[0m, in \u001b[0;36mHfApi.model_info\u001b[0;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, expand, token)\u001b[0m\n\u001b[1;32m   2486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m expand:\n\u001b[1;32m   2487\u001b[0m     params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m expand\n\u001b[0;32m-> 2488\u001b[0m r \u001b[38;5;241m=\u001b[39m get_session()\u001b[38;5;241m.\u001b[39mget(path, headers\u001b[38;5;241m=\u001b[39mheaders, timeout\u001b[38;5;241m=\u001b[39mtimeout, params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m   2489\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   2490\u001b[0m data \u001b[38;5;241m=\u001b[39m r\u001b[38;5;241m.\u001b[39mjson()\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/requests/sessions.py:602\u001b[0m, in \u001b[0;36mSession.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request. Returns :class:`Response` object.\u001b[39;00m\n\u001b[1;32m    595\u001b[0m \n\u001b[1;32m    596\u001b[0m \u001b[38;5;124;03m:param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;124;03m:param \\*\\*kwargs: Optional arguments that ``request`` takes.\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;124;03m:rtype: requests.Response\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 602\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m\"\u001b[39m, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(prep, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39msend_kwargs)\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m adapter\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/huggingface_hub/utils/_http.py:93\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msend(request, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     request_id \u001b[38;5;241m=\u001b[39m request\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(X_AMZN_TRACE_ID)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    664\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(\n\u001b[1;32m    668\u001b[0m         method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    669\u001b[0m         url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m    670\u001b[0m         body\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mbody,\n\u001b[1;32m    671\u001b[0m         headers\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    672\u001b[0m         redirect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    673\u001b[0m         assert_same_host\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    674\u001b[0m         preload_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    675\u001b[0m         decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    676\u001b[0m         retries\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries,\n\u001b[1;32m    677\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    678\u001b[0m         chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    679\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/urllib3/connectionpool.py:716\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    713\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    715\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 716\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(\n\u001b[1;32m    717\u001b[0m     conn,\n\u001b[1;32m    718\u001b[0m     method,\n\u001b[1;32m    719\u001b[0m     url,\n\u001b[1;32m    720\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout_obj,\n\u001b[1;32m    721\u001b[0m     body\u001b[38;5;241m=\u001b[39mbody,\n\u001b[1;32m    722\u001b[0m     headers\u001b[38;5;241m=\u001b[39mheaders,\n\u001b[1;32m    723\u001b[0m     chunked\u001b[38;5;241m=\u001b[39mchunked,\n\u001b[1;32m    724\u001b[0m )\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    730\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/urllib3/connectionpool.py:468\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    463\u001b[0m             httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    465\u001b[0m             \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    466\u001b[0m             \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    467\u001b[0m             \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 468\u001b[0m             six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mread_timeout)\n",
            "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/site-packages/urllib3/connectionpool.py:463\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;66;03m# Python 3\u001b[39;00m\n\u001b[1;32m    462\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 463\u001b[0m         httplib_response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mgetresponse()\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    465\u001b[0m         \u001b[38;5;66;03m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    466\u001b[0m         \u001b[38;5;66;03m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    467\u001b[0m         \u001b[38;5;66;03m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    468\u001b[0m         six\u001b[38;5;241m.\u001b[39mraise_from(e, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/http/client.py:1428\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1428\u001b[0m         response\u001b[38;5;241m.\u001b[39mbegin()\n\u001b[1;32m   1429\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[1;32m   1430\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/http/client.py:331\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m     version, status, reason \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_status()\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m status \u001b[38;5;241m!=\u001b[39m CONTINUE:\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/http/client.py:292\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 292\u001b[0m     line \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfp\u001b[38;5;241m.\u001b[39mreadline(_MAXLINE \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miso-8859-1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) \u001b[38;5;241m>\u001b[39m _MAXLINE:\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstatus line\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/socket.py:720\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39mrecv_into(b)\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    722\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/ssl.py:1251\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1248\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1249\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1250\u001b[0m           \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(nbytes, buffer)\n\u001b[1;32m   1252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
            "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.12/ssl.py:1103\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1103\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1104\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import configfrom concurrent.futures import ThreadPoolExecutorimport timefrom langchain_anthropic import ChatAnthropicfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_core.output_parsers import JsonOutputParserimport jsonimport refrom pygments import highlightfrom pygments.lexers import JsonLexerfrom pygments.formatters import HtmlFormatterfrom IPython.display import HTMLimport pandas as pd# from langchain.chat_models import ChatOpenAIfrom langchain_openai import ChatOpenAIfrom langchain_anthropic import ChatAnthropicfrom langchain.schema import AIMessage, HumanMessage, SystemMessageimport pandas as pdfrom openai import OpenAIfrom typing import List, Tuple, Union, Dict, Anyimport astimport reimport jsonimport globpd.set_option('display.max_colwidth', 500)llm_api_key = config.CUSTOM_API_KEY\"https://api.platform.a15t.com/v1\"client = OpenAI(    api_key = llm_api_key,    base_url = llm_api_url)client_2= OpenAI(    api_key = \"sktax-z2GВxrBfqЗР71Хh7RNIst3xchZdoOjyixfyHlIzGttXuz\",    base_url = \"https://apigw.sktax.chat/api/v1/serving/openai-api/v1\")# from langchain.chat_models import ChatOpenAIfrom langchain_openai import ChatOpenAIfrom langchain_anthropic import ChatAnthropicfrom langchain.schema import AIMessage, HumanMessage, SystemMessageimport pandas as pddef ChatAnthropicSKT(model=\"skt/claude-3-7-sonnet-20250219\", max_tokens=100):    llm_api_key = config.CUSTOM_API_KEY\"https://api.platform.a15t.com/v1\"        # llm_api_url = \"https://43.203.77.11:443/v1\"    # model = \"anthropic/claude-3-5-sonnet-20240620\"    model = ChatOpenAI(        temperature=0,          openai_api_key=llm_api_key,         openai_api_base=llm_api_url,         model=model,        max_tokens=max_tokens        )    return modelllm_cld37 = ChatAnthropicSKT()llm_gem3 = ChatAnthropicSKT(model='skt/gemma3-12b-it')# llm_cld37 = ChatAnthropic(#     api_key=os.getenv(\"ANTHROPIC_API_KEY\"),#     model=\"claude-3-7-sonnet-20250219\",#     max_tokens=3000# )llm_chat = ChatOpenAI(        temperature=0,          model=\"gpt-4o\",        openai_api_key=os.getenv(\"OPENAI_API_KEY\"),        max_tokens=2000,)llm_cld40 = ChatAnthropic(    api_key=os.getenv(\"ANTHROPIC_API_KEY\"),    model=\"claude-sonnet-4-20250514\",    max_tokens=3000)def dataframe_to_markdown_prompt(df, max_rows=None):    # Limit rows if needed    if max_rows is not None and len(df) > max_rows:        display_df = df.head(max_rows)        truncation_note = f\"\\n[Note: Only showing first {max_rows} of {len(df)} rows]\"    else:        display_df = df        truncation_note = \"\"        # Convert to markdown    df_markdown = display_df.to_markdown()        prompt = f\"\"\"    {df_markdown}    {truncation_note}    \"\"\"        return promptdef replace_strings(text, replacements):    for old, new in replacements.items():        text = text.replace(old, new)            return textdef clean_segment(segment):    \"\"\"    Given a segment that is expected to be quoted (i.e. begins and ends with    the same single or double quote), remove any occurrences of that quote    from the inner content.    For example, if segment is:        \"에이닷 T 멤버십 쿠폰함에 \"에이닷은통화요약된닷\" 입력\"    then the outer quotes are preserved but the inner double quotes are removed.    \"\"\"    segment = segment.strip()    if len(segment) >= 2 and segment[0] in ['\"', \"'\"] and segment[-1] == segment[0]:        q = segment[0]        # Remove inner occurrences of the quote character.        inner = segment[1:-1].replace(q, '')        return q + inner + q    return segmentdef split_key_value(text):    \"\"\"    Splits text into key and value based on the first colon that appears    outside any quoted region.    If no colon is found outside quotes, the value will be returned empty.    \"\"\"    in_quote = False    quote_char = ''    for i, char in enumerate(text):        if char in ['\"', \"'\"]:            # Toggle quote state (assumes well-formed starting/ending quotes for each token)            if in_quote:                if char == quote_char:                    in_quote = False                    quote_char = ''            else:                in_quote = True                quote_char = char        elif char == ':' and not in_quote:            return text[:i], text[i+1:]    return text, ''def split_outside_quotes(text, delimiter=','):    \"\"\"    Splits the input text on the given delimiter (default comma) but only    if the delimiter occurs outside of quoted segments.    Returns a list of parts.    \"\"\"    parts = []    current = []    in_quote = False    quote_char = ''    for char in text:        if char in ['\"', \"'\"]:            # When encountering a quote, toggle our state            if in_quote:                if char == quote_char:                    in_quote = False                    quote_char = ''            else:                in_quote = True                quote_char = char            current.append(char)        elif char == delimiter and not in_quote:            parts.append(''.join(current).strip())            current = []        else:            current.append(char)    if current:        parts.append(''.join(current).strip())    return partsdef clean_ill_structured_json(text):    \"\"\"    Given a string that is intended to represent a JSON-like structure    but may be ill-formed (for example, it might contain nested quotes that    break standard JSON rules), attempt to “clean” it by processing each    key–value pair.        The function uses the following heuristics:    1. Split the input text into comma-separated parts (only splitting        when the comma is not inside a quoted string).    2. For each part, split on the first colon (that is outside quotes) to separate key and value.    3. For any segment that begins and ends with a quote, remove any inner occurrences        of that same quote.    4. Rejoin the cleaned key and value.        Note: This approach does not build a fully robust JSON parser. For very complex        or deeply nested ill-structured inputs further refinement would be needed.    \"\"\"    # First, split the text by commas outside of quotes.    parts = split_outside_quotes(text, delimiter=',')        cleaned_parts = []    for part in parts:        # Try to split into key and value on the first colon not inside quotes.        key, value = split_key_value(part)        key_clean = clean_segment(key)        value_clean = clean_segment(value) if value.strip() != \"\" else \"\"        if value_clean:            cleaned_parts.append(f\"{key_clean}: {value_clean}\")        else:            cleaned_parts.append(key_clean)        # Rejoin the cleaned parts with commas (or you can use another format if desired)    return ', '.join(cleaned_parts)def repair_json(broken_json):        # json_str = broken_json.replace(\"'\",'\"')        # Fix unquoted values (like NI00001863)    json_str = re.sub(r':\\s*([a-zA-Z0-9_]+)(\\s*[,}])', r': \"\\1\"\\2', broken_json)        # Fix unquoted keys    json_str = re.sub(r'([{,])\\s*([a-zA-Z0-9_]+):', r'\\1 \"\\2\":', json_str)        # Fix trailing commas    json_str = re.sub(r',\\s*}', '}', json_str)        return json_strdef extract_json_objects(text):    # More sophisticated pattern that tries to match proper JSON syntax    pattern = r'(\\{(?:[^{}]|(?:\\{(?:[^{}]|(?:\\{[^{}]*\\}))*\\}))*\\})'        result = []    for match in re.finditer(pattern, text):        potential_json = match.group(0)        try:            # Try to parse and validate            # json_obj = json.loads(repair_json(potential_json))            json_obj = ast.literal_eval(clean_ill_structured_json(repair_json(potential_json)))            result.append(json_obj)        except json.JSONDecodeError:            # Not valid JSON, skip            pass        return resultdef extract_between(text, start_marker, end_marker):    start_index = text.find(start_marker)    if start_index == -1:        return None        start_index += len(start_marker)    end_index = text.find(end_marker, start_index)    if end_index == -1:        return None        return text[start_index:end_index]def extract_content(text: str, tag_name: str) -> List[str]:    pattern = f'<{tag_name}>(.*?)</{tag_name}>'    matches = re.findall(pattern, text, re.DOTALL)    return matchesdef clean_bad_text(text):    import re        if not isinstance(text, str):        return \"\"        # Remove URLs and emails    text = re.sub(r'https?://\\S+|www\\.\\S+', ' ', text)    text = re.sub(r'\\S+@\\S+', ' ', text)        # Keep Korean, alphanumeric, spaces, and specific punctuation    text = re.sub(r'[^\\uAC00-\\uD7A3\\u1100-\\u11FF\\w\\s\\.\\?!,]', ' ', text)        # Normalize whitespace    text = re.sub(r'\\s+', ' ', text).strip()        return textdef clean_text(text):    \"\"\"    Cleans text by removing special characters that don't affect fine-tuning.    Preserves important structural elements like quotes, brackets, and JSON syntax.    Specifically handles Korean text (Hangul) properly.        Args:        text (str): The input text to clean            Returns:        str: Cleaned text ready for fine-tuning    \"\"\"    import re        # Preserve the basic structure by temporarily replacing important characters    # with placeholder tokens that won't be affected by cleanup        # Step 1: Temporarily replace JSON structural elements    placeholders = {        '\"': \"DQUOTE_TOKEN\",        \"'\": \"SQUOTE_TOKEN\",        \"{\": \"OCURLY_TOKEN\",        \"}\": \"CCURLY_TOKEN\",        \"[\": \"OSQUARE_TOKEN\",        \"]\": \"CSQUARE_TOKEN\",        \":\": \"COLON_TOKEN\",        \",\": \"COMMA_TOKEN\"    }        for char, placeholder in placeholders.items():        text = text.replace(char, placeholder)        # Step 2: Remove problematic characters        # Remove control characters (except newlines, carriage returns, and tabs which can be meaningful)    text = re.sub(r'[\\x00-\\x08\\x0B\\x0C\\x0E-\\x1F\\x7F]', '', text)        # Normalize all types of newlines to \\n    text = re.sub(r'\\r\\n|\\r', '\\n', text)        # Remove zero-width characters and other invisible unicode    text = re.sub(r'[\\u200B-\\u200D\\uFEFF\\u00A0]', '', text)        # MODIFIED: Keep Korean characters (Hangul) along with other useful character sets    # This regex keeps:    # - ASCII (Basic Latin): \\x00-\\x7F    # - Latin-1 Supplement: \\u0080-\\u00FF    # - Latin Extended A & B: \\u0100-\\u017F\\u0180-\\u024F    # - Greek and Coptic: \\u0370-\\u03FF    # - Cyrillic: \\u0400-\\u04FF    # - Korean Hangul Syllables: \\uAC00-\\uD7A3    # - Hangul Jamo (Korean alphabet): \\u1100-\\u11FF    # - Hangul Jamo Extended-A: \\u3130-\\u318F    # - Hangul Jamo Extended-B: \\uA960-\\uA97F    # - Hangul Compatibility Jamo: \\u3130-\\u318F    # - CJK symbols and punctuation: \\u3000-\\u303F    # - Full-width forms (often used with CJK): \\uFF00-\\uFFEF    # - CJK Unified Ideographs (Basic common Chinese/Japanese characters): \\u4E00-\\u9FFF        # Instead of removing characters, we'll define which ones to keep    allowed_chars_pattern = r'[^\\x00-\\x7F\\u0080-\\u00FF\\u0100-\\u024F\\u0370-\\u03FF\\u0400-\\u04FF' + \\                        r'\\u1100-\\u11FF\\u3130-\\u318F\\uA960-\\uA97F\\u3000-\\u303F' + \\                        r'\\uAC00-\\uD7A3\\uFF00-\\uFFEF\\u4E00-\\u9FFF\\n\\r\\t ]'    text = re.sub(allowed_chars_pattern, '', text)        # Step 3: Normalize whitespace (but preserve deliberate line breaks)    text = re.sub(r'[ \\t]+', ' ', text)  # Convert multiple spaces/tabs to single space        # First ensure all newlines are standardized    text = re.sub(r'\\r\\n|\\r', '\\n', text)  # Convert all newline variants to \\n        # Then normalize multiple blank lines to at most two    text = re.sub(r'\\n\\s*\\n+', '\\n\\n', text)  # Convert multiple newlines to at most two        # Step 4: Restore original JSON structural elements    for char, placeholder in placeholders.items():        text = text.replace(placeholder, char)        # Step 5: Fix common JSON syntax issues that might remain    # Fix spaces between quotes and colons in JSON    text = re.sub(r'\"\\s+:', r'\":', text)        # Fix trailing commas in arrays    text = re.sub(r',\\s*]', r']', text)        # Fix trailing commas in objects    text = re.sub(r',\\s*}', r'}', text)        return textdef remove_control_characters(text):    if isinstance(text, str):        # Remove control characters except commonly used whitespace        return re.sub(r'[\\x00-\\x08\\x0B-\\x0C\\x0E-\\x1F\\x7F]', '', text)    return textimport openaifrom langchain.chains import RetrievalQAfrom langchain.llms.openai import OpenAIChat  # For compatibility with newer setup# Create a custom LLM class that uses the OpenAI client directlyclass CustomOpenAI:    def __init__(self, model=\"skt/a.x-3-lg\"):        self.model = model            def __call__(self, prompt):        response = client.chat.completions.create(            model=self.model,            messages=[                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},                {\"role\": \"user\", \"content\": prompt}            ],            temperature=0.1        )        return response.choices[0].message.content# Create a simple retrieval functiondef get_relevant_context(query, vectorstore, topk=5):    docs = vectorstore.similarity_search(query, k=topk)    context = \"\\n\\n\".join([doc.page_content for doc in docs])    titles = \", \".join(set([doc.metadata['title'] for doc in docs if 'title' in doc.metadata.keys()]))    return {'title':titles, 'context':context}# Create a function to combine everythingdef answer_question(query, vectorstore):    # Get relevant context    context = get_relevant_context(query, vectorstore)        # Create combined prompt    prompt = f\"Answer the following question based on the provided context:\\n\\nContext: {context}\\n\\nQuestion: {query}\\n\\nAnswer:\"        # Use OpenAI directly    custom_llm = CustomOpenAI()  # Or your preferred model    response = custom_llm(prompt)        return responsedef is_list_of_dicts(var):    # Check if the variable is a list    if not isinstance(var, list):        return False        # Check if the list is not empty and all elements are dictionaries    if not var:  # Empty list        return False            # Check that all elements are dictionaries    return all(isinstance(item, dict) for item in var)def remove_duplicate_dicts(dict_list):    result = []    seen = set()    for d in dict_list:        # Convert dictionary to a hashable tuple of items        t = tuple(sorted(d.items()))        if t not in seen:            seen.add(t)            result.append(d)    return resultdef convert_to_custom_format(json_items):    custom_format = []        for item in json_items:        item_name = item.get(\"item_name_in_message\", \"\")        item_id = item.get(\"item_id\", \"\")        category = item.get(\"category\", \"\")                # Create custom format for each item        custom_line = f\"[Item Name] {item_name} [Item ID] {item_id} [Item Category] {category}\"        custom_format.append(custom_line)        return \"\\n\".join(custom_format)def remove_urls(text):    # Regular expression pattern to match URLs    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')        # Replace URLs with an empty string    return url_pattern.sub('', text)def remove_custom_pattern(text, keyword=\"바로가기\"):    # Create a pattern that matches any text followed by the specified keyword    # We escape the keyword to handle any special regex characters it might contain    escaped_keyword = re.escape(keyword)    pattern = re.compile(r'.*? ' + escaped_keyword)        # Replace the matched pattern with an empty string    return pattern.sub('', text)from rapidfuzz import fuzz, processimport reclass KoreanEntityMatcher:    def __init__(self, min_similarity=70, ngram_size=2, min_entity_length=2, token_similarity=True):        self.min_similarity = min_similarity        self.ngram_size = ngram_size        self.min_entity_length = min_entity_length        self.token_similarity = token_similarity  # 토큰 단위 유사도 비교 옵션 추가        self.entities = []        self.entity_data = {}            def build_from_list(self, entities):        \"\"\"Build entity index from a list of entities\"\"\"        self.entities = []        self.entity_data = {}                for i, entity in enumerate(entities):            if isinstance(entity, tuple) and len(entity) == 2:                entity_name, data = entity                self.entities.append(entity_name)                self.entity_data[entity_name] = data            else:                self.entities.append(entity)                self.entity_data[entity] = {'id': i, 'entity': entity}                        # 각 엔티티의 정규화된 형태를 저장 (검색 최적화)        self.normalized_entities = {}        for entity in self.entities:            normalized = self._normalize_text(entity)            self.normalized_entities[normalized] = entity                        # Create n-gram index for faster candidate selection        self._build_ngram_index(n=self.ngram_size)        def _normalize_text(self, text):        \"\"\"텍스트 정규화 - 소문자 변환, 공백 제거 등\"\"\"        # 소문자로 변환        text = text.lower()        # 연속된 공백을 하나로 통일        text = re.sub(r'\\s+', ' ', text)        return text.strip()        def _tokenize(self, text):        \"\"\"텍스트를 토큰으로 분리 (한글, 영문, 숫자 분리)\"\"\"        # 한글, 영문, 숫자 토큰 추출        tokens = re.findall(r'[가-힣]+|[a-z0-9]+', self._normalize_text(text))        return tokens        def _build_ngram_index(self, n=2):        \"\"\"Build n-gram index optimized for Korean characters\"\"\"        self.ngram_index = {}                for entity in self.entities:            # Skip entities shorter than min_entity_length            if len(entity) < self.min_entity_length:                continue                            # 정규화된 엔티티 사용            normalized_entity = self._normalize_text(entity)                        # Create n-grams for the entity            entity_chars = list(normalized_entity)  # Split into characters for proper Korean handling            ngrams = []                        # Create character-level n-grams (better for Korean)            for i in range(len(entity_chars) - n + 1):                ngram = ''.join(entity_chars[i:i+n])                ngrams.append(ngram)                        # Add entity to the index for each n-gram            for ngram in ngrams:                if ngram not in self.ngram_index:                    self.ngram_index[ngram] = set()                self.ngram_index[ngram].add(entity)                            # 토큰 기반 n-gram도 추가 (실험적)            tokens = self._tokenize(normalized_entity)            for token in tokens:                if len(token) >= n:                    token_key = f\"TOKEN:{token}\"                    if token_key not in self.ngram_index:                        self.ngram_index[token_key] = set()                    self.ngram_index[token_key].add(entity)        def _get_candidates(self, text, n=None):        \"\"\"Get candidate entities based on n-gram overlap (optimized for Korean)\"\"\"        if n is None:            n = self.ngram_size                    # 텍스트 정규화        normalized_text = self._normalize_text(text)                # 정규화된 텍스트가 정확히 일치하는지 확인 (빠른 경로)        if normalized_text in self.normalized_entities:            entity = self.normalized_entities[normalized_text]            return [(entity, float('inf'))]  # 정확한 일치는 무한대 점수로 표시                text_chars = list(normalized_text)  # Split into characters for proper Korean handling        text_ngrams = set()                # Create character-level n-grams        for i in range(len(text_chars) - n + 1):            ngram = ''.join(text_chars[i:i+n])            text_ngrams.add(ngram)                # 토큰 기반 n-gram 추가        tokens = self._tokenize(normalized_text)        for token in tokens:            if len(token) >= n:                text_ngrams.add(f\"TOKEN:{token}\")                candidates = set()        for ngram in text_ngrams:            if ngram in self.ngram_index:                candidates.update(self.ngram_index[ngram])                # Prioritize candidates with multiple n-gram matches        candidate_scores = {}        for candidate in candidates:            candidate_normalized = self._normalize_text(candidate)            candidate_chars = list(candidate_normalized)            candidate_ngrams = set()                        # 문자 n-gram            for i in range(len(candidate_chars) - n + 1):                ngram = ''.join(candidate_chars[i:i+n])                candidate_ngrams.add(ngram)                        # 토큰 기반 n-gram            candidate_tokens = self._tokenize(candidate_normalized)            for token in candidate_tokens:                if len(token) >= n:                    candidate_ngrams.add(f\"TOKEN:{token}\")                        # n-gram 교집합 크기로 초기 점수 계산            overlap = len(candidate_ngrams.intersection(text_ngrams))                        # 토큰 수준 유사도 보너스 점수 추가            token_bonus = 0            if self.token_similarity:                query_tokens = set(tokens)                cand_tokens = set(candidate_tokens)                                # 공통 토큰 비율 계산                if query_tokens and cand_tokens:                    common = query_tokens.intersection(cand_tokens)                    token_bonus = len(common) * 2  # 토큰 일치에 높은 가중치 부여                        candidate_scores[candidate] = overlap + token_bonus                # Return candidates sorted by n-gram overlap score        return sorted(candidate_scores.items(), key=lambda x: x[1], reverse=True)        def _calculate_similarity(self, text, entity):        \"\"\"다양한 유사도 측정 방법을 결합하여 더 정확한 유사도 계산\"\"\"        normalized_text = self._normalize_text(text)        normalized_entity = self._normalize_text(entity)                # 정확히 일치하면 100점 반환        if normalized_text == normalized_entity:            return 100                # 기본 문자열 유사도 (fuzz.ratio)        ratio_score = fuzz.ratio(normalized_text, normalized_entity)                # 부분 문자열 체크 (한 문자열이 다른 문자열의 부분 문자열인 경우)        partial_score = 0        if normalized_text in normalized_entity:            text_len = len(normalized_text)            entity_len = len(normalized_entity)            partial_score = (text_len / entity_len) * 100 if entity_len > 0 else 0        elif normalized_entity in normalized_text:            text_len = len(normalized_text)            entity_len = len(normalized_entity)            partial_score = (entity_len / text_len) * 100 if text_len > 0 else 0                # 토큰 유사도 (토큰 단위로 비교)        token_score = 0        if self.token_similarity:            text_tokens = set(self._tokenize(normalized_text))            entity_tokens = set(self._tokenize(normalized_entity))                        if text_tokens and entity_tokens:                common_tokens = text_tokens.intersection(entity_tokens)                all_tokens = text_tokens.union(entity_tokens)                                if all_tokens:                    token_score = (len(common_tokens) / len(all_tokens)) * 100                # 토큰 순서 무시 유사도 (fuzz.token_sort_ratio)        token_sort_score = fuzz.token_sort_ratio(normalized_text, normalized_entity)                # 토큰 집합 유사도 (fuzz.token_set_ratio)        token_set_score = fuzz.token_set_ratio(normalized_text, normalized_entity)                # 최종 유사도는 여러 점수의 가중 평균        # 토큰 유사도에 높은 가중치를 부여하여 \"T우주\"와 \"T 우주패스\"의 매칭 향상        final_score = (            ratio_score * 0.3 +  # 기본 유사도            max(partial_score, 0) * 0.1 +  # 부분 문자열 유사도            token_score * 0.2 +  # 토큰 유사도            token_sort_score * 0.2 +  # 토큰 순서 무시 유사도            token_set_score * 0.2  # 토큰 집합 유사도        )                return final_score        def find_entities(self, text, max_candidates_per_span=10):        \"\"\"Find entity matches in Korean text using fuzzy matching\"\"\"        # Extract spans that might contain entities        potential_spans = self._extract_korean_spans(text)        matches = []                for span_text, start, end in potential_spans:            if len(span_text.strip()) < self.min_entity_length:  # Skip spans shorter than min_entity_length                continue            # Get candidate entities based on n-gram overlap            candidates = self._get_candidates(span_text)            # If no candidates found through n-gram filtering, skip            if not candidates:                continue                        # Limit the number of candidates to check            top_candidates = [c[0] for c in candidates[:max_candidates_per_span]]                        # 각 후보 엔티티에 대해 개선된 유사도 계산            scored_matches = []            for entity in top_candidates:                score = self._calculate_similarity(span_text, entity)                                if score >= self.min_similarity:                    scored_matches.append((entity, score, 0))  # 호환성을 위해 3번째 매개변수 추가            # 기존 process.extract 대신 개선된 유사도 계산 사용            best_matches = scored_matches            for entity, score, _ in best_matches:                matches.append({                    'text': span_text,                    'matched_entity': entity,                    'score': score,                    'start': start,                    'end': end,                    'data': self.entity_data.get(entity, {})                })        # Sort by position in text        matches.sort(key=lambda x: (x['start'], -x['score']))                # Handle overlapping matches by keeping the best match        final_matches = self._resolve_overlapping_matches(matches)        return final_matches        def _extract_korean_spans(self, text):        \"\"\"한국어와 영어가 혼합된 텍스트에서 엔티티일 수 있는 잠재적 텍스트 범위 추출\"\"\"        spans = []        min_len = self.min_entity_length                # 1. 영문+한글 혼합 패턴 (붙여쓰기) 예: \"T우주\"        for match in re.finditer(r'[a-zA-Z]+[가-힣]+(?:\\s+[가-힣가-힣a-zA-Z0-9]+)*', text):            if len(match.group(0)) >= min_len:                spans.append((match.group(0), match.start(), match.end()))                # 2. 영문+한글 혼합 패턴 (띄어쓰기) 예: \"T 우주\"        for match in re.finditer(r'[a-zA-Z]+\\s+[가-힣]+(?:\\s+[가-힣가-힣a-zA-Z0-9]+)*', text):            if len(match.group(0)) >= min_len:                spans.append((match.group(0), match.start(), match.end()))                # 3. 특수한 혼합 패턴 - 영문+한글+숫자 (예: \"T우주365\", \"SK텔레콤\")        for match in re.finditer(r'[a-zA-Z]+[가-힣]+(?:[0-9]+)?', text):            if len(match.group(0)) >= min_len:                spans.append((match.group(0), match.start(), match.end()))                # 4. 연속된 두 단어까지 확장 (예: \"T우주 패스\")        # 영문+한글 후 공백 하나를 두고 다른 한글 단어가 나오는 패턴        for match in re.finditer(r'[a-zA-Z]+[가-힣]+\\s+[가-힣]+', text):            if len(match.group(0)) >= min_len:                spans.append((match.group(0), match.start(), match.end()))                        # 5. 연속된 세 단어까지 확장 (예: \"T우주 멤버십 패스\")        for match in re.finditer(r'[a-zA-Z]+[가-힣]+\\s+[가-힣]+\\s+[가-힣]+', text):            if len(match.group(0)) >= min_len:                spans.append((match.group(0), match.start(), match.end()))                # 6. 브랜드명 + 제품명 패턴 (예: \"SK텔레콤 T우주\")        for match in re.finditer(r'[a-zA-Z가-힣]+(?:\\s+[a-zA-Z가-힣]+){1,3}', text):            if len(match.group(0)) >= min_len:                spans.append((match.group(0), match.start(), match.end()))                # 7. 숫자와 영문 결합 패턴 (숫자 space 영문 패턴, e.g. \"0 day\")        for match in re.finditer(r'\\d+\\s+[a-zA-Z]+', text):            if len(match.group(0)) >= min_len:                spans.append((match.group(0), match.start(), match.end()))                # 8. 더 일반적인 영한 혼합 패턴        for match in re.finditer(r'[a-zA-Z가-힣0-9]+(?:\\s+[a-zA-Z가-힣0-9]+)*', text):            if len(match.group(0)) >= min_len:                spans.append((match.group(0), match.start(), match.end()))                # 9. 일반적인 구분자로 분리된 텍스트 조각도 추출        for span in re.split(r'[,\\.!?;:\"\\'…\\(\\)\\[\\]\\{\\}\\s_/]+', text):            if span and len(span) >= min_len:                span_pos = text.find(span)                if span_pos != -1:                    spans.append((span, span_pos, span_pos + len(span)))                        return spans        def _remove_duplicate_entities(self, matches):        \"\"\"Keep only one instance of each unique entity\"\"\"        if not matches:            return []                # Dictionary to track highest-scoring match for each entity        best_matches = {}                for match in matches:            entity_key = match['matched_entity']                        # If we haven't seen this entity before, or if this match has a higher score            # than the previously saved match for this entity, save this one            if (entity_key not in best_matches or                 match['score'] > best_matches[entity_key]['score']):                best_matches[entity_key] = match                # Return the best matches sorted by start position        return sorted(best_matches.values(), key=lambda x: x['start'])        def _resolve_overlapping_matches(self, matches, high_score_threshold=50, overlap_tolerance=0.5):        if not matches:            return []                # 점수 내림차순, 길이 오름차순으로 정렬 (높은 점수, 짧은 매치 우선)        sorted_matches = sorted(matches, key=lambda x: (-x['score'], x['end'] - x['start']))                final_matches = []                for current_match in sorted_matches:            current_score = current_match['score']            current_start, current_end = current_match['start'], current_match['end']            current_range = set(range(current_start, current_end))            current_len = len(current_range)                        # 수정: overlap_ratio를 0으로 초기화            current_match['overlap_ratio'] = 0.0                        # 높은 점수의 매치는 항상 포함            if current_score >= high_score_threshold:                # 기존 매치들과 비교하여 너무 많은 중복이 있는지 확인                is_too_similar = False                                for existing_match in final_matches:                    if existing_match['score'] < high_score_threshold:                        continue  # 낮은 점수의 기존 매치와는 비교하지 않음                                            existing_start, existing_end = existing_match['start'], existing_match['end']                    existing_range = set(range(existing_start, existing_end))                                        # 교집합 비율 계산                    intersection = current_range.intersection(existing_range)                                        # 현재 매치에 대한 중복 비율                     current_overlap_ratio = len(intersection) / current_len if current_len > 0 else 0                                        # 수정: 중복 비율 저장 - 가장 높은 중복 비율 저장                    current_match['overlap_ratio'] = max(current_match['overlap_ratio'], current_overlap_ratio)                                        # 중복 비율이 허용 범위를 초과하고, 동일한 엔티티면 추가하지 않음                    if (current_overlap_ratio > overlap_tolerance                        and current_match['matched_entity'] == existing_match['matched_entity']                        ):                        is_too_similar = True                        break                                if not is_too_similar:                    final_matches.append(current_match)            else:                # 낮은 점수의 매치는 기존 로직 적용 (중복 확인)                should_add = True                                for existing_match in final_matches:                    existing_start, existing_end = existing_match['start'], existing_match['end']                    existing_range = set(range(existing_start, existing_end))                                        # 교집합 비율 계산                    intersection = current_range.intersection(existing_range)                    current_overlap_ratio = len(intersection) / current_len if current_len > 0 else 0                                        # 수정: 중복 비율 저장 - 가장 높은 중복 비율 저장                    current_match['overlap_ratio'] = max(current_match['overlap_ratio'], current_overlap_ratio)                                        # 중복 비율이 허용 범위를 초과하면 추가하지 않음                    if current_overlap_ratio > (1 - overlap_tolerance):                        should_add = False                        break                                if should_add:                    final_matches.append(current_match)                # 시작 위치별로 정렬        final_matches.sort(key=lambda x: x['start'])                return final_matchesdef find_entities_in_text(text, entity_list, min_similarity=70, ngram_size=3, min_entity_length=2,                         token_similarity=True, high_score_threshold=50, overlap_tolerance=0.5):    \"\"\"    Find entity matches in text using fuzzy matching.        Parameters:    -----------    text : str        The text to search for entities    entity_list : list        List of entities to match against    min_similarity : int, default=70        Minimum similarity score (0-100) for fuzzy matching    ngram_size : int, default=2        Size of character n-grams to use for indexing (2 or 3 recommended for Korean)    min_entity_length : int, default=2        Minimum length of entities to consider (characters)    token_similarity : bool, default=True        Whether to use token-based similarity measures    high_score_threshold : int, default=50        Score threshold above which matches are always kept regardless of overlap    overlap_tolerance : float, default=0.5        Overlap tolerance ratio (0-1), higher values allow more overlapping matches            Returns:    --------    list        List of matched entities with position and metadata    \"\"\"    matcher = KoreanEntityMatcher(        min_similarity=min_similarity,        ngram_size=ngram_size,        min_entity_length=min_entity_length,        token_similarity=token_similarity    )    matcher.build_from_list(entity_list)        matches = matcher.find_entities(text)        # 기존 _resolve_overlapping_matches 메서드 대신 직접 호출    final_matches = matcher._resolve_overlapping_matches(        matches,         high_score_threshold=high_score_threshold,        overlap_tolerance=overlap_tolerance    )        return final_matches# Function to highlight entities in textdef highlight_entities(text, matches):    marked_text = text    offset = 0    for match in sorted(matches, key=lambda x: x['start'], reverse=True):        start = match['start'] + offset        end = match['end'] + offset        entity = match['matched_entity']        score = match['score']        marked_text = marked_text[:start] + f\"[{marked_text[start:end]}→{entity} ({score:.1f}%)]\" + marked_text[end:]        offset += len(f\"[→{entity} ({score:.1f}%)]\") + 2        return marked_textimport kiwipiepydef reconstruct_text_from_tokens(tokens):    \"\"\"    tokens: Kiwi.analyze()의 결과로 반환된 Token 객체 리스트    filter_rules: 필터링 규칙 (예: 특정 품사만 선택, 특정 단어 제외 등)    \"\"\"    if tokens:        max_pos = max(token.start + token.len for token in tokens)        text_array = [' '] * max_pos  # 공백으로 초기화                for token in tokens:            for i in range(token.start, token.start + token.len):                if i < max_pos:                    text_array[i] = token.form[i - token.start]                text = ''.join(text_array)    else:        text = ''        return textdef extract_by_tag_pattern(result, tag_patterns, original_text=None):    \"\"\"    kiwi.analyze() 결과에서 특정 tag 패턴에 일치하는 form들을 추출합니다.        Parameters:    - result: kiwi.analyze()의 결과    - tag_patterns: 찾고자 하는 tag 패턴 리스트    - original_text: 원본 텍스트 (위치 기반 추출 시 필요)    \"\"\"    # kiwi.analyze()의 결과에서 토큰 리스트 추출    if isinstance(result, list) and len(result) > 0 and isinstance(result[0], tuple):        tokens = result[0][0]  # 첫 번째 분석 결과에서 토큰 리스트 추출    else:        tokens = result  # 이미 토큰 리스트인 경우        matches = {i: [] for i in range(len(tag_patterns))}  # 패턴별 매치 결과        # 각 패턴에 대해 검색    for pattern_idx, pattern in enumerate(tag_patterns):        pattern_len = len(pattern)                # 슬라이딩 윈도우 방식으로 패턴 검색        for i in range(len(tokens) - pattern_len + 1):            window = tokens[i:i+pattern_len]                        # 현재 윈도우가 패턴과 일치하는지 확인            if all(token.tag == pattern[j] for j, token in enumerate(window)):                # 패턴과 일치하면 form들을 추출하여 저장                if original_text and window:                    start_pos = window[0].start                    end_pos = window[-1].start + window[-1].len                    matched_forms = original_text[start_pos:end_pos]                else:                    # 원본 텍스트가 없으면 토큰 form을 직접 합침 (공백 없이)                    matched_forms = ''.join(token.form for token in window)                                matches[pattern_idx].append(matched_forms)        return matchesdef extract_by_flexible_tag_pattern(result, tag_patterns, max_gap=0, original_text=None):    \"\"\"    kiwi.analyze() 결과에서 특정 tag 패턴에 일치하는 form들을 유연하게 추출합니다.    중간에 다른 태그가 있어도 일정 개수 이내라면 매칭합니다.        Parameters:    - result: kiwi.analyze()의 결과    - tag_patterns: 찾고자 하는 tag 패턴 리스트. 예: [['NNG', 'JKS', 'VV'], ['VA', 'NNG']]    - max_gap: 패턴 사이에 허용되는 최대 간격(다른 태그의 개수)    - original_text: 원본 텍스트 (위치 기반 추출 시 필요)        Returns:    - 패턴별 일치하는 form의 리스트 딕셔너리와 매칭된 토큰 인덱스    \"\"\"    # kiwi.analyze()의 결과에서 토큰 리스트 추출    if isinstance(result, list) and len(result) > 0 and isinstance(result[0], tuple):        tokens = result[0][0]  # 첫 번째 분석 결과에서 토큰 리스트 추출    else:        tokens = result  # 이미 토큰 리스트인 경우        matches = {i: [] for i in range(len(tag_patterns))}  # 패턴별 매치 결과    match_indices = {i: [] for i in range(len(tag_patterns))}  # 매치된 토큰 인덱스        # 각 패턴에 대해 검색    for pattern_idx, pattern in enumerate(tag_patterns):        i = 0        while i < len(tokens):            matched_indices = []            pattern_pos = 0            gaps = 0            j = i                        # 패턴 매칭 시도            match_found = False            while j < len(tokens) and pattern_pos < len(pattern):                if tokens[j].tag == pattern[pattern_pos]:                    matched_indices.append(j)                    pattern_pos += 1                    gaps = 0                else:                    gaps += 1                    if gaps > max_gap:                        # 허용된 간격을 초과하면 매칭 실패                        break                j += 1                                # 패턴을 모두 매칭했는지 확인                if pattern_pos == len(pattern):                    match_found = True                    break                        # 매칭에 성공한 경우 결과 추가            if match_found:                matched_tokens = [tokens[idx] for idx in matched_indices]                                # 원본 텍스트에서 추출하거나 토큰 form 직접 연결                if original_text and matched_tokens:                    start_pos = matched_tokens[0].start                    end_pos = matched_tokens[-1].start + matched_tokens[-1].len                    matched_forms = original_text[start_pos:end_pos]                else:                    # 원본 텍스트가 없으면 토큰 form을 직접 합침 (공백 없이)                    matched_forms = ''.join(token.form for token in matched_tokens)                                    matches[pattern_idx].append(matched_forms)                match_indices[pattern_idx].append(matched_indices)                                # 매칭 후 겹치지 않도록 다음 위치로 이동                i = matched_indices[-1] + 1            else:                i += 1  # 매칭 실패한 경우 다음 위치로 이동        return matches, match_indicesdef reconstruct_with_tag_patterns(result, tag_patterns, include_unmatched=False, original_text=None):    \"\"\"    kiwi.analyze() 결과에서 특정 tag 패턴에 일치하는 부분을 강조하여 텍스트 재구성        Parameters:    - result: kiwi.analyze()의 결과    - tag_patterns: 찾고자 하는 tag 패턴 리스트    - include_unmatched: 패턴에 일치하지 않는 토큰도 포함할지 여부    - original_text: 원본 텍스트 (위치 기반 추출 시 필요)        Returns:    - 재구성된 텍스트 (패턴 일치 부분은 <match>로 강조)    \"\"\"    # kiwi.analyze()의 결과에서 토큰 리스트 추출    if isinstance(result, list) and len(result) > 0 and isinstance(result[0], tuple):        tokens = result[0][0]  # 첫 번째 분석 결과에서 토큰 리스트 추출    else:        tokens = result  # 이미 토큰 리스트인 경우        _, match_indices = extract_by_flexible_tag_pattern(result, tag_patterns, original_text=original_text)        # 모든 매치 인덱스를 하나의 집합으로 합침    all_matched_indices = set()    for indices_list in match_indices.values():        for indices in indices_list:            all_matched_indices.update(indices)        # 텍스트 재구성    reconstructed_parts = []    i = 0    while i < len(tokens):        if i in all_matched_indices:            # 매치된 패턴의 시작 찾기            for pattern_idx, indices_list in match_indices.items():                for indices in indices_list:                    if i == indices[0]:  # 패턴의 시작                        pattern_tokens = [tokens[idx] for idx in indices]                                                # 원본 텍스트에서 추출하거나 토큰 form 직접 연결                        if original_text and pattern_tokens:                            start_pos = pattern_tokens[0].start                            end_pos = pattern_tokens[-1].start + pattern_tokens[-1].len                            pattern_text = original_text[start_pos:end_pos]                        else:                            pattern_text = ''.join(token.form for token in pattern_tokens)                                                    reconstructed_parts.append(f\"<match>{pattern_text}</match>\")                        i = indices[-1] + 1  # 패턴 이후로 인덱스 이동                        break                else:                    continue                break        else:            # 매치되지 않은 토큰            if include_unmatched:                reconstructed_parts.append(tokens[i].form)            i += 1        return ''.join(reconstructed_parts)import numpy as npimport matplotlib.pyplot as pltfrom difflib import SequenceMatcherdef advanced_sequential_similarity(str1, str2, metrics=None, visualize=False):    \"\"\"    Calculate multiple character-level similarity metrics between two strings.        Parameters:    -----------    str1 : str        First string    str2 : str        Second string    metrics : list        List of metrics to compute. Options:         ['ngram', 'lcs', 'subsequence', 'difflib']        If None, all metrics will be computed    visualize : bool        If True, visualize the differences between strings            Returns:    --------    dict        Dictionary containing similarity scores for each metric    \"\"\"    if metrics is None:        metrics = ['ngram', 'lcs', 'subsequence', 'difflib']        results = {}        # Handle empty strings    if not str1 or not str2:        return {metric: 0.0 for metric in metrics}        # Prepare strings    s1, s2 = str1.lower(), str2.lower()        # 1. N-gram similarity (with multiple window sizes)    if 'ngram' in metrics:        ngram_scores = {}        for window in range(min([len(s1),len(s2),2]), min([5,max([len(s1),len(s2)])+1])):            # Skip if strings are shorter than window            if len(s1) < window or len(s2) < window:                ngram_scores[f'window_{window}'] = 0.0                continue                            # Generate character n-grams            ngrams1 = [s1[i:i+window] for i in range(len(s1) - window + 1)]            ngrams2 = [s2[i:i+window] for i in range(len(s2) - window + 1)]                        # Count matches            matches = sum(1 for ng in ngrams1 if ng in ngrams2)            max_possible = max(len(ngrams1), len(ngrams2))                        # Normalize            score = matches / max_possible if max_possible > 0 else 0.0            ngram_scores[f'window_{window}'] = score                    # Average of all n-gram scores        results['ngram'] = max(ngram_scores.values())#sum(ngram_scores.values()) / len(ngram_scores)        results['ngram_details'] = ngram_scores        # 2. Longest Common Substring (LCS)    if 'lcs' in metrics:        def longest_common_substring(s1, s2):            # Dynamic programming approach            m, n = len(s1), len(s2)            dp = [[0] * (n + 1) for _ in range(m + 1)]            max_length = 0                        for i in range(1, m + 1):                for j in range(1, n + 1):                    if s1[i-1] == s2[j-1]:                        dp[i][j] = dp[i-1][j-1] + 1                        max_length = max(max_length, dp[i][j])                        return max_length                lcs_length = longest_common_substring(s1, s2)        max_length = max(len(s1), len(s2))        results['lcs'] = lcs_length / max_length if max_length > 0 else 0.0        # 3. Longest Common Subsequence    if 'subsequence' in metrics:        def longest_common_subsequence(s1, s2):            # Dynamic programming approach for subsequence            m, n = len(s1), len(s2)            dp = [[0] * (n + 1) for _ in range(m + 1)]                        for i in range(1, m + 1):                for j in range(1, n + 1):                    if s1[i-1] == s2[j-1]:                        dp[i][j] = dp[i-1][j-1] + 1                    else:                        dp[i][j] = max(dp[i-1][j], dp[i][j-1])                        return dp[m][n]                subseq_length = longest_common_subsequence(s1, s2)        max_length = max(len(s1), len(s2))        results['subsequence'] = subseq_length / max_length if max_length > 0 else 0.0        # 4. SequenceMatcher from difflib    if 'difflib' in metrics:        sm = SequenceMatcher(None, s1, s2)        results['difflib'] = sm.ratio()        # Visualization of differences    if visualize:        try:            # Only works in notebooks or environments that support plotting            sm = SequenceMatcher(None, s1, s2)            matches = sm.get_matching_blocks()                        # Prepare for visualization            fig, ax = plt.subplots(figsize=(10, 3))                        # Draw strings as horizontal bars            ax.barh(0, len(s1), height=0.4, left=0, color='lightgray', alpha=0.3)            ax.barh(1, len(s2), height=0.4, left=0, color='lightgray', alpha=0.3)                        # Draw matching parts            for match in matches:                i, j, size = match                if size > 0:  # Ignore zero-length matches                    ax.barh(0, size, height=0.4, left=i, color='green', alpha=0.5)                    ax.barh(1, size, height=0.4, left=j, color='green', alpha=0.5)                                        # Draw connection lines between matches                    ax.plot([i + size/2, j + size/2], [0.2, 0.8], 'k-', alpha=0.3)                        # Add string texts            for i, c in enumerate(s1):                ax.text(i + 0.5, 0, c, ha='center', va='center')            for i, c in enumerate(s2):                ax.text(i + 0.5, 1, c, ha='center', va='center')                            ax.set_yticks([0, 1])            ax.set_yticklabels(['String 1', 'String 2'])            ax.set_xlabel('Character Position')            ax.set_title('Character-Level String Comparison')            ax.grid(False)            plt.tight_layout()            # plt.show()  # Uncomment to display        except Exception as e:            print(f\"Visualization error: {e}\")        # Calculate overall similarity score (average of all metrics)    metrics_to_average = [m for m in results.keys() if not m.endswith('_details')]    results['overall'] = sum(results[m] for m in metrics_to_average) / len(metrics_to_average)        return results# advanced_sequential_similarity('시크릿', '시크릿', metrics='ngram')# advanced_sequential_similarity('에이닷_자사', '에이닷')# mms_pdf = pd.read_excel(\"./data/mms_data_250408.xlsx\", engine=\"openpyxl\")mms_pdf = pd.read_csv(\"./data/mms_data_250408.csv\")mms_pdf['msg'] = mms_pdf['msg_nm']+\"\\n\"+mms_pdf['mms_phrs']mms_pdf = mms_pdf.groupby([\"msg_nm\",\"mms_phrs\",\"msg\"])['offer_dt'].min().reset_index(name=\"offer_dt\")mms_pdf = mms_pdf.reset_index()mms_pdf = mms_pdf.astype('str')# mms_pdf.sample(100)[['msg']].to_csv(\"./data/mms_sample.csv\", index=False)item_pdf_raw = pd.read_csv(\"./data/item_info_all_250527.csv\")item_pdf_all = item_pdf_raw.drop_duplicates(['item_nm','item_id'])[['item_nm','item_id','item_desc','domain','start_dt','end_dt','rank']].copy()item_pdf_all.query(\"rank<1000 and item_nm.str.contains('넷플릭스', case=False)\").head()# item_pdf_all.query(\"rank<1000\")[['item_nm']].drop_duplicates().to_csv(\"./data/item_nm_1000.csv\", index=False)alia_rule_set = list(zip(pd.read_csv(\"./data/alias_rules.csv\")['alias_1'], pd.read_csv(\"./data/alias_rules.csv\")['alias_2']))def apply_alias_rule(item_nm):    item_nm_list = [item_nm]    for r in alia_rule_set:        if r[0] in item_nm:            item_nm_list.append(item_nm.replace(r[0], r[1]))        if r[1] in item_nm:            item_nm_list.append(item_nm.replace(r[1], r[0]))    return item_nm_listitem_pdf_all['item_nm_alias'] = item_pdf_all['item_nm'].apply(apply_alias_rule)item_pdf_all = item_pdf_all.explode('item_nm_alias')item_pdf_all.query(\"rank<1000 and item_nm.str.contains('넷플릭스', case=False) or item_nm.str.contains('웨이브', case=False)\")[['item_nm','item_nm_alias','item_id']]user_defined_entity = ['AIA Vitality' , '부스트 파크 건대입구' , 'Boost Park 건대입구']item_pdf_ext = pd.DataFrame([{'item_nm':e,'item_id':e,'item_desc':e, 'domain':'user_defined', 'start_dt':20250101, 'end_dt':99991231, 'rank':1, 'item_nm_alias':e} for e in user_defined_entity])item_pdf_all = pd.concat([item_pdf_all,item_pdf_ext])entity_list_for_fuzzy = []for row in item_pdf_all.to_dict('records'):    entity_list_for_fuzzy.append((row['item_nm'], {'item_id':row['item_id'], 'description':row['item_desc'], 'domain':row['domain'], 'start_dt':row['start_dt'], 'end_dt':row['end_dt'], 'rank':1, 'item_nm_alias':row['item_nm_alias']}))stop_item_names = pd.read_csv(\"./data/stop_words.csv\")['stop_words'].to_list()from sentence_transformers import SentenceTransformerimport torchmodel = SentenceTransformer('jhgan/ko-sbert-nli')import renum_cand_pgms = 5pgm_pdf = pd.read_csv(\"./data/pgm_tag_ext_250516.csv\")def preprocess_text(text):    # 특수문자를 공백으로 변환    text = re.sub(r'[^\\w\\s]', ' ', text)    # 여러 공백을 하나로 통일    text = re.sub(r'\\s+', ' ', text)    # 앞뒤 공백 제거    return text.strip()clue_embeddings = model.encode(pgm_pdf[[\"pgm_nm\",\"clue_tag\"]].apply(lambda x: preprocess_text(x['pgm_nm'].lower())+\" \"+x['clue_tag'].lower(), axis=1).tolist(), convert_to_tensor=True)from kiwipiepy import Kiwikiwi = Kiwi()stop_item_names = list(set(stop_item_names + [x.lower() for x in stop_item_names]))entity_list_for_kiwi = list(item_pdf_all['item_nm_alias'].unique())for w in entity_list_for_kiwi:    kiwi.add_user_word(w, \"NNP\") for w in stop_item_names:    kiwi.add_user_word(w, \"NNG\") kiwi_raw = Kiwi()kiwi_raw.space_tolerance = 2tags_to_exclude = ['W_SERIAL','W_URL','JKO','SSO','SSC','SW','SF','SP','SS','SE','SO','SB','SH']edf = item_pdf_all.copy()edf['token_entity'] = edf.apply(lambda x: kiwi_raw.tokenize(x['item_nm_alias'], normalize_coda=True, z_coda=False, split_complex=False), axis=1)edf['token_entity'] = edf.apply(lambda x: [d[0] for d in x['token_entity'] if d[1] not in tags_to_exclude], axis=1)edf['char_entity'] = edf.apply(lambda x: list(x['item_nm_alias'].lower().replace(' ', '')), axis=1)exc_tag_patterns = [    ['SN', 'NNB'], ['W_SERIAL'], ['JKO'], ['W_URL'], ['W_EMAIL'],    ['XSV', 'EC'], ['VV', 'EC'], ['VCP', 'ETM'], ['XSA', 'ETM'], ['VV', 'ETN']]+[[t] for t in tags_to_exclude]class Token:    def __init__(self, form, tag, start, len):        self.form = form        self.tag = tag        self.start = start        self.len = len        def __repr__(self):        return f\"Token(form='{self.form}', tag='{self.tag}', start={self.start}, len={self.len})\"# 제외할 품사 패턴exc_tag_patterns = [    ['SN', 'NNB'], ['W_SERIAL'], ['JKO'], ['W_URL'], ['W_EMAIL'],    ['XSV', 'EC'], ['VV', 'EC'], ['VCP', 'ETM'], ['XSA', 'ETM'], ['VV', 'ETN']]+[[t] for t in tags_to_exclude]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "schema_prd = {",
        "    \"title\": {",
        "        \"type\": \"string\", ",
        "        'description': '광고 제목. 광고의 핵심 주제와 가치 제안을 명확하게 설명할 수 있도록 생성'",
        "    },",
        "    'purpose': {",
        "        'type': 'array', ",
        "        'description': '광고의 주요 목적을 다음 중에서 선택(복수 가능): [상품 가입 유도, 대리점 방문 유도, 웹/앱 접속 유도, 이벤트 응모 유도, 혜택 안내, 쿠폰 제공 안내, 경품 제공 안내, 기타 정보 제공]'",
        "    },",
        "    'product': {",
        "        'type': 'array',",
        "        'items': {",
        "            'type': 'object',",
        "            'properties': {",
        "            'name': {'type': 'string', 'description': '광고하는 제품이나 서비스 이름'},",
        "            'action': {'type': 'string', 'description': '고객에게 기대하는 행동: [구매, 가입, 사용, 방문, 참여, 코드입력, 쿠폰다운로드, 기타] 중에서 선택'}",
        "            }",
        "        }",
        "    },",
        "    'channel': {",
        "        'type': 'array', ",
        "        'items': {",
        "            'type': 'object', ",
        "            'properties': {",
        "                'type': {'type': 'string', 'description': '채널 종류: [URL, 전화번호, 앱, 대리점] 중에서 선택'},",
        "                'value': {'type': 'string', 'description': '실제 URL, 전화번호, 앱 이름, 대리점 이름 등 구체적 정보'},",
        "                'action': {'type': 'string', 'description': '채널 목적: [가입, 추가 정보, 문의, 수신, 수신 거부] 중에서 선택'},",
        "                'benefit': {'type': 'string', 'description': '해당 채널 이용 시 특별 혜택'},",
        "                'store_code': {'type': 'string', 'description': \"매장 코드 - tworldfriends.co.kr URL에서 D+숫자 9자리(D[0-9]{9}) 패턴의 코드 추출하여 대리점 채널에 설정\"}",
        "            }",
        "        }",
        "    },",
        "    'pgm':{",
        "        'type': 'array', ",
        "        'description': '아래 광고 분류 기준 정보에서 선택. 메세지 내용과 광고 분류 기준을 참고하여, 광고 메세지에 가장 부합하는 2개의 pgm_nm을 적합도 순서대로 제공'",
        "    },",
        "'required': ['purpose', 'product', 'channel', 'pgm'], ",
        "'objectType': 'object'}",
        "",
        "schema_prd_cot = {",
        "\"reasoning\": {",
        "    \"type\": \"object\",",
        "    \"description\": \"단계별 분석 과정 (최종 JSON에는 포함하지 않음)\",",
        "    \"properties\": {",
        "    \"step1_purpose_analysis\": \"광고 목적 분석 과정\",",
        "    \"step2_product_identification\": \"상품 식별 및 도메인 매칭 과정\", ",
        "    \"step3_channel_extraction\": \"채널 정보 추출 과정\",",
        "    \"step4_pgm_classification\": \"프로그램 분류 과정\"",
        "    }",
        "},",
        "\"title\": {",
        "    \"type\": \"string\",",
        "    \"description\": \"광고 제목. 광고의 핵심 주제와 가치 제안을 명확하게 설명\"",
        "},",
        "\"purpose\": {",
        "    \"type\": \"array\",",
        "    \"description\": \"STEP 1에서 분석한 광고의 주요 목적 (복수 가능). [상품 가입 유도, 대리점 방문 유도, 웹/앱 접속 유도, 이벤트 응모 유도, 혜택 안내, 쿠폰 제공 안내, 경품 제공 안내, 기타 정보 제공]에서 선택\"",
        "},",
        "\"product\": {",
        "    \"type\": \"array\",",
        "    \"items\": {",
        "    \"type\": \"object\",",
        "    \"properties\": {",
        "        \"name\": {",
        "        \"type\": \"string\", ",
        "        \"description\": \"STEP 2에서 식별한 제품/서비스 이름\"",
        "        },",
        "        \"action\": {",
        "        \"type\": \"string\",",
        "        \"description\": \"STEP 2-3에서 결정한 고객 기대 행동. [구매, 가입, 사용, 방문, 참여, 코드입력, 쿠폰다운로드, 기타] 중에서 선택\"",
        "        },",
        "        \"domain\": {",
        "        \"type\": \"string\",",
        "        \"description\": \"매칭된 상품 후보의 도메인 정보 (참고용, 최종 JSON에는 제외)\"",
        "        }",
        "    }",
        "    }",
        "},",
        "\"channel\": {",
        "    \"type\": \"array\",",
        "    \"items\": {",
        "      \"type\": \"object\",",
        "      \"properties\": {",
        "        \"type\": {",
        "          \"type\": \"string\",",
        "          \"description\": \"채널 종류: [URL, 전화번호, 앱, 대리점] 중에서 선택\"",
        "        },",
        "        \"value\": {",
        "          \"type\": \"string\",",
        "          \"description\": \"실제 URL, 전화번호, 앱 이름, 대리점 이름 등 구체적 정보\"",
        "        },",
        "        \"action\": {",
        "          \"type\": \"string\",",
        "          \"description\": \"채널 목적: [가입, 추가 정보, 문의, 수신, 수신 거부] 중에서 선택\"",
        "        },",
        "        \"benefit\": {",
        "          \"type\": \"string\",",
        "          \"description\": \"해당 채널 이용 시 특별 혜택\"",
        "        },",
        "        \"store_code\": {",
        "          \"type\": \"string\",",
        "          \"description\": \"매장 코드 - tworldfriends.co.kr URL에서 D+숫자 9자리(D[0-9]{9}) 패턴의 코드 추출하여 대리점 채널에 설정\"",
        "        }",
        "      }",
        "    }",
        "  },",
        "\"pgm\": {",
        "    \"type\": \"array\",",
        "    \"description\": \"STEP 4에서 선택한 프로그램 분류 (적합도 순 2개)\"",
        "}",
        "}",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SK텔레콤] 5GX 프라임 혜택을 확인해 보세요. \n",
            "[SKT] <5GX 프라임> 혜택 안내__#04 고객님, 안녕하세요._고객님이 가입하신 <5GX 프라임>의 혜택을 모두 이용하고 계신가요?_놓치는 혜택이 없도록 아래 URL을 통해 자세히 확인해 보세요.(데이터 통화료 무료)__▶ 요금제 혜택 자세히 보기: http://t-mms.kr/t.do?m=#61&s=23177&a=&u=https://m.tworld.co.kr/product/callplan?prod_id=NA00007790__■ 문의: SKT 고객센터(114)__SKT와 함께해 주셔서 감사합니다.\n",
            "[SK텔레콤] T 청소년안심팩 서비스를 무료로 이용해 보세요.\n",
            "(광고)[SKT] T 청소년안심팩 무료 서비스 안내__고객님, 안녕하세요._자녀의 안전과 부모님의 안심을 위한 서비스, <T 청소년안심팩>을 소개해 드립니다._T 청소년안심팩 서비스로 적절한 스마트폰 사용 시간 관리부터 유해매체 차단까지, 자녀와 함께 이용해 보세요. __■ 주요 안심 기능_- 관리: 자녀 휴대폰 사용 시간, 설치 앱 사용 제어_- 위치: 실시간 위치 조회, 등/하교 알림_- 차단: 유해사이트(URL)/유해 App 접속, 휴대폰 결제_- 알림: 학교 폭력 의심 문자__▶ [안드로이드] T 청소년안심팩(자녀용): http://t-mms.kr/aqB/#74_▶ [안드로이드] T 청소년안심팩(부모용): http://t-mms.kr/aqF/#74_▶ [iOS] T 청소년안심팩(부모용): http://t-mms.kr/aqv/#74__※ 앱 설치/이용 순서_1. 자녀 휴대폰에 자녀용 앱을 설치하신 후, 부모님 휴대폰 번호를 확인해 주세요._2. 부모님 휴대폰에 부모용 앱을 설치하신 후, 부모님 휴대폰 번호를 인증해 주세요.__■ 문의: SKT 고객센터(1558, 무료)__SKT와 함께해 주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] 에스알대리점 지행역점 1월 신년 행사 안내드립니다.\n",
            "(광고)[SKT] 에스알대리점 지행역점 1월 신년 행사 안내__고객님, 안녕하세요. _SK텔레콤 지행역점에서 1월 신년 행사 소식을 안내드립니다. (신시가지 지행 농협 건너편 SKT)__■ 갤럭시 S25 출시임박_ - 문자 받은 고객 한정 정품 고속 충전기 제공_ - 가장 빨리 받아볼 수 있습니다._ _■ 우리 아이 첫 휴대폰 미리미리 준비 하자! 갤럭시 와이드7 기기값 초저가_- 월요금 14,850원 (ZEM플랜 스마트 요금제 + 선택약정 1년 조건)_- 시나모롤 3종 패키지 + 인형 꽃다발 증정__■ 갤럭시 S23, Z플립5, S24 울트라 초특가 구매 찬스!_- 프라임플러스 요금제 또는 프리미엄 요금제 사용_- 공시지원금 및 매장 할인 지원 적용__■ 어르신 효도폰 행사중__■ 인터넷 + BTV 가입 시 최대 사은품 증정__※ 궁금하신 내용은 매장으로 문의 주시면, 자세하게 안내 도와 드리겠습니다.__■ 에스알대리점 지행역점_- 주소 : 경기도 동두천시 지행로 61, 한승빌딩 1층 (지행역 2번 출구, 지행 농협 건너편)_- 연락처 : 031-861-1918_▶매장 홈페이지 : http://t-mms.kr/t.do?m=#61&s=30186&a=&u=http://tworldfriends.co.kr/D150040027__■ 문의: SKT 고객센터(1558, 무료)_SKT와 함께 해주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤]미소대리점 고잔신도시점(본점) 고객 혜택 안내\n",
            "(광고)[SKT]미소대리점 고잔신도시점(본점) 고객 혜택 안내__고객님, 안녕하세요._미소대리점 고잔신도시점(NC 백화점 맞은편 국민은행 건물 1층)에서 안내 드립니다.__■ KT/LG/알뜰폰->SK이동시_- 선택약정 25%할인 + 유통망 추가 지원금 제공 __■ 삼성 전기종 특가할인_- Z플립5/폴드5 안산 최다판매 매장_- 사용 요금 그대로 최저가 보장_- 추가 사은품까지__■ 인터넷+TV 행사_- 결합할인 업그레이드 및 재설계_- 인터넷 최저 요금 및 최대 사은품 지원__■12세미만 자녀 특별행사_-삼성와이드6 128기기 기기값 최저가 보장_-12개월 약정으로 약정고민 NO_-월 이용요금 19,800원 → 14,850원(선택 약정 할인, ZEM 스마트 요금제 기준)_기기값+요금제 월 28,283원__■ 제휴혜택 프로모션 및 캡스홈 CCTV 무료체험/SK 매직렌탈 사은품제공__■ 미소대리점 본점_- 위치: 경기 안산시 단원구 광덕대로 174, 월드타운 B동 120호_- 연락처: 031-487-7277_※주차 1.월드타운 지하주차장 2.덕산타워(주차타워)_▶매장 홈페이지/예약/상담: http://t-mms.kr/t.do?m=#61&s=21844&a=&u=https://tworldfriends.co.kr/D152790000_▶매장 위치: http://t-mms.kr/t.do?m=#61&s=21845&a=&u=https://naver.me/GSi9SmZL__SKT와 함께해 주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] 휴대폰 결제 3천원 할인 혜택을 안내드립니다. \n",
            "(광고)[SKT] 휴대폰 결제 3천원 할인 혜택 안내 __#04 고객님, 7월을 맞이하여 SK텔레콤이 스무살 고객님께 휴대폰 결제 혜택을 준비했습니다. __▶ 혜택: 휴대폰 결제 3천원 할인_▶ 기간: 2022년 6월 22일(수)~7월 31일(일) _▶ 방법: 온라인 쇼핑몰/배달, 원스토어/구글/애플 앱스토어 등에서 1건 & 3천 원 이상 결제하시면 SKT 요금안내서에 자동 할인 적용_▶자세히 보기: http://t-mms.kr/t.do?m=#61&s=13240&a=&u=https://isasevent.sktelecom.com/birthday/sktbirthday.html__※ 유의 사항_- 할인 혜택은 이 문자메시지를 받은 만19세 생일이 지난 고객님께만 1회에 한해 적용됩니다._- 이용하신 휴대폰 결제액은 결제하신 다음 달 요금안내서에 합산 청구됩니다. _- 1건당 이용 금액이 3천 원 미만인 경우 할인 혜택이 적용되지 않습니다. _- 휴대폰 결제 이용 동의를 취소할 경우(서비스 해지, 명의변경, 이용 차단 등) 할인 혜택을 받으실 수 없습니다._- 결제를 취소할 경우 할인 혜택을 받으실 수 없습니다.__■ 문의: SKT 고객센터(1558, 무료)__SKT와 함께 해주셔서 감사합니다._무료 수신거부 1504 \n",
            "[SK텔레콤] 부스트 파크 용인동백에서 12월 제휴 매장 혜택을 안내드립니다. \n",
            "(광고)[SKT] 12월 부스트 파크 용인 동백 제휴처 혜택 안내  고객님, 안녕하세요. 부스트 파크 용인 동백 제휴처에서 사용할 수 있는 할인 쿠폰을 드립니다. 쿠폰 사용하시고, 용인 동백 상권 활성화에 동참해 주세요.  ▶ 제휴처 쿠폰 받기: http://t-mms.kr/t.do?m=#61&u=https://bit.ly/2Ua9z2L (T멤버십 앱 > SKT 5GX Boost Park > 인천/경기 > 용인 동백 > 할인 쿠폰 다운로드)  ■ 제휴처(동춘175 쇼핑몰) 및 쿠폰 혜택 - 동춘상회: 동춘상회 셰익스피어 패턴 상품 30% 할인(인테리어 액자/발 매트/셀룰로오스 행주 등) - 바운스 트램폴린 파크: 평일 2세션 입장료 20% 할인 - 롱브레드: 3만 원 이상 결제 시 탄산음료 1개 증정(테이블당 1회) - 장카츠: 메뉴 2개 이상 결제 시 탄산음료 1개 증정(테이블당 1회) - 4.2베이커리: 주문 예약 시 10% 할인/2만 원 이상 구매 시 미니 트러플 오일 증정  ▶ 혜택 보기: http://t-mms.kr/t.do?m=#61&u=http://asq.kr/42zrwZtTiyZx  ■ 동춘175 쇼핑몰 - 주소: 경기도 용인시 기흥구 동백죽전대로175번길 6 - 영업 시간: 오전 10시 30분~오후 9시 ▶ 찾아 오시는 길: http://t-mms.kr/t.do?m=#61&u=http://asq.kr/hFdyUlwXM7Mi  ■ 문의: SKT 고객센터(1558, 무료) ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "동물 없는 동물원 이벤트 안내\n",
            "(광고)[SKT]   고객님, 안녕하세요. 5G 기술이 자연을 지킬 수 있다는 믿음으로, <동물 없는 동물원> 이벤트가 진행됩니다. 동물과 함께했던 행복한 순간 또는 야생동물을 만나고 싶은 자연배경을 공유해주세요. 펫 리조트 상품권 등 푸짐한 상품이 기다립니다!  ▶ 이벤트 자세히 보기: http://t-mms.kr/t.do?m=#61&u=http://arzoo.sktinsight.com    ■ 동물 없는 동물원 이벤트 안내  - 기간: 2019년 8월 22일(목)~9월 22일(일)  - 참여 방법:  ① 반려동물과 함께하는 사진 또는 야생동물 터전에 손가락 하트 사진이나 영상 찍기 ② ＃동물없는동물원 또는 ＃동물하트챌린지 해시태그와 함께 인스타그램에 업로드 ③ 동물하트챌린지 릴레이에 함께할 친구 소환  - 경품:  ① 멍블랑 펫 리조트 숙박권 (1명) ② 펫프렌즈 10만원 이용권 (3명) ③ WWF 굿즈 랜덤발송 (10명) ④ 스타벅스 아메리카노 Tall 사이즈 기프티콘 (50명)  ★ AR동물원에서 만나고 싶은 동물 추천 이벤트도 놓치지 마세요! 애플 에어팟 2세대 등 다양한 경품을 드립니다  ※ 경품의 제세공과금은 SK텔레콤이 부담합니다.  SKT와 함께해주셔서 감사합니다. 무료 수신거부 1504\n",
            "[SK텔레콤] 보이스피싱 사례를 안내드립니다.\n",
            "[SKT] 보이스피싱 사례 및 대처법 안내__고객님, 안녕하세요._최근 해외 결제/신용 카드 발급 관련 가짜 문자를 보내 돈을 가로채는 보이스피싱 피해 사례가 발생하고 있습니다. 주의해 주시기 바랍니다.__■ 주요 사례_① 피싱범이 허위 결제 문자 또는 통장/신용 카드 발급 문자를 보내 고객님께 접근_② 이후 URL을 보내 악성 앱 설치 유도_③ 1332, 1301 등 정부 기관 번호로 변조해 명의 도용, 범죄 연루 등을 이유로 상품권 결제나 현금 요구_※ 경찰/검찰/금융감독원은 수사 목적으로 상품권 결제나 현금을 요구하지 않습니다._※ 정부 기관을 사칭한 URL은 절대 누르지 않아야 합니다._※ 다른 사람에게 신분증/신용 카드 사진을 보내지 않도록 특별히 주의해 주세요.__■ 대처 방법_- 결제 관련 인증 번호, 계좌 이체, 현금 전달을 요구할 경우 바로 스팸 신고 및 전화번호 차단 조치_- 피해를 입은 경우 바로 112 신고__보이스피싱으로 의심되는 문자를 받으시면 SKT 고객센터(114)로 문의해 주시기 바랍니다. _고객님의 안전한 통신 생활을 위해 최선을 다하겠습니다.__■ 문의: SKT 고객센터(114) __SKT와 함께해 주셔서 감사합니다.\n",
            "[SK텔레콤] 예비0캠 해지 예정입니다. \n",
            "[SKT] 예비0캠 해지 예정 안내__#04 고객님, 안녕하세요._SK텔레콤 0한동 운영진입니다.__예비0캠은 예비 대학생 고객님을 위한 서비스입니다._기간 안에 0한동 앱에서 캠퍼스 인증을 하지 않으실 경우, 예비0캠이 자동 해지될 예정입니다.__■ 예비0캠 해지 안내_- 해지일: 2022년 4월 28일(목) __▶ 0캠퍼스 바로 가기: http://t-mms.kr/t.do?m=#61&s=11544&a=&u=https://bit.ly/3LZZMUY__예비0캠 서비스를 이용해 주셔서 감사합니다._앞으로도 다양한 혜택과 서비스를 통해 고객님께 즐거움을 드리는 0한동이 되겠습니다.__※ 이 문자메시지는 2022년 4월 21일(목) 기준, 예비0캠 가입 고객님 중 캠퍼스 인증을 하지 않은 고객님께 발송되었습니다.__■ 문의: SKT 고객센터(114, 무료), 0한동 앱 1:1 문의_※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다._고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.__무엇이든 될 수 있는 0\n",
            "[SK텔레콤] T 우주가 쏜다! SPOTV NOW 첫 달 1,000원\n",
            "(광고)[SKT] T 우주가 쏜다! SPOTV NOW 첫 달 1,000원__#04 고객님, _T 우주가 해외 축구, 야구 팬들을 위해 쏩니다! _지금 우주패스에서는 SPOTV NOW 베이직 이용권을 첫 달 1,000원으로 시작하실 수 있어요.  __추가로 매일 투썸플레이스+세븐일레븐 30% 할인 혜택까지 받을 수 있으니, 우주패스의 풍성한 혜택을 빠짐없이 누려보세요. __■ SPOTV NOW+우주패스 life_- 이용요금: 9월 30일까지 가입 시 최초 가입 첫 달 1,000원(이후 월 9,900원)_- 혜택_① SPOTV NOW 베이직 이용권_② 세븐일레븐, 투썸플레이스 각각 최대 30% 할인(최대 일 9천 원, 월 3만 원)_▶ 자세히 보기: http://t-mms.kr/bUR/#74__■ 문의: T 우주 고객센터(1505, 무료)__무료 수신거부 1504\n",
            "[SK텔레콤] 0 고객님만을 위한 12월 공연/전시 혜택 안내드립니다.\n",
            "(광고)[SKT] 0×인터파크티켓 <미나 페르호넨 전시> 할인 안내__#04 고객님, 안녕하세요._요금제 상관없이 34세 이하 SK텔레콤 0 고객님이라면, 전시 <미나 페르호넨 디자인 여정: 기억의 순환>을 25% 할인받으실 수 있어요._매달 달라지는 공연/전시 할인 혜택으로 친구, 가족과 특별한 추억을 만들어 보세요.__▶ 지금 예매하기: http://t-mms.kr/jR4/#74__■ 0×인터파크티켓 혜택 안내_- 대상: 34세 이하 SK텔레콤 0 고객님_* 만 14세 미만 고객님은 참여가 제한됩니다.__■ 12월 공연 안내_- 뮤지컬 긴긴밤, 전시 툴루즈 로트렉, 전시 미나 페르호넨 디자인 여정: 기억의 순환_* 모든 공연/전시 각각 예매 가능합니다.__■ 문의_- SKT 고객센터(114, 무료)_- SKT 0 대표 문의 메일: skt0@sktelecom.com__SKT와 함께해 주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] 개인용 폰 업무용 폰 따로 둘까 고민 중이라면?\n",
            "(광고)[SKT] 넘버플러스II 안내__#04 고객님, 안녕하세요._개인용 번호와 업무용 번호, 아직도 같이 쓰세요?_일과 개인 생활을 분리하고 싶다면 <넘버플러스II>를 이용해 보세요._휴대폰 하나로 2개의 번호를 쓰실 수 있습니다.__■ 넘버플러스II_- 요금: 월 3,850원(부가세 포함)_- 이용 중인 휴대폰 번호 외에 010 번호 하나를 더 발급해주는 서비스로 상황에 따라 번호를 골라 쓰실 수 있습니다.__▶ 넘버플러스II 가입하기: http://t-mms.kr/2VO/#74_- T 월드 홈페이지/앱, T 월드 매장, SKT 고객센터, T 통화매니저 앱에서도 가입 가능__※ 유의 사항_함께쓰기 요금제 가입 번호로는 넘버플러스II를 이용하실 수 없습니다.__■ 문의: SKT 고객센터(1558, 무료)__무료 수신거부 1504\n",
            "[SK텔레콤] 지금 해지 신청 취소하시면, 다음 달 우주패스 all 천 원!\n",
            "(광고)[SKT] 지금 해지 신청 취소하시면, 다음 달 우주패스 all 천 원!__#91 해지 신청하신 #04 고객님께 <우주패스 all 1천 원 특가 이용권>을 선물로 보내드립니다.__2022년 6월 30일(목)까지 사용 가능한 쿠폰이니, 지금 바로 해지 신청 취소하시고 우주패스를 천 원에 한 번 더! 이용할 수 있는 기회를 놓치지 마세요!__■ 우주패스 all 1천 원 특가 이용권_- 쿠폰 번호: #92_- 쿠폰 등록 유효 기간: 2022년 6월 30(목)까지__■ 사용 방법_1. 해지 신청 취소_▶ http://t-mms.kr/t.do?m=#61&s=13029&a=&u=https://m-sktuniverse.tworld.co.kr/my/main_2. 나의 구독 > 내가 가입 중인 상품 클릭_3. 쿠폰할인 > 쿠폰 등록 > 쿠폰번호 입력 > 등록__※ 본 문자메시지를 받으신 고객님만 사용 가능 (1인 1회)_※ 쿠폰 적용 중 상품 해지 시, 쿠폰 재적용 불가__■ 문의: 구독 상품 전담 고객센터(1505, 무료)__SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] 통신생활의 최강 휴대폰 보험!\n",
            "(광고)[SKT] 통신 생활의 최강 휴대폰 보험 \"T All케어 플러스Ⅱ\" 가입 안내__고객님, 안녕하세요._SK텔레콤에서만 만날 수 있는 넘버원 휴대폰 보험 <T All케어 플러스 Ⅱ>로 고객님의 소중한 휴대폰을 지키세요. _분실/파손 보상과 프리미엄 서비스까지 한 번에 누리실 수 있습니다.__▶ T All케어 플러스Ⅱ 자세히 보기: www.tallcare.co.kr__■ T All케어 플러스 Ⅱ 상품 안내_ - 분실 시 보상폰 당일 배송(파손 전용 상품 제외)_ - 액정 파손 수리 및 보상 신청 대행_ - 배터리 교체 서비스_ - 스마트폰 관련 24시간 상담 (웹, 앱, 전화 상담)_ - 프리미엄 임대폰 무료 제공_ - 스마트기기(워치/태블릿PC) 파손보상 추가 혜택_ - 통신생활케어(금융사기피해보상 등)__※ 휴대폰 개통 후 60일까지만 T월드 매장을 통해 가입하실 수 있습니다._※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.__SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504\n",
            "[T 우주] 선착순 1만 명에게만 드리는 깜짝 혜택! \n",
            "(광고)[SKT] 선착순 1만 명에게만 드리는 깜짝 혜택! __#04 고객님, 안녕하세요!__배라 X 싸이의 역대급 콜라보! 6월 이달의 맛 <우주 라이크 봉봉> 출시 기념, 가입 감사 이벤트!__우주패스 with YouTube Premium + 배스킨라빈스에 가입하시면, 싱글레귤러는 기본! 추가로 파인트 아이스크림 교환권까지 드려요._이 모든 혜택이 단돈 13,900원!_ _▶ 우주패스 with YouTube Premium x 배스킨라빈스 이벤트 내용 확인하고 싶으시다면?: http://t-mms.kr/2MM/#74__▶ <우주패스 with YouTube Premium x 배스킨라빈스_Y> 혜택 안내_- 이용요금: 월 13,900원(부가세 포함)_- 혜택_① 유튜브 프리미엄 기본 혜택_② 싱글레귤러 교환권 1장_③ 파인트 아이스크림 교환권 1장(6월 가입 고객 한정)__■ 문의: 구독 상품 전담 고객센터(1505, 무료)__나만의 구독 유니버스, T 우주__무료 수신거부 1504\n",
            "[SK텔레콤][0 day] 0 청년 요금제 퀴즈 이벤트\n",
            "(광고)[SKT][0 day] 0 청년 요금제 퀴즈 이벤트__SK텔레콤 청년들을 위한 새로운 요금제!_0 청년 요금제 지금 확인하시고,_퀴즈 이벤트 참여해보세요!__추첨을 통해 5,000명에게 한솥 5천원 금액권을 드려요! __▶ 자세히 보기 : http://t-mms.kr/t.do?m=#61&s=20053&a=&u=https://bit.ly/3MWgN5V__■ 문의: SKT 고객센터(1558, 무료)__무료 수신거부 1504\n",
            "[SK텔레콤] 7월 T day 혜택 안내드립니다.\n",
            "(광고)[SKT] 7월 T day 혜택 안내__SKT [샐러디 메인 메뉴 포함 7,000원 이상 구매 시 3,500원 할인] 이게 되네!_▶ 자세히 보기 :  http://t-mms.kr/t.do?m=#61&s=27085&a=&u=https://bit.ly/3XvsGFA__■ 에이닷 X T 멤버십 구독캘린더 이벤트_T day 일정을 에이닷 캘린더에 등록하고 혜택 날짜에 알림을 받아보세요!_알림 설정하면 추첨을 통해 [다이소 1만원 할인 쿠폰]을 드립니다._▶ 이벤트 참여하기 : https://bit.ly/3L2w4QP__■ 문의: SKT 고객센터(1558, 무료)_무료 수신거부 1504\n",
            "Boost Park 부산 서면 헌혈 캠페인 안내\n",
            "(광고)[SKT] Boost Park 부산 서면 헌혈 캠페인 안내  고객님, 안녕하세요. 최근 코로나19의 영향으로 일선 의료 현장에서 혈액 수급에 어려움을 겪고 있습니다. 레드커넥트 앱을 통해 간편하게 헌혈에 참여해보세요. SKT 5GX 부스트 파크에서 마련한 작은 선물도 드립니다.  ■ 레드커넥트란? - SK텔레콤과 대한적십자사가 함께 만든 새로운 헌혈 앱입니다. 쉽고 빠르게 헌혈 예약을 하고 전자 문진을 받을 수 있으며, 누적된 혈액 검사 결과를 통해 건강을 관리할 수 있습니다. ▶ 레드커넥트 자세히 보기: http://t-mms.kr/t.do?m=#61&u=https://redconnect.co.kr  ■ 헌혈 이벤트 안내 - 기간: 2020년 5월 11일(월)~6월 30일(화) - 장소: 헌혈의집 서면센터, 부전센터, 서면로센터 - 참여 혜택: 레드커넥트 앱 설치하고 헌혈의집에서 헌혈하시면 SKT 5GX 부스트 파크 그립톡 증정  ■ 혜택 하나 더!  레드커넥트 앱 설치하고 서면 SKT 5GX 부스트 파크 T월드 매장에서 5G 서비스를 체험하시면 런닝맨, 보드게임카페, 레고카페 이용권 중 하나를 드립니다.  ▶ 매장 위치 보기: http://t-mms.kr/t.do?m=#61&u=https://bit.ly/2SIZxV2  ■ 문의: SKT 고객센터(114)  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "제목입니다.\n",
            "(광고)[SKT] a  b  c    d   무료 수신거부 1504\n",
            "[SK텔레콤] EBS 데이터팩(청소년) 프로모션의 혜택이 종료되었습니다.\n",
            "[SKT] EBS 데이터팩(청소년) 프로모션 종료 안내  고객님, 안녕하세요. 고객님이 가입하신 <EBS 데이터팩(청소년)> 프로모션의 혜택이 종료되었습니다.  ■ 등교 개학 요금 무료 프로모션 - 기간: 2020년 6월 1일(월)~2020년 12월 31일(목) - 대상: 프로모션 기간 중 EBS 데이터팩(청소년)에 가입하는 한국 나이 13세 이하 고객님 - 혜택: 프로모션 기간 동안 EBS데이터팩(청소년) 월 이용요금(최대 6,600원) 전액 할인 - 프로모션이 종료되어 2021년 1월부터 이용요금이 청구됩니다. 이용을 원하지 않으신다면 고객센터나 T월드를 통해서 EBS 데이터팩(청소년) 부가서비스를 해지하여 주시기 바랍니다.  ■ EBS 데이터팩(청소년) - 월 이용요금 6,600원(부가세 포함) - 주요 혜택: 매일 전용 데이터 2GB 제공(다 쓴 뒤 최대 3Mbps 속도로 무제한 사용 가능) - 이용 가능 사이트: EBSi(m.ebsi.co.kr), EBS 중학(mid.ebs.co.kr), EBS Math(m.ebsmath.co.kr), EBS English(m.ebse.co.kr), EBS 초등(primary.ebs.co.kr),EBS 온라인 클래스(https://oc.ebssw.kr),EBSEnglish(https://www.ebse.co.kr), EBS 방송 다시보기(https://m.ebs.co.kr), EBS 반디(https://m.ebs.co.kr), ebssw(https://www.ebssw.kr), 초목달영어(http://chomokdal.ebslang.co.kr) - 이용 가능 앱: EBSi 고교강의, EBS중학+, EBSMath, EBS English, EBS play, EBS반디, EBS초등, EBSi+, EBSe 에그붐, EBSe 펀리딩, EBS play  SKT와 함께해주셔서 감사합니다.\n",
            "100만 번째 5GX의 주인공이 되어보세요.\n",
            "(광고)[SKT] 5GX 100만 카운트다운 이벤트 안내  #04 고객님, 안녕하세요. 8월에 행운의 5GX 가입자가 되어보세요!  ■ 5GX 100만 카운트다운 이벤트 - 기간: 8월 1일(목)~8월 28일(수) - 대상: 이벤트 기간 중 SKT에서 5G폰을 개통한 고객님 - 내용 ① 자동응모: 80만/85만/90만/95만/100만 번째로 5G폰을 개통한 고객님께 제주도 럭셔리 여행 패키지(300만 원 상당) 증정 ② 퀴즈응모: 5GX 100만 가입자 돌파 축하 퀴즈에 참여하면, 추첨을 통해 경품 증정(최신 기종의 갤럭시 노트 5G, 비스타 워커힐 숙박권 등)  ▶ 이벤트 자세히 보기 http://t-mms.kr/t.do?m=#61&u=http://www.skt5gx-100.com    ■문의: SKT 고객센터(114)   SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "Boost Park 원주 단계 10월 제휴 혜택 안내드립니다. \n",
            "(광고)[SKT] 부스트 파크 원주 단계 제휴 혜택 안내  고객님, 안녕하세요. 부스트 파크 원주 단계에서 SKT 5GX 고객님들을 위해 무료 음료 쿠폰을 준비했습니다.  ▶ 쿠폰 다운로드: http://t-mms.kr/t.do?m=#61&u=https://bit.ly/3dnaHXa  ■ 제휴 혜택 - 제휴처: SK텔레콤 원주지점 카페 아이 갓 에브리씽(AK플라자 맞은편) - 내용: 무료 음료 쿠폰(4,000원 상당) 100% 지급 - 쿠폰 사용 방법: 위 링크를 눌러 T멤버십 앱에 접속한 뒤 다운로드한 쿠폰을 카페 직원에게 보여 주기  ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "[SK텔레콤] 유튜브 프리미엄 첫 달 할인+세븐일레븐 1만 원권\n",
            "(광고)[SKT] 유튜브 프리미엄 첫 달 할인+세븐일레븐 1만 원권__우주패스를 사랑해 주셨던 #04 고객님!_광고없는 유튜브 보고 싶으시다면, 지금 다시 돌아오세요!__8월 31일(목)까지 가입하시면,_유튜브 프리미엄 첫 달 1천 원 할인에 세븐일레븐 1만 원권까지 받을 수 있어요!__■ 행사내용 _2023년 8월 31일(목)까지 아래 이벤트 페이지에서 발급 받은 쿠폰으로 가입하시면_① 우주패스 life 1개월 1천 원 할인_② 세븐일레븐 기프트카드 1만 원권 제공 _▶ 자세히 보기: http://t-mms.kr/bFI/#74__※ 유튜브 프리미엄 외 배달의민족, 배스킨라빈스 등 우주패스 life의 다른 추가혜택을 선택하셔도 혜택이 제공됩니다.__■ 문의: T 우주 고객센터(1505, 무료)__무료 수신거부 1504\n",
            "T데이터쿠폰 이벤트 참여하고 문화상품권 받으세요!\n",
            "(광고)[SKT] T데이터쿠폰 10월 조르기 이벤트 안내    고객님, 안녕하세요. T데이터쿠폰 조르기 이벤트에 참여하시고 문화상품권 5천 원권 받아 가세요.  추첨을 통해 조르기를 보내신 분과 받으신 분 모두에게 드립니다.    ▶ T데이터쿠폰 구매하기: http://t-mms.kr/t.do?m=#61&u=https://tdatacoupon.co.kr/event/eventDetail.view?idx=1230&isOngoingEvent=Y   ■ 10월 조르기 이벤트 - 기간: 2020년 10월 6일(화)~10월 31일(토)  - 참여 방법: 기간 안에 T데이터쿠폰(1GB, 2GB, 5GB) 조르기 한 뒤, 조르기 받으신 분이 T데이터쿠폰을 선물해 주면 추첨을 통해 두 분 모두 문화상품권 5천 원권(300명) 증정 - 당첨자 발표: 2020년 11월 4일(수) * 당첨되신 분께 문자메시지로 안내해 드립니다.    ※ 유의 사항 - 이벤트 기간 안에 T데이터쿠폰 조르기와 T데이터쿠폰 선물 받기까지 완료해야 이벤트에 응모됩니다. - 조르기 후 데이터쿠폰 선물 받기까지 완료하면 자동 응모됩니다. 응모 횟수에는 제한이 없습니다.  - T데이터쿠폰 선물하기를 할 때 경품 추첨 문자 수신에 동의하셔야 이벤트에 응모됩니다.  - 경품 사용 후에는 T데이터쿠폰을 환불하실 수 없습니다.  - 자세한 사항은 이벤트 페이지를 참고해 주세요.    ■ 문의: T데이터쿠폰 고객센터(1599-7963)  ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해바랍니다.  SKT와 함께해주셔서 감사합니다. 무료 수신거부 1504\n",
            "[SK텔레콤] 티다문구점 삼성 갤럭시 버즈3/버즈3프로 새출발 특가 안내\n",
            "(광고)[SKT] 티다문구점 삼성 갤럭시 버즈3/버즈3프로 새출발 특가 안내__고객님, 안녕하세요._갖고 싶었던 갤럭시 버즈3 시리즈, 티다문구점에서만 진행하는 단독 특가전에서 만나보세요! __지금 티다문구점에서는 버즈3+케이스 패키지가 41% 할인!! _추가로 구매자 전원 투명케이스&이어폰 청소스틱을 사은품으로 제공합니다.__▶ 티다문구점 갤럭시 버즈3/버즈3프로 특가전 바로 가기: http://t-mms.kr/a0m/#74_▶ 행사기간 : 25.3.1(토) ~ 3.31일(월) 까지__■ 티다문구점은?_① SK텔레콤 T 다이렉트샵이 운영하는 온라인 편집 숍_② 독창적인 디자인과 우수한 품질의 제품 판매_③ 가격 상관없이 무료 배송__■ 문의: 티다문구점 고객센터(1599-1932)__SKT와 함께해 주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤]광장대리점 광교월드마크점 새봄 맞이 혜택 받아보세요\n",
            "(광고)[SKT]광장대리점 광교월드마크점 새봄 맞이 혜택 안내  고객님, 안녕하세요. 광장대리점 광교월드마크점에서 마련한 최신 휴대폰 및 새학년 새학기 혜택 받아보세요~     ■ 우리 아이 첫 휴대폰 혜택 안내 -생애 최초 휴대폰 가입하는 우리 아이 키즈폰 특가 판매 행사 -선택약정 가입시 요금 25% 할인 제공 -위치확인 서비스, 유해차단 서비스 무료 제공 -강화 유리 액정 필름 무료 제공  ■ 갤럭시 S21 즉시 개통 이벤트 -퍼펙트클럽 : 24개월 사용 후 휴대폰 반납시, 남은 할부금 최대 50% 면제 -중고폰 최대 보상 -휴대폰 구매시 삼성 정품케이스 증정(재고소진시 종료) -삼성 정품 악세사리 10만원 할인 쿠폰 및 악세사리 패키지 증정  ※ 문자 받으시고 내방하셔서 단골고객 등록시 액정필름 무료 교체!  ■ 광장대리점 광교월드마크점 - 주소: 경기도 수원시 영통구 센트럴타운로107 (광교월드마크 , 월드스퀘어) 204동 52호 - 연락처: 031-212-9966 - 영업 시간: 오전 10시~오후 8시 00분(월~금), 오전 11시~오후 8시(주말, 공휴일)  ▶매장 행사 보기: http://t-mms.kr/t.do?m=#61&s=292&a=&u=https://tworldfriends.co.kr/D132250251 (비대면 가입 가능)   ■ 문의: SKT 고객센터(1558, 무료) ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "데이터를 80% 이상 사용하셨네요!\n",
            "(광고)[SKT] #04고객님, 데이터가 부족하시다면 매달 100GB의 데이터를 마음껏 쓸 수 있는 T플랜 <에센스>를 추천해드립니다.__▶ T플랜 에센스 자세히 보기_http://t-mms.kr/t.do?m=#61&u=http://m2.tworld.co.kr/jsp/op.jsp?p=w2005&f=c0001__■ T플랜 에센스 (월 69,000원, 부가세 포함)_- 기본제공 데이터 100GB(데이터를 다 쓰면, 최대 5Mbps 속도로 계속 사용)_- 음성통화(집전화, 이동전화) 무제한, 영상/부가통화 300분 제공__▶ 이용 중인 요금제 자세히 보기 _https://bit.ly/30tPbLb__SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] 최신 영화를 최고의 가성비로 즐기세요.\n",
            "(광고)[SKT] Apple TV 앱 청구 할인 이벤트__#04 고객님, 안녕하세요._SKT 휴대폰 결제로 Apple TV 스토어에서 영화를 소장 또는 대여하시고, 40% 청구 할인 혜택을 받아 보세요. __■ Apple TV 앱 청구 할인 이벤트_- 이벤트 기간: 2024년 8월 1일(목)~8월 31일(토)_- 할인 대상: 이벤트에 참여한 고객님 중 Apple TV 스토어에서 SKT 휴대폰 결제로 영화를 소장 또는 대여한 고객님_- 할인 혜택: 영화 소장 및 대여에 쓰인 SKT 휴대폰 결제 합산 금액의 40% 청구 할인_- 참여 방법: 이벤트 페이지에서 <참여하기>를 눌러 휴대폰 인증을 완료한 후 휴대폰 결제까지 완료__▶ 이벤트 참여하러 가기: http://t-mms.kr/jpB/#74__※ 유의 사항_- 이벤트 페이지에서 <참여하기>를 눌러 인증을 완료해야만 할인 혜택을 받을 수 있습니다._- 최대 청구 할인 금액은 5만 원이며, 청구 할인 금액은 9월 청구 요금에 반영됩니다. _- 휴대폰 결제 이용 동의를 취소할 경우 할인 혜택을 받으실 수 없습니다.__■ 문의: SKT 고객센터(1558, 무료)__SKT와 함께해 주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] 원진대리점 상계역점 9월 추석맞이 행사안내\n",
            "(광고)[SKT] 상계역점 추석맞이 행사안내드립니다__고객님 안녕하세요 친절 만족도 1등 상계역 2번출구앞 SKT 상계역점입니다_추석을 맞이하여 행사를 진행중입니다_매장 방문해주시면 친절하게 자세히 안내해드리겠습니다.__▶이벤트 기간: 23년 9월 1일(금)~9월 30일(토) __● 갤럭시 S23 할인특가_● 플립5, 폴드5 공시 지원금 최대 지원_● 부모님 위한 효도폰 알뜰폰 특가 행사_● 무약정 고객님 약정신청만하셔도 월 25% 할인_● 기초 연금 및 노령 연금 혜택 신청 시 월 12,100원 할인__● 휴대폰 전기종 할인 진행중_- 선택약정할인 최대 62만원_- 제휴카드 월 40만원 사용 시 최대 60만원_- 기존 휴대폰 반납 시 추가 보상 10만원~30만원_- 선택약정할인+제휴카드+기존 휴대폰 보상 진행 시_  최대 150만원 할인 진행!___▶SK텔레콤 상계역점_- 주소 : 서울 노원구 중계동 141-86 1층 SK텔레콤_- 연락처 : 02-930-2929_- 매장 홈페이지 :▶ http://t-mms.kr/bSM/#74_  SKT 상계역점과 함께해주셔서 감사드립니다__■ 문의 : SKT 고객센터(1558, 무료)_무료 수신거부 1504_\n",
            "[SK텔레콤] 가로수대리점 센트라스점 새해맞이 갤럭시 특가 혜택 안내\n",
            "(광고)[SKT] 가로수대리점 센트라스점 새해맞이 갤럭시 특가 혜택 안내__고객님, 안녕하세요. 성동구 고객만족 1위 센트라스점에서 새해맞이 특가 행사를 안내드립니다. 편안히 방문해 주세요.__■ 갤럭시 시리즈 새해맞이 특별 할인_- S22 할부원금 : 최저가_- S22 Ultra : 326,000원_- Z플립4 : 203,000원_- Z폴드4 : 872,700원_(공시지원금 + 프라임플러스요금제 사용 + 제휴 카드 + 매장 추가지원 + 특별지원 적용) ※ 공시지원금 할인은 변동 될 수 있습니다. ※ 특가할인 재고 소진시 행사 자동 종료됩니다.__■ 성동구 인터넷 공식 접수처_- 푸짐한 사은품 혜택 지원_- 인터넷+TV 접수 시 상품권 36만 원 + 추가 사은품 최대 증정_- 결합할인 최대 36,100원 할인 (기가라이트 인터넷 + 4인 가족 결합 기준)__■ 갤럭시 S23 시리즈 사전예약 시작_- S23, 23+, 23 Ultra 사전예약 시 매장 사은품 추가 증정__■ 아이폰14 시리즈 대량 확보, 즉시개통 혜택_- 재고 문의 대환영_- 아이폰 14 시리즈 구매 시 에어팟 또는 애플워치 SE2 동시구매 시 추가 할인 (에어팟 중복 할인 가능)__■ 가로수대리점 센트라스점_- 주소 : 서울특별시 성동구 왕십리로 410, 센트라스상가 L동 110호 (상왕십리역 1번 출구, 버거킹 옆)_- 연락처 : 02-2297-9850_▶ 매장 홈페이지 :http://t-mms.kr/t.do?m=#61&s=17849&a=&u=http://tworldfriends.co.kr/D151980008__■ 문의: SKT 고객센터(1558, 무료)_SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504\n",
            "Error with API call: invalid syntax. Perhaps you forgot a comma? (<unknown>, line 45)\n",
            "[SK텔레콤] 홍릉대리점 사당역점 리뉴얼 오픈 기념 혜택 안내드립니다. \n",
            "(광고)[SKT] 광장대리점 사당역점 리뉴얼 오픈 기념 혜택 안내   고객님, 안녕하세요. 홍릉대리점 사당역점이 리뉴얼 오픈 기념으로 고객님께 혜택을 드립니다.   ■ 리뉴얼 오픈 기념 혜택  - 매장에서 이 문자를 보여주시는 고객님께 음료 제공 - 단골고객 등록 시 액정 보호 필름 무료 교체  - 휴대폰 구매 시 액정 보호 필름, 휴대폰 케이스, 차량용 충전기, 보조배터리 등 푸짐한 사은품 증정 * 구매 고객님께는 선착순 특별 사은품을 드립니다.  ■ 홍릉대리점 사당역점  - 주소: 서울특별시 관악구 과천대로 943 1층 - 연락처: 02-6015-0056 - 주요 업무: 유선/휴대폰 상품 상담, 요금 수납, 명의변경 등 - 영업 시간: 오전 10시~오후 9시(평일), 오전 10시~오후 8시(주말, 공휴일)  ※ SK텔레콤 공식인증대리점은 고객님과 직원의 안전을 위해 체온 체크, 마스크 의무 착용, 손 소독제 비치 등 생활방역 수칙을 철저히 준수하고 있습니다. ※ 매장 방문 시 다른 사람과 충분한 거리를 유지해 주시기 바랍니다.  ■ 문의: SKT 고객센터(1558, 무료) ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "[SK텔레콤] 10월에 받으신 혜택을 안내드립니다. \n",
            "[SKT] 10월 혜택 내역 안내__#04 고객님, 안녕하세요._<5GX 프라임플러스> 가입 후 10월에 받으신 혜택을 안내드립니다.__■ 10월에 받은 혜택_① T 지원금약정 할인: #91_② 휴대폰 요금 할인: #92_③ T 멤버십 할인: #93__자세한 내용은 아래 URL을 통해 확인하실 수 있습니다.(데이터 통화료 무료)__▶ 받은 혜택 자세히 보기: http://t-mms.kr/t.do?m=#61&s=23163&a=&u=https://m.tworld.co.kr/v6/benefit __■ 문의: SKT 고객센터(114)__SKT와 함께해 주셔서 감사합니다.\n",
            "[SK텔레콤] 홍주대리점 내포신도시직영점 매장 오픈안내\n",
            "(광고)[SKT] 홍주대리점 내포신도시직영점 매장 오픈안내__고객님, 안녕하세요!_내포신도시 주민여러분을 위한 [SK텔레콤 홍주대리점 내포신도시직영점]이 오픈하였습니다!__■ 봄 나들이 이벤트(3월 한정)_ - 전 기종 신규/기기변경 시 [성인 또는 아동용 자전거 중 택1] 증정 __■ 고객님들을 위한 파격 이벤트(4월 한정)_ - 4월 아이폰 구매시 [에어팟2], 갤럭시S,폴더블 시리즈 구매시 [버즈2] 증정! _   (수량 소진시까지)__■ 단골 등록 이벤트 (상시)_ - 매장 방문하여 단골 등록하시면 가정용(차량용) 충전기 무료 증정! _   (수량 소진 시까지)__■ 업무처리_ 1. 휴대폰 구매 [내포신도시 주민들을 위한 특별 할인]_ 2. 인터넷 가입 [최대 상품권 증정]_ 3. ADT캡스 [우리집에 배송된 택배, 집앞 유모차 안전보호]__▶매장안내_ - 연락처: 010-5222-7733_ - 주소: 충남 홍성군 홍북읍 청사로48번길12, 장자빌딩 1층 103호_ - 매장홈페이지: https://tworldfriends.co.kr/D631340017/_ - 인스타그램:https://instagram.com/sk_hj_naepo?igshid=YmMyMTA2M2Y=__항상 SKT와 함께해 주셔서 감사합니다__무료 수신거부 1504\n",
            "[SK텔레콤] 3월 0 day 혜택 안내\n",
            "(광고)[SKT] 3월 0 day 혜택 안내__<3월 20일(목) 혜택>_만 13~34세 고객이라면_SKT 0 day_[던킨 츄이스티 도넛 천원에 드림]_이게 되네!_(올리브, 카푸치노 중 택1)_▶ 자세히 보기 : _http://t-mms.kr/t.do?m=#61&s=30904&a=&u=https://bit.ly/41tKjqO__■ 문의: SKT 고객센터(1558, 무료)_무료 수신거부 1504\n",
            "월 16,500원으로 Oculus Go를 만나보세요!\n",
            "(광고)[SKT] 더 저렴하게 오큘러스 고 VR팩 이용하기   고객님, 안녕하세요.  독립형 VR 기기 Oculus Go를 할인된 가격, 월 16,500원에 이용해보세요. 스마트폰 없이도 간편하게 신기한 VR 세상을 경험할 수 있습니다.   ▶ 오큘러스 고 VR팩 자세히 보기:  http://t-mms.kr/t.do?m=#61&u=https://m.sktelecom5gx.com/html/subscription/oculus.html  ■ 오큘러스 고 VR팩 안내 - 제공 혜택: \"Oculus Go\" 기기 + VR 콘텐츠 - 이용요금: 월 16,500원 판매가: 198,000원(부가세 포함), 일시불/12개월 분할 납부 가능  ■ 문의: SKT 고객센터(114)  SKT와 함께해주셔서 감사합니다.   무료 수신거부 1504\n",
            "[SK텔레콤] 에스알대리점 거여직영점 6월 이벤트 안내\n",
            "(광고)[SKT] 에스알대리점 거여직영점 6월 이벤트 안내__고객님, 안녕하세요. _거여동 사거리, 거여역 7번 출구 앞에 위치한 SK텔레콤 거여직영점에서 6월 초특가 이벤트를 진행합니다. __■ SK 인터넷+ B tv 가입 신청 시 사은품 최대 증정__■ 애플 초대박 행사_- 아이폰15 프로 128GB_- 아이폰15 프로맥스 128GB_- 공시지원금 적용, 프리미엄 요금제 사용__■ 삼성 갤럭시 마지막 재고 행사_- 갤럭시 Z플립4 512GB_- 갤럭시 S23_- 공시지원금 적용, 프리미엄 요금제 사용__■ 삼성 갤럭시 A34 / 퀀텀4 / A136_- 선택약정 25% 요금 할인, 기존 쓰던 요금제 그대로 개통__■ 에스알대리점 거여직영점_- 주소 : 서울특별시 송파구 오금로 500, 거여역 7번 출구_- 연락처 : 02-6015-8777_▶매장 홈페이지 : http://t-mms.kr/t.do?m=#61&s=26913&a=&u=http://tworldfriends.co.kr/D150040042__■ 문의: SKT 고객센터(1558, 무료)_SKT와 함께 해주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤]씨앤 사당역점 봄맞이 이벤트 안내\n",
            "(광고)[SKT] 씨앤대리점 사당역점 오픈안내__고객님, 안녕하세요._SK텔레콤 공식 대리점 사당역점을 오픈하였습니다._이제 더 편리하게 SK텔레콤을 이용해 보세요.__매장에 오시면 갤럭시 S22, 아이폰 13, 아이폰 SE 3 를 비롯한 최신 스마트폰을 체험하고 구매할 수 있습니다. 고객님께 꼭 맞는 요금제부터 결합 혜택 등 가족 통신요금 절감 방법도 안내 받을 수 있습니다.__■ 오픈 기념 혜택 안내_- 방문하시는 모든 고객님에게 필름교체 무료로 해드리고 있습니다 _- 구독상품 체험 시 다양한 체휴처에서 사용할 수 있는 할인쿠폰을 드려요_- 휴대폰 구매하시는 모든 고객님에게 2 in 1 그릴 또는 겐지아 와플 메이커를 드려요 _※ 단, 사은품은 선착순 증정 후 마감__■ 오픈 매장 안내_- 주소: 서울특별시 관악구 과천대로 943, 1동 1층 101호 (남현동, 금강빌딩)_- 연락처: 02-525-2011_- 처리업무: 신규가입, 회선이동, 휴대폰변경, 명의변경, 요금납부 등 SKT 각종업무처리 가능합니다._▶ 사당역점 둘러보기: http://t-mms.kr/t.do?m=#61&s=11685&a=&u=http://tworldfriends.co.kr/D150370010__■ 문의: SKT 고객센터(1558, 무료)_※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.__SKT와 함께해 주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] 이엔티대리점 미사역점 봄맞이 휴대폰 행사 안내드립니다\n",
            "(광고)[SKT] 서울ent대리점 미사역점 봄맞이 이벤트__고객님 안녕하세요._SK텔레콤 공식인증대리점 미사역점입니다__봄을 맞이하여 다양한 이벤트가 준비되어 있으며_■ 매장에 방문하셔서 문자를 보여주시면_추가할인, 사은품 등_다양한 혜택을 받아보실 수 있습니다__■ SK공식인증대리점 서울ent대리점 미사역점_- 주소 : 경기 하남시 미사강변동로 73_- 연락처 : 031-8028-1400 _- 구술약도 : 미사튼튼병원 건물 1층(미사역 9번출구에서 80m)_▶ 홈페이지 :http://t-mms.kr/t.do?m=#61&s=24876&a=&u=https://naver.me/GAiQb51P__■ 문의 : SKT 고객센터(1558, 무료)_SK텔레콤과 함께해 주셔서 감사합니다._무료 수신거부 1504\n",
            "[SK텔레콤] T다이렉트샵 클럽기변 및 사전예약 안내드립니다.\n",
            "(광고)[SKT] T다이렉트샵 <폴더블 사전예약/ 클럽기변> 서비스 신청 안내__고객님, 안녕하세요._SK텔레콤 T다이렉트샵에서 갤럭시 폴드3/갤럭시 Z플립3을 사전예약할 때 <클럽기변>을 신청해 보세요. 쓰던 폰의 잔여 할부금을 출고가 기준 최대 50%까지 면제해 드립니다.__① 추천 스마트폰: 갤럭시 폴드3/갤럭시 Z플립3 __■ T다이렉트 샵 클럽기변 신청 방법_① 갤럭시 폴드3/갤럭시 Z플립3 사전예약 시 하단의 <클럽기변 신청하기> 버튼 클릭_② 반납할 휴대폰을 <민팃폰케어(https://app.mintit.co.kr)> 앱으로 사전 점검을 진행_③ 가까운 민팃 ATM에서 개통한 휴대폰 번호를 입력 후 <클럽기변 반납> 선택_④ 휴대폰을 민팃 ATM에 반납_▶ 자세히 보기: https://m.shop.tworld.co.kr/exhibition/view?exhibitionId=P00000213__■T다이렉트샵 사전예약 안내_ ① 기간: 8/17(화)~8/23(월) (7일간)_ ② T다이렉트샵  혜택_     - PXG 에디션 단독 출시: 폴드3/플립3 전용 PXG 정품 케이스, 네임택 등 총 7종 추가 구성품 제공_    - 전용T기프트 : 크루엘라 콜라보(파우치/케이스 등) or 스타워즈 콜라보(무선충전패드 등) 등    _ ③  T안심 특별 보상: 쓰던 폰 반납 시 최대 15 만원 추가 보상 (갤럭시 S및 노트 주요시리즈)_ ▶ 자세히 보기: https://m.shop.tworld.co.kr/exhibition/view?exhibitionId=P00000211__  ■ 문의: T다이렉트샵 고객센터(1525)_※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.__SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504\n",
            "Error with API call: invalid syntax. Perhaps you forgot a comma? (<unknown>, line 21)\n",
            "[SK텔레콤] 광장대리점 화정역점 리뉴얼 오픈 이벤트 행사안내드립니다.\n",
            "(광고)[SKT]광장대리점 화정역점 리뉴얼 오픈행사__고객님 안녕하세요!_광장대리점 화정역점 에서 리뉴얼 행사 안내드립니다._(화정역 1번출구 -> 문화의거리 방향 200M ABC 마트 옆)_ _■ 우리매장 \"방문만\" 하셔도 여행용 파우치 지급__■ 휴대폰 구매를 하지 않으셔도 중고가입,데이터쉐어 유심 무상제공_(프라임요금제 이상 사용 고객님 대상, 공기기 데이터이용 가능 이용료 0원!)__■ 우리아이 첫 스마트폰 파격할인! ZEM 포켓몬2_ZEM플랜 스마트 12개월 약정기준 - 월 14,850원 (가족결합시 추가할인가능)__■ SK 인터넷 신규가입 혜택!_새로 인터넷 가입하시고 푸짐한 사은품,결합할인 추가로 받아가세요!_우리매장 단독행사! BTV 시청이 가능한 삼성 A9+ 태블릿 2대 증정!_(기가인터넷+스탠다드 3년약정 가입시 , BTV AIR 2대 가입시 태블릿증정) __■ 휴대폰요금,가계통신비 점검 해보셧나요?_최적 요금제로 셋팅! 가계통신비 확 낮춰드립니다!_KT,LG 타사 고객님 또한 휴대폰 구매없이 사용하시던 번호,기기 그대로~ _저렴한 요금제로 SKT로 사용이 가능합니다! __■ 본사직영 SK텔레콤 공식인증 광장대리점 화정역대리점_- 주소: 경기 고양시 덕양구 화신로260번길 41 101호(동성골드프라자) 1층_- 연락처: 031-970-2010_▶홈페이지 : http://t-mms.kr/t.do?m=#61&s=25157&a=&u=https://naver.me/FnMEx0Vm__■ 문의: SKT 고객센터(1558, 무료) _SKT와 함께 해주셔서 감사합니다._무료 수신거부 1504\n",
            "양산 물금에서 SK텔레콤의 새로운 공식인증대리점을 만나보세요\n",
            "(광고)[SKT] 공식인증대리점 한백대리점 양산라피에스타점 오픈 안내  #04 고객님, 안녕하세요 SK텔레콤이 증산역 앞 라피에스타(지하 1층)에 공식인증대리점을 오픈했습니다. 이제 더 편리하게 SK텔레콤을 이용해보세요.  ■ 오픈 기념 혜택 안내 - 매장 단골 고객 등록 시 보조배터리 패키지 증정 - 휴대폰 구매 시 친환경 텀블러 증정 ※ 사은품은 선착순 증정 후 마감  ■ 오픈 매장 안내 - 이름: SK텔레콤 한백대리점 양산라피에스타점 - 주소: 양산시 물금읍 증산역로 177 라피에스타 지하1층(B011호) - 전화번호: 055-911-5338 - 주요업무: 이동전화 요금수납, 신규가입, 기기변경, 명의변경, 최신 스마트폰 액세서리 판매, 인터넷/IPTV 가입, ADT캡스 보안상품 상담 등 - 업무시간: 오전 10시 ~ 오후 9시 (연중무휴)  ▶ 한백대리점 양산라피에스타점 위치 확인하기 http://t-mms.kr/t.do?m=#61&u=https://bit.ly/2K4G79m  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "T다이렉트샵 스마트폰 구매 혜택 안내드립니다. \n",
            "(광고)[SKT] T다이렉트샵 스마트폰 구매 혜택 안내  #04 고객님, 안녕하세요. 스마트폰을 바꿀 때가 되셨나요? SK텔레콤 공식 온라인샵, T다이렉트샵에서 고객님께 꼭 맞는 스마트폰을 소개해 드립니다.  ① 추천 스마트폰: #91 ② 추천 요금제: #92 요금제  ※ 추천 스마트폰을 24개월 #93 할인 선택 시, 월 #94원(①+②)에 구매하실 수 있습니다.  ▶자세히 보기: #95  ■ T다이렉트샵만의 구매 혜택 ① 모든 고객님께 드리는 T기프트 - 블루투스 이어폰, 보조배터리 등  ② T다이렉트샵만의 특별한 다이렉트 플랜 - 다이렉트 플랜 선택 시 매달 청구 월정액의 5%를 SK pay point로 제공(12개월)  ③ 원하는 대로 받아보는 T다이렉트샵만의 배송 방식 - 원하는 장소로 당일 찾아가는 [바로도착] - 원하는 곳에서 받아보는 [택배 배송]  - 가까운 대리점에서 찾아가는 [바로픽업] ※ 구매 시 배송별 유의 사항을 확인하세요.  ■ 문의: T다이렉트샵 고객센터(1525)  ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "[SK텔레콤] Jump AR 출석 체크하고 치킨 선물 받으세요.\n",
            "(광고)[SKT] 연말 특집 Jump AR 12월 출석 체크 이벤트 안내  #04 고객님, 안녕하세요. Jump AR 앱 오픈갤러리에 출석 체크하고 치킨 세트, 문화상품권을 받을 수 있는 이벤트에 응모해 보세요.  ■ Jump AR 12월 출석 체크 이벤트 - 대상: Jump AR 앱 오픈갤러리에 3일 이상 콘텐츠를 게시하신 고객님 - 경품: BBQ 황금올리브치킨+콜라 세트(35명), 문화상품권 1만 원권(10명) - 기간: 2020년 12월 11일(금)~12월 20일(일) - 참여 방법 ① Jump AR 앱 다운로드 ② Jump AR의 AR 콘텐츠로 사진/영상 촬영 후 오픈갤러리에 게시하면 1일 출석 체크 완료 ③ 3일 이상 출석 체크하면 응모 완료 * 이벤트 상세 정보는 앱에서 확인하실 수 있습니다.  ▶ Jump AR 앱 바로 가기: http://t-mms.kr/t.do?m=#61&u=http://bit.ly/2vRACGo  ■ 문의: SKT 고객센터(1558, 무료) ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "[SK텔레콤] 서울대리점 선릉직영점 10월 행사 안내\n",
            "(광고)[SKT] 서울대리점 선릉직영점 10월 행사 안내_고객님, 안녕하세요. SK텔레콤 선릉직영점에서 아이폰14 출시 기념 할인 행사를 진행합니다.__■ 아이폰14, 최다 물량 보유, 즉시개통_- 신한카드 사용 시 최대 90만 원 할인 (월 30만원 이상 사용 조건)__■ 갤럭시 Z플립4, Z폴드4 구매 혜택_- 혜택1. 삼성카드 사용 시 최대 72만 원 추가 할인_- 혜택2. 갤럭시 탭 or 갤럭시 워치5 무료 증정 (5GX프라임 요금제 이용기준)__■ 갤럭시 S22 특가 할인 _- 태블릿 무료 증정 및 할부원금 최저가 (공시지원금, 5GX 프라임플러스 요금제 이용기준, 제휴카드 사용 조건) _※ 공시지원금 할인은 변동될 수 있습니다.__■ 삼성 갤럭시 특별 할인 행사_- S21 재고정리 할인, 와이드6, A33 등 5G 모델 특별 할인_- 가성비 최강 스마트폰 퀀텀3 특가 (삼성카드 사용 시 기기값 최저가)__■ 우리집 지킴이 홈 CCTV 및 인터넷, TV 전문 매장 혜택_- 홈CCTV 6개월 무료 이용 + 휴대폰 월 요금 최대 5,500원 할인_- 인터넷, TV 신청 시 푸짐한 사은품 최대 지원__■ 서울대리점 선릉직영점_- 주소 : 서울특별시 강남구 테헤란로 339 (역삼동, 선릉빌딩), 선릉역 6번 출구와 7번 출구 사이_- 연락처 : 02-553-3357 (손님 응대 시 전화상담을 도와드리기 어려울 수 있습니다. 내방을 추천드립니다.)_▶ 매장 홈페이지 :http://t-mms.kr/t.do?m=#61&s=16873&a=&u=http://tworldfriends.co.kr/D151890022__■ 문의: SKT 고객센터(1558, 무료)_SKT와 함께해주셔서 감사합니다._무료 수신거부 1504\n",
            "[SKT] T플랜 에센스 혜택 안내\n",
            "(광고)[SKT] 데이터 100GB 요금제__#04 고객님, 아직 T플랜 에센스로 안 바꾸셨나요? __지금 이용 중인 band 데이터 퍼펙트 기본요금에 월 3,110원만 추가하면 매달 데이터 100GB를 받으실 수 있어요!_* 2019년 #91기준 __▶ T플랜 에센스 자세히 보기_(월 69,000원, 부가세 포함)_http://t-mms.kr/t.do?m=#61&u=http://m2.tworld.co.kr/jsp/op.jsp?p=w2005&f=c0001__SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] 백두대간대리점 방화직영점 오픈 5주년 고객혜택 안내\n",
            "(광고)[SKT]백두대간대리점 방화점에서 고객님을 위한 혜택안내__고객님, 안녕하세요_SK텔레콤 방화직영점에서 드리는 고객혜택을 받아보세요__■ 방문혜택_- 모든기종 필림 무료교체_- 악세사리 원가 판매__■ 추가혜택_1. 갤럭시Z 폴드3, 플립3 구매시 사은품 증정_- 태블릿 또는 스마트워치 무료 증정_- 5GX클럽 가입하고 기기변경시(19개월차 부터 가능) 남은 할부금 출고가의 최대 50% 면제_- 악세사리 10만원 할인 쿠폰 또는 삼성케어 파손보장 1년권 증정__■ ADT캡스 도어가드 또는 이너가드 1년 무료체험 제공(사용요금) _- 사용시 화제보험, 도난/파손 보험 추가 제공__■ SK매직 렌탈상품 15% 할인 혜택제공(가입 첫 3개월 무료 프로모션)__■ SK텔레콤 백두대간대리점 방화직영점_- 주소 : 서울 강서구 방화동 572-7번지 1층 sk_- 연락처 : 02-2664-9600_- 이동전화 : 010-4070-9601_▶ 매장 홈페이지: https://tworldfriends.co.kr/d147050012_ 친구 맺고 상담 예약하시면 매장에서 휴대폰 액정 보호 필름 무상교체__※ SK텔레콤 공식인증대리점은 고객님과 직원의 안전을 위해 코로나19 생활방역 수칙을 철저히 준수하고 있습니다.__SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] 라온대리점 범어점 리뉴얼 오픈 이벤트 안내\n",
            "(광고)[SKT] 라온대리점 범어점 리뉴얼 오픈 이벤트 안내__#04 고객님, 안녕하세요. _KBS 입구 라온대리점 범어점이 T Factory 매장으로 새 단장 했습니다._리뉴얼 기념으로 1월 28일(금)부터 2월 12일(토)까지 이벤트를 진행하오니 많은 방문 부탁드립니다.__■ T Factory란?_고객 경험과 체험을 우선하는 차별화된 디자인의 프리미엄 매장입니다.__■ 리뉴얼 이벤트 하나!_- 매장 체험 후 친구 등록하신 고객님께 그립톡 증정(재고 소진시까지)__■ 리뉴얼 이벤트 둘!_- 친구 등록 고객님 중 네이버 플레이스 리뷰 작성 고객님 고급 선물 택1_<택 1 구성품>_1. 무선 블루투스 스피커 1대_2. 고속 무선 충전 기능 지원 마우스패드 1개_3. 무선 블루투스 이어폰 1개_※ 리뉴얼 이벤트 참여 후, 매장 내방시 경품 수령 가능 __■ 매장안내_- 주소: 대구 수성구 달구벌대로 2484 1층 T Factory (2호선 수성구청역 2번출구, KBS입구)_- 연락처: 053-216-1177(유료)_- 네이버플레이스: http://t-mms.kr/t.do?m=#61&s=10176&a=&u=https://m.place.naver.com/place/1976265692/home_- 매장 홈페이지: http://t-mms.kr/t.do?m=#61&s=10177&a=&u=https://tworldfriends.co.kr/D336740020__■ 문의: SKT 고객센터(1558, 무료)_※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.__SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504  \n",
            "[SK텔레콤] 에스알대리점 동암역점 신설 오픈 혜택 안내\n",
            "(광고)[SKT] 에스알대리점 동암역점 신설 오픈 혜택 안내__고객님, 안녕하세요. SK텔레콤 공식인증 동암역점이 5월 가정의 달 신설 OPEN 하여 오픈 기념 혜택을 안내드립니다. 항상 친절한 동암역점이 되겠습니다.__◆ 갤럭시 시리즈 구매 혜택 (5G 프라임 요금제 사용 기준)_- 갤럭시 S시리즈 또는 Z폴드/플립 시리즈 구매 고님께 갤럭시 워치 or 갤럭시 탭 증정 _- 갤럭시 Z플립 5G : 할부원금 94,800원_- 갤럭시 Z폴드 2 : 70만 원 대 특가 행사_※ 매장 자체 프로모션 추가 할인 적용 가능__◆ 갤럭시 S22 기기값 무료 : 공시지원금 할인 517,500원+ 제휴카드 할인 480,000원 (5G 프라임 요금제 6개월 사용 기준)__◆ 가정의 달 특가 프로모션 _- 키즈폰 신규 가입 시 기기값 무료 (24개월 약정 기준)__※ 공시지원금은 변동될 수 있습니다. 정확한 가격은 매장으로 문의 부탁드립니다.__★OPEN 기념 인터넷 + TV 가입 특별 혜택_- 인터넷 + IPTV 가입 시 최대 사은품 증정__■ 에스알대리점 동암역점_- 주소: 인천광역시 부평구 열우물로 50 (십정동, 제일빌딩), 동암역2번 출구에서 더샵 부평 APT 방향_- 연락처: 032-221-5950_▶ 매장 홈페이지 :http://t-mms.kr/t.do?m=#61&s=12245&a=&u=http://tworldfriends.co.kr/D150040040__■ 문의: SKT 고객센터(1558, 무료)_※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.__SKT와 함께해주셔서 감사합니다._무료 수신거부 1504\n",
            "[SK텔레콤] 휴대폰 고객 정보를 변경해 주시기 바랍니다.\n",
            "[SKT] 휴대폰 고객 정보 변경 요청__고객님, 안녕하세요. 고객님께서 이용하고 계신 휴대폰의 명의와 고객 정보가 일치하지 않아 서비스 이용이 제한될 수 있습니다. 원활한 서비스 이용을 위해 체류 기간을 연장하거나 명의를 변경해 주시기 바랍니다.__■ 고객 정보 불일치 사유_① 명의자의 사망_② 소속 사업자 또는 세금계산서 사업자의 휴업이나 폐업_③ 외국인 체류 기간 만료_④ 외국인 등록 사항 말소_⑤ 기타__고객 정보를 변경하지 않을 경우 이용약관 제10조(고객의 의무)와 제17조(이용정지)에 따라 2023년 12월 7일(목) 이후 휴대폰 수신과 발신이 모두 정지될 예정입니다. 이후 이용약관 제19조(해지)에 따라 2023년 12월 19일(화)~12월 21일(목)에 가입이 해지될 수 있습니다._※ 명의변경을 위해 매장에 방문하기 전 SKT 고객센터(114)에 연락해 필요한 서류를 확인해 주세요. __SKT와 함께해 주셔서 감사합니다.__(Notification from SK Telecom regarding Change in User’s Name) We have verified that there has been a change in user’s name due to death, cancellation of Alien Registration, expiration of period of stay, or permanent closure of business license or tax bill. Under “Clause 10 of Users Terms and Conditions (Responsibility of Users) and “Clause 17 of Users Terms and Conditions (Suspension of Use)”, your incoming/outgoing service will be blocked sequentially after December 7, 2023. Please be informed that your service will be canceled in December 19 to 21, 2023 under “Clause 19 of Users Terms and Conditions (Cancellation)” unless you change the user name or follow up on any other required procedures (e.g. receiving permission for extension of stay).__■ Inquiry: Foreign customer center(080-252-5011)\n",
            "초고속 인터넷 약정할인 기간 종료 안내\n",
            "[SKT] 초고속 인터넷 약정할인  기간 종료 안내  고객님, 안녕하세요. 고객님께서 이용 중인 초고속 인터넷 상품의 약정할인 기간이 다음 달에 종료될 예정입니다.  약정할인 기간이 끝나도 이용 중인 상품을 같은 금액으로 사용하실 수 있습니다. 또한, 이후에 상품을 해지하셔도 할인 반환금은 청구되지 않습니다.  ▶ 약정 문의 1600-2000(유료, 평일 오전 9시~오후 6시)  SK텔레콤과 함께해주셔서 감사합니다.\n",
            "[SK텔레콤] 공식인증 대리점 서대구센터 지점업무 안내\n",
            "(광고)[SKT] 공식인증 대리점 서대구센터 지점업무 안내__고객님, 안녕하세요._앞으로 SK텔레콤 지점업무는 PS&M 서대구센터(구. 죽곡광장점) 에서도 처리하실 수 있습니다.__■ 처리 가능 업무_- 신규가입, 기기변경 등 일반 업무_- 발신 통화 내역서 발급_- 임대폰 신청/반납_- 명의도용 신청/접수_- 기타 지점 특수 업무__■ 처리 불가 업무_- 법인 다회선 업무_- 로밍 임대서비스_- USIM 카드 환불__■ PS&M 서대구센터 안내_ - 주소 : 대구시 달성군 다사읍 달구벌대로 863 진광타워 1층 _ - 전화번호 : 070-7470-5820__■ 지점업무 가능 시간_ - 평일 오전 10시 ~ 오후 6시__SKT와 함께 해주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] 이용하고 계신 요금제의 혜택이 변경됩니다.\n",
            "[SKT] 이용 요금제 혜택 변경 안내   고객님, 안녕하세요. 2021년 5월 1일(토)부로 고객님께서 이용하시는 요금제의 wavve, FLO 혜택이 아래와 같이 변경됩니다. 서비스 이용에 참고해 주시기 바랍니다.  ■ 대상 요금제 - 5GX프라임, T플랜 스페셜, T플랜 시니어 스페셜   5GX프라임+다이렉트플랜, T플랜 스페셜+다이렉트플랜  - 0플랜 라지, 0플랜 슈퍼히어로 요금제에 가입하신 고객님 중 T멤버십 VIP 등급 혜택을 선택하지 않은 고객님 ※ T멤버십 VIP 등급 혜택을 선택하신 고객님은 변경 없이 혜택이 유지되며, 5월 1일(토) 이후 VIP 혜택 대신 FLO/wavve 혜택을 선택할 경우 혜택이 변경되어 적용됩니다.  ■ 변경일 - 2021년 5월 1일(토)  ■ 변경 내용 ① 할인 대상  - 변경 전: wavve 앤 데이터(wavve앤 데이터 플러스 제외) 또는 FLO 앤 데이터 중 택1  - 변경 후: wavve 앤 데이터(wavve앤 데이터 플러스 포함) 또는 FLO 앤 데이터 2종 모두 ② 할인율 (최대 할인 금액)  - 변경 전: 1개만 무료(최대 9,900원 할인 ※ wavve 앤 데이터 가입 시) - 변경 후: 가입한 상품 모두 70% 할인(최대 14,140원 할인 ※ wavve 앤 데이터 플러스와 FLO 앤 데이터 모두 가입 시)  ※ 5월 1일(토) 이후 대상 요금제로 변경하거나 wavve/FLO 상품을 가입 또는 해지 할 경우 변경된 혜택으로 적용됩니다.(상품 해지 후 재가입 포함)  ■ 문의: SKT고객센터(114)  SKT와 함께해주셔서 감사합니다.\n",
            "[SK텔레콤] 큰사랑대리점 명일역점 2월 설연휴 한정 특별 이벤트 안내드립니다.\n",
            "(광고)[SKT] 큰사랑대리점 명일역점 2월 설연휴 한정 특별 이벤트 안내__고객님, 안녕하세요. 강동구에서 가장 오래된 명일역점 점장 권건입니다. _매장 방문하시고 이 문자만 보여주셔도 필름교체 or 락스타 집밥(4p)을 증정합니다. 방문하셔서 문자를 꼭 보여주세요. ^^__■ 갤럭시 S24 구매 혜택_- 농협제휴카드할인 월 40만 24개월 사용조건으로 기기값 696,000원 할인_- 삼성 10만 원 액세서리 구매 쿠폰 증정_- 2년 내내 필름 무상 교체, 케이스 무상 제공__■인터넷+TV 신청 혜택 _- 45만 원 상당 사은품 즉시 증정_- 상품명 : 기가라이트 인터넷+ 스탠다드+스마트 셋톱박스 이용조건_- 월 요금 (가족 구성원수에 따라 상이함)_  : 4인가족 15,600원, 3인가족 21,600원, 2인가족 32,600원_  : 1인가족 36,100원__■ 보안 이벤트 진행 중_- ADT캡스 이너가드 6개월 무료사용 이벤트 (정상요금 월 15,000원)_- 참여고객 전원 6개월 요금 지원 + 해지 시 부담 없음_- 참여고객 전원 휴대폰 요금 (요금제에 따라) 1,100원~5,500원 할인!__■ 큰사랑대리점 명일역직영점_- 주소 : 서울특별시 강동구 양재대로 1627, 명일역 1번 출구 나오시자 마자 우측_- 연락처 : 02-6235-8808_▶ 매장 홈페이지 : http://t-mms.kr/t.do?m=#61&s=24562&a=&u=https://tworldfriends.co.kr/D134220148__■ 문의: SKT 고객센터(1558, 무료)_SKT와 함께 해주셔서 감사합니다._무료 수신거부 1504\n",
            "[SK텔레콤] 우주패스 all 파리바게뜨 혜택 안내\n",
            "(광고)[SKT] 우주패스 all 파리바게뜨 혜택 안내__#04 고객님, 파리바게뜨 좋아하세요? _최초 가입 첫 달 1,000원으로 파리바게뜨 최대 30% 할인 받는 방법, SK텔레콤 천호사거리점으로 오시면 친절하게 안내 드려요. __▶ SK텔레콤 천호사거리점 위치 안내:_http://t-mms.kr/t.do?m=#61&s=11206&a=&u=http://naver.me/xDs6kpVm__■ 파리바게뜨 최대 30% 할인 방법_① 우주패스 all 가입 합니다_② 추가혜택으로 파리바게뜨를 선택 합니다_③ 파리바게뜨 매장 직원에게 T멤버십 앱 [우주패스 매직 바코드]를 활성화시켜 보여주세요 _※ 구매 금액 1,000원 당 300원 할인(월 최대 3만원, 일 최대 9천원 할인 제공)__■ 던킨, 도미노피자, 뚜레쥬르 등 최대 60% 할인 찬스_- 우주패스 all 가입 시 T Day 혜택이 Upgrade!_- 던킨, 도미노피자, 피자헛, 뚜레쥬르 등에서 최대 60% 할인 혜택까지 누리실 수 있습니다. __최초 가입 첫 달 1,000원으로 이 모든 혜택을 받는 방법이 궁금하다면 SK텔레콤 천호사거리점으로 오세요!__■ 문의: 구독상담센터(1505, 무료)_※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.__SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] 0 고객님만을 위한 공연/전시 혜택 안내드립니다.\n",
            "(광고)[SKT] 0×인터파크 티켓 공연/전시 혜택 안내__#04 고객님, 안녕하세요._요금제 상관없이 34세 이하 SK텔레콤 0 고객님이라면, <헬로키티 50주년 특별전>을 30% 할인받아 보세요.__▶ 지금 예매하기: http://t-mms.kr/jEB/#74__■ 0×인터파크 티켓 혜택 안내_- 대상: 34세 이하 SK텔레콤 0 고객님_- 혜택: 매달 달라지는 공연/전시 할인_* 만 14세 미만 고객님은 참여하실 수 없습니다.__■ 7월 공연 안내_- 빨래, 4월은 너의 거짓말, 헬로키티 50주년 특별전_* 모든 공연/전시 각각 1인당 4장 예매 가능합니다.__■ 문의_- SKT 고객센터(1558, 무료)_- SKT 0 대표 문의 메일: skt0@sktelecom.com__SKT와 함께해 주셔서 감사합니다.__무료 수신거부 1504\n",
            "T map 주차로 할인받고 주차하세요.\n",
            "(광고)[SKT] T map 주차 할인 쿠폰 증정  Fun하고 Cool한 주차비 할인 쿠폰이 도착했습니다! 쿠폰으로 주차비를 아껴보세요.  ▶ 주차비 할인 쿠폰 받기:  http://t-mms.kr/t.do?m=#61&u=https://bit.ly/2A7IXIE  ■ T map 주차 요금 할인 혜택 - 시간 주차권 최대 80% 할인 - T멤버십 할인: 10% 할인(1일 1회 최대 5,000원, 월 5회)  ■ T map 주차 앱은?  - 주차장 검색과 주차 요금 결제 등을 쉽게 할 수 있는 앱입니다.  ■ 문의: T map 주차 고객센터(1800-2689)  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "[SK텔레콤] 우주패스 쿠폰 등록 독려 안내\n",
            "(광고)[SKT]_안녕하세요. 고객님은 12월에 우주패스All 구독 상품을 가입한 고객으로_쿠폰 발급 대상입니다.__이미 쿠폰 발급 문자를 받으신 고객께서는, 기존 메시지 함에서 쿠폰 번호 확인하여_등록하시고, 아직 쿠폰 회신을 못 받으신 분은 이번 달 내에 쿠폰 문자가 발송 예정입니다.__■쿠폰 등록 안내_ - 등록방법 : 나의 구독> T우주 우주패스 all 꺽쇠(>) 터치 > 쿠폰 할인 내 쿠폰 등록 > 구독 할인_ - 혜택 : 쿠폰 1회 등록시 우주패스 all 월 구독료 2개월 간 총 10,900원 할인(월 5,450원 x 2개월)_  * 할인 후 구독료 : 2개월 간 총 8,900원(월 4,450원 x 2개월)_ - 아직 쿠폰 문자를 못 받으신 고객께서는 이 달 내 문자 수신 후 쿠폰 등록을 해주시기 바랍니다__■ 우주패스 기본 혜택 안내_ - 매 달 SK pay point 3천점, 아마존 무료배송, 아마존 장바구니 할인 쿠폰 5천원권 2매 등_ - 배달의 민족, 베스킨라빈스 등 주요 제휴처 7~8천원 할인_ - wavve, FLO 이용시 추가 할인__SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] T청소년유해차단 앱을 다시 설치해 주세요.\n",
            "[SKT] T청소년유해차단 앱 설치 안내__고객님, 안녕하세요._자녀의 휴대폰에서 T청소년유해차단 앱이 15일 이상 작동하지 않고 있어 알려 드리오니, 앱이 원활히 작동될 수 있도록 확인해 주시기 바랍니다. 휴대폰을 교체하셨거나 앱이 삭제된 경우, 앱을 다시 설치해 주세요.__이 앱은 안드로이드 스마트폰에서만 설치하고 이용하실 수 있습니다.__■ 문의: SKT 고객센터(114)_※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다._고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.__SKT와 함께해주셔서 감사합니다. \n",
            "[SK텔레콤] 갤럭시 S21 구매 고객님께 드리는 카카오톡 이모티콘 받아가세요!\n",
            "(광고)[SKT] 갤럭시 S21 구매 고객 대상 카카오톡 이모티콘 증정 안내  #04 고객님, 안녕하세요. 갤럭시 S21을 구매하신 모든 고객님께 귀요미 점프 동물들 카카오톡 이모티콘을 드립니다! 다양한 점프 동물들의 모습을 Jump AR 앱에서 지금 바로 확인해 보세요.  ▶ Jump AR 이벤트 바로 가기: http://t-mms.kr/t.do?m=#61&u=http://bit.ly/2vRACGo   ■ 갤럭시 S21 카카오톡 이모티콘 이벤트  - 대상: 갤럭시 S21 신규가입/기기변경 고객님 - 기간: 2021년 1월 22일(금)~쿠폰 소진 시까지 - 경품: 귀요미 점프 동물들 카카오톡 이모티콘(14,000명)  - 참여 방법 ① Jump AR 바로 가기 링크 클릭 ② 앱 실행 후 팝업 이미지를 통해 이벤트 페이지 접속 ③ 이모티콘 받기 버튼을 클릭, 본인인증 후 이모티콘 쿠폰 번호 자동 발급  ■ 문의: SKT 고객센터(1558, 무료)   ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "[SK텔레콤] 강남스타대리점 방배카페골목점 10월 특별 혜택 안내\n",
            "(광고)[SKT] 강남스타 방배카페골목점 10월 특별 혜택 안내__고객님, 안녕하세요. SKT 방배카페골목점에서 아이폰 13 사전 예약 및 10월 특별 혜택을 준비했습니다. 할인 및 결합 혜택 컨설팅 및 단골 등록 시 무료 필름 교체도 해드리오니 언제든지 편하게 방문하여 주세요.__■ 아이폰 13, 미니, 프로, 프로맥스, 전 모델 사전 예약 중_- 방배동에서 재고 최다 보유, 기다림 없이 빠른 수령 가능__■ 갤럭시 Z폴드3 기기변경 시 추가 보상 혜택 (기존 폰 반납 조건)__■ 우주패스all 런칭 기념 프로모션 혜택_- 실속있는 구독형 콘텐츠 총 4만 원의 혜택을 첫달 단돈 1천원으로 제공_- 기본 혜택(아마존+구글원+11번가) + 추가 혜택(파리바게트  30% 할인)__■ SK매직, 인터넷+WIFI, IPTV, ADT캡스 혜택_ - SK매직 구독상품 프로모션 15% 할인 (정수기, 공기청정기, 안마의자 등)_ - ADT캡스 홈CCTV 공식지정 매장 할인 적용 (월 요금 할인+사은품 증정)_ - 초고속 인터넷 + BTV 공식지정 매장 할인 적용 (최저 요금 설계+상품권 증정)__■ 강남스타대리점 방배카페골목점 _- 주소 : 서울 서초구 방배중앙로27길 2 (방배동, 서성빌딩), 방배동 카페골목 4거리_- 연락처 : 02-599-5011_▶ 매장 홈페이지: http://t-mms.kr/t.do?m=#61&s=5573&a=&u=http://tworldfriends.co.kr/D139510080__■ 문의: SKT 고객센터(1558, 무료)_※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.__SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504\n",
            "5GX프라임을 이용하면 FLO가 무료입니다. \n",
            "(광고)[SKT] 5GX프라임 FLO 무료 혜택 안내  #04 고객님,  스마트폰으로 음악을 들으신다면, FLO를 무료로 이용할 수 있는 <5GX프라임> 어떠세요?   ▶ 5GX프라임 혜택 자세히 보기: http://t-mms.kr/t.do?m=#61&u=https://skt.sh/dMrlG  ■ 혜택 1. FLO 또는 wavve 무료 이용 - FLO 앤 데이터 무료(월 7,900원, 부가세 포함) : 모바일 전용 음악 무제한 듣기 - wavve 앤 데이터 무료(월 9,900원, 부가세 포함) : 지상파, 종편 실시간 TV + VOD 무제한 시청 가능  ■ 혜택 2. 스마트 기기 추가 1회선 무료  : 스마트 워치, 태블릿, 자녀의 ZEM워치, 함께쓰기  ■ 혜택 3. T멤버십 VIP 등급 제공 : 연 6회 영화 무료 관람, 패밀리 레스토랑/편의점 등 다양한 제휴 혜택  ■ 혜택 4. 공유 데이터 30GB 제공 : 데이터 선물하기 가능, T가족모아데이터는 제외  ■ 혜택 5. 기본데이터 완전 무제한(속도 제한 없음)  ■ 5GX프라임 요금제: 부가세 포함 월 89,000원  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "갤럭시 노트20/20 Ultra 9월 구매 혜택 신청하세요.\n",
            "[SKT] 갤럭시 노트20/20 Ultra 9월 구매 혜택 안내  #04 고객님, 안녕하세요. 지금 갤럭시 노트20/20 Ultra 구매 혜택으로 사은품을 신청하실 수 있습니다. 바로 혜택 확인하고 신청해보세요.  ■ 갤럭시 노트20/20 Ultra 구매 혜택(택1) ① 장바구니 쿠폰 10만 원권 증정 : 5GX 클라우드 게임(Xbox 게임 패스 얼티밋) 3개월 쿠폰 및 컨트롤러, 갤럭시 워치2, 갤럭시 버즈 라이브 등 상품 구매 시 사용 가능 ② 삼성 케어 플러스 1년권  ■ 쿠폰 신청 방법 삼성 멤버스 앱 접속 > 혜택 클릭 > 갤럭시 노트20 구매 혜택 배너 클릭 > 모바일 이벤트몰 접속 시 쿠폰 자동 발급 ※ 개통 후 3일 뒤부터 발급받을 수 있습니다.   ■ 쿠폰 사용 기간 2020년 9월 18일(금)~10월 15일(목)  ▶ 5GX 클라우드 게임(Xbox 게임 패스 얼티밋) 이용권 - Xbox Live Gold를 비롯하여 100개 이상의 Xbox 게임을 PC/콘솔에서 자유롭게 이용할 수 있는 이용권(16,700원/월)  ▶ 5GX 클라우드 게임(Xbox 게임 패스 얼티밋) 알아보기: http://t-mms.kr/t.do?m=#61&u=https://www.5gxcloudgame.com  ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.  SKT와 함께해주셔서 감사합니다.\n",
            "dd\n",
            "(광고)[SKT]  무료 수신거부 1504\n",
            "[SKT] 2G 이용약관 변경 안내\n",
            "(광고)[SKT] 이동전화, WCDMA 이용약관 변경 안내  고객님 안녕하세요. 이동전화 및 WCDMA 이용약관이 변경되어, 아래와 같이 안내드리오니 이용에 참고하시기 바랍니다.  < 이동전화 이용약관 변경사항 > ▶ 주요 변경 사항 1. 2019. 2. 21일(목)부터 2G 서비스 신규/전환 가입이 중단됩니다. 2. 이용정지 또는 일시정지 상태가 아닌 경우의 회선 중, 3개월 이상 사용량이 없는 경우 이용을 정지 할 수 있습니다. 3. 제17조 1항 13호의 이용정지 사유로 서비스가 정지된 후 14일 안에 이용정지 사유를 해소하지 않은 경우 해지될 수 있습니다. 4. 2G 서비스 신규/전환 가입 중단에 따른 고객 보호 방안이 시행됩니다.  ▶ 변경 일시 : (시행일) 2019년 2월 21일 ※ 세부내용은 T world 홈페이지의 이용약관 전문과 별표를 참조해 주시기 바랍니다. 앞으로도 최상의 서비스를 제공하기 위해 최선의 노력을 다하겠습니다. 감사합니다.  무료 수신거부 1504\n",
            "[SK텔레콤]플립5/폴드5 출시 행사 안내!\n",
            "(광고)[SKT]플립5/폴드5 출시 행사 안내!__고양중학교 근방 이마트에브리데이 맞은편에 위치한 SKT 삼송점입니다.__새롭게 출시 되는 폴더블5 행사 및 매장방문 혜택 안내드립니다._매장 방문해 주시면 더 자세히 안내드리겠습니다!__■ 갤럭시 폴더블5 사전예약 시작~! _- 물방울 흰지적용으로 더욱 얇고 완벽해진 새로운 폴더블5!_- 사전예약 고객 다양한 행사 운영!_- 워치5 특별할인 행사_- 제휴카드할인+약정할인 설계로 최대 100만원 할인!_- 더 늦기전에 지금 바로 전화문의 주세요~! __■ SKT인터넷 최대 지원 가능 매장_- 가족구성원에따라 인터넷 비용부담 없이 사용 가능!_- 고객별 맞춤설계로 최저요금제 컨설팅!_- 인터넷 지원금 최대지원! __■ 내방&리뷰고객 특별 혜택 _- 매장에서 휴대폰 구매하시고 문자 제시하시면,_  푸짐한 사은품증정__■ ACE대리점 삼송직영점 _▶연락처 : 070-4788-7989_▶ 주소   :  경기 고양시 덕양구 삼송로 92, 상가동 1층 티월드_▶매장위치 : http://t-mms.kr/b1A/#74_▶홈페이지 : http://t-mms.kr/b1f/#74__▶홈페이지 방문 후 네이버 톡톡으로도 문의 가능합니다^^__■ SKT와 함께 해 주셔서 감사합니다__무료수신거부 1504_\n",
            "SK텔레콤 활용 팁 안내\n",
            "(광고)[SKT] 구매 후 활용 팁 안내  #04 고객님, 안녕하세요. 이번에도 SK텔레콤을 선택해주셔서 감사합니다. 오랜 시간 저희를 믿어 주시는 고객님께 보답하기 위해 최선을 다하겠습니다. 아래 SK텔레콤 활용 팁 안내 링크에서 휴대폰 구매 후 유의 사항을 확인하시고 활용하기 좋은 상품과 혜택도 알아 보세요.   ▶ SK텔레콤 활용 팁 보기: http://t-mms.kr/t.do?m=#61&u=https://e-form.sktelecom.com:8060/tos/#91  ■ 문의: SKT 고객센터(114) 또는 가까운 T월드 매장  ※ 이 문자는 전날 매장에서 기기변경하신 고객님을 대상으로 발송되었습니다.  ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "[SK텔레콤] AI가 지켜주는 우리집\n",
            "(광고)[SKT] AI가 지켜주는 우리집 _ _#04 고객님, 안녕하세요._외출 후, 우리집에 누가 왔는지, 택배가 잘 도착했는지 궁금하시죠? 언제 어디서나 실시간 영상을 확인하고, 얼굴인식 AI기능을 통해 가족 입퇴실 확인까지 가능한 캡스홈 도어가드로 안심하고 외출하세요! 택배존 감지, 양방향 대화, 24시간 출동 서비스 및 긴급출동 요청까지! 캡스홈 도어가드가 지켜드리겠습니다.__■ 캡스홈 요금 및 혜택 사항_- 기본요금: 월 18,750원(부가세 포함)_- SK텔레콤 회선과 결합 시 _  ① 캡스홈 기본 요금 매달 20%(3,750원) 할인_  ② 휴대폰 요금제에 따라 월 최대 5,500원 할인_- 3개월 무료 프로모션 3월 한정 이벤트 _- 안심보상(화재, 도난, 파손, 택배도난) 무료 가입_- 모든 혜택은 신규 가입자에 한하며, 3년 약정 시 제공__▶ 캡스홈 상품 소개(동영상): https://bit.ly/3FMII1I__▶ 캡스홈 신청하기: http://t-mms.kr/t.do?m=#61&s=10870&a=&u=https://m.adtcaps.co.kr/landing/guard/guard_skt.asp__■ 문의: SKT 보안상품 고객센터(1599-1170)_※ 코로나19확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화연결이 원활하지 않을 수 있으니 양해 바랍니다.__SK텔레콤과 함께 해주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤]T멤버십과 에이닷이 뚜레쥬르 카스테라 무료 쿠폰을 드립니다. \n",
            "(광고)[SKT]T멤버십과 에이닷이 뚜레쥬르 카스테라 무료 쿠폰을 드립니다. __#04 고객님, 안녕하세요?__T멤버십과 에이닷이 뚜레쥬르 카스테라 무료 쿠폰을 드립니다.__지금 에이닷 앱을 켜시고 앱 내 T맴버십 혜택 쿠폰함에 _시크릿 코드 [에이닷과카스테라어때] 를 등록해 보세요.__▶ 이벤트 자세히보기:http://t-mms.kr/t.do?m=#61&s=25876&a=&u=https://my-adot.onelink.me/MAbS/ejxfijk8__■ 이벤트 일정: 2024년 5월 1일~5월 31일__■ 혜택: 뚜레쥬르 곰돌이 푸_부드러운 카스테라 1개 무료 쿠폰 _(매장에서 1,000원 이상 결제 시 사용가능) __■ 문의: 1670-0075 에이닷 고객 센터__SKT와 함께해 주셔서 감사합니다_무료 수신거부 1504\n",
            "[SK텔레콤] 화상 상담 만족도 조사\n",
            "[SKT] 보신각점 화상 상담 만족도 조사 안내__안녕하세요 SK텔레콤 화상 상담을 이용해 주셔서 감사합니다. _서비스 이용에 대한 소중한 의견 주시면 보다 나은 서비스 제공을 위해서 노력하겠습니다__▶ 설문 참여하기 (1분 소요)_http://www.skt-survey.com/m/#71/#70_※ 답변해주신 내용은 통계 분석에만 쓰이며, 다른 목적으로는 이용되지 않습니다.__■ 문의 : SKT 화상상담센터 (070-7470-0934, 무료)__고객님의 소중한 의견에 귀 기울여 더 큰 만족을 드리는 SK텔레콤이 되겠습니다.__무료 수신거부 1504\n",
            "KNK대리점 성복점 고객혜택 안내\n",
            "(광고)[SKT] KNK대리점 성복점 행사 안내__고객님, 안녕하세요?_SK텔레콤 KNK대리점 성복점(성복역 4번 출구 데이파크)에서 설 명절 이벤트를 합니다!!__■ 매장 리뉴얼과 함께 설 명절 특별이벤트를 준비했습니다!!_갤럭시S24 시리즈 출시 이벤트!!_1. 기존폰 반납 시 특별보상 + 하나카드 제휴할인 60만원 (24개월, 월 40만원 사용 조건)_2. 대리점의 다양한 사은품(고급케이스, 삼성 정품충전기, 스타벅스 텀블러)과 인터넷 추가 결합할인 혜택_3. 포켓몬2 출시 신학기 혜택_잼플랜베스트 요금제(월 19,450원) 사용 시 기기 무료+캐릭터 학용품 선물_4. 인터넷+TV 개통 시 최대 45만원 상당의 사은품 지급, 4인 가족 결합 시 월 요금에서 24,000원할인_※ 문의전화, 추가할인 설계 상담 모두 환영합니다 즐거운 설 명절 되시길 바랍니다.__■ KNK대리점 성복점_- 주소: 경기 용인시 수지구 수지로119 C동 111호 (성복동 모던프라자)_- 연락처: 070-8866-7249__▶ 매장 홈페이지/예약/상담: http://t-mms.kr/t.do?m=#61&s=24393&a=&u=https://tworldfriends.co.kr/D151990006__▶ 매장위치 확인: http://t-mms.kr/t.do?m=#61&s=24394&a=&u=http://naver.me/GB0xFoAv__SKT와 함께해 주셔서 감사합니다_무료 수신거부 1504\n",
            "[SK텔레콤] 생활의 건강 이벤트 및 5월 혜택 안내\n",
            "(광고)[SKT] 제주 5월 혜택 안내  #04 고객님, 안녕하세요. 놓치면 아쉬운 5월 혜택 안내해드립니다.   ■ SK텔레콤xSK매직 생활의 건강 이벤트 - 일회용품 줄이기에 실천 약속한 고객님 중 추첨을 통해 식기세척기, 로봇청소기, 네스프레소 커피머신 등 선물을 드립니다. - 자세히 보기: http://t-mms.kr/t.do?m=#61&s=1951&a=&u=https://skt-localevent.co.kr/ - 기간: 2021년 6월 20일(일) 까지  ■ SK텔레콤x파리바게뜨 할인 구독 상품 - 요일 상관없이 파리바게뜨 전 메뉴 최대 30% 할인받을 수 있는 구독 상품 가입해 보세요. - 자세히 보기: https://bit.ly/3bjEjpZ - 기간 : 2021년 6월 30일(수)까지 이용  ■ 5/26(수) T Day 혜택 안내 - T map 택시의 새로운 이름, UT 택시 요금 50% 할인 - 도미노피장 방문 포장 50% 할인  - 자세히 보기: https://bit.ly/2SmzdCM - 기간 : 2021년 5월 26일(수)   ■ 모두가 원하는 번호, 골드번호 득템 찬스 - 고객님을 더욱 특별하게 만들어 줄 네 자리, 골드번호를 가질 수 있는 단 한번의 기회를 놓치지 마세요. - 자세히 보기: https://bit.ly/3vjtXyo - 기간 : 2021년 5월 28일(금)까지 - 당첨자 발표: 2021년 6월 9일(수)   ■ 문의: 고객센터(1558, 무료) ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.  SK텔레콤과 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "[SK텔레콤] 3월 T day 혜택 안내\n",
            "(광고)[SKT] 3월 T day 혜택 안내__SKT [착한소비×담우 50% 할인] 이게 되네!_▶ 자세히 보기 : _http://t-mms.kr/t.do?m=#61&s=30681&a=&u=https://bit.ly/4icHnV7__■ 문의: SKT 고객센터(1558, 무료)__무료 수신거부 1504\n",
            "[SK텔레콤] 8월 T day 혜택 안내 \n",
            "(광고)[SKT] 8월 T day 혜택 안내 __8월 14일(월)~8월 18일(금)_톤28 모든 상품 15,000원 할인!_0청년 요금제 가입 고객님은 20,000원 할인!_▶ 자세히 보기: http://t-mms.kr/t.do?m=#61&s=21502&a=&u=https://bit.ly/43LAMJs  __■ 새로워진 A.(에이닷)을 만나보세요 _취향에 맞는 콘텐츠를 한눈에 볼 수 있는 홈 화면과 더 귀여워진 캐릭터들, 찐친 바이브 A. 프렌즈까지! _지금 바로 경험하실 수 있습니다._▶ A.(에이닷) 앱 설치하기: https://my-adot.onelink.me/MAbS/09iqlj8n __■ 문의: SKT 고객센터(1558, 무료)__무료 수신거부 1504\n",
            "우리 아이 첫 휴대폰은 ZEM과 함께하세요.\n",
            "(광고)[SKT] ZEM 프로모션 안내   #04 고객님, 안녕하세요. 아이의 첫 휴대폰을 고민하시나요?  ZEM과 함께하고 다양한 혜택 받아보세요.  ■ ZEM만의 특별한 요금 할인 - 기간: 2020년 3월 31일(화)까지  - 대상: 만 12세 이하 고객, T지원금 약정 또는 선택 약정하고 ZEM 요금제 사용 고객  (ZEM플랜 워치/ZEM플랜 라이트/ZEM플랜 스마트) - 혜택: 가입한 달 포함 3개월 동안 월정액 50% 할인  ■ ZEM만의 특별한 휴대폰 - 게임과 웹 서핑은 제한하고, 위치는 실시간으로 확인할 수 있는 키즈폰  - LG X2 ZEM, 갤럭시 A10e, 갤럭시 와이드4 등 초저가형 휴대폰(199,100원~286,000원)  ■ ZEM만의 특별한 사용 습관 관리 - ZEM 앱으로 자녀의 휴대폰 사용 관리, 자녀 위치 조회  가까운 T월드 매장에서 상담 받아보세요.  ▶ 가까운 T월드 매장 찾기: http://t-mms.kr/t.do?m=#61&u=http://bitly.kr/r7p9UkFU  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "[SK텔레콤]참스타대리점 로데오중앙점 10월 행사안내\n",
            "(광고)[SKT]참스타대리점 로데오중앙점 10월 이벤트 안내__고객님, 안녕하세요._인천최대 매장에서 10월 아이폰14 출시를 맞아 할인행사 진행합니다.__■ 아이폰14 사전예약 및 즉시개통_- 아이폰14예약 가입 시 스타벅스 텀블러셋트 증정_  (선착순 증정)__■ 갤럭시 Z 폴드4, Z 플립4 즉시개통 최대할인_- 중고기기반납시 특별보상할인_- 제휴 카드 월30만 원 이상 사용시 24개월 최대 72만 원 제휴할인_- T나는폰교체 가입 시 최대80만 원 할인_  (24개월후기기반납시-A급기준)_- 인터넷 동시 가입 시 60만 원 결합할인까지__■ 인터넷 재약정고객 기기추가할인_- 인터넷만 가입하셔도 현금+신세계 상품권 증정__■ 효도폰&학생폰 최대할인_- 갤럭시 와이드6, 퀀텀3, A32, A12_- 아이폰se3 추가할인 행사진행 중__▶매장홈페이지가기: http://t-mms.kr/t.do?m=#61&s=16548&a=&u=https://tworldfriends.co.kr/D139520203_▶매장안내_- 주소: 인천 남동구 인하대로 497-22 알라딘중고서점 1층 T Factory_- 연락처: T.032-433-6010__■ 문의: SKT 고객센터(1558, 무료)__SKT와 함께해 주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤]제이스대리점 본점 고객혜택 안내\n",
            "(광고)[SKT]제이스대리점 본점 고객혜택 안내_고객님, 안녕하세요_SKT 제이스대리점 본점(평택역 앞, 파주옥(곰탕집) 맞은 편 피자헛 옆)에서 신학기 맞이 다양한 고객 혜택을 준비하였습니다__■갤럭시 S22 시리즈 즉시 개통_-삼성 악세사리 구매 10만 원 쿠폰 제공_-갤럭시 클럽 가입 시 50만원~72만원 할인_-제휴신용카드(국민,롯데) 사용 시 월 2만원 통신료 할인(월 40만원 카드결재 조건)__■갤럭시 Z플립3 / Z폴드3_ -5GX 프라임 요금제 지원금 100% + 15% 추가 지원금 적용 총 625,000원 할인_ -제휴신용카드(국민,롯데) 사용 시 월 2만원 통신료 할인(월 40만원 카드결재 조건)__■아이폰SE 3세대 드디어 출시_-더욱 강력해져 돌아온 아이폰SE3 즉시개통_-제휴카드 적용시 기기값 최저가 보장__※이상 정확한 기기가격은 매장으로 문의 부탁드립니다__■초고속인터넷+TV 동시 가입시 사은품 최대지급__■제이스대리점 본점_-주소: 경기 평택시 중앙2로 8 (평택동)_-연락처: 031-658-6464_▶매장 홈페이지/예약/상담: http://t-mms.kr/t.do?m=#61&s=11068&a=&u=https://tworldfriends.co.kr/D145710000_▶매장 위치: http://t-mms.kr/t.do?m=#61&s=11069&a=&u=http://naver.me/xWNnrLl1__■문의: SKT 고객센터(1558, 무료)_※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.__SKT와 함께해주셔서 감사합니다_무료 수신거부 1504\n",
            "[SK텔레콤] 강남스타대리점 선정릉역점 폴더블6 신모델 출시 안내\n",
            "(광고)[SKT] 강남스타대리점 선정릉역점 폴더블6 신모델 출시 안내__고객님, 안녕하세요. 9호선 선정릉역 2번 출구 SKT 선정릉역점에서 기다리던 폴드블6 신모델 출시를 안내드립니다.__■  Z플립6, Z폴드6 출시 사전예약 중!_- 사전예약 : 7월 18일 까지_- 최대 사은품 증정 (갤럭시 워치 & 정품 액세서리)_- 기존 쓰던폰 최대 보상 + 최대 할인_- 인터넷 신규가입 시 최대 사은품 추가 증정_- 공식 개통 : 7월19일 부터_   : Z플립6 색상 (옐로우, 그라파이트, 그린, 블루)_   : Z폴드6 색상 (핑크, 네이비, 그라파이트)_※ 서둘러서 예약하시고, 빠르게 받으세요!__■ AI 번역기능 프리미엄폰 갤럭시 S24 행사중__■ 아이폰 할인 행사중_- 아이폰15, 아이폰15 플러스, 아이폰15 프로, 아이폰15 프로 맥스_- 기존 아이폰 사용 고객님, 업그레이드 행사 중__■ 우리집 지켜주는 캡스 도어가드 무료 체험 중_- 6개월 무료 체험 + 체험 중 휴대폰 월 요금 5천원 추가 할인__■ 인터넷 + TV +WI-FI 사은품 최대 증정__■ 강남스타대리점 선정릉역점_- 주소 : 서울특별시 강남구 봉은사로 415, 1층(삼성동, 청림빌딩), 9호선 선정릉역 2번 출구_- 연락처 : 02-542-5500_▶ 단골이라 더 드림(매장 홈페이지) : http://t-mms.kr/t.do?m=#61&s=27510&a=&u=https://www.tworldfriends.co.kr/D139510069 __■ 문의: SKT 고객센터(1558, 무료)_SKT와 함께 해주셔서 감사합니다._무료 수신거부 1504\n",
            "[SK텔레콤] 갤럭시 노트20/20 Ultra 11월 구매 혜택 신청하세요.\n",
            "[SKT] 갤럭시 노트20/20 Ultra 구매 혜택 신청 안내  #04 고객님, 안녕하세요. 지금 갤럭시 노트20/20 Ultra 구매 혜택으로 사은품을 신청하실 수 있습니다. 바로 혜택을 확인하고 신청해 보세요.  ■ 갤럭시 노트20/20 Ultra 구매 혜택(택1) ① 장바구니 쿠폰 10만 원권 증정 - 5GX 클라우드 게임(Xbox 게임 패스 얼티밋) 3개월 쿠폰 및 컨트롤러, 갤럭시 워치3, 갤럭시 버즈 라이브 등 상품 구매 시 사용 가능 ② 삼성 케어 플러스 1년권(최초 통화일 기준 30일 이내 가입 가능)  ■ 쿠폰 신청 방법 - 삼성 멤버스 앱 접속 > 혜택 클릭 > 갤럭시 노트20 구매 혜택 배너 클릭 > 모바일 이벤트 몰 접속 시 쿠폰 자동 발급 ※ 개통하고 3일 뒤부터 발급받으실 수 있습니다.  ■ 쿠폰 사용 기간: 2020년 11월 19일(목)~12월 15일(화)  ▶ 5GX 클라우드 게임(Xbox 게임 패스 얼티밋) 이용권 - Xbox Live Gold를 비롯하여 100개 이상의 Xbox 게임을 PC/콘솔/모바일에서 자유롭게 이용할 수 있는 이용권(16,700원/월)  ▶ 5GX 클라우드 게임(Xbox 게임 패스 얼티밋) 알아보기: http://t-mms.kr/t.do?m=#61&u=https://www.5gxcloudgame.com  ■ 문의: SKT 고객센터(114) ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.  SKT와 함께해주셔서 감사합니다.\n",
            "d\n",
            "(광고)[SKT]_dddd_무료 수신거부 1504\n",
            "[SK텔레콤] 01X 한시적 세대간 번호이동 서비스가 종료됩니다. \n",
            "[SKT] 01X 한시적 세대간 번호이동 서비스 종료 안내  고객님, 안녕하세요. 2019년 2월부터 시행된 <01X 한시적 세대간 번호이동> 서비스가 2021년 6월 30일(수) 종료됩니다. 01X 번호(011/017/016/018/019)로 3G/LTE/5G를 이용하는 고객님께서는 2021년 6월 30(수)까지 반드시 010으로 변경해 주시기 바랍니다. 010으로 번호가 변경됨에 따라 휴대폰 번호가 활용되는 카카오톡, 금융 거래 알람 등은 사전/사후에 백업/변경해 주셔야 합니다.  2021년 6월 21일(월)까지 번호를 변경하지 않으시면 2021년 6월 22일(화) 밤 12시부터 순서대로 010으로 전화번호가 자동 변경됩니다. 자동 변경 시 통화 불가능 표시가 될 수 있으며, 이 경우 전원을 껐다 켜면 휴대폰을 정상적으로 이용하실 수 있습니다. ※ 자동 변경 시 고객님의 번호는 #91입니다. 자동 변경 고객님들께는 <변경번호안내> 서비스가 2021년 12월 31일(금)까지 무료로 제공됩니다.  자동 변경 시, 고객님께서 가입하신 <00700 프리 10>, <자사/타사번호안내>,<발신번호메모플러스>, <번호도용문자차단>,<리모콘>, <전화번호 안심로그인> 서비스가 일시 해지됩니다.  <00700 프리 10>, <자사/타사번호안내>,<발신번호메모플러스>, <번호도용문자차단> 서비스는 번호 변경 후 자동 재가입되나, <리모콘>, <전화번호 안심로그인> 서비스는 번호 변경 후 고객님께서 직접 다시 서비스를 신청하셔야 합니다.   자동 변경을 원하지 않으시면 2021년 6월 21일(월)까지 T월드 홈페이지 또는 T월드 매장에서 010으로 번호를 변경해 주시기 바랍니다. 2021년 6월 30일(수)까지 변경하지 않으시면 7월부터 발신, 10월부터 수신이 제한됩니다. 이용에 불편이 없도록 기간 안에 변경해 주시기 바랍니다.  ■ 문의: SKT 고객센터(114)  SKT와 함께해주셔서 감사합니다.\n",
            "testtest\n",
            "(광고)[SKT]  무료 수신거부 1504ㅇㅅㄷㅅ\n",
            "[SK텔레콤] 2월 0 day 혜택 안내\n",
            "(광고)[SKT] 2월 0 day 혜택 안내__<2월 20일(목) 혜택>_만 13~34세 고객이라면_SKT 0 day_[달콤커피 아메리카노(R) 한잔 무료]_이게 되네!_(선착순 1만 명 증정)_▶ 자세히 보기 : http://t-mms.kr/t.do?m=#61&s=30481&a=&u=https://bit.ly/4aw5Rpv__■ 문의: SKT 고객센터(1558, 무료)__무료 수신거부 1504\n",
            "데이터 충전하고 사은품도 받아가세요!\n",
            "(광고)[SKT] T데이터쿠폰 사은품 증정 안내  고객님, 안녕하세요. T데이터쿠폰으로 데이터 충전하고 선물도 받아가세요. 웹툰 자유이용권, 포토북 무료제작쿠폰, 포켓몬GO 아이템, SK스토아 추가적립 쿠폰까지, 푸짐하게 드립니다.  ■ T데이터쿠폰 사은품 증정 이벤트 ① 참여방법: T데이터쿠폰 100MB, 500MB, 1GB, 2GB, 5GB 중 하나를 구매하고 등록 ② 증정 사은품:  - T데이터쿠폰 100MB(코미코 웹툰 7일권, 스코피 포토북 무료제작쿠폰)  - T데이터쿠폰 500MB(포켓몬GO 아이템+루어모듈)  - T데이터쿠폰 1GB(코미코 웹툰 7일권, 스코피 포토북 무료제작쿠폰, SK스토아 2천 원 추가적립 쿠폰)  - T데이터쿠폰 2GB(코미코 웹툰 7일권, 스코피 포토북 무료제작쿠폰, SK스토아 2천 원 추가적립 쿠폰) - T데이터쿠폰 5GB(코미코 웹툰 7일권, 스코피 포토북 무료제작쿠폰, SK스토아 5천 원 추가적립 쿠폰)  ▶T데이터쿠폰 구매하기  http://t-mms.kr/t.do?m=#61&u=http://tdatacoupon.co.kr   [유의사항] - 쿠폰을 구매할 때 사은품 문자 수신에 동의해야만 사은품을 받으실 수 있습니다.  - 사은품별로 제공 기간이 다르며, 종류에 따라 조기 종료될 수 있습니다.   [문의] T데이터쿠폰 고객센터(1599-7963)  SK텔레콤과 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "[SK텔레콤] SKT 홍익 대리점 행사 안내\n",
            "(광고)[SKT] SKT홍익 대리점 필름 무료 교체 행사 안내 __SKT공식인증대리점과 친구맺기하시고 필름무료교체권 받으셔서 편안하게 교체하세요~__■ 친구맺기 하는 방법_ - 아래 친구맺기 URL을 접속해서 등록_  ☞ 친구 맺기:https://tworldfriends.co.kr/D731550138/subscribers/create_  ☎ 매장에 전화해서 도움받기 : 043-836-8861__■ 필름 무료 교체권 받는 방법_ - 친구맺기 후 언제든 매장에 방문하셔서, 필름 무료 교체 행사 말씀하시면 확인 후 교체 해드립니다._ - 제공되는 무료 필름은 고성능의 방탄필름이며, 1년(동일연도)에 최대 12회 교체 가능합니다._ - 필름 교체 시점에 우리 매장에 친구 맺기가 되어 있어야 합니다.__■ 안내사항_-  친구맺기는 SKT사용자가 아니어도 전 국민 누구나(KT, LGU+등 사용자) 가능합니다! _   친구 지인분들께 이 문자 전달하셔도 혜택 가능!__■ 매장안내_  - 주소 : 증평군 증평읍 중앙로213 (베스킨라빈스옆SKT대리점)_  - 문의:  043-836-8861 __무료 수신거부 1504\n",
            "MMS 설문조사 테스트\n",
            "[SKT] 0000 만족도 조사 안내  고객님, 안녕하세요. 0000를 이용해주셔서 감사합니다. 더 나은 서비스를 드리기 위해 설문 조사를 진행하고 있습니다. 잠시 시간을 내어 고객님의 소중한 의견을 들려주세요.  ▶ 설문 참여하기(0분 소요) http://www.skt-survey.com/m/#71/#70 -이 텍스트를 지우고 [설문 조사 추가] 버튼을 눌러 URL을 입력하세요  ■ 문의 0000고객센터(000)  ※ 설문 조사 기간: 월 일( )~ 월 일( ) ※ 답변해주신 내용은 통계 분석에만 쓰이며, 다른 목적으로는 이용되지 않습니다.  고객님의 소중한 의견에 귀 기울여 더 큰 만족을 드리는 SK텔레콤이 되겠습니다.  무료 수신거부 1504\n",
            "[SK텔레콤] T우주 정기배송구독으로 투썸플레이스 캡슐커피 할인 혜택 받으세요! \n",
            "(광고)[SKT] 투썸플레이스 캡슐커피 정기배송__고객님, 안녕하세요._투썸플레이스 구독하시고 캡슐커피를 할인된 가격으로 정기배송 받으세요~__■ 투썸플레이스 정기배송_- 캡슐커피 30개입 월 16,900원(첫 달 13,500원)_- 캡슐커피 60개입 월 32,900원(첫 달 23,000원)__▶ 구독 신청하기: http://t-mms.kr/t.do?m=#61&s=17890&a=&u=https://m-sktuniverse.tworld.co.kr/product/view?prodId=270__■ 문의: 구독 전용 고객센터(1505, 무료)__SKT와 함께해 주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] 강남스타대리점 선정릉역점 9월 혜택 안내\n",
            "(광고)[SKT] 강남스타대리점 선정릉역점 9월 혜택 안내__고객님, 안녕하세요. SKT 강남스타대리점 선정릉역점에서 고객님을 위한 특별한 혜택을 준비했습니다. 저희 매장은 사용중이신 휴대폰 클린 혜택을 드리고 있사오니, 편안히 방문하여 주세요. 매장을 방문 하시면 휴대폰 살균 서비스 및 액정보호 필름을 무료 증정 합니다.__■ 특별 구매 혜택_- 인터넷+IPTV 가입 시 월 최저 요금 설계 및 태블릿 증정 + 상품권 또는 사은품 최대 지원_- ADT 캡스 1년 무료 체험 + 핸드폰 요금 추가 할인 (T&캡스)_- SK매직 정수기, 공기청정기, 비데 가입 시 15%할인 및 상품권 증정_- 상담만 받으셔도 젤리케이스, 필름 무료 부착_ _■ 강남스타대리점 선정릉역점_- 주소 : 서울 강남구 봉은사로 415 (삼성동, 청림빌딩, 선정릉역 2번 출구)_- 연락처 : 02-542-5500_▶ 매장 홈페이지 가기 :http://t-mms.kr/t.do?m=#61&s=4326&a=&u=http://tworldfriends.co.kr/D139510069__※ SK텔레콤 공식인증대리점은 고객님과 직원의 안전을 위해 비말 가림막 상담, 체온 체크, 마스크 의무 착용, 손 소독제 비치 등 생활방역 수칙을 철저히 준수하고 있습니다.__■ 문의: SKT 고객센터(1558, 무료)_※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.__SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504\n",
            "11월 T Day 혜택 안내\n",
            "(광고)[SKT] 11월 T Day 혜택 안내  11월 27일(수) 단 하루! FLO, 11번가 등  다양한 T Day 혜택을 놓치지 마세요!  FLO 올인원 무제한 듣기 6개월 이용권 60% 할인! * 이용권 쿠폰 등록 기간: 11월 27일(수)~12월 25일(수)  11번가 iPhone 액세서리 최대 22% 할인! * 최대 1만 원 할인  지금 바로 할인받고 구매하세요.  ▶ 자세히 보기: http://t-mms.kr/t.do?m=#61&u=https://goo.gl/f6p7ob  ★T멤버십만의 5가지 혜택★ ① 원하는 날, \"내맘대로\" 혜택 ② 매달 첫 주, 매주 수요일 \"T Day\" ③ SKT 5GX 고객님을 위한 부스트 파크 특별 혜택 ④ 착한 소비에 할인까지 \"열린멤버십\" ⑤ 할인 한도는 연간 무제한    무료 수신거부 1504\n",
            "남다른 유전자 FLEX하고 경품 받으세요!\n",
            "(광고)[SKT] Care8 DNA 출시 이벤트 안내  #04 고객님, 안녕하세요. 유전자 검사 기반 구독형 헬스케어 서비스 <Care8 DNA> 출시 이벤트에 참여하고 풍성한 경품도 받아 보세요.  ▶ 이벤트 자세히 보기: http://t-mms.kr/t.do?m=#61&u=https://bit.ly/2FMXZps  ■ Care8 DNA 출시 이벤트 - 기간: 2020년 9월 21일(월)~10월 30일(금) - 당첨자 발표: 2020년 11월 12일(목) - 대상: Care8 DNA 서비스 가입 후 인스타그램에 자랑하고 싶은 유전자 검사 결과를 인증하신 고객님 - 경품 1등: 갤럭시 노트20 Ultra(1명) 2등: 에어팟 프로, 에스티로더 어드밴스드 나이트 리페어 세트, 발뮤다 더 토스터 중 택1(6명) 3등: 신세계상품권 2만 원권(350명) - 경품 배송: 당첨자 발표 후 약 2~3주 소요  ※ 이 이벤트는 이 문자를 받으신 고객님 본인의 인스타그램 계정에 유전자 검사 결과 페이지를 인증하셔야만 참여가 가능합니다.  ※ 이벤트 참여 및 당첨 시 경품 제공을 위해 이벤트 응모를 할 때 인스타그램 게시물에 <＃Care8DNA이벤트＃대박유전자＃수집이용동의＃처리위탁동의>를 필수로 등록해야 합니다. ※ 유전자 분석에 2주가 소요됩니다. 이벤트 마감일에 유의하여 서비스를 신청해 주시기 바랍니다.  ■ 문의: SKT 고객센터(114)  ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "[SK텔레콤] 티다문구점 아이폰16e 액세서리 기획전\n",
            "(광고)[SKT] 티다문구점 아이폰16e 액세서리 기획전 안내__고객님, 안녕하세요._나의 소중한 아이폰16e를 위한 다양한 액세서리를 티다문구점에서 구매하세요! _애플 정품 실리콘 케이스부터 다양한 충전용품과 보호필름까지 풀세팅하기. __지금 티다문구점 가입하면 바로 사용할 수 있는 10% 할인 쿠폰으로 더욱 많은 혜택을 누려보세요._또한 첫 구매 시 다음에 사용할 수 있는 10% 쿠폰까지 추가로 받을 수 있습니다.__▶ 티다문구점 아이폰16e 액세서리 기획전 바로 가기: http://t-mms.kr/aw3/#74__■ 티다문구점은?_① SK텔레콤 T 다이렉트샵이 운영하는 온라인 편집 숍_② 독창적인 디자인과 우수한 품질의 제품 판매_③ 가격 상관없이 무료 배송__■ 문의: 티다문구점 고객센터(1599-1932)__SKT와 함께해 주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] iPhone 13 사전예약 이벤트 안내 드립니다.\n",
            "(광고)[SKT] iPhone 13 사전예약 안내__#04 고객님, 안녕하세요. 남들보다 iPhone 13을 더 빠르게 받고 싶으시다면?_T다이렉트샵에서 예약(선착순 1만명) 하시면 출시일 새벽에 집에서 받아 보실 수 있습니다. 10월 1일 00시 01분 시작하는 사전예약을 놓치지 마세요.__▶ 사전예약하고 혜택 받기: http://t-mms.kr/t.do?m=#61&s=5542&a=&u=https://bit.ly/3CM5ANn __■ 사전예약 일정 : 10월 1일(금) 사전예약 시작, 10월 8일(금) 출시__■ iPhone 13 스펙_- 대폭 개선 된 카메라/영상 성능_- 더 빠르고 효율적인 A15 바이오닉 칩 탑재_- 더 밝아진 Super Retina XDR 디스플레이(Pro/Pro Max 120Hz 화면 주사율 적용)_- 아이폰 12보다 더욱 길어진 배터리 사용 시간(mini/Pro +1.5시간, 일반/Pro Max +2.5시간)__■ T다이렉트샵 iPhone 13 사전예약 혜택 안내_- 1차 사전예약한 모든 고객님께 2021년 10월 8일(금) 당일 배송_- 색다른 매력의 T기프트 증정_- 제휴 카드 할인과 캐시백 프로모션_- 추첨을 통해 \"모베러웍스\" 컬래버레이션 MD 상품 및 애플 경품 증정_- 추첨을 통해 애플 정품 액세서리 3/5/10만 원 할인 쿠폰 증정_- 사전예약 시작 시 추가 공개 되는 혜택까지!__■ 문의: SKT 고객센터(1558, 무료)_※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다._고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.__SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK 텔레콤] 2021 LoL 롤 서머리그를 Jump AR에서 Faker 페이커와 함께 즐기세요!\n",
            "(광고)[SKT] Jump AR x LoL 롤 플레이어 Faker 등장 안내  #04 고객님, 안녕하세요.  Jump AR에 2021 LoL 서머리그를 축하하기 위해 레전드 플레이어 Faker 페이커가 등장했습니다! Faker 페이커를 만난 틱톡커들과 함께 내 눈 앞에 페이커를 소환하여 함께 즐겨보세요!  ▶ Faker 페이커 영상 보러가기 : http://t-mms.kr/t.do?m=#61&s=2224&a=&u=https://bit.ly/3cLmUaP ▶ Faker 페이커 소환하러 가기 : http://t-mms.kr/t.do?m=#61&s=2221&a=&u=http://bit.ly/2vRACGo  ■ 문의: SKT 고객센터(1558, 무료)  ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\n",
            "[SK텔레콤]지상대리점 경기대점(본점) 고객혜택 안내\n",
            "(광고)[SKT]지상대리점 경기대점(본점) 고객혜택 안내__고객님, 안녕하세요._지상대리점 경기대 본점에서 연말 특별이벤트 안내드립니다.__■ EVENT 1. SKT를 소개시켜줘! _- 단골고객님 지인분들에게 SKT를 소개시켜 주세요. _소개 받은 지인분이 매장에서 상담만 하셔도 소개해 주신 단골고객님께 소정의 사은품을 증정해드립니다 (30명 선착순)__■ EVENT 2. 크리스마스는 아이폰15와 함께_아이폰15 단독특가_-출고가: 1,243,000원_-공시지원금 할인 400,000원_-제휴카드할인: 600,000원(하나T다운카드, 월 40만원 이용, 24개월)_-T안심보상 : 200,000원(아이폰12 B급 기준)_-할부원금 : 43,000원_※ 공시지원금은 변동될 수 있음__■ 아이폰 15 구매 혜택_-아이폰 정품 충전기 증정_-고급케이스,필름/고급무선충전기_-사용기간 동안 기본케이스/필름 무제한증정!__휴대폰 구매뿐만 아니라 모든 통신업무를 친절 정확 신속하게 도와드리겠습니다__■ 지상대리점 경기대점(본점)_-위치: 경기도 수원시 영통구 대학3로 1 케이타워 1층 (주차장완비)_-연락처: 070-8845-7249_▶매장 홈페이지/예약/상담: http://t-mms.kr/t.do?m=#61&s=23130&a=&u=https://tworldfriends.co.kr/D152750000_▶매장위치: http://t-mms.kr/t.do?m=#61&s=23131&a=&u=http://naver.me/Fqljwn3P__SKT와 함께해 주셔서 감사합니다__무료 수신거부 1504\n",
            "[SK텔레콤] 내방역대리점 본점 폴더블5 출시, 예약 이벤트 혜택 안내\n",
            "(광고)[SKT] 내방역대리점 본점 폴더블5 출시, 예약 이벤트 혜택 안내__고객님, 안녕하세요. SK텔레콤 공식인증 우수매장 내방역대리점 본점에서 폴더블5 사전예약 이벤트 혜택을 안내드립니다. 8월7일 까지 저희 매장에 사전예약 하시고, 이벤트 혜택 꼭 챙겨가세요.__■ [공식] Z폴드5, Z플립5 사전예약 중!_- 최대 200만 원 상당의 할인 혜택 제공!_- 매장 할인+선택약정 할인+삼성 프로모션+매장 사은품_- 선택약정 요금 할인 594,000원 (프라임플러스 요금제, 24개월 사용)_- 삼성 노트북 or 워치6 택1 (약 60만 원 상당) 무료 증정! (프라임 이상 요금제, 24개월 약정)_- 256G 가격을 512G로 무료 업그레이드! (약 15만 원 상당 혜택)_- 삼성 케어 플러스(파손) 1년권 무료! (약 10만 원 상당)_- 삼성 정품커버 증정! (S펜 포함, 약 5만 원 상당)_- 가정용,차량용 초고속 충전기 세트 증정! (약 5만 원 상당)_※ 사전 예약 전화 문의 환영__■ 내방역대리점 본점_- 주소 : 서울특별시 서초대로 108, 1층 _ (지하철 7호선 내방역 2번 출구, 신한은행 옆, 에스컬레이터 상행선 왼쪽 위치)_- 연락처 : 02-582-3667_▶ 매장 홈페이지/예약/상담 : http://t-mms.kr/bU9/#74__■ 문의: SKT 고객센터(1558, 무료)_SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] 갤럭시 노트20/20 Ultra 11월 구매 혜택 신청하세요.\n",
            "[SKT] 갤럭시 노트20/20 Ultra 구매 혜택 신청 안내  #04 고객님, 안녕하세요. 지금 갤럭시 노트20/20 Ultra 구매 혜택으로 사은품을 신청하실 수 있습니다. 바로 혜택을 확인하고 신청해 보세요.  ■ 갤럭시 노트20/20 Ultra 구매 혜택(택1) ① 장바구니 쿠폰 10만 원권 증정 - 5GX 클라우드 게임(Xbox 게임 패스 얼티밋) 3개월 쿠폰 및 컨트롤러, 갤럭시 워치3, 갤럭시 버즈 라이브 등 상품 구매 시 사용 가능 ② 삼성 케어 플러스 1년권(최초 통화일 기준 30일 이내 가입 가능)   ■ 쿠폰 신청 방법 - 삼성 멤버스 앱 접속 > 혜택 클릭 > 갤럭시 노트20 구매 혜택 배너 클릭 > 모바일 이벤트 몰 접속 시 쿠폰 자동 발급 ※ 개통 후 3일 뒤부터 발급받으실 수 있습니다.   ■ 쿠폰 사용 기간: 2020년 11월 10일(화)~12월 15일(화)  ▶ 5GX 클라우드 게임(Xbox 게임 패스 얼티밋) 이용권 - Xbox Live Gold를 비롯하여 100개 이상의 Xbox 게임을 PC/콘솔에서 자유롭게 이용할 수 있는 이용권(16,700원/월)  ▶ 5GX 클라우드 게임(Xbox 게임 패스 얼티밋) 알아보기: http://t-mms.kr/t.do?m=#61&u=https://www.5gxcloudgame.com  ■ 문의: SKT 고객센터(114) ※ 코로나19 확산으로 고객센터에 문의가 증가하고 있습니다. 고객센터와 전화 연결이 원활하지 않을 수 있으니 양해 바랍니다.  SKT와 함께해주셔서 감사합니다.\n",
            "[SK텔레콤] 7월 대교대리점 안양직영점 요금할인 혜택 안내\n",
            "(광고)[SKT] 대교대리점 안양직영점 7월 요금할인 혜택__안녕하세요 고객님_SK텔레콤 안양직영점 입니다.__■지인찬스 쿠폰_- 기기 구매 예정인 지인 분을 소개해 주시면 요금할인 혜택을 드립니다.__■우리 매장 특가폰 1+1 이벤트_- 7월 휴대폰 구매이벤트  _- 갤럭시S22시리즈,Z플립3_- 구매고객 1+1 추가 할인 _- 갤럭시 워치4 or 탭 무상 지급(5GX 프라임요금제 가입조건)  __■맞춤 상담과 폰케어 서비스_- 필름 무료 교체 지속 운영 _- 통신 요금 컨설팅은 365일 운영  _ _■SK텔레콤 안양직영점_-홈페이지 : http://t-mms.kr/t.do?m=#61&s=13888&a=&u=http://tworldfriends.co.kr/D139650172 _자세한 사항은 매장방문하셔서 상담받아보세요!!__■ 문의: SKT 고객센터(1558, 무료)__SK텔레콤과 함께 해 주셔서 감사합니다__무료 수신거부 1504\n",
            "[SK텔레콤] 캠핑테이블, 쿨러백 등 선물 받아가세요!\n",
            "(광고)[SKT] B tv x NUGU에게 외치고, 캠핑 용품 받자!__#04고객님, 안녕하세요.__지금 B tv x NUGU에게 \"캠핑 가자\"라고 말씀하신 후 이벤트 응모 정보를 남겨주세요~_추첨을 통해 캠핑 꿀템을 선물로 드릴게요~__▶기간 : 2022년 6월 21일(화)~ 6월 30일(목)_▶참여 방법 :_① AI 셋톱박스: \"아리아\"라고 부른 다음 \"캠핑 가자”라고 말하고 이벤트 페이지에서 응모하면 참여 완료_② B tv 셋톱박스: B tv 리모컨의 NUGU(음성 마이크) 버튼 누르고 \"캠핑 가자\"라고 말하고 이벤트 페이지에서 응모하면 참여 완료__▶응모 정보 남기기: http://t-mms.kr/t.do?m=#61&s=13048&a=&u=https://bit.ly/3MQZAYd__▶경품 : 추첨을 통해 당첨되신 100분께 아래 경품 6종 중 랜덤 증정합니다._-스탠리 클래식 런치박스 (10개)_-써모스 트레일스맨 파티큐브 쿨러백 33L (10명)_-다니고 캠핑 롤테이블 (20명)_-하이브로우 밀크 박스 (20명)_-스탠리 글래스 세트 (20명)_-첨스 부비 이지 체어 (20명)__▶당첨자 발표 : 2022년 7월 14일(목), NUGU 홈페이지/앱__이벤트 자세한 내용 또는 유의사항은 아래 링크에서 참고 부탁드립니다._▶이벤트 자세히 보기: http://t-mms.kr/t.do?m=#61&s=13047&a=&u=https://bit.ly/3xuLqGs__■문의 :_-SK텔레콤 고객센터: 1558_-㈜이든앤앨리스마케팅 02-3448-9971(평일 오전 9시~오후 6시, 유료)__무료 수신거부 1504\n",
            "[SK텔레콤] 강서대리점 신월본점에서 12월 연말행사를 진행합니다\n",
            "(광고)[SKT]_강서대리점 신월본점에서 12월 연말 행사를 진행합니다__■갤럭시 Z플립4  ,갤럭시 S22 삼성카드 제휴할인+단말기 지원금 할인적용시 기기값 무료행사(※5GX프라임플러스 이용기준)__■ 삼성 수험생이벤트(01~04년생)_갤럭시휴대폰 구매시 버즈2프로 무료증정_에어팟50%할인판매 아이폰14시리즈 구매고객님 애플워치SE 50%할인__■휴대폰 기기 변경 이벤트_갤럭시 휴대폰 구매 고객님 워치5 & 삼성태블릿 중에 택1 무료증정_※5GX프라임플러스 이용기준)__■인터넷+TV 최대사은품 지급_약정만료고객님 재약정시 추가 사은품증정_우리집 홈보안 (6개월 무료체험)_현관앞 CCTV로 택배분실 걱정NO_거실 CCTV로 반려가족 걱정 NO_6개월 체험후 해지시 위약금 없음 + 체험기간중 요금추가할인혜택 가능__★신월본점 매장 방문고객님 무료필름교체_자세한문의는 매장방문하시거나 전화주시면 친절히 상담 도와드라겠습니다__■SK강서대리점 신월본점_매장주소:서울특별시 양천구 남부순환로354,1층(주차장있음)_전화번호:02-6460-0077_홈페이지:http://t-mms.kr/t.do?m=#61&s=17613&a=&u=https://tworldfriends.co.kr/D153200000__■문의:SKT 고객센터(1558,무료)_SKT와 함께해주셔서 감사합니다_무료수신거부 1504\n",
            "[SK텔레콤]구독서비스 T우주 출시 혜택안내\n",
            "(광고)[SKT] ACT대리점 청량리역전점 SKT 구독서비스 \"T우주\" 출시!!_ _SKT 구독패키지 \"T우주\" 출시 이벤트!!_ _출시 기념 첫달 1천원 내시고 40,000원 혜택을 받아가세요!!_첫달은 특별히 1천원만 내시면 됩니다.__■ 구독패키지 우주패스ALL 기본혜택_① 11번가 매달 SK pay point 3,000점 지급_② 아마존 매달 배송비 무제한 무료 & 5천원 쿠폰 2매_③ 구글 ONE 클라우드 100GB 제공(월 2,400원 혜택)__■ 구독패키지 우주패스ALL 추가혜택(택 1)_- e-마트 매주 3천원 쿠폰 제공(월 12천원 혜택)_- 스타벅스 아메리카노 4잔 구매 시 1잔 무료 제공(월2회)(월 8,200원 혜택)_- 파리바케트 30% 할인(월 최대 3만원 할인)_- SKT 웨이브 또는 플로 무료 제공__■ ACT대리점 청량리역전점_- 주소 : 서울 동대문구 왕산로 207 (청량리동,스타키빌딩)_- 연락처 : 02-965-1162_▶ 매장 홈페이지 : http://t-mms.kr/t.do?m=#61&s=4152&a=&u=https://tworldfriends.co.kr/D135460140__저희 매장 홈페이지에서 최신 스마트폰 정보 확인할 수 있습니다._궁금하신 내용은 전화 주시면 자세히 안내 드리겠습니다.__■ 문의 : SKT 고객센터(1558, 무료)__SKT와 함께해 주셔서 감사합니다.__무료 수신거부 1504\n",
            "[SK텔레콤] 통화 가능한 상태를 알려주는 서비스를 소개합니다.\n",
            "(광고)[SKT] 통화가능통보플러스 서비스 안내__#04 고객님, 안녕하세요._상대방이 통화 중일 때 언제 전화를 끊을지 몰라, 여러 번 통화를 시도하신 적 있으시죠?_상대방이 통화할 수 있는 상태가 되면 문자메시지로 알려 주는 <통화가능통보플러스> 서비스를 소개합니다.__■ 통화가능통보플러스 서비스란?_- 이용요금: 월 770원(부가세 포함)_- 상대방이 통화 중이라 전화 연결이 되지 않을 때, 통화할 수 있는 상태가 되면 문자메시지로 알려주고 상대방에게는 연락 요청 호출 메시지를 자동 발송해 주는 서비스입니다.__▶ 통화가능통보플러스 자세히 보기: http://t-mms.kr/t.do?m=#61&s=17400&a=&u=https://skt.sh/B45jj__■ 문의: SKT 고객센터(1558, 무료)__SKT와 함께해주셔서 감사합니다.__무료 수신거부 1504\n"
          ]
        }
      ],
      "source": [
        "final_result_list = []",
        "interim_result_list = []",
        "",
        "for mms_msg in mms_pdf.sample(100)['msg'].tolist():",
        "",
        "    final_result_dict = {}",
        "    interim_result_dict = {}",
        "",
        "    print(mms_msg)",
        "",
        "    mms_embedding = model.encode([mms_msg.lower()], convert_to_tensor=True)",
        "",
        "    similarities = torch.nn.functional.cosine_similarity(",
        "        mms_embedding,  ",
        "        clue_embeddings,  ",
        "        dim=1 ",
        "    ).cpu().numpy()",
        "",
        "    pgm_pdf_tmp = pgm_pdf.copy()",
        "    pgm_pdf_tmp['sim'] = similarities",
        "",
        "    pgm_pdf_tmp = pgm_pdf_tmp.sort_values('sim', ascending=False)",
        "",
        "    def filter_specific_terms(strings: List[str]) -> List[str]:",
        "        unique_strings = list(set(strings))  # 중복 제거",
        "        unique_strings.sort(key=len, reverse=True)  # 길이 기준 내림차순 정렬",
        "",
        "        filtered = []",
        "        for s in unique_strings:",
        "            if not any(s in other for other in filtered):",
        "                filtered.append(s)",
        "",
        "        return filtered",
        "",
        "    def sliding_window_with_step(data, window_size, step=1):",
        "        \"\"\"Sliding window with configurable step size.\"\"\"",
        "        return [data[i:i + window_size] for i in range(0, len(data) - window_size + 1, step)]",
        "",
        "    # tdf = pd.DataFrame([{'form_text':d[0],'tag_text':d[1],'start_text':d[2],'end_text':d[2]+d[3]} for d in kiwi_raw.analyze(mms_msg)[0][0]])",
        "    result_msg_raw = kiwi_raw.tokenize(mms_msg, normalize_coda=True, z_coda=False, split_complex=False)",
        "    token_list_msg = [d for d in result_msg_raw ",
        "                    if d[1] not in tags_to_exclude",
        "                    ]",
        "",
        "    result_msg = kiwi.tokenize(mms_msg, normalize_coda=True, z_coda=False, split_complex=False)",
        "    entities_from_kiwi = []",
        "    for token in result_msg:  # 첫 번째 분석 결과의 토큰 리스트",
        "        if token.tag == 'NNP' and token.form not in stop_item_names+['-'] and len(token.form)>=2 and not token.form.lower() in stop_item_names:  # 고유명사인 경우",
        "        # if token.tag == 'NNG' and token.form in stop_item_names_ext:  # 고유명사인 경우",
        "            entities_from_kiwi.append(token.form)",
        "",
        "    from typing import List",
        "    # 결과",
        "    entities_from_kiwi = filter_specific_terms(entities_from_kiwi)",
        "",
        "    # print(\"추출된 개체명:\", list(set(entities_from_kiwi)))",
        "",
        "    ngram_list_msg = []",
        "    for w_size in range(1,5):",
        "        windows = sliding_window_with_step(token_list_msg, w_size, step=1)",
        "        windows_new = []",
        "        for w in windows:",
        "            tag_str = ','.join([t.tag for t in w])",
        "            flag = True",
        "            for et in exc_tag_patterns:",
        "                if ','.join(et) in tag_str:",
        "                    flag = False",
        "                    # print(w)",
        "                    break",
        "        ",
        "            if flag:",
        "                windows_new.append([[d.form for d in w], [d.tag for d in w]])",
        "",
        "        ngram_list_msg.extend(windows_new)",
        "",
        "    # 패턴에 해당하는 토큰 인덱스 찾기",
        "    def find_pattern_indices(tokens, patterns):",
        "        indices_to_exclude = set()",
        "        ",
        "        # 단일 태그 패턴 먼저 체크",
        "        for i in range(len(tokens)):",
        "            for pattern in patterns:",
        "                if len(pattern) == 1 and tokens[i].tag == pattern[0]:",
        "                    indices_to_exclude.add(i)",
        "        ",
        "        # 연속된 패턴 검사",
        "        i = 0",
        "        while i < len(tokens):",
        "            if i in indices_to_exclude:",
        "                i += 1",
        "                continue",
        "                ",
        "            for pattern in patterns:",
        "                if len(pattern) > 1:  # 두 개 이상의 태그로 구성된 패턴",
        "                    if i + len(pattern) <= len(tokens):  # 패턴 길이만큼 토큰이 남아있는지 확인",
        "                        match = True",
        "                        for j in range(len(pattern)):",
        "                            if tokens[i+j].tag != pattern[j]:",
        "                                match = False",
        "                                break",
        "                        ",
        "                        if match:  # 패턴이 일치하면 해당 토큰들의 인덱스를 모두 추가",
        "                            for j in range(len(pattern)):",
        "                                indices_to_exclude.add(i+j)",
        "            i += 1",
        "                        ",
        "        return indices_to_exclude",
        "",
        "    # 패턴에 해당하지 않는 토큰만 필터링",
        "    def filter_tokens_by_patterns(tokens, patterns):",
        "        indices_to_exclude = find_pattern_indices(tokens, patterns)",
        "        return [tokens[i] for i in range(len(tokens)) if i not in indices_to_exclude]",
        "",
        "    # 제외된 토큰 없이 텍스트 재구성 - 단순 연결 방식",
        "    def reconstruct_text_without_spaces(tokens):",
        "        # 토큰들을 원래 시작 위치에 따라 정렬",
        "        sorted_tokens = sorted(tokens, key=lambda token: token.start)",
        "        ",
        "        result = []",
        "        for token in sorted_tokens:",
        "            result.append(token.form)",
        "        ",
        "        # 토큰들을 공백 하나로 구분하여 결합",
        "        return ' '.join(result)",
        "",
        "    # 더 자연스러운 텍스트 재구성 - 원본 위치 기반 보존, 제외된 토큰은 건너뜀",
        "    def reconstruct_text_preserved_positions(original_tokens, filtered_tokens):",
        "        # 원본 토큰의 위치와 형태를 기록할 사전 생성",
        "        token_map = {}",
        "        for i, token in enumerate(original_tokens):",
        "            token_map[(token.start, token.len)] = (i, token.form)",
        "        ",
        "        # 필터링된 토큰의 인덱스 찾기",
        "        filtered_indices = set()",
        "        for token in filtered_tokens:",
        "            key = (token.start, token.len)",
        "            if key in token_map:",
        "                filtered_indices.add(token_map[key][0])",
        "        ",
        "        # 원본 순서대로 필터링된 토큰만 선택",
        "        result = []",
        "        for i, token in enumerate(original_tokens):",
        "            if i in filtered_indices:",
        "                result.append(token.form)",
        "        ",
        "        return ' '.join(result)",
        "",
        "    # 결과 출력",
        "    filtered_tokens = filter_tokens_by_patterns(result_msg_raw, exc_tag_patterns)",
        "    msg_text_filtered = reconstruct_text_preserved_positions(result_msg_raw, filtered_tokens)",
        "",
        "    msg_text_filtered",
        "",
        "    ngram_list_msg_filtered = []",
        "    for w_size in range(2,4):",
        "        windows = sliding_window_with_step(list(msg_text_filtered.lower().replace(' ', '')), w_size, step=1)",
        "        ngram_list_msg_filtered.extend(windows)",
        "",
        "    col_for_form_tmp_ent = 'char_entity'",
        "    col_for_form_tmp_msg = 'char_msg'",
        "",
        "    edf['form_tmp'] = edf[col_for_form_tmp_ent].apply(lambda x: [' '.join(s) for s in sliding_window_with_step(x, 2, step=1)])",
        "",
        "    tdf = pd.DataFrame(ngram_list_msg).rename(columns={0:'token_txt', 1:'token_tag'})",
        "    tdf['token_key'] = tdf.apply(lambda x: ''.join(x['token_txt'])+''.join(x['token_tag']), axis=1)",
        "    tdf = tdf.drop_duplicates(['token_key']).drop(['token_key'], axis=1)",
        "    tdf['char_msg'] = tdf.apply(lambda x: list((\" \".join(x['token_txt'])).lower().replace(' ', '')), axis=1)",
        "",
        "    tdf['form_tmp'] = tdf[col_for_form_tmp_msg].apply(lambda x: [' '.join(s) for s in sliding_window_with_step(x, 2, step=1)])",
        "    tdf['token_txt_str'] = tdf['token_txt'].str.join(',')",
        "    tdf['token_tag_str'] = tdf['token_tag'].str.join(',')",
        "",
        "    # tdf['txt'] = tdf.apply(lambda x: ' '.join(x['token_txt']), axis=1) ",
        "",
        "    fdf = edf.explode('form_tmp').merge(tdf.explode('form_tmp'), on='form_tmp').drop(['form_tmp'], axis=1)",
        "",
        "    fdf = fdf.query(\"item_nm_alias.str.lower() not in @stop_item_names and token_txt_str.replace(',','').str.lower() not in @stop_item_names\").drop_duplicates(['item_nm','item_nm_alias','item_id','token_txt_str','token_tag_str'])",
        "",
        "    def ngram_jaccard_similarity(list1, list2, n=2):",
        "        \"\"\"Calculate similarity using Jaccard similarity of n-grams.\"\"\"",
        "        # Generate n-grams for both lists",
        "        def get_ngrams(lst, n):",
        "            return [tuple(lst[i:i+n]) for i in range(len(lst)-n+1)]",
        "        ",
        "        # Handle edge cases",
        "        if len(list1) < n or len(list2) < n:",
        "            if list1 == list2:",
        "                return 1.0",
        "            else:",
        "                return 0.0",
        "        ",
        "        # Generate n-grams and calculate Jaccard similarity",
        "        ngrams1 = set(get_ngrams(list1, n))",
        "        ngrams2 = set(get_ngrams(list2, n))",
        "        ",
        "        intersection = ngrams1.intersection(ngrams2)",
        "        union = ngrams1.union(ngrams2)",
        "        ",
        "        return len(intersection) / len(union) if union else 0",
        "",
        "    def needleman_wunsch_similarity(list1, list2, match_score=1, mismatch_penalty=1, gap_penalty=1):",
        "        \"\"\"Global sequence alignment with Needleman-Wunsch algorithm.\"\"\"",
        "        m, n = len(list1), len(list2)",
        "        ",
        "        # Initialize score matrix",
        "        score = np.zeros((m+1, n+1))",
        "        ",
        "        # Initialize first row and column with gap penalties",
        "        for i in range(m+1):",
        "            score[i][0] = -i * gap_penalty",
        "        for j in range(n+1):",
        "            score[0][j] = -j * gap_penalty",
        "        ",
        "        # Fill the score matrix",
        "        for i in range(1, m+1):",
        "            for j in range(1, n+1):",
        "                match = score[i-1][j-1] + (match_score if list1[i-1] == list2[j-1] else -mismatch_penalty)",
        "                delete = score[i-1][j] - gap_penalty",
        "                insert = score[i][j-1] - gap_penalty",
        "                score[i][j] = max(match, delete, insert)",
        "        ",
        "        # Calculate similarity score",
        "        max_possible_score = min(m, n) * match_score",
        "        alignment_score = score[m][n]",
        "        ",
        "        # Normalize to 0-1 range",
        "        min_possible_score = -max(m, n) * max(gap_penalty, mismatch_penalty)",
        "        normalized_score = (alignment_score - min_possible_score) / (max_possible_score - min_possible_score)",
        "        ",
        "        return normalized_score",
        "",
        "    fdf['sim_score_token'] = fdf.apply(lambda row: needleman_wunsch_similarity(row['token_txt'], row['token_entity']), axis=1)",
        "    fdf['sim_score_char'] = fdf.apply(lambda row: advanced_sequential_similarity((''.join(row['char_msg'])), (''.join(row['char_entity'])),metrics='difflib')['difflib'], axis=1)",
        "",
        "    entity_list = [e.replace(' ', '').lower() for e in list(edf['item_nm_alias'].unique())]",
        "    entities_from_kiwi_rev = [e.replace(' ', '').lower() for e in entities_from_kiwi]",
        "",
        "    kdf = fdf.query(\"item_nm_alias in @entities_from_kiwi_rev or token_txt_str.str.replace(',',' ').str.lower() in @entities_from_kiwi_rev or token_txt_str.str.replace(',','').str.lower() in @entities_from_kiwi_rev\").copy()",
        "    kdf = kdf.query(\"(sim_score_token>=0.75 and sim_score_char>=0.75) or sim_score_char>=1\").query(\"item_nm_alias.str.replace(',','').str.lower() in @entity_list or item_nm_alias.str.replace(' ','').str.lower() in @entity_list\")",
        "    kdf['rank'] = kdf.groupby(['token_txt_str'])['sim_score_char'].rank(ascending=False, method='dense')#.reset_index(name='rank')",
        "    kdf = kdf.query(\"rank<=1\")[['item_nm','item_nm_alias','item_id','token_txt_str','domain','sim_score_token','sim_score_char']].drop_duplicates()",
        "    # kdf = kdf.query(\"rank<=1\")",
        "",
        "    # kdf = kdf.groupby('item_nm_alias', group_keys=False).apply(lambda x: x.sample(n=min(len(x), 2), random_state=42), include_groups=False)",
        "",
        "    tags_to_exclude_final = ['SN']",
        "    filtering_condition = [",
        "    \"\"\"not token_tag_str in @tags_to_exclude_final\"\"\"",
        "    ,\"\"\"and token_txt_str.str.len()>=2\"\"\"",
        "    ,\"\"\"and not token_txt_str in @stop_item_names\"\"\"",
        "    ,\"\"\"and not token_txt_str.str.replace(',','').str.lower() in @stop_item_names\"\"\"",
        "    ,\"\"\"and not item_nm_alias in @stop_item_names\"\"\"",
        "    ]",
        "",
        "    sdf = (",
        "        fdf",
        "        .query(\"item_nm_alias.str.lower() not in @stop_item_names\")",
        "        .query(\"(sim_score_token>=0.7 and sim_score_char>=0.8) or (sim_score_token>=0.1 and sim_score_char>=0.9)\")",
        "        # .query(\"item_nm_alias.str.contains('에이닷', case=False)\")",
        "        .query(' '.join(filtering_condition))",
        "        .sort_values('sim_score_char', ascending=False)",
        "        [['item_nm_alias','item_id','token_txt','token_txt_str','sim_score_token','sim_score_char','domain']]",
        "    ).copy()",
        "",
        "    sdf['rank_e'] = sdf.groupby(['item_nm_alias'])['sim_score_char'].rank(ascending=False, method='dense')#.reset_index(name='rank')",
        "    sdf['rank_t'] = sdf.groupby(['token_txt_str'])['sim_score_char'].rank(ascending=False, method='dense')#.reset_index(name='rank')",
        "    sdf = sdf.query(\"rank_t<=1 and rank_e<=1\")[['item_nm_alias','item_id','token_txt_str','domain']].drop_duplicates()",
        "",
        "    # sdf = sdf.groupby('item_nm_alias', group_keys=False).apply(lambda x: x.sample(n=min(len(x), 2), random_state=42), include_groups=False)",
        "",
        "    if pd.concat([kdf,sdf]).shape[0]<1:",
        "        continue",
        "    ",
        "    product_df = pd.concat([kdf,sdf]).drop_duplicates(['item_id','item_nm','item_nm_alias','domain']).groupby([\"item_nm\",\"item_nm_alias\",\"item_id\",\"domain\"])['token_txt_str'].apply(list).reset_index(name='item_name_in_message').rename(columns={'item_nm':'item_name_in_voca'}).sort_values('item_name_in_voca')",
        "",
        "    product_df['item_name_in_message'] = product_df['item_name_in_message'].apply(lambda x: \",\".join(list(set([w.replace(',',' ') for w in x]))))",
        "",
        "    product_df[['item_name_in_message','item_name_in_voca','item_id','domain']]#.query(\"item_name_in_voca.str.contains('netflix', case=False)\").drop_duplicates(['item_name_in_voca']).sort_values('item_id')",
        "",
        "    ### Entity-Assisted",
        "",
        "    # product_info = (\",\\n\".join(product_df.apply(lambda x: f'\"item_name_in_msg\":\"{x['item_name_in_msg']}\", \"item_name_in_voca\":\"{x['item_name_in_voca']}\", \"item_id\":\"{x['item_id']}:, \"action\":고객에게 기대하는 행동. [구매, 가입, 사용, 방문, 참여, 코드입력, 쿠폰다운로드, 없음, 기타] 중에서 선택', axis=1).tolist()))",
        "    # product_info = \", \".join(product_df['item_name_in_voca'].unique().tolist())",
        "    product_info = \", \".join(product_df[['item_name_in_voca','domain']].apply(lambda x: x['item_name_in_voca']+\"(\"+x['domain']+\")\", axis=1))",
        "",
        "    # product_df = product_df.drop_duplicates(['item_name_in_message','item_name_in_voca'])",
        "    # product_df = product_df.merge(product_df.groupby('item_name_in_message')['item_id'].size().reset_index(name='count').sort_values('count', ascending=False), on='item_name_in_message', how='left').query('count<=3')",
        "    product_df = product_df[['item_name_in_voca','item_id','domain']].drop_duplicates()",
        "    product_df['action'] = '고객에게 기대하는 행동. [구매, 가입, 사용, 방문, 참여, 코드입력, 쿠폰다운로드, 없음, 기타] 중에서 선택'",
        "",
        "    # product_element = product_df.to_dict(orient='records') if product_df.shape[0]>0 else schema_prd['product']",
        "",
        "    # pgm_cand_info = \"\\n\\t\".join(pgm_pdf_tmp.iloc[:num_cand_pgms][['pgm_nm','clue_tag']].apply(lambda x: re.sub(r'\\[.*?\\]', '', x['pgm_nm'])+\" : \"+x['clue_tag'], axis=1).to_list())",
        "    # rag_context = f\"\\n### 광고 분류 기준 정보 ###\\n\\t{pgm_cand_info}\" if num_cand_pgms>0 else \"\"",
        "",
        "    # schema_prd_ent = {",
        "    #     \"title\": {",
        "    #         \"type\": \"string\", ",
        "    #         'description': '광고 제목. 광고의 핵심 주제와 가치 제안을 명확하게 설명할 수 있도록 생성'",
        "    #     },",
        "    #     \"purpose\": {",
        "    #         \"type\": \"array\", ",
        "    #         'description': '광고의 주요 목적을 다음 중에서 선택(복수 가능): [상품 가입 유도, 대리점 방문 유도, 웹/앱 접속 유도, 이벤트 응모 유도, 혜택 안내, 쿠폰 제공 안내, 경품 제공 안내, 기타 정보 제공]'",
        "    #     },",
        "    #     \"product\": ",
        "    #         product_element",
        "    #     ,",
        "    #     'channel': {",
        "    #         'type': 'array', ",
        "    #         'items': {",
        "    #             'type': 'object', ",
        "    #             'properties': {",
        "    #                 'type': {'type': 'string', 'description': '채널 종류: [URL, 전화번호, 앱, 대리점] 중에서 선택'},",
        "    #                 'value': {'type': 'string', 'description': '실제 URL, 전화번호, 앱 이름, 대리점 이름 등 구체적 정보'},",
        "    #                 'action': {'type': 'string', 'description': '채널 목적: [방문, 접속, 가입, 추가 정보, 문의, 수신, 수신 거부] 중에서 선택'},",
        "    #                 # 'benefit': {'type': 'string', 'description': '해당 채널 이용 시 특별 혜택'},",
        "    #                 'store_code': {'type': 'string', 'description': \"매장 코드 - tworldfriends.co.kr URL에서 D+숫자 9자리(D[0-9]{9}) 패턴의 코드 추출하여 대리점 채널에 설정\"}",
        "    #             }",
        "    #         },",
        "    #     },",
        "    #     'pgm':{",
        "    #         'type': 'array', ",
        "    #         'description': '아래 광고 분류 기준 정보에서 선택. 메세지 내용과 광고 분류 기준을 참고하여, 광고 메세지에 가장 부합하는 2개의 pgm_nm을 적합도 순서대로 제공'",
        "    #     }",
        "    # }",
        "",
        "    # # Improved extraction guidance",
        "    # extraction_guide = \"\"\"",
        "    # ### 분석 목표 ###",
        "    # * Schema의 Product 태그 내에 action을 추출하세요.",
        "    # * Schema내 action 항목 외 태그 정보는 원본 그대로 두세요.",
        "",
        "    # ### 고려사항 ###",
        "    # * 상품 정보에 있는 항목을 임의로 변형하거나 누락시키지 마세요.",
        "    # * 광고 분류 기준 정보는 pgm_nm : clue_tag 로 구성",
        "",
        "    # ### JSON 응답 형식 ###",
        "    # 응답은 설명 없이 순수한 JSON 형식으로만 제공하세요. 응답의 시작과 끝은 '{'와 '}'여야 합니다. 어떠한 추가 텍스트나 설명도 포함하지 마세요.",
        "    # \"\"\"",
        "",
        "    # # Create the system message with clear JSON output requirements",
        "    # user_message = f\"\"\"당신은 SKT 캠페인 메시지에서 정확한 정보를 추출하는 전문가입니다. 아래 schema에 따라 광고 메시지를 분석하여 완전하고 정확한 JSON 객체를 생성해 주세요:",
        "",
        "    # ### 분석 대상 광고 메세지 ###",
        "    # {mms_msg}",
        "",
        "    # ### 결과 Schema ###",
        "    # {json.dumps(schema_prd_ent, indent=2, ensure_ascii=False)}",
        "",
        "    # {extraction_guide}",
        "",
        "    # {rag_context}",
        "",
        "    # \"\"\"",
        "",
        "    # try:",
        "    #     # # Use OpenAI's ChatCompletion with the current API format",
        "    #     # response = client.chat.completions.create(",
        "    #     #     model=\"skt/a.x-3-lg\",  # Or your preferred OpenAI model",
        "    #     # # model=\"skt/claude-3-5-sonnet-20241022\",",
        "    #     #     messages = [",
        "    #     #         {\"role\": \"user\", \"content\": user_message},",
        "    #     #     ],",
        "    #     #     temperature=0.0,",
        "    #     #     max_tokens=4000,",
        "    #     #     top_p=0.95,  # Reduces randomness",
        "    #     #     frequency_penalty=0.0,  # Avoid repetition in JSON",
        "    #     #     presence_penalty=0.0,",
        "    #     #     response_format={\"type\": \"json_object\"}  # Explicitly request JSON format",
        "    #     # )",
        "        ",
        "    #     # # Extract the JSON from the response",
        "    #     # result_json_text = response.choices[0].message.content",
        "    #     # json_objects = extract_json_objects(result_json_text)[0]",
        "",
        "    #     llm_result = llm_gem3.invoke(user_message, max_tokens=4000)",
        "    #     json_objects = extract_json_objects(llm_result.content)[0]",
        "",
        "    #     pgm_json = pgm_pdf[pgm_pdf['pgm_nm'].apply(lambda x: re.sub(r'\\[.*?\\]', '', x) in ' '.join(json_objects['pgm']))][['pgm_nm','pgm_id']].to_dict('records')",
        "",
        "    #     final_result = json_objects.copy()",
        "    #     final_result['pgm'] = pgm_json",
        "",
        "    #     final_result_dict['ent'] = final_result",
        "",
        "    # except Exception as e:",
        "    #     print(f\"Error with API call: {e}\")",
        "",
        "    # print(json.dumps(final_json, indent=4, ensure_ascii=False))",
        "",
        "    ### LLM-only",
        "",
        "    extraction_guide = \"\"\"",
        "    ### 분석 시 고려사항 ###",
        "    * 하나의 광고에 여러 상품이 포함될 수 있으며, 각 상품별로 별도 객체 생성",
        "    * 재현율이 높도록 모든 상품을 선택",
        "    * 상품 후보 정보는 상품 이름 (도메인) 형식으로 제공",
        "    * 광고 분류 기준 정보는 pgm_nm : clue_tag 로 구성",
        "",
        "    ### 분석 목표 ###",
        "    * 텍스트 매칭 기법으로 만들어진 상품 후보 정보가 제공되면 이를 확인하여 참고하라.",
        "    * 제공된 상품 이름이 적합하지 않으면 무시하고, 목록에 없어도 적합한 상품이 있으면 추출하세요.",
        "",
        "    ### JSON 응답 형식 ###",
        "    응답은 설명 없이 순수한 JSON 형식으로만 제공하세요. 응답의 시작과 끝은 '{'와 '}'여야 합니다. 어떠한 추가 텍스트나 설명도 포함하지 마세요.",
        "    \"\"\"",
        "",
        "    # product_info = \", \".join(product_df['item_name_in_voca'].unique().tolist())",
        "    product_info = \", \".join(product_df[['item_name_in_voca','domain']].apply(lambda x: x['item_name_in_voca']+\"(\"+x['domain']+\")\", axis=1))",
        "",
        "    rag_context = f\"### 상품 후보 정보 ###\\n\\t{product_info}\" if product_df.shape[0]>0 else \"\"",
        "",
        "    pgm_cand_info = \"\\n\\t\".join(pgm_pdf_tmp.iloc[:num_cand_pgms][['pgm_nm','clue_tag']].apply(lambda x: re.sub(r'\\[.*?\\]', '', x['pgm_nm'])+\" : \"+x['clue_tag'], axis=1).to_list())",
        "    rag_context += f\"\\n\\n### 광고 분류 기준 정보 ###\\n\\t{pgm_cand_info}\" if num_cand_pgms>0 else \"\"",
        "",
        "    # Create the system message with clear JSON output requirements",
        "    user_message = f\"\"\"당신은 SKT 캠페인 메시지에서 정확한 정보를 추출하는 전문가입니다. 아래 schema에 따라 광고 메시지를 분석하여 완전하고 정확한 JSON 객체를 생성해 주세요:",
        "",
        "    ### 분석 대상 광고 메세지 ###",
        "    {mms_msg}",
        "",
        "    ### 결과 Schema ###",
        "    {json.dumps(schema_prd, indent=2, ensure_ascii=False)}",
        "",
        "    {extraction_guide}",
        "",
        "    {rag_context}",
        "",
        "    \"\"\"",
        "",
        "    try:",
        "        # Use OpenAI's ChatCompletion with the current API format",
        "        response = client.chat.completions.create(",
        "            model=\"skt/a.x-3-lg\",  # Or your preferred OpenAI model",
        "        #   model=\"skt/claude-3-5-sonnet-20241022\",",
        "            messages = [",
        "                {\"role\": \"user\", \"content\": user_message},",
        "            ],",
        "            temperature=0.0,",
        "            max_tokens=4000,",
        "            top_p=0.95,  # Reduces randomness",
        "            frequency_penalty=0.0,  # Avoid repetition in JSON",
        "            presence_penalty=0.0,",
        "            response_format={\"type\": \"json_object\"}  # Explicitly request JSON format",
        "        )",
        "        ",
        "        # Extract the JSON from the response",
        "        result_json_text = response.choices[0].message.content",
        "        json_objects = extract_json_objects(result_json_text)[0]",
        "",
        "        interim_result_dict['ax'] = json_objects",
        "",
        "        llm_result = llm_gem3.invoke(user_message, max_tokens=4000)",
        "        json_objects = extract_json_objects(llm_result.content)[0]",
        "",
        "        interim_result_dict['gem'] = json_objects",
        "",
        "    except Exception as e:",
        "        print(f\"Error with API call: {e}\")",
        "        # print(f\"Error with API call: {e}\")",
        "",
        "    # matches = []",
        "    # for item_name_message in json_objects['product']:",
        "    #     matches.extend(find_entities_in_text(",
        "    #         item_name_message['name'], ",
        "    #         entity_list_for_fuzzy, ",
        "    #         min_similarity=50,",
        "    #         high_score_threshold=50,",
        "    #         overlap_tolerance=0.5",
        "    #     ))",
        "",
        "    # mdf = pd.DataFrame(matches)",
        "    # if len(matches)>0:",
        "    #     mdf = mdf.query(\"text.str.lower() not in @stop_item_names and matched_entity.str.lower() not in @stop_item_names\")",
        "",
        "    # if mdf.shape[0]>0:",
        "    #     mdf['item_id'] = mdf['data'].apply(lambda x: x['item_id'])",
        "    #     mdf['domain'] = mdf['data'].apply(lambda x: x['domain'])",
        "    #     mdf = mdf.query(\"not matched_entity.str.contains('test', case=False)\").drop_duplicates(['item_id','domain'])",
        "",
        "    #     mdf = mdf.merge(mdf.groupby(['text','start'])['end'].max().reset_index(name='end'), on=['text', 'start', 'end'])",
        "",
        "    #     mdf['rank'] = mdf['data'].apply(lambda x: x['rank'])",
        "    #     mdf['re_rank'] = mdf.groupby('text')['score'].rank(ascending=False)",
        "    #     mdf = mdf.query(\"re_rank<=2\")",
        "",
        "    #     mdf = mdf.merge(pd.DataFrame(json_objects['product']).rename(columns={'name':'text'}), on='text', how='left')",
        "",
        "    #     product_tag = mdf.rename(columns={'text':'item_name_in_message','matched_entity':'item_name_in_voca'})[['item_name_in_message','item_name_in_voca','item_id','domain']].drop_duplicates().to_dict(orient='records')",
        "",
        "    #     final_result = {",
        "    #         \"title\":json_objects['title'],",
        "    #         \"purpose\":json_objects['purpose'],",
        "    #         \"product\":product_tag,",
        "    #         \"channel\":json_objects['channel'],",
        "    #         \"pgm\":json_objects['pgm']",
        "    #     }",
        "",
        "    # else:",
        "    #     final_result = json_objects",
        "    #     final_result['product'] = [{'item_name_in_message':d['name'], 'item_name_in_voca':d['name'], 'item_id': '#', 'domain': '#'} for d in final_result['product']]",
        "",
        "    # if num_cand_pgms>0:",
        "    #     pgm_json = pgm_pdf[pgm_pdf['pgm_nm'].apply(lambda x: re.sub(r'\\[.*?\\]', '', x) in ' '.join(json_objects['pgm']))][['pgm_nm','pgm_id']].to_dict('records')",
        "    #     final_result['pgm'] = pgm_json",
        "",
        "    # # print(json.dumps(final_result, indent=4, ensure_ascii=False))",
        "",
        "    # final_result_dict['llm'] = final_result",
        "",
        "    ### cld 40",
        "",
        "    try:",
        "        response = llm_cld40.invoke([",
        "                {\"role\": \"user\", \"content\": user_message}",
        "        ])",
        "        ",
        "        # Extract the JSON from the response",
        "        result_json_text = response.content",
        "        json_objects = extract_json_objects(result_json_text)[0]",
        "",
        "        interim_result_dict['c40'] = json_objects",
        "",
        "    except Exception as e:",
        "        print(f\"Error with API call: {e}\")",
        "",
        "    # matches = []",
        "    # for item_name_message in json_objects['product']:",
        "    #     matches.extend(find_entities_in_text(",
        "    #         item_name_message['name'], ",
        "    #         entity_list_for_fuzzy, ",
        "    #         min_similarity=50,",
        "    #         high_score_threshold=50,",
        "    #         overlap_tolerance=0.5",
        "    #     ))",
        "",
        "    # mdf = pd.DataFrame(matches)",
        "    # if len(matches)>0:",
        "    #     mdf = mdf.query(\"text.str.lower() not in @stop_item_names and matched_entity.str.lower() not in @stop_item_names\")",
        "",
        "    # if mdf.shape[0]>0:",
        "    #     mdf['item_id'] = mdf['data'].apply(lambda x: x['item_id'])",
        "    #     mdf['domain'] = mdf['data'].apply(lambda x: x['domain'])",
        "    #     mdf = mdf.query(\"not matched_entity.str.contains('test', case=False)\").drop_duplicates(['item_id','domain'])",
        "",
        "    #     mdf = mdf.merge(mdf.groupby(['text','start'])['end'].max().reset_index(name='end'), on=['text', 'start', 'end'])",
        "",
        "    #     mdf['rank'] = mdf['data'].apply(lambda x: x['rank'])",
        "    #     mdf['re_rank'] = mdf.groupby('text')['score'].rank(ascending=False)",
        "    #     mdf = mdf.query(\"re_rank<=2\")",
        "",
        "    #     mdf = mdf.merge(pd.DataFrame(json_objects['product']).rename(columns={'name':'text'}), on='text', how='left')",
        "",
        "    #     product_tag = mdf.rename(columns={'text':'item_name_in_message','matched_entity':'item_name_in_voca'})[['item_name_in_message','item_name_in_voca','item_id','domain']].drop_duplicates().to_dict(orient='records')",
        "",
        "    #     final_result = {",
        "    #         \"title\":json_objects['title'],",
        "    #         \"purpose\":json_objects['purpose'],",
        "    #         \"product\":product_tag,",
        "    #         \"channel\":json_objects['channel'],",
        "    #         \"pgm\":json_objects['pgm']",
        "    #     }",
        "",
        "    # else:",
        "    #     final_result = json_objects",
        "    #     final_result['product'] = [{'item_name_in_message':d['name'], 'item_name_in_voca':d['name'], 'item_id': '#', 'domain': '#'} for d in final_result['product']]",
        "",
        "    # if num_cand_pgms>0:",
        "    #     pgm_json = pgm_pdf[pgm_pdf['pgm_nm'].apply(lambda x: re.sub(r'\\[.*?\\]', '', x) in ' '.join(json_objects['pgm']))][['pgm_nm','pgm_id']].to_dict('records')",
        "    #     final_result['pgm'] = pgm_json",
        "",
        "    # # print(json.dumps(final_result, indent=4, ensure_ascii=False))",
        "",
        "    # final_result_dict['c40'] = final_result",
        "",
        "    ### LLM-COT",
        "",
        "    # extraction_guide = \"\"\"",
        "    # ## 분석 지침",
        "    # 1. **재현율 우선**: 광고에서 언급된 모든 상품을 누락 없이 추출",
        "    # 2. **도메인 활용**: 상품 후보의 도메인 정보를 적극 활용하여 정확한 매칭 수행",
        "    # 3. **목적 기반 추론**: 광고 목적을 명확히 파악한 후 다른 요소들을 일관성 있게 분석",
        "    # 4. **채널 완전성**: 모든 접촉 채널을 누락 없이 추출하고 각각의 역할과 혜택을 명확히 식별",
        "    # 5. **컨텍스트 고려**: 제공된 상품 후보가 부적합하면 무시하고, 누락된 중요 상품이 있으면 추가",
        "    # 6. **매장 코드 정확성**: tworldfriends.co.kr URL에서 정확한 패턴 매칭을 통해 매장 코드 추출",
        "",
        "    # ## JSON 응답 형식",
        "    # - reasoning 섹션은 분석 과정 설명용이며 최종 JSON에는 포함하지 않음",
        "    # - 순수한 JSON 형식으로만 응답",
        "    # - 시작과 끝은 '{'와 '}'",
        "    # - 추가 텍스트나 설명 없이 JSON만 제공",
        "    # \"\"\"",
        "",
        "    # # product_info = \", \".join(product_df['item_name_in_voca'].unique().tolist())",
        "    # product_info = \", \".join(product_df[['item_name_in_voca','domain']].apply(lambda x: x['item_name_in_voca']+\"(\"+x['domain']+\")\", axis=1))",
        "",
        "    # rag_context = f\"### 상품 후보 정보 ###\\n\\t{product_info}\" if product_df.shape[0]>0 else \"\"",
        "",
        "    # pgm_cand_info = \"\\n\\t\".join(pgm_pdf_tmp.iloc[:num_cand_pgms][['pgm_nm','clue_tag']].apply(lambda x: re.sub(r'\\[.*?\\]', '', x['pgm_nm'])+\" : \"+x['clue_tag'], axis=1).to_list())",
        "    # rag_context += f\"\\n\\n### 광고 분류 기준 정보 ###\\n\\t{pgm_cand_info}\" if num_cand_pgms>0 else \"\"",
        "",
        "    # # Create the system message with clear JSON output requirements",
        "    # user_message = f\"\"\"당당신은 SKT 캠페인 메시지에서 정확한 정보를 추출하는 전문가입니다. **단계별 사고 과정(Chain of Thought)**을 통해 광고 메시지를 분석하여 완전하고 정확한 JSON 객체를 생성해 주세요.",
        "",
        "    # ## 분석 단계 (Chain of Thought)",
        "",
        "    # ### STEP 1: 광고 목적(Purpose) 분석",
        "    # 먼저 광고 메시지 전체를 읽고 광고의 주요 목적을 파악하세요.",
        "",
        "    # ### STEP 2: 상품(Product) 식별 및 도메인 매칭",
        "    # 파악된 목적을 바탕으로 다음 과정을 거쳐 상품을 식별하세요:",
        "",
        "    # **2-1. 광고 메시지에서 언급된 모든 상품/서비스 추출**",
        "    # - 직접적으로 언급된 상품명을 모두 나열",
        "    # - 묵시적으로 언급된 서비스나 혜택도 포함",
        "",
        "    # **2-2. RAG Context의 상품 후보 정보와 도메인 매칭**",
        "    # - 각 추출된 상품을 상품 후보 정보와 비교",
        "    # - 도메인 정보(product, subscription_service 등)를 고려하여 가장 적합한 매칭 수행",
        "    # - 상품 후보에 없어도 광고에서 중요하게 다뤄지는 상품이 있다면 추가",
        "",
        "    # **2-3. 각 상품별 고객 행동(Action) 결정**",
        "    # - STEP 1에서 파악한 목적과 연결하여 각 상품에 대한 기대 행동 결정",
        "    # - 행동 후보: [구매, 가입, 사용, 방문, 참여, 코드입력, 쿠폰다운로드, 기타]",
        "",
        "    # ### STEP 3: 채널(Channel) 및 연락처 정보 추출",
        "    # 광고 메시지에서 고객이 접촉할 수 있는 모든 채널을 식별하고 분석하세요:",
        "",
        "    # **3-1. 채널 유형별 식별**",
        "    # - **URL**: 웹사이트 링크, 프로모션 페이지, 랜딩 페이지 등",
        "    # - **전화번호**: 고객센터, 상담 전화, 수신거부 번호 등",
        "    # - **앱**: 모바일 앱, 웹앱 등의 애플리케이션",
        "    # - **대리점**: 매장, 지점, 서비스센터 등",
        "",
        "    # **3-2. 각 채널별 세부 정보 분석**",
        "    # - **value**: 정확한 URL, 전화번호, 앱명, 대리점명 추출",
        "    # - **action**: 해당 채널의 주요 목적 파악 [가입, 추가 정보, 문의, 수신, 수신 거부]",
        "    # - **benefit**: 채널 이용 시 제공되는 특별 혜택이나 무료 서비스 등",
        "    # - **store_code**: tworldfriends.co.kr URL에서 D+숫자 9자리(D[0-9]{9}) 패턴 추출",
        "",
        "    # **3-3. 채널 우선순위 및 역할 분석**",
        "    # - 주요 행동 유도 채널 vs 보조 정보 제공 채널 구분",
        "    # - 각 채널이 STEP 1에서 파악한 목적과 어떻게 연결되는지 분석",
        "",
        "    # ### STEP 4: 프로그램 분류(PGM) 결정",
        "    # - 광고 분류 기준 정보의 키워드와 메시지 내용 매칭",
        "    # - 적합도 순서대로 2개 선택",
        "",
        "    # ### 분석 대상 광고 메세지 ###",
        "    # {mms_msg}",
        "",
        "    # {rag_context}",
        "",
        "    # ### 결과 Schema ###",
        "    # {json.dumps(schema_prd_cot, indent=2, ensure_ascii=False)}",
        "",
        "    # {extraction_guide}",
        "",
        "    # \"\"\"",
        "",
        "    # try:",
        "    #     # Use OpenAI's ChatCompletion with the current API format",
        "    #     response = client.chat.completions.create(",
        "    #         # model=\"skt/a.x-3-lg\",  # Or your preferred OpenAI model",
        "    #       model=\"skt/claude-3-5-sonnet-20241022\",",
        "    #         messages = [",
        "    #             {\"role\": \"user\", \"content\": user_message},",
        "    #         ],",
        "    #         temperature=0.0,",
        "    #         max_tokens=4000,",
        "    #         top_p=0.95,  # Reduces randomness",
        "    #         frequency_penalty=0.0,  # Avoid repetition in JSON",
        "    #         presence_penalty=0.0,",
        "    #         response_format={\"type\": \"json_object\"}  # Explicitly request JSON format",
        "    #     )",
        "        ",
        "    #     # Extract the JSON from the response",
        "    #     result_json_text = response.choices[0].message.content",
        "    #     json_objects = extract_json_objects(result_json_text)[0]",
        "",
        "    #     interim_result_dict['cot'] = json_objects",
        "                    ",
        "    # except Exception as e:",
        "    #     print(f\"Error with API call: {e}\")",
        "",
        "    # matches = []",
        "    # for item_name_message in json_objects['product']:",
        "    #     matches.extend(find_entities_in_text(",
        "    #         item_name_message['name'], ",
        "    #         entity_list_for_fuzzy, ",
        "    #         min_similarity=50,",
        "    #         high_score_threshold=50,",
        "    #         overlap_tolerance=0.5",
        "    #     ))",
        "",
        "    # mdf = pd.DataFrame(matches)",
        "    # if len(matches)>0:",
        "    #     mdf = mdf.query(\"text.str.lower() not in @stop_item_names and matched_entity.str.lower() not in @stop_item_names\")",
        "",
        "    # if mdf.shape[0]>0:",
        "    #     mdf['item_id'] = mdf['data'].apply(lambda x: x['item_id'])",
        "    #     mdf['domain'] = mdf['data'].apply(lambda x: x['domain'])",
        "    #     mdf = mdf.query(\"not matched_entity.str.contains('test', case=False)\").drop_duplicates(['item_id','domain'])",
        "",
        "    #     mdf = mdf.merge(mdf.groupby(['text','start'])['end'].max().reset_index(name='end'), on=['text', 'start', 'end'])",
        "",
        "    #     mdf['rank'] = mdf['data'].apply(lambda x: x['rank'])",
        "    #     mdf['re_rank'] = mdf.groupby('text')['score'].rank(ascending=False)",
        "    #     mdf = mdf.query(\"re_rank<=2\")",
        "",
        "    #     mdf = mdf.merge(pd.DataFrame(json_objects['product']).rename(columns={'name':'text'}), on='text', how='left')",
        "",
        "    #     product_tag = mdf.rename(columns={'text':'item_name_in_message','matched_entity':'item_name_in_voca'})[['item_name_in_message','item_name_in_voca','item_id','domain']].drop_duplicates().to_dict(orient='records')",
        "",
        "    #     final_result = {",
        "    #         \"title\":json_objects['title'],",
        "    #         \"purpose\":json_objects['purpose'],",
        "    #         \"product\":product_tag,",
        "    #         \"channel\":json_objects['channel'],",
        "    #         \"pgm\":json_objects['pgm']",
        "    #     }",
        "",
        "    # else:",
        "    #     final_result = json_objects",
        "    #     final_result['product'] = [{'item_name_in_message':d['name'], 'item_name_in_voca':d['name'], 'item_id': '#', 'domain': '#'} for d in final_result['product']]",
        "",
        "    # if num_cand_pgms>0:",
        "    #     pgm_json = pgm_pdf[pgm_pdf['pgm_nm'].apply(lambda x: re.sub(r'\\[.*?\\]', '', x) in ' '.join(json_objects['pgm']))][['pgm_nm','pgm_id']].to_dict('records')",
        "    #     final_result['pgm'] = pgm_json",
        "",
        "    # # print(json.dumps(final_result, indent=4, ensure_ascii=False))",
        "",
        "    # final_result_dict['cot'] = final_result",
        "",
        "    final_result_list.append(final_result_dict)",
        "    interim_result_list.append(interim_result_dict)",
        "",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from difflib import SequenceMatcher\n",
        "def calculate_list_similarity(list1, list2):\n",
        "    \"\"\"Calculate Jaccard similarity between two lists\"\"\"\n",
        "    if isinstance(list1, dict):\n",
        "        list1 = [str(item) for item in list1.values()]\n",
        "    if isinstance(list2, dict):\n",
        "        list2 = [str(item) for item in list2.values()]\n",
        "    # Ensure lists contain strings\n",
        "    list1 = [str(item) for item in list1]\n",
        "    list2 = [str(item) for item in list2]\n",
        "    # Convert lists to sets for comparison\n",
        "    set1 = set(sorted(set(list1)))\n",
        "    set2 = set(sorted(set(list2)))\n",
        "    # Calculate Jaccard similarity\n",
        "    intersection = len(set1.intersection(set2))\n",
        "    union = len(set1.union(set2))\n",
        "    return intersection / union if union > 0 else 0\n",
        "def calculate_text_similarity(text1, text2):\n",
        "    \"\"\"Calculate text similarity using SequenceMatcher\"\"\"\n",
        "    return SequenceMatcher(None, str(text1), str(text2)).ratio()\n",
        "def calculate_product_similarity(prod1, prod2):\n",
        "    \"\"\"Calculate similarity between product dictionaries with detailed structure\"\"\"\n",
        "    if not isinstance(prod1, dict) or not isinstance(prod2, dict):\n",
        "        return 0.0\n",
        "    # Calculate similarity for each field\n",
        "    item_name_message_sim = calculate_text_similarity(\n",
        "        prod1.get('item_name_in_message', '#'),\n",
        "        prod2.get('item_name_in_message', '&')\n",
        "    )\n",
        "    item_name_voca_sim = calculate_text_similarity(\n",
        "        prod1.get('item_name_in_voca', '#'),\n",
        "        prod2.get('item_name_in_voca', '&')\n",
        "    )\n",
        "    item_id_sim = calculate_text_similarity(\n",
        "        prod1.get('item_id', '#'),\n",
        "        prod2.get('item_id', '&')\n",
        "    )\n",
        "    domain_sim = calculate_text_similarity(\n",
        "        prod1.get('domain', '#'),\n",
        "        prod2.get('domain', '&')\n",
        "    )\n",
        "    name_sim = calculate_text_similarity(\n",
        "        prod1.get('name', '#'),\n",
        "        prod2.get('name', '&')\n",
        "    )\n",
        "    action_sim = calculate_text_similarity(\n",
        "        prod1.get('action', '#'),\n",
        "        prod2.get('action', '&')\n",
        "    )\n",
        "    # print(item_name_message_sim, item_name_voca_sim, item_id_sim, domain_sim, name_sim, action_sim)\n",
        "    # Weighted average - item_id and domain are more distinctive\n",
        "    similarity = (\n",
        "        item_name_message_sim +\n",
        "        item_name_voca_sim +\n",
        "        item_id_sim +\n",
        "        domain_sim +\n",
        "        name_sim +\n",
        "        action_sim\n",
        "    )/len(prod1.keys())\n",
        "    return similarity\n",
        "def calculate_channel_similarity(chan1, chan2):\n",
        "    \"\"\"Calculate similarity between channel dictionaries\"\"\"\n",
        "    if not isinstance(chan1, dict) or not isinstance(chan2, dict):\n",
        "        return 0.0\n",
        "    type_sim = calculate_text_similarity(chan1.get('type', ''), chan2.get('type', ''))\n",
        "    value_sim = calculate_text_similarity(chan1.get('value', ''), chan2.get('value', ''))\n",
        "    action_sim = calculate_text_similarity(chan1.get('action', ''), chan2.get('action', ''))\n",
        "    return (type_sim + value_sim + action_sim) / 3\n",
        "def calculate_pgm_similarity(pgm1, pgm2):\n",
        "    \"\"\"Calculate similarity between program dictionaries\"\"\"\n",
        "    if isinstance(pgm1, dict) and isinstance(pgm2, dict):\n",
        "        pgm_nm_sim = calculate_text_similarity(pgm1.get('pgm_nm', ''), pgm2.get('pgm_nm', ''))\n",
        "        pgm_id_sim = calculate_text_similarity(pgm1.get('pgm_id', ''), pgm2.get('pgm_id', ''))\n",
        "        pgm_sim = pgm_nm_sim * 0.4 + pgm_id_sim * 0.6\n",
        "    else:\n",
        "        pgm_sim = 0.0\n",
        "    # pgm_id is more distinctive, so give it higher weight\n",
        "    return pgm_sim\n",
        "def calculate_products_list_similarity(products1, products2):\n",
        "    \"\"\"Calculate similarity between two lists of product dictionaries\"\"\"\n",
        "    if not products1 or not products2:\n",
        "        return 0.0\n",
        "    # For each product in list1, find best match in list2\n",
        "    similarities = []\n",
        "    for p1 in products1:\n",
        "        best_match = 0.0\n",
        "        for p2 in products2:\n",
        "            similarity = calculate_product_similarity(p1, p2)\n",
        "            best_match = max(best_match, similarity)\n",
        "        similarities.append(best_match)\n",
        "    # Also check reverse direction to handle different list sizes\n",
        "    reverse_similarities = []\n",
        "    for p2 in products2:\n",
        "        best_match = 0.0\n",
        "        for p1 in products1:\n",
        "            similarity = calculate_product_similarity(p1, p2)\n",
        "            best_match = max(best_match, similarity)\n",
        "        reverse_similarities.append(best_match)\n",
        "    # Take average of both directions\n",
        "    forward_avg = sum(similarities) / len(similarities)\n",
        "    reverse_avg = sum(reverse_similarities) / len(reverse_similarities)\n",
        "    return (forward_avg + reverse_avg) / 2\n",
        "def calculate_channels_list_similarity(channels1, channels2):\n",
        "    \"\"\"Calculate similarity between two lists of channel dictionaries\"\"\"\n",
        "    if not channels1 or not channels2:\n",
        "        return 0.0\n",
        "    similarities = []\n",
        "    for c1 in channels1:\n",
        "        best_match = 0.0\n",
        "        for c2 in channels2:\n",
        "            similarity = calculate_channel_similarity(c1, c2)\n",
        "            best_match = max(best_match, similarity)\n",
        "        similarities.append(best_match)\n",
        "    return sum(similarities) / len(similarities)\n",
        "def calculate_pgms_list_similarity(pgms1, pgms2):\n",
        "    \"\"\"Calculate similarity between two lists of program dictionaries\"\"\"\n",
        "    if not pgms1 or not pgms2:\n",
        "        return 0.0\n",
        "    if isinstance(pgms1, list) and isinstance(pgms2, list):\n",
        "        # print(pgms1, pgms2)\n",
        "        pgm_sim = calculate_list_similarity(pgms1, pgms2)\n",
        "        return pgm_sim\n",
        "    # For each pgm in list1, find best match in list2\n",
        "    similarities = []\n",
        "    for p1 in pgms1:\n",
        "        best_match = 0.0\n",
        "        for p2 in pgms2:\n",
        "            similarity = calculate_pgm_similarity(p1, p2)\n",
        "            best_match = max(best_match, similarity)\n",
        "        similarities.append(best_match)\n",
        "    # Also check reverse direction\n",
        "    reverse_similarities = []\n",
        "    for p2 in pgms2:\n",
        "        best_match = 0.0\n",
        "        for p1 in pgms1:\n",
        "            similarity = calculate_pgm_similarity(p1, p2)\n",
        "            best_match = max(best_match, similarity)\n",
        "        reverse_similarities.append(best_match)\n",
        "    # Take average of both directions\n",
        "    forward_avg = sum(similarities) / len(similarities)\n",
        "    reverse_avg = sum(reverse_similarities) / len(reverse_similarities)\n",
        "    return (forward_avg + reverse_avg) / 2\n",
        "def calculate_dictionary_similarity(dict1, dict2):\n",
        "    \"\"\"\n",
        "    Calculate similarity between two dictionaries with generalized structure:\n",
        "    {\n",
        "        'title': str,\n",
        "        'purpose': [list of strings],\n",
        "        'product': [list of product dicts],\n",
        "        'channel': [list of channel dicts],\n",
        "        'pgm': [list of program dicts]\n",
        "    }\n",
        "    \"\"\"\n",
        "    if not isinstance(dict1, dict) or not isinstance(dict2, dict):\n",
        "        return {'overall_similarity': 0.0, 'error': 'Both inputs must be dictionaries'}\n",
        "    # Calculate title similarity\n",
        "    title_similarity = calculate_text_similarity(\n",
        "        dict1.get('title', ''),\n",
        "        dict2.get('title', '')\n",
        "    )\n",
        "    # Calculate purpose similarity (list of strings)\n",
        "    purpose_similarity = calculate_list_similarity(\n",
        "        dict1.get('purpose', []),\n",
        "        dict2.get('purpose', [])\n",
        "    )\n",
        "    # Calculate product similarity (list of product dicts)\n",
        "    product_similarity = calculate_products_list_similarity(\n",
        "        dict1.get('product', []),\n",
        "        dict2.get('product', [])\n",
        "    )\n",
        "    # Calculate channel similarity (list of channel dicts)\n",
        "    channel_similarity = calculate_channels_list_similarity(\n",
        "        dict1.get('channel', []),\n",
        "        dict2.get('channel', [])\n",
        "    )\n",
        "    # Calculate pgm similarity (list of program dicts)\n",
        "    pgm_similarity = calculate_pgms_list_similarity(\n",
        "        dict1.get('pgm', []),\n",
        "        dict2.get('pgm', [])\n",
        "    )\n",
        "    # Calculate overall similarity (weighted average)\n",
        "    # Adjusted weights to reflect importance of each component\n",
        "    overall_similarity = (\n",
        "        title_similarity * 0.2 +\n",
        "        purpose_similarity * 0.15 +\n",
        "        product_similarity * 0.35 +\n",
        "        channel_similarity * 0.15 +\n",
        "        pgm_similarity * 0.15\n",
        "    )\n",
        "    return {\n",
        "        'overall_similarity': overall_similarity,\n",
        "        'title_similarity': title_similarity,\n",
        "        'purpose_similarity': purpose_similarity,\n",
        "        'product_similarity': product_similarity,\n",
        "        'channel_similarity': channel_similarity,\n",
        "        'pgm_similarity': pgm_similarity\n",
        "    }\n",
        "def get_detailed_product_comparison(dict1, dict2):\n",
        "    \"\"\"\n",
        "    Get detailed comparison of products between two dictionaries\n",
        "    \"\"\"\n",
        "    products1 = dict1.get('product', [])\n",
        "    products2 = dict2.get('product', [])\n",
        "    detailed_comparison = []\n",
        "    for i, p1 in enumerate(products1):\n",
        "        best_match = {'similarity': 0.0, 'match_index': -1, 'match_product': None}\n",
        "        for j, p2 in enumerate(products2):\n",
        "            similarity = calculate_product_similarity(p1, p2)\n",
        "            if similarity > best_match['similarity']:\n",
        "                best_match = {\n",
        "                    'similarity': similarity,\n",
        "                    'match_index': j,\n",
        "                    'match_product': p2\n",
        "                }\n",
        "        detailed_comparison.append({\n",
        "            'product1_index': i,\n",
        "            'product1': p1,\n",
        "            'best_match': best_match\n",
        "        })\n",
        "    return detailed_comparison\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Example dictionaries with the new schema\n",
        "    dict1 = {\n",
        "        'title': 'POOQ 콘텐츠 팩 출시 기념 혜택',\n",
        "        'purpose': ['상품 가입 유도'],\n",
        "        'product': [\n",
        "            {'item_name_in_message': 'POOQ', 'item_name_in_voca': 'PooQ 팩', 'item_id': 'T000009330', 'domain': 'product'},\n",
        "            {'item_name_in_message': 'POOQ 콘텐츠 팩', 'item_name_in_voca': 'FLO 콘텐츠 팩', 'item_id': 'PR00000217', 'domain': 'subscription_service'}\n",
        "        ],\n",
        "        'channel': [{'type': 'URL', 'value': 'http://t-mms.kr/t.do?m=#61&u=http://m2.tworld.co.kr/jsp/op.jsp?p=w1026', 'action': '가입'}],\n",
        "        'pgm': [\n",
        "            {'pgm_nm': '[마케팅_Sales]상품및부가서비스가입유도_구독'},\n",
        "            {'pgm_nm': '[마케팅_Sales]타사회선(가망)_win-back'}\n",
        "        ]\n",
        "    }\n",
        "    dict2 = {\n",
        "        'title': 'POOQ 콘텐츠 팩 특별 혜택',\n",
        "        'purpose': ['상품 가입 유도', '프로모션'],\n",
        "        'product': [\n",
        "            {'item_name_in_message': 'POOQ', 'item_name_in_voca': 'PooQ 팩', 'item_id': 'T000009330', 'domain': 'product'},\n",
        "            {'item_name_in_message': 'POOQ 콘텐츠 팩', 'item_name_in_voca': 'FLO 콘텐츠 팩 플러스', 'item_id': 'PR00000218', 'domain': 'subscription_service'}\n",
        "        ],\n",
        "        'channel': [{'type': 'URL', 'value': 'http://different-url.com', 'action': '가입'}],\n",
        "        'pgm': [\n",
        "            {'pgm_nm': '[마케팅_Sales]상품및부가서비스가입유도_구독'}\n",
        "        ]\n",
        "    }\n",
        "    # Calculate similarity\n",
        "    result = calculate_dictionary_similarity(dict1, dict2)\n",
        "    print(\"Similarity Results:\")\n",
        "    for key, value in result.items():\n",
        "        print(f\"{key}: {value:.3f}\")\n",
        "    print(\"\\nDetailed Product Comparison:\")\n",
        "    detailed = get_detailed_product_comparison(dict1, dict2)\n",
        "    for comparison in detailed:\n",
        "        print(f\"Product {comparison['product1_index']}: {comparison['product1']['item_name_in_message']}\")\n",
        "        print(f\"  Best match (similarity: {comparison['best_match']['similarity']:.3f}): {comparison['best_match']['match_product']['item_name_in_message'] if comparison['best_match']['match_product'] else 'None'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "interim_result_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(87, 87)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ax_result_list = []\n",
        "gem_result_list = []\n",
        "for interim_result_dict in interim_result_list:\n",
        "    try:\n",
        "        if len(interim_result_dict['c40'])<1 or len(interim_result_dict['ax'])<1 or len(interim_result_dict['gem'])<1: continue\n",
        "        ax_result_list.append(calculate_dictionary_similarity(interim_result_dict['c40'], interim_result_dict['ax']))\n",
        "        gem_result_list.append(calculate_dictionary_similarity(interim_result_dict['c40'], interim_result_dict['gem']))\n",
        "    except Exception as e:\n",
        "        pass\n",
        "len(ax_result_list), len(gem_result_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a.x-3</th>\n",
              "      <th>gemma-3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>overall_similarity</th>\n",
              "      <td>0.58</td>\n",
              "      <td>0.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>title_similarity</th>\n",
              "      <td>0.64</td>\n",
              "      <td>0.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>purpose_similarity</th>\n",
              "      <td>0.54</td>\n",
              "      <td>0.64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>product_similarity</th>\n",
              "      <td>0.56</td>\n",
              "      <td>0.71</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>channel_similarity</th>\n",
              "      <td>0.61</td>\n",
              "      <td>0.84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pgm_similarity</th>\n",
              "      <td>0.58</td>\n",
              "      <td>0.60</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    a.x-3  gemma-3\n",
              "overall_similarity   0.58     0.70\n",
              "title_similarity     0.64     0.69\n",
              "purpose_similarity   0.54     0.64\n",
              "product_similarity   0.56     0.71\n",
              "channel_similarity   0.61     0.84\n",
              "pgm_similarity       0.58     0.60"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(ax_result_list).mean().to_frame().rename(columns={0:'a.x-3'}).merge(pd.DataFrame(gem_result_list).mean().to_frame().rename(columns={0:'gemma-3'}), left_index=True, right_index=True).round(2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "interim_result_dict['c40']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "interim_result_dict['cot']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "calculate_dictionary_similarity(interim_result_dict['c40'], interim_result_dict['cot'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spacy",
        "",
        "nlp = spacy.load(\"ko_core_news_sm\")",
        "",
        "msg_text_list = [\"\"\"",
        "    광고 제목:[SK텔레콤] 2월 0 day 혜택 안내",
        "    광고 내용:(광고)[SKT] 2월 0 day 혜택 안내__[2월 10일(토) 혜택]_만 13~34세 고객이라면_베어유 모든 강의 14일 무료 수강 쿠폰 드립니다!_(선착순 3만 명 증정)_▶ 자세히 보기: http://t-mms.kr/t.do?m=#61&s=24589&a=&u=https://bit.ly/3SfBjjc__■ 에이닷 X T 멤버십 시크릿코드 이벤트_에이닷 T 멤버십 쿠폰함에 ‘에이닷이빵쏜닷’을 입력해보세요!_뚜레쥬르 데일리우유식빵 무료 쿠폰을 드립니다._▶ 시크릿코드 입력하러 가기: https://bit.ly/3HCUhLM__■ 문의: SKT 고객센터(1558, 무료)_무료 수신거부 1504",
        "    \"\"\",",
        "    \"\"\"",
        "    광고 제목:통화 부가서비스를 패키지로 저렴하게!",
        "    광고 내용:(광고)[SKT] 콜링플러스 이용 안내  #04 고객님, 안녕하세요. <콜링플러스>에 가입하고 콜키퍼, 컬러링, 통화가능통보플러스까지 총 3가지의 부가서비스를 패키지로 저렴하게 이용해보세요.  ■ 콜링플러스 - 이용요금: 월 1,650원, 부가세 포함 - 콜키퍼(550원), 컬러링(990원), 통화가능통보플러스(770원)를 저렴하게 이용할 수 있는 상품  ■ 콜링플러스 가입 방법 - T월드 앱: 오른쪽 위에 있는 돋보기를 눌러 콜링플러스 검색 > 가입  ▶ 콜링플러스 가입하기: http://t-mms.kr/t.do?m=#61&u=https://skt.sh/17tNH  ■ 유의 사항 - 콜링플러스에 가입하면 기존에 이용 중인 콜키퍼, 컬러링, 통화가능통보플러스 서비스는 자동으로 해지됩니다. - 기존에 구매한 컬러링 음원은 콜링플러스 가입 후에도 계속 이용할 수 있습니다.(시간대, 발신자별 설정 정보는 다시 설정해야 합니다.)  * 최근 다운로드한 음원은 보관함에서 무료로 재설정 가능(다운로드한 날로부터 1년 이내)   ■ 문의: SKT 고객센터(114)  SKT와 함께해주셔서 감사합니다.  무료 수신거부 1504\\n    ', ",
        "    \"\"\",",
        "    \"\"\"",
        "    (광고)[SKT] 1월 0 day 혜택 안내_ _[1월 20일(토) 혜택]_만 13~34세 고객이라면 _CU에서 핫바 1,000원에 구매 하세요!_(선착순 1만 명 증정)_▶ 자세히 보기 : http://t-mms.kr/t.do?m=#61&s=24264&a=&u=https://bit.ly/3H2OHSs__■ 에이닷 X T 멤버십 구독캘린더 이벤트_0 day 일정을 에이닷 캘린더에 등록하고 혜택 날짜에 알림을 받아보세요! _알림 설정하면 추첨을 통해 [스타벅스 카페 라떼tall 모바일쿠폰]을 드립니다. _▶ 이벤트 참여하기 : https://bit.ly/3RVSojv_ _■ 문의: SKT 고객센터(1558, 무료)_무료 수신거부 1504",
        "    \"\"\",",
        "    \"\"\"",
        "    '[T 우주] 넷플릭스와 웨이브를 월 9,900원에! \\n(광고)[SKT] 넷플릭스+웨이브 월 9,900원, 이게 되네! __#04 고객님,_넷플릭스와 웨이브 둘 다 보고 싶었지만, 가격 때문에 망설이셨다면 지금이 바로 기회! __오직 T 우주에서만, _2개월 동안 월 9,900원에 넷플릭스와 웨이브를 모두 즐기실 수 있습니다.__8월 31일까지만 드리는 혜택이니, 지금 바로 가입해 보세요! __■ 우주패스 Netflix 런칭 프로모션 _- 기간 : 2024년 8월 31일(토)까지_- 혜택 : 우주패스 Netflix(광고형 스탠다드)를 2개월 동안 월 9,900원에 이용 가능한 쿠폰 제공_▶ 프로모션 자세히 보기: http://t-mms.kr/jAs/#74__■ 우주패스 Netflix(월 12,000원)  _- 기본 혜택 : Netflix 광고형 스탠다드 멤버십_- 추가 혜택 : Wavve 콘텐츠 팩 _* 추가 요금을 내시면 Netflix 스탠다드와 프리미엄 멤버십 상품으로 가입 가능합니다.  __■ 유의 사항_-  프로모션 쿠폰은 1인당 1회 다운로드 가능합니다. _-  쿠폰 할인 기간이 끝나면 정상 이용금액으로 자동 결제 됩니다. __■ 문의: T 우주 고객센터 (1505, 무료)__나만의 구독 유니버스, T 우주 __무료 수신거부 1504'",
        "    \"\"\",",
        "    \"\"\"",
        "    광고 제목:[SK텔레콤] T건강습관 X AIA Vitality, 우리 가족의 든든한 보험!",
        "    광고 내용:(광고)[SKT] 가족의 든든한 보험 (무배당)AIA Vitality 베스트핏 보장보험 안내  고객님, 안녕하세요. 4인 가족 표준생계비, 준비하고 계시나요? (무배당)AIA Vitality 베스트핏 보장보험(디지털 전용)으로 최대 20% 보험료 할인과 가족의 든든한 보험 보장까지 누려 보세요.   ▶ 자세히 보기: http://t-mms.kr/t.do?m=#61&u=https://bit.ly/36oWjgX  ■ AIA Vitality  혜택 - 매달 리워드 최대 12,000원 - 등급 업그레이드 시 특별 리워드 - T건강습관 제휴 할인 최대 40% ※ 제휴사별 할인 조건과 주간 미션 달성 혜택 등 자세한 내용은 AIA Vitality 사이트에서 확인하세요. ※ 이 광고는 AIA생명의 광고이며 SK텔레콤은 모집 행위를 하지 않습니다.  - 보험료 납입 기간 중 피보험자가 장해분류표 중 동일한 재해 또는 재해 이외의 동일한 원인으로 여러 신체 부위의 장해지급률을 더하여 50% 이상인 장해 상태가 된 경우 차회 이후의 보험료 납입 면제 - 사망보험금은 계약일(부활일/효력회복일)로부터 2년 안에 자살한 경우 보장하지 않음 - 일부 특약 갱신 시 보험료 인상 가능 - 기존 계약 해지 후 신계약 체결 시 보험인수 거절, 보험료 인상, 보장 내용 변경 가능 - 해약 환급금(또는 만기 시 보험금이나 사고보험금)에 기타 지급금을 합해 5천만 원까지(본 보험 회사 모든 상품 합산) 예금자 보호 - 계약 체결 전 상품 설명서 및 약관 참조 - 월 보험료 5,500원(부가세 포함)  * 생명보험협회 심의필 제2020-03026호(2020-09-22) COM-2020-09-32426  ■문의: 청약 관련(1600-0880)  무료 수신거부 1504    ",
        "    \"\"\"",
        "    ]",
        "",
        "message_idx = 0",
        "",
        "longer_text = msg_text_list[message_idx]",
        "",
        "doc = nlp(longer_text)",
        "",
        "print(\"=== Alternative 1: Extract All Nouns and Proper Nouns ===\")",
        "nouns = []",
        "for token in doc:",
        "    if token.pos_ in [\"NOUN\", \"PROPN\"] and not token.is_space and not token.is_punct:",
        "        nouns.append(f\"{token.text} ({token.pos_})\")",
        "",
        "for noun in nouns:",
        "    print(f\"  {noun}\")",
        "",
        "print(\"\\n=== Alternative 2: Group Adjacent Nouns ===\")",
        "def extract_noun_groups(doc):",
        "    noun_groups = []",
        "    current_group = []",
        "    ",
        "    for token in doc:",
        "        if token.pos_ in [\"NOUN\", \"PROPN\"]:",
        "            current_group.append(token.text)",
        "        else:",
        "            if current_group:",
        "                noun_groups.append(\" \".join(current_group))",
        "                current_group = []",
        "    ",
        "    # Don't forget the last group",
        "    if current_group:",
        "        noun_groups.append(\" \".join(current_group))",
        "    ",
        "    return noun_groups",
        "",
        "noun_groups = extract_noun_groups(doc)",
        "for group in noun_groups:",
        "    print(f\"  {group}\")",
        "",
        "print(\"\\n=== Alternative 3: Extract Compound Nouns (연속된 명사) ===\")",
        "def extract_compound_nouns(doc):",
        "    compounds = []",
        "    current_compound = []",
        "    ",
        "    for token in doc:",
        "        # Include nouns, proper nouns, and some particles that connect nouns",
        "        if token.pos_ in [\"NOUN\", \"PROPN\"] or (token.pos_ == \"ADP\" and token.text in [\"의\", \"에서\"]):",
        "            current_compound.append(token.text)",
        "        else:",
        "            if len(current_compound) > 1:  # Only keep compounds with multiple parts",
        "                compounds.append(\"\".join(current_compound))",
        "            current_compound = []",
        "    ",
        "    if len(current_compound) > 1:",
        "        compounds.append(\"\".join(current_compound))",
        "    ",
        "    return compounds",
        "",
        "compounds = extract_compound_nouns(doc)",
        "for compound in compounds:",
        "    print(f\"  {compound}\")",
        "",
        "print(\"\\n=== Alternative 4: Named Entities (Most Reliable) ===\")",
        "for ent in doc.ents:",
        "    print(f\"  {ent.text} ({ent.label_})\")",
        "",
        "print(\"\\n=== Alternative 5: Custom Korean Noun Phrase Pattern ===\")",
        "# This is a simple heuristic for Korean noun phrases",
        "def korean_noun_phrases(doc):",
        "    phrases = []",
        "    i = 0",
        "    while i < len(doc):",
        "        if doc[i].pos_ in [\"NOUN\", \"PROPN\"]:",
        "            phrase = [doc[i].text]",
        "            j = i + 1",
        "            ",
        "            # Look ahead for particles and more nouns",
        "            while j < len(doc):",
        "                if doc[j].pos_ == \"ADP\" and doc[j].text in [\"의\", \"에서\", \"에게\", \"로\", \"으로\"]:",
        "                    phrase.append(doc[j].text)",
        "                    j += 1",
        "                elif doc[j].pos_ in [\"NOUN\", \"PROPN\"]:",
        "                    phrase.append(doc[j].text)",
        "                    j += 1",
        "                else:",
        "                    break",
        "            ",
        "            if len(phrase) > 1:",
        "                phrases.append(\"\".join(phrase))",
        "            i = j",
        "        else:",
        "            i += 1",
        "    ",
        "    return phrases",
        "",
        "korean_phrases = korean_noun_phrases(doc)",
        "for phrase in korean_phrases:",
        "    print(f\"  {phrase}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}