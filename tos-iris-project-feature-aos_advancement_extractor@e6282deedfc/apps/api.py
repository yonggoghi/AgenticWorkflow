#!/usr/bin/env python3
# =============================================================================
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# =============================================================================
import sys
import os
# Add parent directory to path to allow imports from core
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import json
import logging
import time
import argparse
import warnings
import atexit
from pathlib import Path
from pprint import pprint

from config import settings
# for [FastAPI]
from fastapi import FastAPI, Request            # for FastAPI definition and request
from fastapi.responses import JSONResponse, FileResponse      # for JSON Response, File Dowload(DAG)
from starlette.exceptions import HTTPException as APIHTTPException # for error handling
import uvicorn # for FastAPI running
from pydantic import BaseModel # for POST
from fastapi import BackgroundTasks # for async
# for [global application variable(ex: global_extractor)
from store import ExtractorStore
from contextlib import asynccontextmanager
from utils.db_utils import get_message_from_database, insert_extract_result_to_database, get_message_list_from_database
from typing import Dict, Any, List
import inspect

# =============================================================================
# ê²½ê³  ë©”ì‹œì§€ ì–µì œ (ë¡œê·¸ ë…¸ì´ì¦ˆ ê°ì†Œ)
# =============================================================================
# joblibê³¼ multiprocessing ê´€ë ¨ ê²½ê³  ì–µì œ
warnings.filterwarnings("ignore", category=UserWarning, module="joblib")
warnings.filterwarnings("ignore", category=UserWarning, module="multiprocessing") 
warnings.filterwarnings("ignore", message=".*resource_tracker.*")
warnings.filterwarnings("ignore", message=".*leaked.*")

# =============================================================================
# ê²½ë¡œ ì„¤ì • ë° ëª¨ë“ˆ ì„í¬íŠ¸ ì¤€ë¹„
# =============================================================================
# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€ (ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸ë¥¼ ìœ„í•´)
current_dir = Path(__file__).parent.absolute()
sys.path.insert(0, str(current_dir))

# =============================================================================
# í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸ (ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)
# =============================================================================
# MMS ì¶”ì¶œê¸° ë° ì„¤ì • ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from core.mms_extractor import MMSExtractor, process_message_worker, process_messages_batch, save_result_to_mongodb_if_enabled
    from config.settings import API_CONFIG, MODEL_CONFIG, PROCESSING_CONFIG
    # Lazy import for DAG extractor
    from core.entity_dag_extractor import DAGParser, extract_dag, llm_ax, llm_gem, llm_cld, llm_gen, llm_gpt
    from quick_extractor import MessageInfoExtractor  # Quick Extractor ì„í¬íŠ¸
except ImportError as e:
    print(f"âŒ ëª¨ë“ˆ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
    print("ğŸ“ mms_extractor.pyê°€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
    print("ğŸ“ config/ ë””ë ‰í† ë¦¬ì™€ ì„¤ì • íŒŒì¼ë“¤ì„ í™•ì¸í•˜ì„¸ìš”")
    print("ğŸ“ quick_extractor.pyê°€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
    sys.exit(1)

def cleanup_resources():
    """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ í•¨ìˆ˜ - í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ í˜¸ì¶œ"""
    try:
        import gc
        import multiprocessing
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
        gc.collect()
        
        # ë©€í‹°í”„ë¡œì„¸ì‹± ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        if hasattr(multiprocessing, 'active_children'):
            for child in multiprocessing.active_children():
                try:
                    child.terminate()
                    child.join(timeout=1)
                except:
                    pass
                    
        print("ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
    except Exception as e:
        print(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
atexit.register(cleanup_resources)

# ë¡œê¹… ì„¤ì • - ì½˜ì†”ê³¼ íŒŒì¼ ëª¨ë‘ì— ì¶œë ¥
import logging.handlers

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
log_dir = Path(__file__).parent.parent / 'logs'
log_dir.mkdir(exist_ok=True)

# API ì „ìš© ë¡œê·¸ íŒŒì¼ ê²½ë¡œ - ì‹¤ì‹œê°„ API ìš”ì²­/ì‘ë‹µ ë¡œê·¸
log_file = log_dir / 'api_server.log'

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# í¬ë§·í„° ì„¤ì • - ëª¨ë“ˆëª… í¬í•¨í•˜ì—¬ ë¡œê·¸ ì¶œì²˜ ëª…í™•í™”
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# ì½˜ì†” í•¸ë“¤ëŸ¬
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(formatter)

# API ì „ìš© íŒŒì¼ í•¸ë“¤ëŸ¬ (íšŒì „ ë¡œê·¸ - 5MBì”© ìµœëŒ€ 10ê°œ íŒŒì¼, ì§§ì€ ë³´ì¡´ê¸°ê°„)
file_handler = logging.handlers.RotatingFileHandler(
    log_file, 
    maxBytes=5*1024*1024,   # 5MB (API ë¡œê·¸ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì‘ìŒ)
    backupCount=10,         # ë” ë§ì€ íŒŒì¼ ë³´ì¡´ (ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ìš©)
    encoding='utf-8'
)
file_handler.setLevel(logging.INFO)
file_handler.setFormatter(formatter)

# ë£¨íŠ¸ ë¡œê±°ì—ë§Œ í•¸ë“¤ëŸ¬ ì¶”ê°€í•˜ì—¬ ëª¨ë“  í•˜ìœ„ ë¡œê±°ì˜ ë¡œê·¸ë¥¼ ì²˜ë¦¬
root_logger = logging.getLogger()
root_logger.setLevel(logging.INFO)
root_logger.addHandler(console_handler)
root_logger.addHandler(file_handler)

# ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
root_logger.handlers = [console_handler, file_handler]

# ê°œë³„ ë¡œê±°ë“¤ì€ ë£¨íŠ¸ ë¡œê±°ë¡œ ì „íŒŒí•˜ë„ë¡ ì„¤ì • (í•¸ë“¤ëŸ¬ ì¤‘ë³µ ë“±ë¡ ë°©ì§€)
logger.setLevel(logging.INFO)
mms_logger = logging.getLogger('mms_extractor')
mms_logger.setLevel(logging.INFO)

# ì „íŒŒ ì„¤ì • í™•ì¸ (ê¸°ë³¸ê°’ì´ Trueì´ë¯€ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •)
logger.propagate = True
mms_logger.propagate = True

# ì „ì—­ ì¶”ì¶œê¸° ì¸ìŠ¤í„´ìŠ¤ - ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¡œë“œ
global_extractor = None

# ì „ì—­ Quick Extractor ì¸ìŠ¤í„´ìŠ¤ (ì œëª©/ìˆ˜ì‹ ê±°ë¶€ ë²ˆí˜¸ ì¶”ì¶œìš©)
global_quick_extractor = None

# CLIì—ì„œ ì„¤ì •ëœ ë°ì´í„° ì†ŒìŠ¤ (ì „ì—­ ë³€ìˆ˜)
CLI_DATA_SOURCE = 'local'

def initialize_global_extractor(offer_info_data_src='db', num_cand_pgms=None, num_select_pgms=None):
    """
    ì „ì—­ ì¶”ì¶œê¸° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì´ˆê¸°í™”

    ì´ í•¨ìˆ˜ëŠ” ë¬´ê±°ìš´ ë°ì´í„° ë¡œë”© ì‘ì—…(ìƒí’ˆ ì •ë³´, ì„ë² ë”© ëª¨ë¸ ë“±)ì„
    ì„œë²„ ì‹œì‘ ì‹œ ë¯¸ë¦¬ ìˆ˜í–‰í•˜ì—¬ API ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤.

    Args:
        offer_info_data_src: ìƒí’ˆ ì •ë³´ ë°ì´í„° ì†ŒìŠ¤ ('local' ë˜ëŠ” 'db')
        num_cand_pgms: í”„ë¡œê·¸ë¨ í›„ë³´ ê°œìˆ˜ (Noneì´ë©´ config ê¸°ë³¸ê°’ ì‚¬ìš©)
        num_select_pgms: LLMì´ ìµœì¢… ì„ ì •í•  í”„ë¡œê·¸ë¨ ìˆ˜ (Noneì´ë©´ config ê¸°ë³¸ê°’ ì‚¬ìš©)

    Returns:
        MMSExtractor: ì´ˆê¸°í™”ëœ ì¶”ì¶œê¸° ì¸ìŠ¤í„´ìŠ¤
    """
    global global_extractor
    if global_extractor is None:
        # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¶”ì¶œê¸° ì´ˆê¸°í™” (CLIì™€ ë™ì¼í•œ ê¸°ë³¸ê°’ ì‚¬ìš©)
        global_extractor = MMSExtractor(
            model_path='./models/ko-sbert-nli',      # ì„ë² ë”© ëª¨ë¸ ê²½ë¡œ
            data_dir='./data',                       # ë°ì´í„° ë””ë ‰í† ë¦¬
            offer_info_data_src=offer_info_data_src, # ìƒí’ˆ ì •ë³´ ì†ŒìŠ¤
            llm_model='ax',                          # ê¸°ë³¸ LLM: AX (CLIì™€ ë™ì¼)
            product_info_extraction_mode='llm',      # ê¸°ë³¸ ìƒí’ˆ ì¶”ì¶œ ëª¨ë“œ: LLM (CLIì™€ ë™ì¼)
            entity_extraction_mode='llm',            # ê¸°ë³¸ ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ: LLM (CLIì™€ ë™ì¼)
            extract_entity_dag=True,
            entity_extraction_context_mode='dag',    # ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ ëª¨ë“œ: DAG
            num_cand_pgms=num_cand_pgms,
            num_select_pgms=num_select_pgms,
        )
        logger.info("ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    return global_extractor

def initialize_quick_extractor(use_llm=False, llm_model='ax'):
    """
    ì „ì—­ Quick Extractor ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ˆê¸°í™”
    
    Args:
        use_llm: LLM ì‚¬ìš© ì—¬ë¶€
        llm_model: ì‚¬ìš©í•  LLM ëª¨ë¸ ('ax', 'gpt', 'claude', 'gemini' ë“±)
    
    Returns:
        MessageInfoExtractor: ì´ˆê¸°í™”ëœ Quick Extractor ì¸ìŠ¤í„´ìŠ¤
    """
    global global_quick_extractor
    
    if global_quick_extractor is None:
        logger.info(f"Quick Extractor ì´ˆê¸°í™” ì¤‘... (LLM: {use_llm}, ëª¨ë¸: {llm_model})")
        
        # Quick Extractor ì´ˆê¸°í™” (csv_pathëŠ” APIì—ì„œ í•„ìš” ì—†ìŒ)
        global_quick_extractor = MessageInfoExtractor(
            csv_path=None,
            use_llm=use_llm,
            llm_model=llm_model
        )
        
        logger.info("Quick Extractor ì´ˆê¸°í™” ì™„ë£Œ")
    
    return global_quick_extractor

def get_configured_quick_extractor(use_llm=False, llm_model='ax'):
    """
    ëŸ°íƒ€ì„ ì„¤ì •ìœ¼ë¡œ Quick Extractor êµ¬ì„±
    
    Args:
        use_llm: LLM ì‚¬ìš© ì—¬ë¶€
        llm_model: ì‚¬ìš©í•  LLM ëª¨ë¸
    
    Returns:
        MessageInfoExtractor: êµ¬ì„±ëœ Quick Extractor ì¸ìŠ¤í„´ìŠ¤
    """
    if global_quick_extractor is None:
        return initialize_quick_extractor(use_llm, llm_model)
    
    # LLM ì„¤ì •ì´ ë³€ê²½ëœ ê²½ìš° ì¬ì´ˆê¸°í™”
    if use_llm != global_quick_extractor.use_llm or llm_model != global_quick_extractor.llm_model_name:
        logger.info(f"Quick Extractor ì¬ì„¤ì • ì¤‘... (LLM: {use_llm}, ëª¨ë¸: {llm_model})")
        return initialize_quick_extractor(use_llm, llm_model)
    
    return global_quick_extractor

def get_configured_extractor(llm_model='ax', product_info_extraction_mode='llm', entity_matching_mode='llm', entity_llm_model='ax', extract_entity_dag=True, entity_extraction_context_mode='dag'):
    #global global_extractor
    #global_extractor = app.state.store.global_extractor

    if global_extractor is None:
        raise RuntimeError("ì „ì—­ ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. initialize_global_extractor()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
    
    # í˜„ì¬ ì„¤ì •ê³¼ ë¹„êµí•˜ì—¬ ë³€ê²½ëœ ê²½ìš°ë§Œ ì—…ë°ì´íŠ¸
    current_llm_model = getattr(global_extractor, 'llm_model_name', None)
    llm_model_changed = current_llm_model != llm_model
    
    # ë°ì´í„° ì¬ë¡œë”© ì—†ì´ ëŸ°íƒ€ì„ ì„¤ì •ë§Œ ì—…ë°ì´íŠ¸
    global_extractor.llm_model_name = llm_model
    global_extractor.entity_llm_model_name = entity_llm_model
    global_extractor.product_info_extraction_mode = product_info_extraction_mode
    global_extractor.entity_extraction_mode = entity_matching_mode
    global_extractor.extract_entity_dag = extract_entity_dag
    global_extractor.entity_extraction_context_mode = entity_extraction_context_mode
    
    # ResultBuilderì˜ llm_modelë„ ì—…ë°ì´íŠ¸
    if hasattr(global_extractor, 'result_builder'):
        global_extractor.result_builder.llm_model = entity_llm_model
    
    # LLM ëª¨ë¸ì´ ì‹¤ì œë¡œ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ ì¬ì´ˆê¸°í™”
    if llm_model_changed:
        logger.info(f"LLM ëª¨ë¸ì´ {current_llm_model} -> {llm_model}ë¡œ ë³€ê²½ë¨. ì¬ì´ˆê¸°í™” ì¤‘...")
        global_extractor._initialize_llm()
    
    return global_extractor

# ì „ì—­ ì¶”ì¶œê¸° ë³€ìˆ˜ ì •ë³´ë¥¼ application ì „ì—­ì—ì„œ ê´€ë¦¬
@asynccontextmanager
async def lifespan(app: FastAPI):
    app.state.store = ExtractorStore()
    # ì§€ì •ëœ ë°ì´í„° ì†ŒìŠ¤ë¡œ ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™”
    logger.info("ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì¤‘...")
    app.state.store.init('db')
    yield
    # shutdown ì‹œ ì²˜ë¦¬ ê¸°ëŠ¥ #

app = FastAPI(lifespan=lifespan)

#Added by P099870, 2026.01.14
class MessageRequest(BaseModel):
    message_id: str

class SaveAnswerSheet(BaseModel):
    message_id: str
    data: Dict[str, Any]

class BatchRequest(BaseModel):
    message_ids: List[str]

@app.post('/ai/mms/v1/extract/batch')
async def extract_batch(request: BatchRequest, background_tasks: BackgroundTasks):
    logger.info(f">>>>>>>>>>REQUEST_API::{inspect.currentframe().f_code.co_name}<<<<<<<<<<")
    global global_extractor
    global_extractor = app.state.store.global_extractor
    # ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
    if global_extractor is None:
        logger.error(f"ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤..")
        return {
             "success": False,
             "error": "ì„œë²„ ë‚´ë¶€ ì—ëŸ¬ ë°œìƒ(EM01)",
             "timestamp": time.time()
        }, 500
    
    try:
        message_ids = request.message_ids
        if not message_ids or len(message_ids) == 0:
            return {"status": "400", "success": False, "error": "ë©”ì‹œì§€ID Listê°€ ì—†ìŠµë‹ˆë‹¤","timestamp": time.time()}, 400
        if len(message_ids) > 100:
            return {"status":"400", "success": False, "error": f"ë°°ì¹˜ë‹¹ ìµœëŒ€ 100ê°œ ë©”ì‹œì§€ê¹Œì§€ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤({len(message_ids)})","timestamp": time.time()}, 400
        if not isinstance(message_ids, list):
            return {"status":"400", "success": False, "error": "'message_ids' í•„ë“œëŠ” ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤","timestamp": time.time()}, 400

        # ë©”ì‹œì§€ IDs ë¡œê¹…
        logger.info(f"ğŸ“‹ ë©”ì‹œì§€ ID Count: {len(message_ids)}")
        logger.info(f"ğŸ“‹ ë©”ì‹œì§€ ID List: {message_ids}")
        pprint(message_ids);
        message_list = get_message_list_from_database(message_ids)
        if not message_list :
            logger.warning(f"DBì—ì„œ message list ë°ì´í„° ì—†ìŒ")
            return {"status":"400", "success": False, "error": "'message_ids'ì— í•´ë‹¹í•˜ëŠ” message listê°€ DBì— í•œê±´ë„ ì—†ìŠµë‹ˆë‹¤","timestamp": time.time()}, 400
        else:
            logger.info(f"DBì—ì„œ ì¡°íšŒëœ message_list ê±´ìˆ˜[{len(message_list)}/{len(message_ids)}]")
        data = {}
        # ì„ íƒì  íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        data["offer_info_data_src"] = "db"
        data["llm_model"] = "ax"
        data["entity_llm_model"] =  'ax'
        data["product_info_extraction_mode"] = settings.ProcessingConfig.product_info_extraction_mode
        data["entity_matching_mode"] = settings.ProcessingConfig.entity_extraction_mode
        data["extract_entity_dag"] = True
        data["entity_extraction_context_mode"] = 'dag'
        data["max_workers"] = None
        data["save_to_mongodb"] = True
        data["result_type"] = 'ext'
        data['processing_mode'] = 'batch'
        data['message_list'] = message_list

        background_tasks.add_task(extract_batch_background, data)

        # ìš”ì²­ íŒŒë¦¬ë¯¸í„° ìœ íš¨ì„± ê²€ì¦ ê²°ê³¼ ë¦¬í„´
        return {
             "status": "200",
             "error" : None,
             "success": True,
             "timestamp": time.time()
        }, 200

    except Exception as e:
        logger.error(f"ìš”ì²­ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {
            "status": "500",
             "success": False,
             #"error": str(e),
             "error": "ì˜ˆìƒì¹˜ ëª»í•œ ì„œë²„ ì—ëŸ¬ ë°œìƒ",
             "timestamp": time.time()
        }, 500

# ë¶„ì„ ìš”ì²­ ë°°ì¹˜ ë¹„ë™ê¸° ì²˜ë¦¬
def extract_batch_background(data):        
    try:
        message_list = data['message_list']
        offer_info_data_src = data.get('offer_info_data_src')
        llm_model = data.get('llm_model')
        entity_llm_model = data.get('entity_llm_model')
        product_info_extraction_mode = data.get('product_info_extraction_mode')
        entity_matching_mode = data.get('entity_matching_mode')
        extract_entity_dag = data.get('extract_entity_dag')
        entity_extraction_context_mode = data.get('entity_extraction_context_mode')
        max_workers = data.get('max_workers')
        save_to_mongodb = data.get('save_to_mongodb')
        result_type = data.get('result_type')

        # êµ¬ì„±ëœ ì¶”ì¶œê¸° ê°€ì ¸ì˜¤ê¸°
        extractor = get_configured_extractor(llm_model, product_info_extraction_mode, entity_matching_mode, entity_llm_model, extract_entity_dag, entity_extraction_context_mode)
        
        # ë©€í‹°í”„ë¡œì„¸ìŠ¤ ë°°ì¹˜ ì²˜ë¦¬
        start_time = time.time()
        
        # í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ë¥¼ ìœ„í•œ ìŠ¤ë ˆë“œ ë¡œì»¬ ì €ì¥ì†Œ ì´ˆê¸°í™”
        import threading
        current_thread = threading.current_thread()
        current_thread.stored_prompts = {}
        
        # ë¹ˆ ë©”ì‹œì§€ í•„í„°ë§ ë° message_id ì¶”ì¶œ
        valid_messages = []
        message_ids = []
        message_indices = []
        for i, msg_item in enumerate(message_list):
            # ë©”ì‹œì§€ê°€ ë¬¸ìì—´ì´ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ì¼ ìˆ˜ ìˆìŒ
            if isinstance(msg_item, dict):
                message = msg_item.get('message', '')
                message_id = msg_item.get('message_id', '#')
            else:
                message = msg_item
                message_id = '#'
            
            if message and message.strip():
                valid_messages.append(message)
                message_ids.append(message_id)
                message_indices.append(i)
        
        logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(valid_messages)}/{len(message_list)}ê°œ ìœ íš¨í•œ ë©”ì‹œì§€")
        
        # MongoDB ì €ì¥ ì¹´ìš´í„° ì´ˆê¸°í™”
        saved_count = 0
        
        try:
            # ê° ë©”ì‹œì§€ë¥¼ message_idì™€ í•¨ê»˜ ì²˜ë¦¬
            batch_results = []
            for message, message_id in zip(valid_messages, message_ids):
                if extract_entity_dag:
                    result = process_message_worker(
                        extractor, 
                        message, 
                        extract_dag=True,
                        message_id=message_id
                    )
                else:
                    result = extractor.process_message(message, message_id=message_id)
                    result['ext_result']['entity_dag'] = []
                    result['raw_result']['entity_dag'] = []
                
                batch_results.append(result)
            
            # ê²°ê³¼ë¥¼ ì›ë˜ ì¸ë±ìŠ¤ì™€ ë§¤í•‘ ë° MongoDB ì €ì¥
            results = []
            valid_result_idx = 0
            
            for i, msg_item in enumerate(message_list):
                # ë©”ì‹œì§€ê°€ ë¬¸ìì—´ì´ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ì¼ ìˆ˜ ìˆìŒ
                if isinstance(msg_item, dict):
                    message_text = msg_item.get('message', '')
                else:
                    message_text = msg_item
                
                if not message_text or not message_text.strip():
                    results.append({
                        "index": i,
                        "success": False,
                        "error": "ë¹ˆ ë©”ì‹œì§€ì…ë‹ˆë‹¤"
                    })
                else:
                    if valid_result_idx < len(batch_results):
                        batch_result = batch_results[valid_result_idx]

                        # result_typeì— ë”°ë¼ ê²°ê³¼ ì„ íƒ
                        if result_type == 'raw':
                            result_data = batch_result.get('raw_result', {})
                        else:
                            result_data = batch_result.get('ext_result', {})

                        # print("=" * 50 + " batch_result " + "=" * 50)
                        # print(batch_result)
                        # print("=" * 50 + " batch_result " + "=" * 50)
                        
                        if result_data.get('error'):
                            results.append({
                                "index": i,
                                "success": False,
                                "error": result_data['error']
                            })
                        else:
                            # MongoDB ì €ì¥ (ë°°ì¹˜ ì²˜ë¦¬ì—ì„œëŠ” ê° ë©”ì‹œì§€ë³„ë¡œ ì €ì¥)
                            if save_to_mongodb:
                                try:
                                    saved_id = save_result_to_mongodb_if_enabled(message_text, batch_result, data, extractor)
                                    logger.info(f"SavedId = {saved_id}")
                                    if saved_id:
                                        saved_count += 1
                                        logger.debug(f"ë©”ì‹œì§€ {i} MongoDB ì €ì¥ ì™„ë£Œ (ID: {saved_id[:8]}...)")
                                        insert_extract_result_to_database(result, message_id, saved_id)
                                        logger.info("DB ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ!(API-BATCH)")
                                except Exception as e:
                                    logger.warning(f"ë©”ì‹œì§€ {i} MongoDB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
                                
                            results.append({
                                "index": i,
                                "success": True,
                                "result": result_data
                            })
                        valid_result_idx += 1
                    else:
                        results.append({
                            "index": i,
                            "success": False,
                            "error": "ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ë¶€ì¡±"
                        })
            
            if save_to_mongodb and saved_count > 0:
                logger.info(f"MongoDB ì €ì¥ ì™„ë£Œ: {saved_count}/{len(valid_messages)}ê°œ ë©”ì‹œì§€")
        
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ëª¨ë“  ë©”ì‹œì§€ë¥¼ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
            results = []
            for i, message in enumerate(message_list):
                results.append({
                    "index": i,
                    "success": False,
                    "error": f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                })
        
        processing_time = time.time() - start_time
        
        # ìº¡ì²˜ëœ í”„ë¡¬í”„íŠ¸ë“¤ ê°€ì ¸ì˜¤ê¸°
        captured_prompts = getattr(current_thread, 'stored_prompts', {})
        logger.info(f"ë°°ì¹˜ ì¶”ì¶œ ê³¼ì •ì—ì„œ ìº¡ì²˜ëœ í”„ë¡¬í”„íŠ¸: {len(captured_prompts)}ê°œ")
        
        # ì„±ê³µ/ì‹¤íŒ¨ ê°œìˆ˜ ì§‘ê³„
        successful = sum(1 for r in results if r["success"])
        failed = len(results) - successful
        
        response = {
            "success": True,
            "results": results,
            "summary": {
                "total_messages": len(message_list),
                "successful": successful,
                "failed": failed,
                "saved_to_mongodb": saved_count if save_to_mongodb else 0
            },
            "metadata": {
                "llm_model": llm_model,
                "offer_info_data_src": offer_info_data_src,
                "product_info_extraction_mode": product_info_extraction_mode,
                "entity_matching_mode": entity_matching_mode,
                "extract_entity_dag": extract_entity_dag,
                "max_workers": max_workers,
                "processing_time_seconds": round(processing_time, 3),
                "timestamp": time.time()
            },
            "prompts": {
                "success": True,
                "prompts": captured_prompts,
                "settings": {
                    "llm_model": llm_model,
                    "offer_info_data_src": offer_info_data_src,
                    "product_info_extraction_mode": product_info_extraction_mode,
                    "entity_matching_mode": entity_matching_mode,
                    "extract_entity_dag": extract_entity_dag
                },
                "batch_info": {
                    "total_messages": len(message_list),
                    "successful": successful,
                    "failed": failed
                },
                "timestamp": time.time()
            }
        }
        
        logger.info(f"ë°°ì¹˜ ì¶”ì¶œ ì™„ë£Œ: {successful}/{len(message_list)}ê°œ ì„±ê³µ, {processing_time:.3f}ì´ˆ ì†Œìš”")
        logger.info(f"ì¶”ì¶œ ì™„ë£Œ: {processing_time:.3f}ì´ˆ")
    except Exception as e:
        logger.error(f"ë°°ì¹˜ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

@app.put('/ai/mms/v1/answer_sheet/{message_id}')
def save_answer_sheet(request: SaveAnswerSheet):
    message_id = None
    try:
        logger.info(f">>>>>>>>>>REQUEST_API::{inspect.currentframe().f_code.co_name}<<<<<<<<<<")
        message_id = request.message_id
        if not message_id or not message_id.strip():
            return {"success": False, "error": "ë©”ì‹œì§€ëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤","timestamp": time.time()}, 400

        # ë©”ì‹œì§€ ID ë¡œê¹…
        if message_id != '#':
            logger.info(f"ğŸ“‹ ë©”ì‹œì§€ ID: {message_id}")

        data = request.data;
        if not data:
            return {"success": False, "error": "ì •ë‹µì§€ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤","timestamp": time.time()}, 400
        
        pprint(data)
        from utils.mongodb_utils import MongoDBManager
        mongoMgr = MongoDBManager()
        saved_id = mongoMgr.save_answer_sheet(message_id, data)
        logger.info(f"saved_id: {saved_id}")

        if saved_id:
            return {
                "success": True,
                "status": 200,
                "data": {"message_id": message_id},
                "timestamp": time.time()
            }, 200
        else:
            return {
                "success": False,
                "status": 400,
                "data": {"message_id": message_id},
                "error": "ì²˜ë¦¬ì‹œ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬ ë°œìƒ",
                "timestamp": time.time()
            }, 200

    except Exception as e:
        logger.error(f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {
             "success": False,
             "status": 500,
             #"error": str(e),
             "data": {"message_id": message_id},
             "error": "ì˜ˆìƒì¹˜ ëª»í•œ ì„œë²„ ì—ëŸ¬ ë°œìƒ",
             "timestamp": time.time()
        }, 500

@app.post('/ai/mms/v1/extract_result')
def get_extract_result(request: MessageRequest):
    try:
        logger.info(f">>>>>>>>>>REQUEST_API::{inspect.currentframe().f_code.co_name}<<<<<<<<<<")
        logger.info("[get_extract_result::Requested Options]");
        message_id = request.message_id
        #logger.info(json.dumps(data, indent=2, ensure_ascii=False))
        #pprint(req)

        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        #if 'message_id' not in req:
        #    return {"success": False, "error": "í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: 'message_id'","timestamp": time.time()}, 400

        #message_id = req.get('message_id', '#')
        if not message_id or not message_id.strip():
            return {"success": False, "error": "ë©”ì‹œì§€ëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤","timestamp": time.time()}, 400

        # ë©”ì‹œì§€ ID ë¡œê¹…
        if message_id != '#':
            logger.info(f"ğŸ“‹ ë©”ì‹œì§€ ID: {message_id}")

        from utils.mongodb_utils import MongoDBManager
        mongoMgr = MongoDBManager()
        result = mongoMgr.get_extract_result(message_id)
        pprint(result)

        if not result:
            return {
                "error": "No Data",
                "status": "400",
                "success": False,
                "data": {},
                "timestamp": time.time()
            }, 400
        else:
            return {
                "status": "200",
                "success": True,
                "data": result.get('data'),
                "timestamp": time.time()
            }, 200

    except Exception as e:
        logger.error(f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {
             "success": False,
             "status": "500",
             "data": {},
             #"error": str(e),
             "error": "ì˜ˆìƒì¹˜ ëª»í•œ ì„œë²„ ì—ëŸ¬ ë°œìƒ",
             "timestamp": time.time()
        }, 500

@app.post('/ai/mms/v1/answer_sheet')
def get_answer_sheet(request: MessageRequest):
    try:
        logger.info(f">>>>>>>>>>REQUEST_API::{inspect.currentframe().f_code.co_name}<<<<<<<<<<")
        message_id = request.message_id
        errorMsg = None
        if not message_id or not message_id.strip():
            errorMsg = "ë©”ì‹œì§€IDëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            logger.warn(errorMsg)
            return {"success": False, "error": {errorMsg},"timestamp": time.time()}, 400

        # ë©”ì‹œì§€ ID ë¡œê¹…
        if message_id != '#':
            logger.info(f"ğŸ“‹ ë©”ì‹œì§€ ID: {message_id}")

        from utils.mongodb_utils import MongoDBManager
        mongoMgr = MongoDBManager()
        result = mongoMgr.get_answer_sheet(message_id)
        pprint(result)

        if not result:
            errorMsg = f"message_id: [{message_id}]ì˜ ì •ë‹µì§€ê°€ ì—†ìŠµë‹ˆë‹¤"
            logger.warn(errorMsg)
            return {
                "success": False,
                "status": "400",
                "error": errorMsg,
                "data": {},
                "timestamp": time.time()
            }, 400
        else:
            logger.info(f"message_id: [{message_id}] ì •ë‹µì§€ ì¡°íšŒê²°ê³¼ ì •ìƒë¦¬í„´")
            return {
                "success": True,
                "status": "200",
                "data": result.get('data'),
                "timestamp": time.time()
            }, 200

    except Exception as e:
        errorMsg = f"[ì •ë‹µì§€ ì¡°íšŒ]ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
        logger.error(errorMsg)
        return {
             "success": False,
             "status": "500",
             "data": {},
             #"error": str(e),
             "error": "ì˜ˆìƒì¹˜ ëª»í•œ ì„œë²„ ì—ëŸ¬ ë°œìƒ",
             "timestamp": time.time()
        }, 500

# ì´ì „(ì´ˆê¸°) ë²„ì „ ë¶„ì„ì¶”ì¶œ API for CLI : message, message_id, optionsì„ ìš”ì²­ë°›ì•„ ì²˜ë¦¬
@app.post('/extract_cli')
async def extract_message_cli(request: Request, background_tasks: BackgroundTasks):
    logger.info(f">>>>>>>>>>REQUEST_API::{inspect.currentframe().f_code.co_name}<<<<<<<<<<")
    global global_extractor
    global_extractor = app.state.store.global_extractor
    # ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
    if global_extractor is None:
        logger.error(f"ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤..")
        return {
             "success": False,
             "status": "500",
             "error": "ì„œë²„ ë‚´ë¶€ ì—ëŸ¬ ë°œìƒ(EM01)",
             "timestamp": time.time()
        }, 500
    # print(global_extractor.__dict__)
    try:
        if request.headers.get("content-type") != "application/json":
            return {"success": False, "error": "Content-Typeì€ application/jsonì´ì–´ì•¼ í•©ë‹ˆë‹¤","timestamp": time.time()}, 400
        data = await request.json()
        logger.info("[Requested Extract Options]");
        logger.info(json.dumps(data, indent=2, ensure_ascii=False))

        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if 'message' not in data:
            return {"success": False, "error": "í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: 'message'","timestamp": time.time()}, 400
        
        message = data['message']
        if not message or not message.strip():
            return {"success": False, "error": "ë©”ì‹œì§€ëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤","timestamp": time.time()}, 400
        
        # ì„ íƒì  íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ê¸°ë³¸ê°’ ì‚¬ìš©)
        data_source = data.get('data_source', CLI_DATA_SOURCE)
        offer_info_data_src = data.get('offer_info_data_src', CLI_DATA_SOURCE)
        llm_model = data.get('llm_model', settings.ModelConfig.llm_model)
        entity_llm_model = data.get('entity_llm_model', 'ax')
        product_info_extraction_mode = data.get('product_info_extraction_mode', settings.ProcessingConfig.product_info_extraction_mode)
        entity_matching_mode = data.get('entity_matching_mode', settings.ProcessingConfig.entity_extraction_mode)
        extract_entity_dag = data.get('extract_entity_dag', True)
        entity_extraction_context_mode = data.get('entity_extraction_context_mode', 'dag')
        save_to_mongodb = data.get('save_to_mongodb', True)
        result_type = data.get('result_type', 'ext')
        message_id = data.get('message_id', '#')  # ë©”ì‹œì§€ ID (ê¸°ë³¸ê°’: '#')

        data['save_to_mongodb'] = save_to_mongodb
        data['result_type'] = result_type
        data['processing_mode'] = 'single'
        # DAG ì¶”ì¶œ ìš”ì²­ ë¡œê¹…
        if extract_entity_dag:
            logger.info(f"ğŸ¯ DAG ì¶”ì¶œ ìš”ì²­ë¨ - LLM: {llm_model}, ë©”ì‹œì§€ ê¸¸ì´: {len(message)}ì")
        
        # ë©”ì‹œì§€ ID ë¡œê¹…
        if message_id != '#':
            logger.info(f"ğŸ“‹ ë©”ì‹œì§€ ID: {message_id}")
        
        # ìš”ì²­ íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì¦
        valid_sources = ['local', 'db']
        if offer_info_data_src not in valid_sources:
            return {"success": False, "error": f"ì˜ëª»ëœ offer_info_data_srcì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_sources}", "timestamp": time.time()}, 400
            
        valid_llm_models = ['gemma', 'ax', 'claude', 'gemini']
        if llm_model not in valid_llm_models:
            return {"success": False, "error": f"ì˜ëª»ëœ llm_modelì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_llm_models}", "timestamp": time.time()}, 400
            
        valid_product_modes = ['nlp', 'llm', 'rag']
        if product_info_extraction_mode not in valid_product_modes:
            return {"success": False, "error": f"ì˜ëª»ëœ product_info_extraction_modeì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_product_modes}", "timestamp": time.time()}, 400
            
        valid_entity_modes = ['logic', 'llm']
        if entity_matching_mode not in valid_entity_modes:
            return {"success": False, "error": f"ì˜ëª»ëœ entity_matching_modeì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_entity_modes}", "timestamp": time.time()}, 400
        
        # from pprint import pprint
        # logger.info("[Arranged Extract Options]");
        # pprint(data)

        background_tasks.add_task(extract_background, data)
        # ìš”ì²­ íŒŒë¦¬ë¯¸í„° ìœ íš¨ì„± ê²€ì¦ ê²°ê³¼ ë¦¬í„´
        return {
             "error" : None,
             "success": True,
             "status": "200",
             "timestamp": time.time()
        }, 200

    except Exception as e:
        logger.error(f"ìš”ì²­ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {
             "success": False,
             "status": "500",
             #"error": str(e),
             "error": "ì˜ˆìƒì¹˜ ëª»í•œ ì„œë²„ ì—ëŸ¬ ë°œìƒ",
             "timestamp": time.time()
        }, 500

# Web ë¶„ì„ ì¶”ì¶œ ìš”ì²­ API - message_idë§Œ ë°›ì•„ ì²˜ë¦¬
# (1) message_idë¡œ TMSG_MMS_SCRPT í…Œì´ë¸”ì—ì„œ message ì¡°íšŒ
#     SELECT MMS_PHRS FROM TMSG_MMS_SCRPT WHERE MSG_ID = 'M23ALO262368'
# (2) message ë¶„ì„ ì¶”ì¶œ ì²˜ë¦¬
# (3) ì²˜ë¦¬ê²°ê³¼ dbì— ì €ì¥ - TCAM_MSG_ANALS_RSLT
# (4) ì²˜ë¦¬ê²°ê³¼ mongodbì— ì €ì¥ - aos.mmsext
@app.post('/ai/mms/v1/extract')
async def extract_message(request: Request, background_tasks: BackgroundTasks):
    logger.info(f">>>>>>>>>>REQUEST_API::{inspect.currentframe().f_code.co_name}<<<<<<<<<<")
    global global_extractor
    global_extractor = app.state.store.global_extractor
    # ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
    if global_extractor is None:
        logger.error(f"ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤..")
        return {
             "success": False,
             "status": "500",
             "error": "ì„œë²„ ë‚´ë¶€ ì—ëŸ¬ ë°œìƒ(EM01)",
             "timestamp": time.time()
        }, 500
    # print(global_extractor.__dict__)
    try:
        if request.headers.get("content-type") != "application/json":
            return {"status": 400, "success": False, "error": "Content-Typeì€ application/jsonì´ì–´ì•¼ í•©ë‹ˆë‹¤","timestamp": time.time()}, 400
        data = await request.json()
        logger.info("[Requested Extract Options]");
        logger.info(json.dumps(data, indent=2, ensure_ascii=False))

        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if 'message_id' not in data:
            return {"status": 400, "success": False, "error": "í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: 'message_id'","timestamp": time.time()}, 400
        
        message_id = data.get('message_id', '#')  # ë©”ì‹œì§€ ID (ê¸°ë³¸ê°’: '#')
        if not message_id or not message_id.strip():
            return {"status": 400, "success": False, "error": "ë©”ì‹œì§€ëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤","timestamp": time.time()}, 400

        # ë©”ì‹œì§€ ID ë¡œê¹…
        if message_id != '#':
            logger.info(f"ğŸ“‹ ë©”ì‹œì§€ ID: {message_id}")

        # (1) message_idë¡œ TMSG_MMS_SCRPT í…Œì´ë¸”ì—ì„œ message ì¡°íšŒ
        #     SELECT MMS_PHRS FROM TMSG_MMS_SCRPT WHERE MSG_ID = 'M23ALO262368'
        message = get_message_from_database(message_id)
        if message is not None:
            data["message"] = message
        else:
            return {"status": 400, "success": False, "error": f"ë©”ì‹œì§€ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. message_id={message_id}","timestamp": time.time()}, 400

        logger.info(f"ğŸ“‹ ë©”ì‹œì§€: {message} by message_id={message_id}")

        # ë¶„ì„ íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ê¸°ë³¸ê°’ ì‚¬ìš©)
        data_source = data.get('data_source', CLI_DATA_SOURCE)
        offer_info_data_src = data.get('offer_info_data_src', CLI_DATA_SOURCE)
        #llm_model = data.get('llm_model', settings.ModelConfig.llm_model)
        llm_model = data.get('llm_model', "ax")
        entity_llm_model = data.get('entity_llm_model', 'ax')
        product_info_extraction_mode = data.get('product_info_extraction_mode', settings.ProcessingConfig.product_info_extraction_mode)
        entity_matching_mode = data.get('entity_matching_mode', settings.ProcessingConfig.entity_extraction_mode)
        extract_entity_dag = data.get('extract_entity_dag', True)
        entity_extraction_context_mode = data.get('entity_extraction_context_mode', 'dag')
        save_to_mongodb = data.get('save_to_mongodb', True)
        result_type = data.get('result_type', 'ext')

        data['save_to_mongodb'] = save_to_mongodb
        data['result_type'] = result_type
        data['processing_mode'] = 'single'
        # DAG ì¶”ì¶œ ìš”ì²­ ë¡œê¹…
        if extract_entity_dag:
            logger.info(f"ğŸ¯ DAG ì¶”ì¶œ ìš”ì²­ë¨ - LLM: {llm_model}, ë©”ì‹œì§€ID ê¸¸ì´: {len(message_id)}ì")
        
        # ìš”ì²­ íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì¦
        valid_sources = ['local', 'db']
        if offer_info_data_src not in valid_sources:
            raise Exception(f"ì˜ëª»ëœ offer_info_data_srcì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_sources}")
            
        valid_llm_models = ['gemma', 'ax', 'claude', 'gemini']
        if llm_model not in valid_llm_models:
            raise Exception(f"ì˜ëª»ëœ llm_modelì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_llm_models}")
            
        valid_product_modes = ['nlp', 'llm', 'rag']
        if product_info_extraction_mode not in valid_product_modes:
            raise Exception(f"ì˜ëª»ëœ product_info_extraction_modeì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_product_modes}")

        valid_entity_modes = ['logic', 'llm']
        if entity_matching_mode not in valid_entity_modes:
            raise Exception(f"ì˜ëª»ëœ entity_matching_modeì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_entity_modes}")
        
        # from pprint import pprint
        # logger.info("[Arranged Extract Options]");
        # pprint(data)

        background_tasks.add_task(extract_background, data)
        # ìš”ì²­ íŒŒë¦¬ë¯¸í„° ìœ íš¨ì„± ê²€ì¦ ê²°ê³¼ ë¦¬í„´
        return {
             "error" : None,
             "status": "200",
             "success": True,
             "timestamp": time.time()
        }, 200

    except Exception as e:
        logger.error(f"ìš”ì²­ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {
             "success": False,
             "status": "500",
             #"error": str(e),
             "error": "ì˜ˆìƒì¹˜ ëª»í•œ ì„œë²„ ì—ëŸ¬ ë°œìƒ",
             "timestamp": time.time()
        }, 500

def extract_background(data):        
    try:
        message = data['message']
        data_source = data.get('data_source')
        offer_info_data_src = data.get('offer_info_data_src')
        llm_model = data.get('llm_model')
        entity_llm_model = data.get('entity_llm_model')
        product_info_extraction_mode = data.get('product_info_extraction_mode')
        entity_matching_mode = data.get('entity_matching_mode')
        extract_entity_dag = data.get('extract_entity_dag')
        entity_extraction_context_mode = data.get('entity_extraction_context_mode')
        save_to_mongodb = data.get('save_to_mongodb')
        result_type = data.get('result_type')
        message_id = data.get('message_id')

        # DAG ì¶”ì¶œ ê¸°ëŠ¥ í™œì„±í™”
        # extract_entity_dag=Trueì¸ ê²½ìš°:
        # 1. ë©”ì‹œì§€ì—ì„œ ì—”í‹°í‹° ê°„ ê´€ê³„ë¥¼ DAG(Directed Acyclic Graph) í˜•íƒœë¡œ ì¶”ì¶œ
        # 2. NetworkXë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ êµ¬ì¡° ìƒì„±
        # 3. Graphvizë¥¼ í†µí•´ ì‹œê°ì  ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± (./dag_images/ ë””ë ‰í† ë¦¬ì— ì €ì¥)
        # 4. ê²°ê³¼ì˜ entity_dag í•„ë“œì— DAG í…ìŠ¤íŠ¸ í‘œí˜„ í¬í•¨
        
        # êµ¬ì„±ëœ ì¶”ì¶œê¸°ë¡œ ë©”ì‹œì§€ ì²˜ë¦¬ (í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ í¬í•¨)
        start_time = time.time()
        extractor = get_configured_extractor(llm_model, product_info_extraction_mode, entity_matching_mode, entity_llm_model, extract_entity_dag, entity_extraction_context_mode)
        
        logger.info(f"ë°ì´í„° ì†ŒìŠ¤ë¡œ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘: {offer_info_data_src}")
        
        # í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ë¥¼ ìœ„í•œ ìŠ¤ë ˆë“œ ë¡œì»¬ ì €ì¥ì†Œ ì´ˆê¸°í™”
        import threading
        current_thread = threading.current_thread()
        current_thread.stored_prompts = {}
        
        # DAG ì¶”ì¶œ ì—¬ë¶€ì— ë”°ë¼ ë³‘ë ¬ ì²˜ë¦¬ ë˜ëŠ” ë‹¨ì¼ ì²˜ë¦¬
        if extract_entity_dag:
            logger.info("DAG ì¶”ì¶œê³¼ í•¨ê»˜ ìˆœì°¨ ì²˜ë¦¬ ì‹œì‘")
            result = process_message_worker(extractor, message, extract_dag=True, message_id=message_id)
        else:
            result = extractor.process_message(message, message_id=message_id)
            result['ext_result']['entity_dag'] = []
            result['raw_result']['entity_dag'] = []  # DAG ì¶”ì¶œí•˜ì§€ ì•Šì€ ê²½ìš° ë¹ˆ ë°°ì—´
        if save_to_mongodb:
            logger.info("MongoDB ì €ì¥ ì¤‘...")

            logger.info(f"MessageId={message_id}")
            logger.info("#######extractor_result######"*4)
            logger.info(result)

            logger.info("========db_result======="*4)
            #db_result = result.get('ext_result')
            db_result = result['ext_result']
            logger.info(f"db_result-------->{db_result}")
            pprint(db_result)

            saved_id = save_result_to_mongodb_if_enabled(message, result, data, extractor)
            logger.info(f"SavedId = {saved_id}")
            if saved_id:
                logger.info("MongoDB ì €ì¥ ì™„ë£Œ!")
                insert_extract_result_to_database(result, message_id, saved_id)
                logger.info("DB ë¶„ì„ ê²°ê³¼ ì €ì¥ ì™„ë£Œ!(API)")
        if result_type == 'raw':
            result = result.get('raw_result', {})
        else:
            result = result.get('ext_result', {})
            
        processing_time = time.time() - start_time
        
        # ìº¡ì²˜ëœ í”„ë¡¬í”„íŠ¸ë“¤ ê°€ì ¸ì˜¤ê¸°
        captured_prompts = getattr(current_thread, 'stored_prompts', {})
        logger.info(f"ì¶”ì¶œ ê³¼ì •ì—ì„œ ìº¡ì²˜ëœ í”„ë¡¬í”„íŠ¸: {len(captured_prompts)}ê°œ")
        
        # DAG ì¶”ì¶œ ê²°ê³¼ ê²€ì¦ ë° ë¡œê¹…
        # entity_dag í•„ë“œëŠ” ì¶”ì¶œëœ ì—”í‹°í‹° ê°„ì˜ ê´€ê³„ë¥¼ í…ìŠ¤íŠ¸ë¡œ í‘œí˜„í•œ ê²ƒ
        # ì˜ˆ: "(ê³ ê°:ê°€ì…) -[í•˜ë©´]-> (í˜œíƒ:ìˆ˜ë ¹)"
        if extract_entity_dag and 'entity_dag' in result:
            dag_length = len(result['entity_dag']) if result['entity_dag'] else 0
            if dag_length > 0:
                logger.info(f"âœ… DAG ì¶”ì¶œ ì„±ê³µ - ê¸¸ì´: {dag_length}ì")
                logger.info(f"DAG ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {result['entity_dag'][:100]}...")
            else:
                logger.warning("âš ï¸ DAG ì¶”ì¶œ ìš”ì²­ë˜ì—ˆìœ¼ë‚˜ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
        
        # ì„±ê³µ ê²°ê³¼ ë°˜í™˜ (í”„ë¡¬í”„íŠ¸ í¬í•¨)
        response = {
            "success": True,
            "result": result,
            "metadata": {
                "llm_model": llm_model,
                "offer_info_data_src": offer_info_data_src,
                "product_info_extraction_mode": product_info_extraction_mode,
                "entity_matching_mode": entity_matching_mode,
                "extract_entity_dag": extract_entity_dag,
                "processing_time_seconds": round(processing_time, 3),
                "timestamp": time.time(),
                "message_length": len(message)
            },
            "prompts": {
                "success": True,
                "prompts": captured_prompts,
                "settings": {
                    "llm_model": llm_model,
                    "offer_info_data_src": offer_info_data_src,
                    "product_info_extraction_mode": product_info_extraction_mode,
                    "entity_matching_mode": entity_matching_mode,
                    "extract_entity_dag": extract_entity_dag
                },
                "message_info": {
                    "length": len(message),
                    "preview": message[:200] + "..." if len(message) > 200 else message
                },
                "timestamp": time.time()
            }
        }
        
        logger.info(f"ì¶”ì¶œ ì™„ë£Œ: {processing_time:.3f}ì´ˆ")
        logger.info(json.dumps(response, indent=2, ensure_ascii=False))

    except Exception as e:
        logger.error(f"ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


@app.get("/health")
def health_check():
    logger.info(f">>>>>>>>>>REQUEST_API::{inspect.currentframe().f_code.co_name}<<<<<<<<<<")
    return {
        "status": "healthy",
        "service": "MMS Extractor API",
        "version": "2.0.0",
        "model": "skt/gemma3-12b-it",
        "timestamp": time.time()
    }

@app.get('/models')
def list_models():
    logger.info(f">>>>>>>>>>REQUEST_API::{inspect.currentframe().f_code.co_name}<<<<<<<<<<")
    return {
        "available_llm_models": ["gemma", "ax", "claude", "gemini"],
        "default_llm_model": "ax",
        "available_data_sources": ["local", "db"],
        "default_data_source": "local",
        "available_product_info_extraction_modes": ["nlp", "llm", "rag"],
        "default_product_info_extraction_mode": "nlp",
        "available_entity_matching_modes": ["logic", "llm"],
        "default_entity_matching_mode": "logic",
        "features": [
            "Korean morphological analysis (Kiwi)",      # í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„
            "Embedding-based similarity search",         # ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
            "Entity extraction and matching",            # ì—”í‹°í‹° ì¶”ì¶œ ë° ë§¤ì¹­
            "Program classification",                     # í”„ë¡œê·¸ë¨ ë¶„ë¥˜
            "Multiple LLM support (Gemma, GPT, Claude)" # ë‹¤ì¤‘ LLM ì§€ì›
        ]
    }

@app.get('/status')
def get_status():
    logger.info(f">>>>>>>>>>REQUEST_API::{inspect.currentframe().f_code.co_name}<<<<<<<<<<")
    global global_extractor
    global_extractor = app.state.store.global_extractor
    # ì¶”ì¶œê¸° ìƒíƒœ ì •ë³´ ìˆ˜ì§‘
    extractor_status = {
        "initialized": global_extractor is not None,
        "data_source": CLI_DATA_SOURCE if global_extractor else None,
        "current_llm_model": global_extractor.llm_model_name if global_extractor else None,
        "current_product_mode": global_extractor.product_info_extraction_mode if global_extractor else None,
        "current_entity_mode": global_extractor.entity_extraction_mode if global_extractor else None
    }
    
    return {
        "status": "running",
        "extractor": extractor_status,
        "timestamp": time.time()
    }

@app.post('/prompts')
async def get_prompts(request: Request):
    logger.info(f">>>>>>>>>>REQUEST_API::{inspect.currentframe().f_code.co_name}<<<<<<<<<<")
    content_type = request.headers.get("content-type")
    logger.info(f"content-type: {content_type}" )
    if content_type != "application/json":
        return {"success": False, "error": "Content-Type is not application/json","timestamp": time.time()}, 400
    global global_extractor
    global_extractor = app.state.store.global_extractor
    try:
        if not global_extractor:
            return {
                "success": False,
                "error": "ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }, 500
        # ìš”ì²­ ë°ì´í„° íŒŒì‹±
        data = await request.json()
        if not data:
            return {
                "success": False,
                "error": "JSON ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }, 400
        # logger.info(json.dumps(data, indent=4, ensure_ascii=False))
        message = data.get('message', '')
        if not message:
            return {
                "success": False,
                "error": "ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }, 400
        # ì„¤ì • íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        llm_model = data.get('llm_model', 'ax')
        offer_info_data_src = data.get('offer_info_data_src', 'db')
        product_info_extraction_mode = data.get('product_info_extraction_mode', 'llm')
        entity_matching_mode = data.get('entity_matching_mode', 'logic')
        extract_entity_dag = data.get('extract_entity_dag', True)
        
        # ì¶”ì¶œê¸° ì„¤ì • ì—…ë°ì´íŠ¸
        extractor = get_configured_extractor(llm_model, product_info_extraction_mode, entity_matching_mode, extract_entity_dag)
        
        # ì‹¤ì œ ì¶”ì¶œ ìˆ˜í–‰ (í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ë¥¼ ìœ„í•´)
        import threading
        current_thread = threading.current_thread()
        current_thread.stored_prompts = {}  # í”„ë¡¬í”„íŠ¸ ì €ì¥ì†Œ ì´ˆê¸°í™”
        
        logger.info(f"í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ì‹œì‘ - ìŠ¤ë ˆë“œ ID: {current_thread.ident}")
        
        # ì¶”ì¶œ ìˆ˜í–‰
        if extract_entity_dag:
            result = process_message_worker(extractor, message, extract_dag=True)['extracted_result']
        else:
            result = extractor.process_message(message)['extracted_result']
        
        # ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ë“¤ ê°€ì ¸ì˜¤ê¸°
        stored_prompts = getattr(current_thread, 'stored_prompts', {})
        
        logger.info(f"í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ì™„ë£Œ - ìŠ¤ë ˆë“œ ID: {current_thread.ident}")
        logger.info(f"ì‹¤ì œ stored_prompts ë‚´ìš©: {stored_prompts}")
        
        logger.info(f"í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ìƒíƒœ: {len(stored_prompts)}ê°œ í”„ë¡¬í”„íŠ¸")
        logger.info(f"í”„ë¡¬í”„íŠ¸ í‚¤ë“¤: {list(stored_prompts.keys())}")
        
        # í”„ë¡¬í”„íŠ¸ê°€ ì—†ì–´ë„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ (ì¼ë¶€ ëª¨ë“œì—ì„œëŠ” íŠ¹ì • í”„ë¡¬í”„íŠ¸ë§Œ ìƒì„±ë¨)
        # if not stored_prompts:
        #     return jsonify({
        #         "success": False,
        #         "error": "í”„ë¡¬í”„íŠ¸ê°€ ìº¡ì²˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
        #         "prompts": {},
        #         "settings": {...}
        #     }), 200
        
        # ì‘ë‹µ êµ¬ì„±
        response = {
            "success": True,
            "prompts": stored_prompts,
            "settings": {
                "llm_model": llm_model,
                "offer_info_data_src": offer_info_data_src,
                "product_info_extraction_mode": product_info_extraction_mode,
                "entity_matching_mode": entity_matching_mode,
                "extract_entity_dag": extract_entity_dag
            },
            "message_info": {
                "length": len(message),
                "preview": message[:200] + "..." if len(message) > 200 else message
            },
            "timestamp": time.time(),
            "extraction_result": result  # ì¶”ì¶œ ê²°ê³¼ë„ í•¨ê»˜ ë°˜í™˜ (ì°¸ê³ ìš©)
        }
        
        logger.info(f"ì‹¤ì œ í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ì™„ë£Œ: {len(stored_prompts)}ê°œ í”„ë¡¬í”„íŠ¸")
        return response
        
    except Exception as e:
        logger.error(f"í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return {
            "success": False,
            "error": str(e),
            "timestamp": time.time()
        }, 500

@app.post('/dag')
async def extract_dag_endpoint(request: Request):
    logger.info(f">>>>>>>>>>REQUEST_API::{inspect.currentframe().f_code.co_name}<<<<<<<<<<")
    try:
        # ìš”ì²­ ë°ì´í„° ê²€ì¦
        content_type = request.headers.get("content-type")
        logger.info(f"content-type: {content_type}" )
        if content_type != "application/json":
            return {"success": False, "error": "Content-Type is not application/json","timestamp": time.time()}, 400

        data = await request.json()
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if 'message' not in data:
            return {"error": "í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: 'message'"}, 400
        
        message = data['message']
        if not message or not message.strip():
            return {"error": "ë©”ì‹œì§€ëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}, 400
        
        # ì„ íƒì  íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        llm_model_name = data.get('llm_model', 'ax')
        save_dag_image = data.get('save_dag_image', False)
        message_id = data.get('message_id', '#')  # ë©”ì‹œì§€ ID (ê¸°ë³¸ê°’: '#')
        
        # íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì¦
        valid_llm_models = ['ax', 'gem', 'cld', 'gen', 'gpt']
        if llm_model_name not in valid_llm_models:
            return {"error": f"ì˜ëª»ëœ llm_modelì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_llm_models}"}, 400
        
        # LLM ëª¨ë¸ ë§¤í•‘
        llm_model_map = {
            'ax': llm_ax,
            'gem': llm_gem,
            'cld': llm_cld,
            'gen': llm_gen,
            'gpt': llm_gpt
        }
        llm_model = llm_model_map[llm_model_name]
        
        logger.info(f"ğŸ¯ DAG ì¶”ì¶œ ìš”ì²­ - LLM: {llm_model_name}, ë©”ì‹œì§€ ê¸¸ì´: {len(message)}ì")
        
        # ë©”ì‹œì§€ ID ë¡œê¹…
        if message_id != '#':
            logger.info(f"ğŸ“‹ ë©”ì‹œì§€ ID: {message_id}")
        
        # DAG íŒŒì„œ ì´ˆê¸°í™”
        parser = DAGParser()
        
        # DAG ì¶”ì¶œ ì‹¤í–‰
        start_time = time.time()
        result = extract_dag(parser, message, llm_model)
        processing_time = time.time() - start_time
        
        # NetworkX ê·¸ë˜í”„ë¥¼ JSONìœ¼ë¡œ ë³€í™˜
        dag = result['dag']
        dag_json = parser.to_json(dag)
        analysis = parser.analyze_graph(dag)
        
        # ì´ë¯¸ì§€ ì €ì¥ (ì„ íƒ ì‚¬í•­)
        dag_image_url = None
        dag_image_path = None
        if save_dag_image:
            try:
                from utils import create_dag_diagram, sha256_hash
                from config import settings
                
                dag_hash = sha256_hash(message)
                dag_image_filename = f'dag_{message_id}_{dag_hash}.png'
                
                # ì„¤ì •ì— ë”°ë¼ ì €ì¥ ìœ„ì¹˜ ê²°ì • (ì¬ìƒì„±ëœ STORAGE_CONFIG ì‚¬ìš©)
                dag_dir = settings.STORAGE_CONFIG.get_dag_images_dir()
                output_dir = f'./{dag_dir}'
                
                # DAG ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ë° ì €ì¥ (output_dir ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬)
                create_dag_diagram(dag, filename=f'dag_{message_id}_{dag_hash}', output_dir=output_dir)
                
                # HTTP URL ìƒì„± (ìŠ¤í† ë¦¬ì§€ ëª¨ë“œì— ë”°ë¼ URL ê²°ì •)
                # - local ëª¨ë“œ: API ì„œë²„ ê³ ì • ì£¼ì†Œ ì‚¬ìš© (http://skt-tosaipoc01:8000)
                # - nas ëª¨ë“œ: NAS ì„œë²„ ì ˆëŒ€ IP ì£¼ì†Œ ì‚¬ìš© (http://172.27.7.58)
                dag_image_url = settings.STORAGE_CONFIG.get_dag_image_url(dag_image_filename)
                
                # ì‹¤ì œ ë¡œì»¬ ê²½ë¡œ (ì €ì¥ëœ ì‹¤ì œ ê²½ë¡œ)
                dag_image_path = str(Path(__file__).parent / dag_dir / dag_image_filename)
                
                logger.info(f"ğŸ“Š DAG ì´ë¯¸ì§€ ì €ì¥ë¨: {dag_image_path} ({settings.STORAGE_CONFIG.dag_storage_mode} ëª¨ë“œ)")
                logger.info(f"ğŸŒ DAG ì´ë¯¸ì§€ URL: {dag_image_url}")
            except Exception as e:
                logger.warning(f"âš ï¸ DAG ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # MongoDB ì €ì¥ (ì„ íƒ ì‚¬í•­)
        save_to_mongodb = data.get('save_to_mongodb', False)
        if save_to_mongodb:
            try:
                # save_result_to_mongodb_if_enabled í•¨ìˆ˜ê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ êµ¬ì„±
                # ext_resultì™€ raw_resultì— DAG ì •ë³´ í¬í•¨
                dag_list = sorted([d for d in result['dag_section'].split('\n') if d!=''])
                
                mock_result = {
                    'ext_result': {
                        'message_id': message_id,
                        'entity_dag': dag_list,
                        'dag_json': json.loads(dag_json),
                        'dag_analysis': analysis
                    },
                    'raw_result': {
                        'message_id': message_id,
                        'dag_raw': result['dag_raw']
                    },
                    'processing_time': processing_time
                }
                
                # ê°€ì§œ args ê°ì²´ ìƒì„± (í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ë§ì¶”ê¸° ìœ„í•¨)
                mock_args = {
                    'save_to_mongodb': True,
                    'llm_model': llm_model_name,
                    'processing_mode': 'api_dag',
                    'user_id': 'API_USER'
                }
                
                logger.info("MongoDB ì €ì¥ ì¤‘...")
                saved_id = save_result_to_mongodb_if_enabled(message, mock_result, mock_args)
                if saved_id:
                    logger.info(f"MongoDB ì €ì¥ ì™„ë£Œ! ID: {saved_id}")
            except Exception as e:
                logger.error(f"MongoDB ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # ì‘ë‹µ êµ¬ì„±
        response = {
            "success": True,
            "result": {
                "message_id": message_id,  # message_id ì¶”ê°€
                "dag_section": result['dag_section'],
                "dag_raw": result['dag_raw'],
                "dag_json": json.loads(dag_json),
                "analysis": analysis,
                "dag_image_url": dag_image_url,  # HTTP URL (ì™¸ë¶€ ì‹œìŠ¤í…œìš©)
                "dag_image_path": dag_image_path  # ë¡œì»¬ ê²½ë¡œ (ë‚´ë¶€ ì°¸ì¡°ìš©)
            },
            "metadata": {
                "llm_model": llm_model_name,
                "processing_time_seconds": round(processing_time, 3),
                "timestamp": time.time(),
                "message_length": len(message),
                "save_dag_image": save_dag_image
            }
        }
        
        logger.info(f"âœ… DAG ì¶”ì¶œ ì™„ë£Œ: {processing_time:.3f}ì´ˆ, ë…¸ë“œ: {analysis['num_nodes']}, ì—£ì§€: {analysis['num_edges']}")
        return response
        
    except Exception as e:
        logger.error(f"âŒ DAG ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {
            "success": False,
            "error": str(e),
            "timestamp": time.time()
        }, 500

# =============================================================================
# Quick Extractor API ì—”ë“œí¬ì¸íŠ¸ (ì œëª© ë° ìˆ˜ì‹ ê±°ë¶€ ë²ˆí˜¸ ì¶”ì¶œ)
# =============================================================================

@app.post('/quick/extract')
async def quick_extract(request: Request):
    logger.info(f">>>>>>>>>>REQUEST_API::{inspect.currentframe().f_code.co_name}<<<<<<<<<<")
    try:
        content_type = request.headers.get("content-type")
        logger.info(f"content-type: {content_type}" )
        if content_type != "application/json":
            return {"success": False, "error": "Content-Type is not application/json","timestamp": time.time()}, 400

        # ìš”ì²­ ì‹œì‘ ì‹œê°„
        start_time = time.time()
        
        # ìš”ì²­ ë°ì´í„° íŒŒì‹±
        data = await request.json()
        if not data:
            return {
                "success": False,
                "error": "ìš”ì²­ ë³¸ë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì „ì†¡í•˜ì„¸ìš”."
            }, 400
        
        # í•„ìˆ˜ íŒŒë¼ë¯¸í„° ê²€ì¦
        message = data.get('message')
        if not message:
            return {
                "success": False,
                "error": "'message' í•„ë“œëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤."
            }, 400
        
        # ì„ íƒì  íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’ ì„¤ì •)
        method = data.get('method', 'textrank')
        use_llm = data.get('use_llm', method == 'llm')
        llm_model = data.get('llm_model', 'ax')
        message_id = data.get('message_id', '#')  # ë©”ì‹œì§€ ID (ê¸°ë³¸ê°’: '#')
        
        # ë©”ì„œë“œ ê²€ì¦
        valid_methods = ['textrank', 'tfidf', 'first_bracket', 'llm']
        if method not in valid_methods:
            return {
                "success": False,
                "error": f"ìœ íš¨í•˜ì§€ ì•Šì€ method: {method}. ì‚¬ìš© ê°€ëŠ¥: {', '.join(valid_methods)}"
            }, 400
        
        # Quick Extractor êµ¬ì„± ë° ê°€ì ¸ì˜¤ê¸°
        extractor = get_configured_quick_extractor(use_llm=use_llm, llm_model=llm_model)
        
        # ë©”ì‹œì§€ ì²˜ë¦¬
        logger.info(f"ğŸ“ Quick Extract ì‹œì‘: method={method}, use_llm={use_llm}, llm_model={llm_model}")
        result = extractor.process_single_message(message, method=method)
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = time.time() - start_time
        
        # ë©”íƒ€ë°ì´í„°ì— ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
        result['metadata']['processing_time_seconds'] = round(processing_time, 3)
        result['metadata']['timestamp'] = time.time()
        
        # message_id ì¶”ê°€
        result['data']['message_id'] = message_id
        
        logger.info(f"âœ… Quick Extract ì™„ë£Œ: {processing_time:.3f}ì´ˆ, ì œëª©={result['data']['title'][:50]}...")
        return result
        
    except Exception as e:
        logger.error(f"âŒ Quick Extract ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {
            "success": False,
            "error": str(e),
            "timestamp": time.time()
        }, 500

@app.post('/quick/extract/batch')
async def quick_extract_batch(request: Request):
    logger.info(f">>>>>>>>>>REQUEST_API::{inspect.currentframe().f_code.co_name}<<<<<<<<<<")
    try:
        content_type = request.headers.get("content-type")
        logger.info(f"content-type: {content_type}" )
        if content_type != "application/json":
            return {"success": False, "error": "Content-Type is not application/json","timestamp": time.time()}, 400

        # ìš”ì²­ ì‹œì‘ ì‹œê°„
        start_time = time.time()
        
        # ìš”ì²­ ë°ì´í„° íŒŒì‹±
        data = await request.json()
        if not data:
            return {
                "success": False,
                "error": "ìš”ì²­ ë³¸ë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì „ì†¡í•˜ì„¸ìš”."
            }, 400
        
        # í•„ìˆ˜ íŒŒë¼ë¯¸í„° ê²€ì¦
        messages = data.get('messages')
        if not messages:
            return {
                "success": False,
                "error": "'messages' í•„ë“œëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤."
            }, 400
        
        if not isinstance(messages, list):
            return {
                "success": False,
                "error": "'messages'ëŠ” ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
            }, 400
        
        if len(messages) == 0:
            return {
                "success": False,
                "error": "ìµœì†Œ 1ê°œ ì´ìƒì˜ ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            }, 400
        
        # ì„ íƒì  íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’ ì„¤ì •)
        method = data.get('method', 'textrank')
        use_llm = data.get('use_llm', method == 'llm')
        llm_model = data.get('llm_model', 'ax')
        
        # ë©”ì„œë“œ ê²€ì¦
        valid_methods = ['textrank', 'tfidf', 'first_bracket', 'llm']
        if method not in valid_methods:
            return {
                "success": False,
                "error": f"ìœ íš¨í•˜ì§€ ì•Šì€ method: {method}. ì‚¬ìš© ê°€ëŠ¥: {', '.join(valid_methods)}"
            }, 400
        
        # Quick Extractor êµ¬ì„± ë° ê°€ì ¸ì˜¤ê¸°
        extractor = get_configured_quick_extractor(use_llm=use_llm, llm_model=llm_model)
        
        # ë°°ì¹˜ ë©”ì‹œì§€ ì²˜ë¦¬
        logger.info(f"ğŸ“ Quick Extract Batch ì‹œì‘: {len(messages)}ê°œ ë©”ì‹œì§€, method={method}, use_llm={use_llm}")
        
        results = []
        msg_processing_times = []
        
        for idx, msg_item in enumerate(messages):
            # ë©”ì‹œì§€ê°€ ë¬¸ìì—´ì´ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ì¼ ìˆ˜ ìˆìŒ
            if isinstance(msg_item, dict):
                message = msg_item.get('message', '')
                message_id = msg_item.get('message_id', '#')
            else:
                message = msg_item
                message_id = '#'
            
            msg_start_time = time.time()
            result = extractor.process_single_message(message, method=method)
            msg_processing_time = time.time() - msg_start_time
            
            # ê²°ê³¼ì— ë©”ì‹œì§€ IDì™€ ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
            message_result = {
                'msg_id': idx,
                'message_id': message_id,  # message_id ì¶”ê°€
                'title': result['data']['title'],
                'unsubscribe_phone': result['data']['unsubscribe_phone'],
                'message': result['data']['message'],
                'processing_time_seconds': round(msg_processing_time, 3)
            }
            results.append(message_result)
            msg_processing_times.append(msg_processing_time)
        
        # í†µê³„ ê³„ì‚°
        total = len(results)
        with_phone = sum(1 for r in results if r.get('unsubscribe_phone'))
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = time.time() - start_time
        avg_time = sum(msg_processing_times) / total if total > 0 else 0
        min_time = min(msg_processing_times) if msg_processing_times else 0
        max_time = max(msg_processing_times) if msg_processing_times else 0
        
        # ì‘ë‹µ êµ¬ì„±
        response = {
            'success': True,
            'data': {
                'results': results,
                'statistics': {
                    'total_messages': total,
                    'with_unsubscribe_phone': with_phone,
                    'extraction_rate': round(with_phone / total * 100, 2) if total > 0 else 0,
                    'total_processing_time_seconds': round(sum(msg_processing_times), 3),
                    'avg_processing_time_seconds': round(avg_time, 3),
                    'min_processing_time_seconds': round(min_time, 3),
                    'max_processing_time_seconds': round(max_time, 3)
                }
            },
            'metadata': {
                'method': method,
                'total_time_seconds': round(processing_time, 3),
                'timestamp': time.time()
            }
        }
        
        logger.info(f"âœ… Quick Extract Batch ì™„ë£Œ: {processing_time:.3f}ì´ˆ, {total}ê°œ ë©”ì‹œì§€ ì²˜ë¦¬")
        return response
        
    except Exception as e:
        logger.error(f"âŒ Quick Extract Batch ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return {
            "success": False,
            "error": str(e),
            "timestamp": time.time()
        }, 500

@app.get('/dag_images/{filename}')
def serve_dag_image(filename: str):
    logger.info(f">>>>>>>>>>REQUEST_API::{inspect.currentframe().f_code.co_name}<<<<<<<<<<")
    try:
        from config import settings
        
        # DAG ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ (ìŠ¤í† ë¦¬ì§€ ëª¨ë“œì™€ ê´€ê³„ì—†ì´ ë™ì¼)
        dag_dir = settings.STORAGE_CONFIG.get_dag_images_dir()
        logger.info(f"dag_dir:{dag_dir}")
        dag_images_dir = Path(__file__).parent / dag_dir
        logger.info(f"ğŸ“Š DAG ì´ë¯¸ì§€ ìš”ì²­: {filename} (from {dag_dir})")
    
        file_path = dag_images_dir / filename
        logger.info(f"DAG file_path: {file_path}")
        return FileResponse(
            path=file_path,
            filename=filename,
            media_type="application/octet-stream"
        )
        
    except FileNotFoundError:
        logger.warning(f"âš ï¸ DAG ì´ë¯¸ì§€ ì—†ìŒ: {filename}")
        return {
            "success": False,
            "error": "Image not found"
        }, 404
    except Exception as e:
        logger.error(f"âŒ DAG ì´ë¯¸ì§€ ì œê³µ ì˜¤ë¥˜: {e}")
        return {
            "success": False,
            "error": str(e)
        }, 500


@app.exception_handler(APIHTTPException)
async def not_found(request: Request, exc: APIHTTPException):
    if exc.status_code == 404:
        return JSONResponse(
            status_code=404,content={"error": "ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        )
        """404 ì—ëŸ¬ í•¸ë“¤ëŸ¬ - ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì—”ë“œí¬ì¸íŠ¸ ì ‘ê·¼ ì‹œ"""
    return {"error": "ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}, 404

@app.exception_handler(APIHTTPException)
async def internal_error(request: Request, exc: APIHTTPException):
    if exc.status_code == 500:
        return JSONResponse(
            status_code=500,content={"error": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"}
        )
        """500 ì—ëŸ¬ í•¸ë“¤ëŸ¬ - ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ ë°œìƒ ì‹œ"""
    return {"error": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"}, 500

def main():

    global CLI_DATA_SOURCE
    
    # ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì„œ ì„¤ì •
    parser = argparse.ArgumentParser(description='MMS ì¶”ì¶œê¸° API ì„œë²„')
    parser.add_argument('--host', default='0.0.0.0', help='ë°”ì¸ë”©í•  í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ')
    parser.add_argument('--port', type=int, default=8000, help='ë°”ì¸ë”©í•  í¬íŠ¸ ë²ˆí˜¸')
    parser.add_argument('--debug', action='store_true', help='ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”')
    parser.add_argument('--test', action='store_true', help='í…ŒìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤í–‰')
    parser.add_argument('--message', type=str, help='í…ŒìŠ¤íŠ¸í•  ë©”ì‹œì§€')
    parser.add_argument('--offer-data-source', choices=['local', 'db'], default='db',
                       help='ë°ì´í„° ì†ŒìŠ¤ (local: CSV íŒŒì¼, db: ë°ì´í„°ë² ì´ìŠ¤)')
    parser.add_argument('--product-info-extraction-mode', choices=['nlp', 'llm' ,'rag'], default='llm',
                       help='ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ëª¨ë“œ (nlp: í˜•íƒœì†Œë¶„ì„, llm: LLM ê¸°ë°˜, rag: ê²€ìƒ‰ì¦ê°•ìƒì„±)')
    parser.add_argument('--entity-matching-mode', choices=['logic', 'llm'], default='llm',
                       help='ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ (logic: ë¡œì§ ê¸°ë°˜, llm: LLM ê¸°ë°˜)')
    parser.add_argument('--llm-model', choices=['gem', 'ax', 'cld', 'gen', 'gpt'], default='ax',
                       help='ì‚¬ìš©í•  LLM ëª¨ë¸ (gem: Gemma, ax: ax, cld: Claude, gen: Gemini, gpt: GPT)')
    parser.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'], default='INFO',
                       help='ë¡œê·¸ ë ˆë²¨ ì„¤ì • (DEBUG: ìƒì„¸, INFO: ì¼ë°˜, WARNING: ê²½ê³ , ERROR: ì˜¤ë¥˜ë§Œ)')
    parser.add_argument('--extract-entity-dag', action='store_true', default=False, help='Entity DAG extraction (default: False)')
    parser.add_argument('--storage', choices=['local', 'nas'], default='local',
                       help='DAG ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜ (local: ë¡œì»¬ ë””ìŠ¤í¬, nas: NAS ì„œë²„)')
    parser.add_argument('--num-cand-pgms', type=int, default=None,
                       help='í”„ë¡œê·¸ë¨ í›„ë³´ ê°œìˆ˜ (ê¸°ë³¸ê°’: configì˜ num_candidate_programs=15)')
    parser.add_argument('--num-select-pgms', type=int, default=None,
                       help='LLMì´ ìµœì¢… ì„ ì •í•  í”„ë¡œê·¸ë¨ ìˆ˜ (ê¸°ë³¸ê°’: configì˜ num_select_programs=1)')

    args = parser.parse_args()
    
    # ë¡œê·¸ ë ˆë²¨ ì„¤ì • - ë£¨íŠ¸ ë¡œê±°ì™€ ëª¨ë“  í•¸ë“¤ëŸ¬ì— ì ìš©
    log_level = getattr(logging, args.log_level)
    root_logger.setLevel(log_level)
    for handler in root_logger.handlers:
        handler.setLevel(log_level)
    logger.setLevel(log_level)
    mms_logger.setLevel(log_level)
    
    logger.info(f"ë¡œê·¸ ë ˆë²¨ ì„¤ì •: {args.log_level}")
    
    # DAG ì €ì¥ ëª¨ë“œ ì„¤ì •
    logger.info(f"ğŸ”§ --storage ì˜µì…˜: {args.storage}")
    os.environ['DAG_STORAGE_MODE'] = args.storage
    logger.info(f"ğŸ”§ í™˜ê²½ë³€ìˆ˜ DAG_STORAGE_MODE ì„¤ì •: {os.environ.get('DAG_STORAGE_MODE')}")
    
    # STORAGE_CONFIG ì¬ìƒì„± (í™˜ê²½ë³€ìˆ˜ ì ìš©)
    from config.settings import StorageConfig
    from config import settings
    settings.STORAGE_CONFIG = StorageConfig()
    STORAGE_CONFIG = settings.STORAGE_CONFIG
    
    logger.info(f"ğŸ“ DAG ì €ì¥ ëª¨ë“œ: {STORAGE_CONFIG.dag_storage_mode} - {STORAGE_CONFIG.get_storage_description()}")
    logger.info(f"ğŸ“‚ DAG ì €ì¥ ê²½ë¡œ: {STORAGE_CONFIG.get_dag_images_dir()}")
    if STORAGE_CONFIG.dag_storage_mode == 'local':
        logger.info(f"ğŸŒ ë¡œì»¬ ì„œë²„ URL: {STORAGE_CONFIG.local_base_url}")
    else:
        logger.info(f"ğŸŒ NAS ì„œë²„ URL: {STORAGE_CONFIG.nas_base_url}")
    
    # ì „ì—­ CLI ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •
    CLI_DATA_SOURCE = args.offer_data_source
    logger.info(f"CLI ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •: {CLI_DATA_SOURCE}")
    
    # ì§€ì •ëœ ë°ì´í„° ì†ŒìŠ¤ë¡œ ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™”
    #logger.info("ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì¤‘...")

    #deprecated    
    #initialize_global_extractor(CLI_DATA_SOURCE)

    # ì„œë²„ ëª¨ë“œ ì‹¤í–‰
    logger.info(f"íŒŒì‹±ëœ ì¸ì: host={args.host}, port={args.port}, debug={args.debug}")
    logger.info("âœ… ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ, ìš”ì²­ ì²˜ë¦¬ ì¤€ë¹„ë¨")
    logger.info(f"MMS ì¶”ì¶œê¸° API ì„œë²„ë¥¼ {args.host}:{args.port}ì—ì„œ ì‹œì‘í•©ë‹ˆë‹¤")
    logger.info("ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸:")
    logger.info("  GET  /health - í—¬ìŠ¤ì²´í¬")
    logger.info("  GET  /models - ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡")
    logger.info("  GET  /status - ì„œë²„ ìƒíƒœ ì¡°íšŒ")
    logger.info("  POST /extract - ë‹¨ì¼ ë©”ì‹œì§€ ì¶”ì¶œ")
    logger.info("  POST /extract/batch - ë‹¤ì¤‘ ë©”ì‹œì§€ ë°°ì¹˜ ì¶”ì¶œ")
    logger.info("  POST /dag - Entity DAG ì¶”ì¶œ")
    
    log_level = 'debug'

    try:
        # ì„œë²„ ì‹œì‘ (ë¦¬ë¡œë” ë¹„í™œì„±í™”, ìŠ¤ë ˆë”© í™œì„±í™”)
        uvicorn.run("api:app", host=args.host, port=args.port, reload=False, log_level="debug" if args.debug else "info")
    except Exception as e:
        logger.error(f"ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()


