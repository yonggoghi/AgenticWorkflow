#!/usr/bin/env python3
"""
crawl_details ì˜µì…˜ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ğŸ†• í˜ì´ì§€ íƒ€ì… ìë™ ê°ì§€ ê¸°ëŠ¥ ì¶”ê°€!
"""

from product_crawler import ProductCrawler

def test_crawl_details():
    """ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§ í…ŒìŠ¤íŠ¸ (ìë™ ê°ì§€ í™œìš©)"""
    print("="*80)
    print("crawl_details ì˜µì…˜ í…ŒìŠ¤íŠ¸")
    print("ğŸ†• í˜ì´ì§€ íƒ€ì… ìë™ ê°ì§€ ì‚¬ìš©")
    print("="*80)
    
    url = "https://m.sktuniverse.co.kr/category/sub/tab/detail?ctanId=CC00000012&ctgId=CA00000001"
    
    # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
    crawler = ProductCrawler(
        base_url=url,
        use_llm=True,
        model_name="ax"
    )
    
    # print("\n[í…ŒìŠ¤íŠ¸ 1] crawl_details=False")
    # print("-" * 80)
    # df1 = crawler.run(
    #     url=url,
    #     infinite_scroll=True,
    #     scroll_count=5,          # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 5íšŒë§Œ
    #     crawl_details=False,     # âŒ ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§ ì•ˆ í•¨
    #     output_path="output/test_no_details"
    # )
    
    # print(f"\nì¶”ì¶œëœ ìƒí’ˆ: {len(df1)}ê°œ")
    # print(f"ì»¬ëŸ¼: {list(df1.columns)}")
    # if not df1.empty:
    #     print("\nì²« ë²ˆì§¸ ìƒí’ˆ:")
    #     print(df1.iloc[0].to_dict())
        
    #     # detail_url í†µê³„
    #     has_detail_url = df1['detail_url'].notna() & (df1['detail_url'] != '')
    #     print(f"\ndetail_url í†µê³„: {has_detail_url.sum()}/{len(df1)}ê°œ ìƒí’ˆì— URL ìˆìŒ")
    
    print("\n" + "="*80)
    print("\n[í…ŒìŠ¤íŠ¸] crawl_details=True (ìµœëŒ€ 2ê°œ, ìë™ ê°ì§€)")
    print("-" * 80)
    df2 = crawler.run(
        url=url,
        auto_detect=True,        # ğŸ†• í˜ì´ì§€ íƒ€ì… ìë™ ê°ì§€
        crawl_details=True,      # âœ… ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§
        max_detail_pages=2,      # 2ê°œë§Œ í…ŒìŠ¤íŠ¸
        output_path="output/test_with_details"
    )
    
    print(f"\nì¶”ì¶œëœ ìƒí’ˆ: {len(df2)}ê°œ")
    print(f"ì»¬ëŸ¼: {list(df2.columns)}")
    if not df2.empty:
        print("\nì²« ë²ˆì§¸ ìƒí’ˆ:")
        print(df2.iloc[0].to_dict())
        
        # detail_url í†µê³„
        has_detail_url = df2['detail_url'].notna() & (df2['detail_url'] != '')
        print(f"\ndetail_url í†µê³„: {has_detail_url.sum()}/{len(df2)}ê°œ ìƒí’ˆì— URL ìˆìŒ")
    
    print("\n" + "="*80)
    print("í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("="*80)
    
    # ìƒì„¸ ì •ë³´ í™•ì¸
    print("\n[ê²°ê³¼ ë¶„ì„]")
    print(f"ì¶”ì¶œëœ ìƒí’ˆ: {len(df2)}ê°œ")
    
    if not df2.empty:
        # ìƒì„¸ ì •ë³´ê°€ ì¶”ê°€ë˜ì—ˆëŠ”ì§€ í™•ì¸
        detail_fields = ['category', 'features', 'specifications']
        has_details = any(field in df2.columns for field in detail_fields)
        print(f"\nìƒì„¸ ì •ë³´ ì¶”ê°€ ì—¬ë¶€: {'âœ… ìˆìŒ' if has_details else 'âŒ ì—†ìŒ'}")
        
        if has_details:
            print("\nìƒì„¸ ì •ë³´ í•„ë“œë³„ ë°ì´í„°:")
            for field in detail_fields:
                if field in df2.columns:
                    non_empty = df2[field].notna().sum()
                    print(f"  - {field}: {non_empty}/{len(df2)}ê°œ ìƒí’ˆì— ë°ì´í„° ìˆìŒ")
        
        print(f"\nğŸ’¡ ìë™ ê°ì§€ ê¸°ëŠ¥:")
        print("   - í˜ì´ì§€ íƒ€ì…ì´ ìë™ìœ¼ë¡œ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤")
        print("   - ìµœì ì˜ ìŠ¤í¬ë¡¤ ì „ëµì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤")
        print("   - ë¬´í•œ ìŠ¤í¬ë¡¤ í˜ì´ì§€: ì¬ìŠ¤í¬ë¡¤ í•„ìš”")
        print("   - ì¼ë°˜ í˜ì´ì§€: ì¬ìŠ¤í¬ë¡¤ ìƒëµ â†’ 2ë°° ë¹ ë¦„!")


if __name__ == '__main__':
    test_crawl_details()

