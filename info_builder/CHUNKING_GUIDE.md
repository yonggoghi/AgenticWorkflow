# 텍스트 청킹 처리 가이드

## 개요

product_crawler는 긴 웹 페이지를 자동으로 청크(chunk)로 나눠서 처리합니다. 이를 통해 LLM의 컨텍스트 제한을 극복하고 안정적으로 정보를 추출할 수 있습니다.

## 작동 방식

### 1. 텍스트 분할

긴 텍스트는 다음과 같이 분할됩니다:

```python
# 기본 설정
chunk_size = 4000    # 청크 크기 (문자 수)
overlap = 500        # 청크 간 오버랩 (중복 영역)
```

### 2. 스마트 분할

단순히 문자 수로 자르지 않고, 문장 경계에서 자릅니다:

1. `\n\n` (문단 경계)
2. `\n` (줄 바꿈)
3. `. ` (문장 종료)
4. ` ` (공백)

이렇게 하면 문장이 중간에 잘리는 것을 방지합니다.

### 3. 오버랩

청크 간 500자 오버랩을 두어 경계에 있는 정보가 누락되는 것을 방지합니다.

```
청크1: [0...........5000]
청크2:          [4500...........9500]
청크3:                   [9000.........14000]
```

### 4. 중복 제거

각 청크에서 추출된 상품 정보는 자동으로 중복 제거됩니다:

```python
# 상품명 + 가격으로 중복 체크
product_key = product.get('name', '') + product.get('price', '')
```

## 예시

### 입력

웹 페이지 텍스트: 13,607 문자

```
[1단계] 목록 페이지 크롤링
  페이지 로딩: https://...
  텍스트: 13607 문자
  링크: 1 개

[2단계] 상품/서비스 정보 추출
  텍스트를 3개 청크로 분할
  청크 1/3 처리 중... (5000 문자)
    → 복구 성공: 18개 상품 발견 (총 18개)
  청크 2/3 처리 중... (5000 문자)
    → 25개 상품 발견 (총 43개)
  청크 3/3 처리 중... (4107 문자)
    → 30개 상품 발견 (총 73개)
  총 73개의 고유 상품/서비스를 추출했습니다.
```

### 장점

1. **안정성**: LLM의 토큰 제한 초과 방지
2. **완전성**: 긴 페이지의 모든 상품 정보 수집
3. **정확성**: 문장 경계에서 분할하여 정보 손실 최소화
4. **효율성**: 중복 제거로 불필요한 데이터 방지

## 설정 변경

청크 크기나 오버랩을 변경하고 싶다면 `product_crawler.py`를 수정하세요:

```python
# product_crawler.py, extract_products_with_llm 메서드

# 기본값 (권장)
chunks = self._chunk_text(text_content, chunk_size=4000, overlap=500)

# 더 작은 청크 (더 안전하지만 느림)
chunks = self._chunk_text(text_content, chunk_size=3000, overlap=500)

# 더 큰 청크 (빠르지만 응답이 잘릴 위험)
chunks = self._chunk_text(text_content, chunk_size=6000, overlap=500)
```

## 비용 고려사항

청크 수가 많아지면 LLM 호출 횟수가 증가합니다:

- **1개 청크**: 1번 LLM 호출
- **2개 청크**: 2번 LLM 호출
- **3개 청크**: 3번 LLM 호출

예상 비용:
- 청크당 약 $0.01-0.02 (모델에 따라 다름)
- 10,000자 페이지: 2청크 = $0.02-0.04

## 문제 해결

### 너무 많은 청크가 생성됨

```python
# chunk_size를 늘립니다
chunks = self._chunk_text(text_content, chunk_size=10000, overlap=500)
```

### JSON 파싱 오류가 계속 발생함

1. 청크 크기를 줄입니다
2. 프롬프트를 더 명확하게 수정합니다
3. 다른 LLM 모델을 시도합니다 (`--model gemini` 등)

### 중복된 상품이 여전히 나타남

중복 제거 로직을 강화하세요:

```python
# product_crawler.py에서
product_key = (
    product.get('name', '') + 
    product.get('price', '') + 
    product.get('id', '')
)
```

## 모니터링

실행 시 청킹 과정을 모니터링할 수 있습니다:

```
텍스트를 2개 청크로 분할
청크 1/2 처리 중... (8000 문자)
  → 5개 상품 발견 (총 5개)
청크 2/2 처리 중... (6107 문자)
  → 3개 상품 발견 (총 8개)
총 8개의 고유 상품/서비스를 추출했습니다.
```

이 정보를 통해:
- 청크가 잘 나뉘어졌는지
- 각 청크에서 상품을 찾았는지
- 중복 제거가 작동하는지
확인할 수 있습니다.

## 베스트 프랙티스

1. **첫 실행은 작은 페이지로 테스트**
   ```bash
   python product_crawler.py "simple-page.html" --scroll
   ```

2. **청크 크기 조정**
   - 일반 페이지: 4,000자 (기본값, 권장)
   - 짧은 페이지: 6,000자 (빠름)
   - 복잡하거나 JSON 오류 발생 시: 3,000자 (안전)

3. **모니터링**
   - 청크 수가 너무 많으면 (5개 이상) chunk_size 증가
   - JSON 오류가 많으면 chunk_size 감소

4. **비용 최적화**
   - 불필요한 텍스트 제거 (헤더, 푸터 등)
   - chunk_size를 최대한 크게 (but 안정성 유지)
   - 캐싱 활용 (같은 페이지 반복 크롤링 방지)

## 참고

- 청킹은 목록 페이지에만 적용됩니다
- 상세 페이지는 앞부분 8,000자만 사용 (상세 정보는 보통 처음에 있음)
- 중복 제거는 상품명+가격 조합으로 수행됩니다

