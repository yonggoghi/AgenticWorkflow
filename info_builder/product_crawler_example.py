#!/usr/bin/env python3
"""
ìƒí’ˆ/ì„œë¹„ìŠ¤ í¬ë¡¤ëŸ¬ ì‚¬ìš© ì˜ˆì œ

í˜ì´ì§€ íƒ€ì… ìë™ ê°ì§€ ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤! ğŸ†•
- ë¬´í•œ ìŠ¤í¬ë¡¤ / í˜ì´ì§€ë„¤ì´ì…˜ / ë”ë³´ê¸° ë²„íŠ¼ / ì •ì  í˜ì´ì§€ ìë™ ì¸ì‹
- í˜ì´ì§€ íƒ€ì…ì— ë”°ë¼ ìµœì  ì „ëµ ìë™ ì ìš©
- ë¶ˆí•„ìš”í•œ ì¬ìŠ¤í¬ë¡¤ ìë™ ìƒëµ â†’ 2ë°° ë¹ ë¥¸ ì†ë„!
"""

from product_crawler import ProductCrawler
import pandas as pd


def example_auto_detect():
    """ğŸ†• í˜ì´ì§€ íƒ€ì… ìë™ ê°ì§€ ì˜ˆì œ (ê¶Œì¥)"""
    print("\n=== ğŸ†• í˜ì´ì§€ íƒ€ì… ìë™ ê°ì§€ (ê¶Œì¥) ===\n")
    
    url = "https://m.sktuniverse.co.kr/category/sub/tab/detail?ctanId=CC00000012&ctgId=CA00000001"
    
    # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
    crawler = ProductCrawler(
        base_url=url,
        use_llm=True,
        model_name="ax"
    )
    
    # ì‹¤í–‰ - í˜ì´ì§€ íƒ€ì… ìë™ ê°ì§€ (ê¸°ë³¸ê°’)
    df = crawler.run(
        url=url,
        auto_detect=True,        # ğŸ†• í˜ì´ì§€ íƒ€ì… ìë™ ê°ì§€ (ê¸°ë³¸ê°’)
        crawl_details=False,
        output_path="output/products_auto_detect"
    )
    
    print(f"\nì¶”ì¶œëœ ìƒí’ˆ: {len(df)}ê°œ")
    print("\nìƒìœ„ 5ê°œ:")
    print(df.head())
    
    print("\nğŸ’¡ ìë™ ê°ì§€ ê²°ê³¼:")
    print("   - í˜ì´ì§€ íƒ€ì…ì´ ìë™ìœ¼ë¡œ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤")
    print("   - ìµœì ì˜ ìŠ¤í¬ë¡¤ ì „ëµì´ ìë™ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤")
    print("   - ë¬´í•œ ìŠ¤í¬ë¡¤: ì¬ìŠ¤í¬ë¡¤ í•„ìš”")
    print("   - ì •ì  í˜ì´ì§€: ì¬ìŠ¤í¬ë¡¤ ìƒëµ â†’ 2ë°° ë¹ ë¦„!")


def example_basic():
    """ê¸°ë³¸ ì‚¬ìš© ì˜ˆì œ (ìˆ˜ë™ ì„¤ì •)"""
    print("\n=== ê¸°ë³¸ ì‚¬ìš© ì˜ˆì œ (ìˆ˜ë™ ì„¤ì •) ===\n")
    
    url = "https://m.sktuniverse.co.kr/category/sub/tab/detail?ctanId=CC00000012&ctgId=CA00000001"
    
    # í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”
    crawler = ProductCrawler(
        base_url=url,
        use_llm=True,           # LLM ì‚¬ìš©
        model_name="ax"         # AX ëª¨ë¸ ì‚¬ìš© (gemma, ax, claude, gemini, gpt ì¤‘ ì„ íƒ)
    )
    
    # ì‹¤í–‰ (ìˆ˜ë™ ì„¤ì •)
    df = crawler.run(
        url=url,
        auto_detect=False,       # ìë™ ê°ì§€ ë¹„í™œì„±í™”
        infinite_scroll=True,    # ìˆ˜ë™ìœ¼ë¡œ ë¬´í•œ ìŠ¤í¬ë¡¤ ì§€ì •
        scroll_count=30,         # ìµœëŒ€ 30íšŒ ìŠ¤í¬ë¡¤
        crawl_details=False,     # ìƒì„¸ í˜ì´ì§€ëŠ” í¬ë¡¤ë§ ì•ˆ í•¨
        output_path="output/products_basic"
    )
    
    print(f"\nì¶”ì¶œëœ ìƒí’ˆ: {len(df)}ê°œ")
    print("\nìƒìœ„ 5ê°œ:")
    print(df.head())


def example_with_details():
    """ìƒì„¸ í˜ì´ì§€ í¬í•¨ ì˜ˆì œ (ìë™ ê°ì§€)"""
    print("\n=== ìƒì„¸ í˜ì´ì§€ í¬í•¨ ì˜ˆì œ (ìë™ ê°ì§€) ===\n")
    
    url = "https://m.sktuniverse.co.kr/category/sub/tab/detail?ctanId=CC00000012&ctgId=CA00000001"
    
    crawler = ProductCrawler(
        base_url=url,
        use_llm=True,
        model_name="ax"
    )
    
    # ì‹¤í–‰ - ìë™ ê°ì§€ + ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§
    df = crawler.run(
        url=url,
        auto_detect=True,        # ğŸ†• ìë™ ê°ì§€ (ê¸°ë³¸ê°’)
        crawl_details=True,      # ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§ âœ…
        max_detail_pages=3,      # ìµœëŒ€ 3ê°œë§Œ í…ŒìŠ¤íŠ¸
        output_path="output/products_with_details"
    )
    
    print(f"\nì¶”ì¶œëœ ìƒí’ˆ: {len(df)}ê°œ")
    print("\nìƒìœ„ 5ê°œ (ìƒì„¸ ì •ë³´ í¬í•¨):")
    print(df.head())
    
    # ìƒì„¸ ì •ë³´ í•„ë“œ í™•ì¸
    detail_fields = ['category', 'features', 'specifications']
    has_details = any(field in df.columns for field in detail_fields)
    if has_details:
        print("\nâœ… ìƒì„¸ ì •ë³´ í•„ë“œ:")
        for field in detail_fields:
            if field in df.columns:
                print(f"   - {field}")
    else:
        print("\nâš ï¸  ìƒì„¸ ì •ë³´ ì—†ìŒ")


def example_no_llm():
    """LLM ì—†ì´ ì‚¬ìš©í•˜ëŠ” ì˜ˆì œ"""
    print("\n=== LLM ì—†ì´ ì‚¬ìš© (ê·œì¹™ ê¸°ë°˜) ===\n")
    
    url = "https://example.com/products"
    
    crawler = ProductCrawler(
        base_url=url,
        use_llm=False  # LLM ì‚¬ìš© ì•ˆ í•¨
    )
    
    # ì‹¤í–‰
    df = crawler.run(
        url=url,
        infinite_scroll=True,
        scroll_count=10,
        crawl_details=False,
        output_path="output/products_no_llm"
    )
    
    print(f"\nì¶”ì¶œëœ ìƒí’ˆ ë§í¬: {len(df)}ê°œ")


def example_manual_control():
    """ìˆ˜ë™ ì œì–´ ì˜ˆì œ (ìë™ ê°ì§€ í™œìš©)"""
    print("\n=== ìˆ˜ë™ ì œì–´ ì˜ˆì œ (ìë™ ê°ì§€ í™œìš©) ===\n")
    
    url = "https://m.sktuniverse.co.kr/category/sub/tab/detail?ctanId=CC00000012&ctgId=CA00000001"
    
    crawler = ProductCrawler(
        base_url=url,
        use_llm=True,
        model_name="gemini"  # Gemini ëª¨ë¸ ì‚¬ìš© ì˜ˆì‹œ
    )
    
    # 1ë‹¨ê³„: ëª©ë¡ í˜ì´ì§€ë§Œ í¬ë¡¤ë§ (ìë™ ê°ì§€)
    products = crawler.crawl_list_page(
        url, 
        auto_detect=True  # ğŸ†• ìë™ ê°ì§€ ì‚¬ìš©
    )
    print(f"ì¶”ì¶œëœ ìƒí’ˆ: {len(products)}ê°œ")
    
    # 2ë‹¨ê³„: íŠ¹ì • ìƒí’ˆë“¤ë§Œ ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§
    selected_products = products[:3]  # ì²˜ìŒ 3ê°œë§Œ
    products_with_details = crawler.crawl_detail_pages(selected_products)
    
    # 3ë‹¨ê³„: DataFrameìœ¼ë¡œ ì €ì¥
    df = crawler.save_to_dataframe(products_with_details, output_path="output/products_manual")
    
    print(f"\nìµœì¢… ë°ì´í„°: {len(df)}ê°œ")
    print(df.head())


def example_data_analysis():
    """ë°ì´í„° ë¶„ì„ ì˜ˆì œ"""
    print("\n=== ë°ì´í„° ë¶„ì„ ì˜ˆì œ ===\n")
    
    # ì €ì¥ëœ ë°ì´í„° ë¡œë“œ
    df = pd.read_csv("output/products_basic.csv")
    
    print(f"ì´ ìƒí’ˆ ìˆ˜: {len(df)}")
    print(f"\nì»¬ëŸ¼: {list(df.columns)}")
    
    # ê°€ê²©ì´ ìˆëŠ” ìƒí’ˆë§Œ í•„í„°ë§
    if 'price' in df.columns:
        df_with_price = df[df['price'].notna() & (df['price'] != '')]
        print(f"ê°€ê²© ì •ë³´ê°€ ìˆëŠ” ìƒí’ˆ: {len(df_with_price)}ê°œ")
    
    # ìƒì„¸ URLì´ ìˆëŠ” ìƒí’ˆ
    if 'detail_url' in df.columns:
        df_with_url = df[df['detail_url'].notna() & (df['detail_url'] != '')]
        print(f"ìƒì„¸ í˜ì´ì§€ê°€ ìˆëŠ” ìƒí’ˆ: {len(df_with_url)}ê°œ")
    
    # ì´ë¦„ ê¸¸ì´ ë¶„ì„
    if 'name' in df.columns:
        df['name_length'] = df['name'].str.len()
        print(f"\ní‰ê·  ìƒí’ˆëª… ê¸¸ì´: {df['name_length'].mean():.1f}ì")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("="*80)
    print("ìƒí’ˆ/ì„œë¹„ìŠ¤ í¬ë¡¤ëŸ¬ ì˜ˆì œ")
    print("="*80)
    print("\nğŸ†• í˜ì´ì§€ íƒ€ì… ìë™ ê°ì§€ ê¸°ëŠ¥ ì¶”ê°€!")
    print("   - ë¬´í•œ ìŠ¤í¬ë¡¤ / í˜ì´ì§€ë„¤ì´ì…˜ / ë”ë³´ê¸° / ì •ì  í˜ì´ì§€ ìë™ ì¸ì‹")
    print("   - ìµœì  ì „ëµ ìë™ ì ìš© â†’ 2ë°° ë¹ ë¥¸ ì†ë„!")
    print("="*80)
    
    # ì›í•˜ëŠ” ì˜ˆì œì˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”
    
    # ì˜ˆì œ 0: ğŸ†• í˜ì´ì§€ íƒ€ì… ìë™ ê°ì§€ (ê¶Œì¥!)
    example_auto_detect()
    
    # ì˜ˆì œ 1: ê¸°ë³¸ ì‚¬ìš© (ìˆ˜ë™ ì„¤ì •)
    # example_basic()
    
    # ì˜ˆì œ 2: ìƒì„¸ í˜ì´ì§€ í¬í•¨ (ìë™ ê°ì§€)
    # example_with_details()
    
    # ì˜ˆì œ 3: LLM ì—†ì´ ì‚¬ìš©
    # example_no_llm()
    
    # ì˜ˆì œ 4: ìˆ˜ë™ ì œì–´ (ìë™ ê°ì§€ í™œìš©)
    # example_manual_control()
    
    # ì˜ˆì œ 5: ë°ì´í„° ë¶„ì„
    # example_data_analysis()
    
    print("\n" + "="*80)
    print("ì™„ë£Œ!")
    print("="*80 + "\n")


if __name__ == '__main__':
    main()

