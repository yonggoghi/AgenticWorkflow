# Info Builder - ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

## 1ë¶„ ì•ˆì— ì‹œì‘í•˜ê¸°

### 1ë‹¨ê³„: ì„¤ì¹˜ (1ë¶„)

```bash
# ë””ë ‰í† ë¦¬ ì´ë™
cd info_builder

# íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install playwright pandas tqdm langchain-openai langchain

# ë¸Œë¼ìš°ì € ì„¤ì¹˜
playwright install chromium
```

### 2ë‹¨ê³„: API í‚¤ ì„¤ì • (30ì´ˆ)

```bash
# LLM API í‚¤ ì„¤ì •
export LLM_API_KEY="your-api-key-here"
export LLM_API_URL="https://api.openai.com/v1"
```

> ìƒì„¸ ì„¤ì •ì€ [ENV_SETUP.md](ENV_SETUP.md)ë¥¼ ì°¸ê³ í•˜ì„¸ìš”.

### 3ë‹¨ê³„: ì‹¤í–‰! (10ì´ˆ)

```bash
# SKT ìœ ë‹ˆë²„ìŠ¤ ìƒí’ˆ í¬ë¡¤ë§
python product_crawler.py \
  "https://m.sktuniverse.co.kr/category/sub/tab/detail?ctanId=CC00000013&ctgId=CA00000002" \
  --scroll \
  --scroll-count 10 \
  --output my_first_crawl
```

ì™„ë£Œ! ğŸ‰

ê²°ê³¼ íŒŒì¼:
- `my_first_crawl.csv` - Excelì—ì„œ ì—´ê¸°
- `my_first_crawl.json` - í”„ë¡œê·¸ë˜ë° ì‚¬ìš©
- `my_first_crawl.xlsx` - ë¹„ì¦ˆë‹ˆìŠ¤ íŒ€ê³¼ ê³µìœ 

## ì‹¤í–‰ ê²°ê³¼ ì˜ˆì‹œ

```
================================================================================
ìƒí’ˆ/ì„œë¹„ìŠ¤ ì •ë³´ í¬ë¡¤ëŸ¬
================================================================================
URL: https://m.sktuniverse.co.kr/...
LLM: í™œì„±í™” (anthropic)
ë¬´í•œ ìŠ¤í¬ë¡¤: True
ìƒì„¸ í˜ì´ì§€: False
================================================================================

[1ë‹¨ê³„] ëª©ë¡ í˜ì´ì§€ í¬ë¡¤ë§
  í˜ì´ì§€ ë¡œë”©: https://m.sktuniverse.co.kr/...
ë¬´í•œ ìŠ¤í¬ë¡¤ ì‹œì‘ (ìµœëŒ€ 10íšŒ)
  ìŠ¤í¬ë¡¤ 1/10: 8234px â†’ 12456px
  ìŠ¤í¬ë¡¤ 2/10: 12456px â†’ 16789px
  ...
  í…ìŠ¤íŠ¸: 45678 ë¬¸ì
  ë§í¬: 234 ê°œ

[2ë‹¨ê³„] ìƒí’ˆ/ì„œë¹„ìŠ¤ ì •ë³´ ì¶”ì¶œ
  LLMì´ 42ê°œì˜ ìƒí’ˆ/ì„œë¹„ìŠ¤ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.

ì¶”ì¶œëœ ìƒí’ˆ/ì„œë¹„ìŠ¤: 42ê°œ

[4ë‹¨ê³„] ë°ì´í„° ì •ë¦¬ ë° ì €ì¥
  42ê°œì˜ ìƒí’ˆ/ì„œë¹„ìŠ¤ ì •ë³´ë¥¼ ì •ë¦¬í–ˆìŠµë‹ˆë‹¤.
  
  ì»¬ëŸ¼: ['id', 'name', 'description', 'price', 'detail_url']
  CSV ì €ì¥: my_first_crawl.csv
  JSON ì €ì¥: my_first_crawl.json
  Excel ì €ì¥: my_first_crawl.xlsx

================================================================================
í¬ë¡¤ë§ ì™„ë£Œ!
================================================================================
```

## ë°ì´í„° í™•ì¸

### Excelì—ì„œ ì—´ê¸°

```bash
open my_first_crawl.xlsx  # macOS
# ë˜ëŠ”
start my_first_crawl.xlsx  # Windows
# ë˜ëŠ”
xdg-open my_first_crawl.xlsx  # Linux
```

### Pythonì—ì„œ ë¶„ì„

```python
import pandas as pd

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv('my_first_crawl.csv')

# í™•ì¸
print(f"ì´ ìƒí’ˆ: {len(df)}ê°œ")
print(df.head())

# ìƒí’ˆëª…ë§Œ ë³´ê¸°
print(df['name'].tolist())
```

## ë‹¤ìŒ ë‹¨ê³„

### ë” ë§ì€ ì˜µì…˜

```bash
# ìƒì„¸ í˜ì´ì§€ë„ í¬ë¡¤ë§ (ë” ë§ì€ ì •ë³´)
python product_crawler.py "URL" --scroll --details --max-details 10

# LLM ì—†ì´ (ë¬´ë£Œ, í•˜ì§€ë§Œ ì •í™•ë„ ë‚®ìŒ)
python product_crawler.py "URL" --scroll --no-llm

# GPT ì‚¬ìš©
python product_crawler.py "URL" --scroll --llm-provider openai
```

### ë” ì•Œì•„ë³´ê¸°

- **ìƒì„¸ ê°€ì´ë“œ**: [PRODUCT_CRAWLER_GUIDE.md](PRODUCT_CRAWLER_GUIDE.md)
- **ì˜ˆì œ ì½”ë“œ**: `product_crawler_example.py`
- **ì›¹ í¬ë¡¤ëŸ¬**: [WEB_CRAWLER_GUIDE.md](WEB_CRAWLER_GUIDE.md)

## ë¬¸ì œ í•´ê²°

### "LLM API key not found"

```bash
# API í‚¤ ì„¤ì • í™•ì¸
echo $LLM_API_KEY
echo $LLM_API_URL

# ì—†ìœ¼ë©´ ì„¤ì •
export LLM_API_KEY="your-key"
export LLM_API_URL="https://api.openai.com/v1"
```

ìƒì„¸ ì„¤ì •: [ENV_SETUP.md](ENV_SETUP.md)

### "playwright not installed"

```bash
pip install playwright
playwright install chromium
```

### URL ì˜¤ë¥˜

URLì„ ë”°ì˜´í‘œë¡œ ê°ì‹¸ì£¼ì„¸ìš”:

```bash
# âŒ ì˜ëª»ë¨
python product_crawler.py https://example.com?id=1&type=2

# âœ… ì˜¬ë°”ë¦„
python product_crawler.py "https://example.com?id=1&type=2"
```

## ì¶”ê°€ ì˜ˆì œ

### ë‹¤ë¥¸ ì‡¼í•‘ëª° í¬ë¡¤ë§

```bash
# ì˜ˆ: 11ë²ˆê°€ (ì˜ˆì‹œ)
python product_crawler.py \
  "https://m.11st.co.kr/products/..." \
  --scroll \
  --scroll-count 20 \
  --output 11st_products

# ì˜ˆ: ì¿ íŒ¡ (ì˜ˆì‹œ)
python product_crawler.py \
  "https://m.coupang.com/..." \
  --scroll \
  --output coupang_products
```

> **ì£¼ì˜**: ê° ì›¹ì‚¬ì´íŠ¸ì˜ ì´ìš© ì•½ê´€ì„ í™•ì¸í•˜ì„¸ìš”!

### ì—¬ëŸ¬ í˜ì´ì§€ í¬ë¡¤ë§

```python
from product_crawler import ProductCrawler

# URL ë¦¬ìŠ¤íŠ¸
urls = [
    "https://site.com/category/phones",
    "https://site.com/category/tablets",
    "https://site.com/category/laptops"
]

crawler = ProductCrawler(base_url="https://site.com", use_llm=True)

all_products = []
for url in urls:
    products = crawler.crawl_list_page(url, infinite_scroll=True)
    all_products.extend(products)

# ì €ì¥
df = crawler.save_to_dataframe(all_products, output_path="all_products")
print(f"ì´ {len(df)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ!")
```

## ì„±ê³µ! ğŸ‰

ì´ì œ ì–´ë–¤ ì›¹ í˜ì´ì§€ë“  ìƒí’ˆ ì •ë³´ë¥¼ ìë™ìœ¼ë¡œ ìˆ˜ì§‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!

ë‹¤ìŒ ëª©í‘œ:
- [ ] ë‹¤ë¥¸ ì‡¼í•‘ëª° ì‹œë„í•´ë³´ê¸°
- [ ] ìƒì„¸ í˜ì´ì§€ í¬ë¡¤ë§ í•´ë³´ê¸°
- [ ] ë°ì´í„° ë¶„ì„ í•´ë³´ê¸°
- [ ] ìë™í™” ìŠ¤í¬ë¦½íŠ¸ ë§Œë“¤ê¸°

