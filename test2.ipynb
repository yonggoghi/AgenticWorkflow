{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}\n",
            "env: LANGSMITH_TRACING=true\n",
            "env: LANGSMITH_API_KEY=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\n",
            "env: TAVILY_API_KEY=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\n",
            "env: OPENAI_API_KEY=${OPENAI_API_KEY}\n",
            "env: LANGCHAIN_API_KEY=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\n",
            "env: LANGCHAIN_TRACING_V2=true\n",
            "env: LANGCHAIN_PROJECT=\"Multi-agent Collaboration\"\n"
          ]
        }
      ],
      "source": [
        "%set_env ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}",
        "%set_env LANGSMITH_TRACING=true",
        "%set_env LANGSMITH_API_KEY=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",
        "%set_env TAVILY_API_KEY=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",
        "",
        "%set_env OPENAI_API_KEY=${OPENAI_API_KEY}",
        "%set_env LANGCHAIN_API_KEY=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",
        "",
        "%set_env LANGCHAIN_TRACING_V2=true",
        "%set_env LANGCHAIN_PROJECT=\"Multi-agent Collaboration\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yongwook/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import config",
        "# from langchain.chat_models import ChatOpenAI",
        "from langchain_openai import ChatOpenAI",
        "from langchain_anthropic import ChatAnthropic",
        "from langchain.schema import AIMessage, HumanMessage, SystemMessage",
        "",
        "def ChatAnthropicSKT(model=\"anthropic/claude-3-5-sonnet-20240620\"):",
        "    llm_api_key = config.CUSTOM_API_KEY\"https://api.platform.a15t.com/v1\"",
        "",
        "    # model = \"anthropic/claude-3-5-sonnet-20240620\"",
        "",
        "    model = ChatOpenAI(",
        "        temperature=0,  ",
        "        openai_api_key=llm_api_key, ",
        "        openai_api_base=llm_api_url, ",
        "        model=model",
        "        )",
        "    return model",
        "",
        "llm = ChatAnthropicSKT()",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pydantic.v1'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [3], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Annotated, Sequence, TypedDict, List, Optional, Dict, Any\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseMessage, HumanMessage, SystemMessage, AIMessage\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m END, StateGraph, START\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tool\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAgentState\u001b[39;00m(TypedDict):\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langgraph/graph/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m END, START, Graph\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MessageGraph, MessagesState, add_messages\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StateGraph\n\u001b[1;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEND\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSTART\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMessagesState\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m ]\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langgraph/graph/message.py:12\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Annotated, TypedDict, Union\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmessages\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      5\u001b[0m     AnyMessage,\n\u001b[1;32m      6\u001b[0m     MessageLikeRepresentation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     message_chunk_to_message,\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StateGraph\n\u001b[1;32m     14\u001b[0m Messages \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mlist\u001b[39m[MessageLikeRepresentation], MessageLikeRepresentation]\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_messages\u001b[39m(left: Messages, right: Messages) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Messages:\n",
            "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/langgraph/graph/state.py:24\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_model\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpydantic\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mv1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel \u001b[38;5;28;01mas\u001b[39;00m BaseModelV1\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchannels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseChannel\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlanggraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchannels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbinop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BinaryOperatorAggregate\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydantic.v1'"
          ]
        }
      ],
      "source": [
        "import operator\n",
        "from typing import Annotated, Sequence, TypedDict, List, Optional, Dict, Any\n",
        "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, AIMessage\n",
        "from langgraph.graph import END, StateGraph, START\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    messages: Annotated[List[BaseMessage], operator.add]\n",
        "    team_members: List[str]\n",
        "    next: Optional[str]\n",
        "    dataframe_json: str\n",
        "    df_schema: Optional[str]\n",
        "    dataframe_path: str\n",
        "    sql_query: Optional[str]\n",
        "    search_result: Optional[str]\n",
        "\n",
        "from langchain.tools import StructuredTool\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "def create_agent(llm, tools: List[StructuredTool], system_message: str):\n",
        "    \"\"\"Create an agent.\"\"\"\n",
        "\n",
        "    tool_names = [tool.name for tool in tools]\n",
        "    tool_descriptions = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in tools])\n",
        "\n",
        "    prompt = ChatPromptTemplate.from_messages(\n",
        "        [\n",
        "            (\n",
        "                \"system\",\n",
        "                \"You are a helpful AI assistant, collaborating with other assistants.\"\n",
        "                \" Use the provided tools to progress towards answering the question.\"\n",
        "                \" If you are unable to fully answer, that's OK, another assistant with different tools \"\n",
        "                \" will help where you left off. Execute what you can to make progress.\"\n",
        "                \" If you or any of the other assistants have the final answer or deliverable,\"\n",
        "                \" prefix your response with FINAL ANSWER so the team knows to stop.\"\n",
        "                \" You have access to the following tools: {tool_names}.\\n{system_message}\",\n",
        "            ),\n",
        "            MessagesPlaceholder(variable_name=\"messages\"),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    prompt = prompt.partial(system_message=system_message)\n",
        "    prompt = prompt.partial(tool_names=tool_names)\n",
        "    # prompt = prompt.partial(tool_descriptions=tool_descriptions)\n",
        "    return prompt | llm.bind_tools(tools)\n",
        "\n",
        "@tool\n",
        "def check_schema(\n",
        "    dataframe_json: Annotated[str, \"dataframe in JSON format.\"], \n",
        "    dataframe_path: Annotated[str, \"path to the dataframe.\"]\n",
        "):    \n",
        "    \"\"\"\n",
        "    Check the schema of a dataframe.\n",
        "    \n",
        "    Args:\n",
        "        dataframe_json (str): The dataframe in JSON format.\n",
        "        dataframe_path (str): The path to the dataframe.\n",
        "    \n",
        "    Returns:\n",
        "        str: The schema of the dataframe.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"----------------- dataframe_json:\", dataframe_json)\n",
        "    print(\"----------------- dataframe_path:\", dataframe_path)\n",
        "\n",
        "    try:\n",
        "\n",
        "        # If it's a string, try to parse it as JSON\n",
        "        try:\n",
        "            if isinstance(dataframe_json, str):\n",
        "                json_data = json.loads(dataframe_json)\n",
        "            else:\n",
        "                json_data = dataframe_json\n",
        "            \n",
        "            # Create a DataFrame\n",
        "            df = pd.DataFrame(json_data)\n",
        "        except:\n",
        "            df = pd.read_csv(dataframe_path)\n",
        "        \n",
        "        # Get the schema\n",
        "        schema = df.dtypes.to_string()\n",
        "        return f\"DataFrame schema:\\n{schema}\"\n",
        "    except json.JSONDecodeError as e:\n",
        "        error_msg = f\"Error decoding JSON string: {str(e)}\"\n",
        "        return error_msg\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Error checking schema: {str(e)}\"\n",
        "        return error_msg\n",
        "\n",
        "# check_schema_tool = StructuredTool.from_function(\n",
        "#     func=check_schema,\n",
        "#     name=\"check_schema\",\n",
        "#     description=\"Check the schema of a pandas DataFrame\"\n",
        "# )\n",
        "\n",
        "from langchain_core.messages import AIMessage, ToolMessage\n",
        "\n",
        "# Helper function to create a node for a given agent\n",
        "def agent_node(state, agent, name):\n",
        "\n",
        "    print(name, state)\n",
        "\n",
        "    result = agent.invoke(state)\n",
        "\n",
        "    print(result)\n",
        "\n",
        "    output = result[\"output\"]\n",
        "\n",
        "    new_state = state.copy()\n",
        "    new_state[\"messages\"] = state[\"messages\"] + [HumanMessage(content=output, name=name)]\n",
        "    \n",
        "    if name == \"Schema_Analyst\":\n",
        "        new_state[\"df_schema\"] = output if \"DataFrame schema:\" in output else state['df_schema']\n",
        "    elif name == \"SQL_Expert\":\n",
        "        new_state[\"sql_query\"] = output\n",
        "    \n",
        "    return new_state\n",
        "\n",
        "import functools\n",
        "\n",
        "schema_agent = create_agent(llm, [check_schema], \"You are a data analyst specializing in understanding data schemas.\")\n",
        "\n",
        "schema_node = functools.partial(agent_node, agent=schema_agent, name=\"Schema_Analyst\")\n",
        "\n",
        "from langgraph.prebuilt import ToolNode\n",
        "\n",
        "tools = [check_schema]\n",
        "tool_node = ToolNode(tools)\n",
        "\n",
        "# Either agent can decide to end\n",
        "from typing import Literal\n",
        "\n",
        "def router(state) -> Literal[\"call_tool\", \"__end__\", \"continue\"]:\n",
        "    # This is the router\n",
        "    messages = state[\"messages\"]\n",
        "    last_message = messages[-1]\n",
        "    if last_message.tool_calls:\n",
        "        # The previous agent is invoking a tool\n",
        "        return \"call_tool\"\n",
        "    if \"FINAL ANSWER\" in last_message.content:\n",
        "        # Any agent decided the work is done\n",
        "        return \"__end__\"\n",
        "    return \"continue\"\n",
        "\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "workflow.add_node(\"Schema_Analyst\", schema_node)\n",
        "workflow.add_node(\"call_tool\", tool_node)\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"Schema_Analyst\",\n",
        "    router,\n",
        "    {\"continue\": END, \"call_tool\": \"call_tool\", \"__end__\": END},\n",
        ")\n",
        "\n",
        "workflow.add_edge(START, \"Schema_Analyst\")\n",
        "graph = workflow.compile()\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
        "    'Age': [25, 30, 35],\n",
        "    'City': ['New York', 'San Francisco', 'Los Angeles']\n",
        "})\n",
        "\n",
        "initial_state = AgentState(\n",
        "    messages=[HumanMessage(content=\"find the schema of the dataframe\", name=\"Human\")],\n",
        "    team_members=[\n",
        "        \"Schema_Analyst\",\n",
        "        # \"SQL_Expert\", \n",
        "        # \"Data_Scientist\"\n",
        "                  ],\n",
        "    next=None,\n",
        "    dataframe_json=df.to_json(orient='records'),\n",
        "    dataframe_path=\"data/example.csv\",\n",
        "    df_schema=None,\n",
        "    sql_query=None,\n",
        "    search_result=None\n",
        ")\n",
        "\n",
        "i = 0\n",
        "for output in graph.stream(initial_state):\n",
        "    print(\"Workflow output:\", output)\n",
        "    if i > 20:\n",
        "        break\n",
        "    i += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}