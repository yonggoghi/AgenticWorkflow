{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: OPENAI_API_KEY=${OPENAI_API_KEY}\n"
          ]
        }
      ],
      "source": [
        "%set_env OPENAI_API_KEY=${OPENAI_API_KEY}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain_anthropic import ChatAnthropic\n",
        "llm = ChatAnthropic(\n",
        "    api_key=os.getenv(\"ANTHROPIC_API_KEY\"),\n",
        "    model=\"claude-3-7-sonnet-20250219\",\n",
        "    max_tokens=2000\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from neo4j import GraphDatabase\n",
        "from openai import OpenAI\n",
        "import numpy as np\n",
        "\n",
        "# Initialize clients\n",
        "openai_client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "# Neo4j connection\n",
        "uri = \"bolt://localhost:7687\"\n",
        "username = \"neo4j\"\n",
        "password = \"sktelecom\"\n",
        "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
        "\n",
        "class Neo4jVectorExample:\n",
        "    def __init__(self, driver, embedding_model=\"text-embedding-3-small\"):\n",
        "        self.driver = driver\n",
        "        self.embedding_model = embedding_model\n",
        "    \n",
        "    def create_vector_index(self):\n",
        "        \"\"\"Create a vector index for the Chunk nodes\"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            # Create vector index for chunks\n",
        "            session.run(\"\"\"\n",
        "                CREATE VECTOR INDEX chunk_embeddings IF NOT EXISTS\n",
        "                FOR (c:Chunk) ON c.embedding\n",
        "                OPTIONS {\n",
        "                  indexConfig: {\n",
        "                    `vector.dimensions`: 1536,\n",
        "                    `vector.similarity_function`: 'cosine'\n",
        "                  }\n",
        "                }\n",
        "            \"\"\")\n",
        "            \n",
        "            print(\"Vector index created successfully\")\n",
        "    \n",
        "    def generate_embedding(self, text):\n",
        "        \"\"\"Generate an embedding using OpenAI API\"\"\"\n",
        "        response = openai_client.embeddings.create(\n",
        "            input=text,\n",
        "            model=self.embedding_model\n",
        "        )\n",
        "        return response.data[0].embedding\n",
        "    \n",
        "    def add_document_with_chunks(self, title, chunks):\n",
        "        \"\"\"Add a document with chunks to Neo4j\"\"\"\n",
        "        # Generate document embedding from all text\n",
        "        all_text = \" \".join(chunks)\n",
        "        doc_embedding = self.generate_embedding(all_text)\n",
        "        \n",
        "        with self.driver.session() as session:\n",
        "            # Create document node\n",
        "            doc_result = session.run(\"\"\"\n",
        "                CREATE (d:Document {\n",
        "                    title: $title,\n",
        "                    embedding: $embedding\n",
        "                })\n",
        "                RETURN id(d) as doc_id\n",
        "            \"\"\", {\n",
        "                \"title\": title,\n",
        "                \"embedding\": doc_embedding\n",
        "            })\n",
        "            \n",
        "            doc_id = doc_result.single()[\"doc_id\"]\n",
        "            \n",
        "            # Create chunks with embeddings\n",
        "            for i, chunk_text in enumerate(chunks):\n",
        "                # Generate embedding for each chunk\n",
        "                chunk_embedding = self.generate_embedding(chunk_text)\n",
        "                \n",
        "                # Create chunk node and relationship to document\n",
        "                session.run(\"\"\"\n",
        "                    MATCH (d:Document) WHERE id(d) = $doc_id\n",
        "                    CREATE (c:Chunk {\n",
        "                        text: $text,\n",
        "                        position: $position,\n",
        "                        embedding: $embedding\n",
        "                    })\n",
        "                    CREATE (c)-[:CONTAINED_IN]->(d)\n",
        "                \"\"\", {\n",
        "                    \"doc_id\": doc_id,\n",
        "                    \"text\": chunk_text,\n",
        "                    \"position\": i,\n",
        "                    \"embedding\": chunk_embedding\n",
        "                })\n",
        "            \n",
        "            print(f\"Added document '{title}' with {len(chunks)} chunks\")\n",
        "    \n",
        "    def vector_search(self, query_text, k=5):\n",
        "        \"\"\"Perform vector similarity search\"\"\"\n",
        "        # Generate embedding for query\n",
        "        query_embedding = self.generate_embedding(query_text)\n",
        "        \n",
        "        with self.driver.session() as session:\n",
        "            # Vector search using the index\n",
        "            result = session.run(\"\"\"\n",
        "                // Vector similarity search on chunks\n",
        "                CALL db.index.vector.queryNodes('chunk_embeddings', $k, $embedding)\n",
        "                YIELD node, score\n",
        "                \n",
        "                // Get document info\n",
        "                MATCH (node)-[:CONTAINED_IN]->(doc:Document)\n",
        "                \n",
        "                RETURN \n",
        "                    doc.title AS document_title,\n",
        "                    node.text AS chunk_text,\n",
        "                    score AS similarity\n",
        "                ORDER BY similarity DESC\n",
        "            \"\"\", {\n",
        "                \"embedding\": query_embedding,\n",
        "                \"k\": k\n",
        "            })\n",
        "            \n",
        "            # Process results\n",
        "            results = []\n",
        "            for record in result:\n",
        "                results.append({\n",
        "                    \"document\": record[\"document_title\"],\n",
        "                    \"chunk\": record[\"chunk_text\"],\n",
        "                    \"similarity\": record[\"similarity\"]\n",
        "                })\n",
        "            \n",
        "            return results\n",
        "\n",
        "\n",
        "example = Neo4jVectorExample(driver)\n",
        "\n",
        "# # 1. Create vector index\n",
        "# example.create_vector_index()\n",
        "\n",
        "# # 2. Add sample document with chunks\n",
        "# sample_doc = \"Introduction to Graph Databases\"\n",
        "# sample_chunks = [\n",
        "#     \"A graph database is a database that uses graph structures for semantic queries with nodes, edges, and properties to represent and store data.\",\n",
        "#     \"Neo4j is a graph database management system developed by Neo4j, Inc. It is a native graph database that uses a property graph data model.\",\n",
        "#     \"Vector search in Neo4j combines the power of graph relationships with vector similarity for more contextual retrieval.\",\n",
        "#     \"Graph-based RAG systems can leverage both semantic similarity and explicit relationships between document chunks.\"\n",
        "# ]\n",
        "# example.add_document_with_chunks(sample_doc, sample_chunks)\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Search Results for: How can I use vector search with graphs?\n",
            "------------------------------------------------------------\n",
            "1. Document: Introduction to Graph Databases\n",
            "   Chunk: Vector search in Neo4j combines the power of graph relationships with vector similarity for more contextual retrieval.\n",
            "   Similarity: 0.8459\n",
            "\n",
            "2. Document: Introduction to Graph Databases\n",
            "   Chunk: A graph database is a database that uses graph structures for semantic queries with nodes, edges, and properties to represent and store data.\n",
            "   Similarity: 0.7191\n",
            "\n",
            "3. Document: Introduction to Graph Databases\n",
            "   Chunk: Graph-based RAG systems can leverage both semantic similarity and explicit relationships between document chunks.\n",
            "   Similarity: 0.6808\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 3. Perform vector search\n",
        "user_query = \"How can I use vector search with graphs?\"\n",
        "context = example.vector_search(user_query, k=3)\n",
        "\n",
        "prompt = f\"\"\"\n",
        "    Based on the following information, please answer the user's question:\n",
        "    \n",
        "    CONTEXT:\n",
        "    {context}\n",
        "    \n",
        "    USER QUESTION: {user_query}\n",
        "    \n",
        "    Answer the question using only the provided context. If you cannot answer from the context, say so.\n",
        "    \"\"\"\n",
        "\n",
        "# 4. Display results\n",
        "print(\"\\nSearch Results for:\", user_query)\n",
        "print(\"-\" * 60)\n",
        "for i, result in enumerate(context, 1):\n",
        "    print(f\"{i}. Document: {result['document']}\")\n",
        "    print(f\"   Chunk: {result['chunk']}\")\n",
        "    print(f\"   Similarity: {result['similarity']:.4f}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# Vector Search with Graphs\n",
            "\n",
            "Vector search can be combined with graph database techniques to create powerful search and recommendation systems. Here are ways to integrate these approaches:\n",
            "\n",
            "## Key Implementation Approaches\n",
            "\n",
            "1. **Hybrid Search Architecture**\n",
            "   - Use vector search for semantic similarity matching\n",
            "   - Use graph traversal for relationship-based queries\n",
            "   - Combine results for more contextually relevant answers\n",
            "\n",
            "2. **Knowledge Graphs with Vector Embeddings**\n",
            "   - Store vector embeddings as properties on graph nodes\n",
            "   - Perform vector similarity search to find entry points\n",
            "   - Use graph traversal to explore connected entities\n",
            "\n",
            "3. **Graph Neural Networks (GNNs)**\n",
            "   - Generate node embeddings that incorporate both content and structural information\n",
            "   - Allows for similarity search that considers graph topology\n",
            "\n",
            "## Practical Implementation Strategies\n",
            "\n",
            "- **Two-Stage Query Processing**:\n",
            "  ```\n",
            "  1. Find relevant nodes via vector similarity search\n",
            "  2. Explore graph connections from these starting points\n",
            "  ```\n",
            "\n",
            "- **GraphQL + Vector Search**: Extend GraphQL queries with vector similarity parameters\n",
            "\n",
            "- **Tools/Libraries**:\n",
            "  - Neo4j with vector index capabilities\n",
            "  - Amazon Neptune with vector search\n",
            "  - TigerGraph with vector search extension\n",
            "  - Specialized platforms like Pinecone or Weaviate that offer graph contexts\n",
            "\n",
            "Would you like more details on any specific aspect of implementing vector search with graphs?\n"
          ]
        }
      ],
      "source": [
        "print(llm.invoke(user_query).content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the provided context, vector search in Neo4j combines the power of graph relationships with vector similarity to enable more contextual retrieval. Graph-based RAG (Retrieval Augmented Generation) systems can leverage both semantic similarity and explicit relationships between document chunks. This suggests that when using vector search with graphs, you can benefit from both the semantic similarity capabilities of vector search and the relational structure that graphs provide, resulting in more contextually relevant retrieval of information.\n",
            "\n",
            "The context doesn't provide specific implementation details or step-by-step instructions on how to use vector search with graphs.\n"
          ]
        }
      ],
      "source": [
        "print(llm.invoke(prompt).content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}