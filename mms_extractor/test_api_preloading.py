#!/usr/bin/env python3
"""
Test script to demonstrate API preloading functionality.
This script shows how preloading improves API response times.
"""

import requests
import time
import json

def test_api_endpoint(url, description):
    """Test an API endpoint and measure response time."""
    print(f"\nğŸ§ª Testing: {description}")
    print(f"ğŸ“¡ URL: {url}")
    
    try:
        start_time = time.time()
        response = requests.get(url, timeout=10)
        response_time = time.time() - start_time
        
        if response.status_code == 200:
            print(f"âœ… SUCCESS ({response.status_code}) - Response time: {response_time:.2f}s")
            return response.json(), response_time
        else:
            print(f"âŒ FAILED ({response.status_code}) - Response time: {response_time:.2f}s")
            return None, response_time
            
    except requests.exceptions.ConnectionError:
        print("âŒ FAILED - API server not running")
        return None, 0
    except requests.exceptions.Timeout:
        print("âŒ TIMEOUT - Request took too long")
        return None, 10
    except Exception as e:
        print(f"âŒ ERROR - {e}")
        return None, 0

def test_extraction(message, extraction_mode="nlp"):
    """Test message extraction and measure response time."""
    url = "http://localhost:8080/extract"
    
    print(f"\nğŸ” Testing Extraction: {extraction_mode} mode")
    print(f"ğŸ“ Message: {message[:50]}...")
    
    data = {
        "message": message,
        "model": "gemma_3",
        "extraction_mode": extraction_mode
    }
    
    try:
        start_time = time.time()
        response = requests.post(url, json=data, timeout=30)
        response_time = time.time() - start_time
        
        if response.status_code == 200:
            result = response.json()
            processing_time = result.get('metadata', {}).get('processing_time_seconds', 0)
            print(f"âœ… SUCCESS - Total time: {response_time:.2f}s, Processing: {processing_time:.2f}s")
            
            # Show extracted products
            products = result.get('result', {}).get('product', [])
            if products:
                print(f"ğŸ¯ Extracted {len(products)} products:")
                for product in products[:3]:  # Show first 3
                    name = product.get('item_name_in_msg', 'Unknown')
                    print(f"   â€¢ {name}")
            else:
                print("ğŸ¯ No products extracted")
                
            return result, response_time
        else:
            print(f"âŒ FAILED ({response.status_code}) - Response time: {response_time:.2f}s")
            print(f"Response: {response.text}")
            return None, response_time
            
    except requests.exceptions.ConnectionError:
        print("âŒ FAILED - API server not running")
        return None, 0
    except requests.exceptions.Timeout:
        print("âŒ TIMEOUT - Request took too long (>30s)")
        return None, 30
    except Exception as e:
        print(f"âŒ ERROR - {e}")
        return None, 0

def main():
    """Main test function."""
    print("ğŸš€ MMS Extractor API Preloading Test")
    print("=" * 60)
    
    # Test health check
    health_data, health_time = test_api_endpoint(
        "http://localhost:8080/health", 
        "Health Check"
    )
    
    if not health_data:
        print("\nâŒ API server is not running. Please start it with:")
        print("   python api.py --model-loading-mode local --port 8080")
        return
    
    # Test status endpoint
    status_data, status_time = test_api_endpoint(
        "http://localhost:8080/status", 
        "Status Check (shows preloaded models)"
    )
    
    if status_data:
        extractors = status_data.get('preloaded_extractors', {})
        count = extractors.get('count', 0)
        print(f"ğŸ“Š Preloaded extractors: {count}")
        
        if count > 0:
            details = extractors.get('details', {})
            for key in details.keys():
                print(f"   â€¢ {key}")
        else:
            print("âš ï¸  No extractors preloaded")
    
    # Test model info
    model_data, model_time = test_api_endpoint(
        "http://localhost:8080/model-info",
        "Model Information"
    )
    
    if model_data:
        config = model_data.get('embedding_model_config', {})
        loading_mode = config.get('loading_mode', 'unknown')
        print(f"ğŸ”§ Model loading mode: {loading_mode}")
        
        status = model_data.get('model_status', {})
        if isinstance(status, dict):
            model_loaded = status.get('model_loaded', False)
            device = status.get('device', 'unknown')
            print(f"ğŸ“ Model loaded: {model_loaded}, Device: {device}")
    
    # Test extraction (this should be fast if preloaded)
    test_message = "ê´‘ê³  ì œëª©:[SKí…”ë ˆì½¤] 2ì›” 0 day í˜œíƒ ì•ˆë‚´ - ë² ì–´ìœ  ëª¨ë“  ê°•ì˜ 14ì¼ ë¬´ë£Œ ìˆ˜ê°• ì¿ í° ë“œë¦½ë‹ˆë‹¤!"
    
    extraction_result, extraction_time = test_extraction(test_message, "nlp")
    
    # Summary
    print("\n" + "=" * 60)
    print("ğŸ“ˆ PERFORMANCE SUMMARY")
    print("=" * 60)
    print(f"Health check:     {health_time:.2f}s")
    print(f"Status check:     {status_time:.2f}s") 
    print(f"Model info:       {model_time:.2f}s")
    print(f"Extraction (NLP): {extraction_time:.2f}s")
    
    total_time = health_time + status_time + model_time + extraction_time
    print(f"Total test time:  {total_time:.2f}s")
    
    # Analysis
    print("\nğŸ’¡ ANALYSIS:")
    if extraction_time < 15:
        print("âœ… Excellent performance! Models are preloaded.")
        print("   First extraction request was fast (<15s)")
    elif extraction_time < 30:
        print("âš ï¸  Good performance, but could be better.")
        print("   Consider using --preload-all-modes for faster mode switching")
    else:
        print("ğŸŒ Slow performance detected.")
        print("   Models might not be preloaded. Check server startup logs.")
    
    print("\nğŸ”§ TIPS:")
    print("â€¢ For fastest API responses: Use default preloading")
    print("â€¢ For development: Use --no-preload for faster server restarts")
    print("â€¢ For production: Keep preloading enabled")

if __name__ == "__main__":
    main() 