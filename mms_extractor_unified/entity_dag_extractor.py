from concurrent.futures import ThreadPoolExecutor
import time
import logging
from langchain_anthropic import ChatAnthropic
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import JsonOutputParser
import json
import re
import pandas as pd
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
from langchain.schema import AIMessage, HumanMessage, SystemMessage
from openai import OpenAI
from typing import List, Tuple, Union, Dict, Any, Optional, Set
import ast
from rapidfuzz import fuzz, process
import glob
import os
from config import settings
import networkx as nx
import random
from utils import create_dag_diagram, sha256_hash

llm_api_key = settings.API_CONFIG.llm_api_key
llm_api_url = settings.API_CONFIG.llm_api_url
client = OpenAI(
    api_key = llm_api_key,
    base_url = llm_api_url
)

# LLM ëª¨ë¸ ì„¤ì •
llm_gem = ChatOpenAI(
        temperature=0,
        openai_api_key=llm_api_key,
        openai_api_base=llm_api_url,
        model=settings.ModelConfig.gemma_model,
        max_tokens=settings.ModelConfig.llm_max_tokens
        )

llm_ax = ChatOpenAI(
        temperature=0,
        openai_api_key=llm_api_key,
        openai_api_base=llm_api_url,
        model=settings.ModelConfig.ax_model,
        max_tokens=settings.ModelConfig.llm_max_tokens
        )

llm_cld = ChatOpenAI(
        temperature=0,
        openai_api_key=llm_api_key,
        openai_api_base=llm_api_url,
        model=settings.ModelConfig.claude_model,
        max_tokens=settings.ModelConfig.llm_max_tokens
        )

llm_gen = ChatOpenAI(
        temperature=0,
        openai_api_key=llm_api_key,
        openai_api_base=llm_api_url,
        model=settings.ModelConfig.gemini_model,
        max_tokens=settings.ModelConfig.llm_max_tokens
        )

llm_gpt = ChatOpenAI(
        temperature=0,
        openai_api_key=llm_api_key,
        openai_api_base=llm_api_url,
        model=settings.ModelConfig.gpt_model,
        max_tokens=settings.ModelConfig.llm_max_tokens
        )

stop_item_names = pd.read_csv(settings.METADATA_CONFIG.stop_items_path)['stop_words'].to_list()
mms_pdf = pd.read_csv(settings.METADATA_CONFIG.mms_msg_path)
mms_pdf = mms_pdf.astype('str')

###############################################################################
# 1) ê¸°ì¡´ ì •ê·œì‹ ë° íŒŒì„œ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
###############################################################################
PAT = re.compile(r"\((.*?)\)\s*-\[(.*?)\]->\s*\((.*?)\)")
NODE_ONLY = re.compile(r"\((.*?)\)\s*$")

def parse_block(text: str):
    nodes: Set[str] = set()
    edges: List[Tuple[str,str,str]] = []
    for line in filter(None, map(str.strip, text.splitlines())):
        m = PAT.match(line)
        if m:                            # (A) -[rel]-> (B)
            src, rel, dst = map(str.strip, m.groups())
            nodes.update([src, dst])
            edges.append((src, dst, rel))
            continue

        m2 = NODE_ONLY.match(line)       # (A:B:C)
        if m2:                           # â† ë…ë¦½ ë…¸ë“œ
            nodes.add(m2.group(1).strip())
            continue

        raise ValueError(f"ëª»ì½ì€ ë¼ì¸:\n  {line}")
    return list(nodes), edges

###############################################################################
# 2) ê°œì„ ëœ ë…¸ë“œ ìŠ¤í”Œë¦¬í„° â€“ ìœ ì—°í•œ íŒŒíŠ¸ ì²˜ë¦¬
###############################################################################
def split_node(raw: str) -> Dict[str,str]:
    parts = [p.strip() for p in raw.split(":")]
    
    if len(parts) == 1:                       # entity only
        ent, act, kpi = parts[0], "", ""
    elif len(parts) == 2:                     # entity:metric
        ent, act = parts
        kpi = ""
    elif len(parts) == 3:                     # entity:action:metric
        ent, act, kpi = parts
    elif len(parts) == 4:                     # entity:action:behavior:metric
        ent, act, behavior, kpi = parts
        # Combine action and behavior, or handle separately
        act = f"{act}:{behavior}"  # Option 1: combine them
        # Or you could add a new field:
        # return {"entity": ent, "action": act, "behavior": behavior, "metric": kpi}
    elif len(parts) >= 5:                     # Handle even more parts flexibly
        ent = parts[0]
        kpi = parts[-1]  # Last part is usually the metric
        act = ":".join(parts[1:-1])  # Everything in between becomes action
    else:
        # This shouldn't happen with len(parts) >= 1, but just in case
        raise ValueError(f"ì•Œ ìˆ˜ ì—†ëŠ” ë…¸ë“œ í˜•ì‹: {raw}")
    
    return {"entity": ent, "action": act, "metric": kpi}

###############################################################################
# 3) ê¸°ì¡´ DAG ë¹Œë” (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
###############################################################################
def build_dag(nodes: List[str], edges: List[Tuple[str,str,str]]) -> nx.DiGraph:
    g = nx.DiGraph()
    
    # Add nodes with error handling
    for n in nodes:
        try:
            node_attrs = split_node(n)
            g.add_node(n, **node_attrs)
        except ValueError as e:
            print(f"Warning: {e}")
            # Add node with minimal attributes if parsing fails
            g.add_node(n, entity=n, action="", metric="")
    
    # Add edges
    for src, dst, rel in edges:
        g.add_edge(src, dst, relation=rel)
    
    return g

###############################################################################
# 4) ê¸°ì¡´ Path Finder (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
###############################################################################
def get_root_to_leaf_paths(dag):
    """Generate all paths from root nodes (no predecessors) to leaf nodes (no successors)"""
    # Find root nodes (no incoming edges)
    root_nodes = [node for node in dag.nodes() if dag.in_degree(node) == 0]
    
    # Find leaf nodes (no outgoing edges)
    leaf_nodes = [node for node in dag.nodes() if dag.out_degree(node) == 0]
    
    all_paths = []
    for root in root_nodes:
        for leaf in leaf_nodes:
            try:
                paths = list(nx.all_simple_paths(dag, root, leaf))
                all_paths.extend(paths)
            except nx.NetworkXNoPath:
                continue
    
    return all_paths, root_nodes, leaf_nodes

###############################################################################
# 5) ìƒˆë¡œìš´ ê°œì„ ëœ DAGParser í´ë˜ìŠ¤
###############################################################################
class DAGParser:
    """
    DAG íŒŒì‹± í´ë˜ìŠ¤
    
    LLMì´ ìƒì„±í•œ DAG í…ìŠ¤íŠ¸ë¥¼ NetworkX ê·¸ë˜í”„ ê°ì²´ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    ì£¼ìš” ê¸°ëŠ¥:
    - LLM ì‘ë‹µì—ì„œ DAG ì„¹ì…˜ ì¶”ì¶œ
    - DAG í…ìŠ¤íŠ¸ë¥¼ NetworkX DiGraphë¡œ íŒŒì‹±
    - ë…¸ë“œì™€ ì—£ì§€ ê´€ê³„ ë¶„ì„
    
    ì§€ì›í•˜ëŠ” DAG í˜•ì‹:
    - ì—£ì§€: (ì—”í‹°í‹°:í–‰ë™) -[ê´€ê³„ë™ì‚¬]-> (ì—”í‹°í‹°:í–‰ë™)
    - ë…ë¦½ ë…¸ë“œ: (ì—”í‹°í‹°:í–‰ë™)
    """
    
    def __init__(self):
        # ê°œì„ ëœ ì •ê·œí‘œí˜„ì‹ íŒ¨í„´ - ê´€ê³„ ë¶€ë¶„ì— ì‰¼í‘œì™€ ê³µë°± í—ˆìš©
        # ê´€ê³„ ë¶€ë¶„([...])ì— ëª¨ë“  ë¬¸ì í—ˆìš© (]ë¥¼ ì œì™¸í•˜ê³ )
        self.edge_pattern = r'\(([^:)]+):([^)]+)\)\s*-\[([^\]]+)\]->\s*\(([^:)]+):([^)]+)\)'
        # ë…ë¦½í˜• ë…¸ë“œ íŒ¨í„´ ì¶”ê°€
        self.standalone_node_pattern = r'\(([^:)]+):([^)]+)\)\s*$'
        # ì„¹ì…˜ íŒ¨í„´ ìˆ˜ì •: ## ë˜ëŠ” ###ë¡œ ì‹œì‘í•˜ëŠ” 2. ì¶”ì¶œëœ DAG ì„¹ì…˜
        self.section_pattern = r'#{2,3}\s*2\.\s*ì¶”ì¶œëœ\s*DAG'
        
    def parse_dag_line(self, line: str) -> Optional[Union[Tuple[str, str, str, str, str], Tuple[str, str]]]:
        """ë‹¨ì¼ DAG ë¼ì¸ì„ íŒŒì‹±í•˜ì—¬ êµ¬ì„± ìš”ì†Œ ë°˜í™˜"""
        # ë¨¼ì € ì—£ì§€ íŒ¨í„´ í™•ì¸
        edge_match = re.match(self.edge_pattern, line)
        if edge_match:
            return (
                edge_match.group(1).strip(),  # src_entity
                edge_match.group(2).strip(),  # src_action
                edge_match.group(3).strip(),  # relation (ì‰¼í‘œ, ì¡°ê±´ í¬í•¨ ê°€ëŠ¥)
                edge_match.group(4).strip(),  # dst_entity
                edge_match.group(5).strip()   # dst_action
            )
        
        # ë…ë¦½í˜• ë…¸ë“œ íŒ¨í„´ í™•ì¸
        standalone_match = re.match(self.standalone_node_pattern, line)
        if standalone_match:
            return (
                standalone_match.group(1).strip(),  # entity
                standalone_match.group(2).strip()   # action
            )
        
        return None
        
    def extract_dag_section(self, full_text: str) -> str:
        """ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ DAG ì„¹ì…˜ë§Œ ì¶”ì¶œ"""
        lines = full_text.split('\n')
        
        # ë” ìœ ì—°í•œ DAG ì„¹ì…˜ ì°¾ê¸°
        dag_section_patterns = [
            r'#{2,3}\s*ìµœì¢…\s*DAG',            # ìµœì¢… DAG
            r'#{2,3}\s*4\.\s*ìˆ˜ì •ëœ\s*DAG',    # 4. ìˆ˜ì •ëœ DAG ìµœìš°ì„ 
            r'#{2,3}\s*ìˆ˜ì •ëœ\s*DAG',          # ìˆ˜ì •ëœ DAG
            r'#{2,3}\s*2\.\s*ì¶”ì¶œëœ\s*DAG',    # 2. ì¶”ì¶œëœ DAG (ê¸°ë³¸)
            r'#{2,3}\s*DAG',
            r'ì¶”ì¶œëœ\s*DAG',
            r'2\.\s*ì¶”ì¶œëœ\s*DAG'
        ]
        
        # DAG ì„¹ì…˜ ì°¾ê¸°
        start_idx = -1
        end_idx = len(lines)
        in_dag_section = False
        in_code_block = False
        
        # íŒ¨í„´ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹œë„
        for pattern in dag_section_patterns:
            for i, line in enumerate(lines):
                if re.search(pattern, line, re.IGNORECASE):
                    in_dag_section = True
                    
                    # DAG í—¤ë” ë‹¤ìŒì—ì„œ ``` ì°¾ê¸° (ë¹ˆ ì¤„ì´ ìˆì–´ë„ ê´œì°®ìŒ)
                    code_block_found = False
                    for j in range(i + 1, min(i + 4, len(lines))):  # ìµœëŒ€ 3ì¤„ê¹Œì§€ í™•ì¸
                        next_line = lines[j].strip()
                        if next_line == '```':
                            start_idx = j + 1
                            in_code_block = True
                            code_block_found = True
                            break
                        elif next_line and not next_line == '':  # ë¹ˆ ì¤„ì´ ì•„ë‹Œ ë‹¤ë¥¸ ë‚´ìš©ì´ ë‚˜ì˜¤ë©´ ì¤‘ë‹¨
                            # DAG íŒ¨í„´ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì¤„ì´ë©´ ì½”ë“œë¸”ë¡ ì—†ì´ ì‹œì‘
                            if (re.match(self.edge_pattern, next_line) or 
                                re.match(self.standalone_node_pattern, next_line)):
                                start_idx = j
                                in_code_block = False
                                code_block_found = True
                                break
                            else:
                                break
                    
                    # ì½”ë“œë¸”ë¡ì„ ì°¾ì§€ ëª»í–ˆë‹¤ë©´ í—¤ë” ë‹¤ìŒ ì¤„ë¶€í„° ì‹œì‘
                    if not code_block_found:
                        start_idx = i + 1
                        in_code_block = False
                    
                    break
            if start_idx != -1:
                break
        
        # DAG ì„¹ì…˜ ì¢…ë£Œ ì¡°ê±´ ì°¾ê¸°
        if start_idx != -1:
            for i in range(start_idx, len(lines)):
                line = lines[i]
                if in_code_block and line.strip() == '```':
                    end_idx = i
                    break
                elif not in_code_block and re.match(r'#{2,3}\s*[3-9]\.', line):  # 3ë²ˆ ì´ìƒ ì„¹ì…˜ì—ì„œ ì¢…ë£Œ
                    end_idx = i
                    break
        
        if start_idx == -1:
            # ì„¹ì…˜ í—¤ë”ê°€ ì—†ëŠ” ê²½ìš°, DAG íŒ¨í„´ì„ ì§ì ‘ ì°¾ê¸°
            dag_lines = []
            for line in lines:
                if (re.match(self.edge_pattern, line) or 
                    re.match(self.standalone_node_pattern, line) or 
                    line.strip().startswith('#')):
                    dag_lines.append(line)
            
            if dag_lines:
                result = '\n'.join(dag_lines)
                return result
            else:
                raise ValueError("DAG ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        result = '\n'.join(lines[start_idx:end_idx])
        return result
    
    def parse_dag(self, dag_text: str) -> nx.DiGraph:
        """DAG í…ìŠ¤íŠ¸ë¥¼ NetworkX DiGraphë¡œ ë³€í™˜"""
        G = nx.DiGraph()
        
        # í†µê³„ ì •ë³´ ì €ì¥
        stats = {
            'total_edges': 0,
            'comment_lines': 0,
            'empty_lines': 0,
            'paths': [],
            'parse_errors': [],
            'parsed_lines': []
        }
        
        current_path = None
        
        for line_num, line in enumerate(dag_text.strip().split('\n'), 1):
            line = line.strip()
            
            # ë¹ˆ ë¼ì¸ ì²˜ë¦¬
            if not line:
                stats['empty_lines'] += 1
                continue
            
            # ì£¼ì„ ë¼ì¸ ì²˜ë¦¬ (ê²½ë¡œ ì •ë³´ ì¶”ì¶œ)
            if line.startswith('#'):
                stats['comment_lines'] += 1
                current_path = line[1:].strip()
                if current_path:
                    stats['paths'].append(current_path)
                continue
            
            # DAG ì—£ì§€ ë˜ëŠ” ë…ë¦½í˜• ë…¸ë“œ íŒŒì‹±
            parsed = self.parse_dag_line(line)
            if parsed:
                try:
                    if len(parsed) == 5:  # ì—£ì§€ (src_entity, src_action, relation, dst_entity, dst_action)
                        src_entity, src_action, relation, dst_entity, dst_action = parsed
                        
                        # ë…¸ë“œ ID ìƒì„±
                        src_node = f"{src_entity}:{src_action}"
                        dst_node = f"{dst_entity}:{dst_action}"
                        
                        # ë…¸ë“œ ì¶”ê°€ (ì†ì„± í¬í•¨)
                        G.add_node(src_node, 
                                  entity=src_entity, 
                                  action=src_action,
                                  path=current_path)
                        G.add_node(dst_node, 
                                  entity=dst_entity, 
                                  action=dst_action,
                                  path=current_path)
                        
                        # ì—£ì§€ ì¶”ê°€ (ê´€ê³„ì— ì‰¼í‘œë‚˜ ì¡°ê±´ì´ í¬í•¨ë  ìˆ˜ ìˆìŒ)
                        G.add_edge(src_node, dst_node, 
                                  relation=relation,
                                  path=current_path)
                        
                        stats['total_edges'] += 1
                        stats['parsed_lines'].append(f"Line {line_num}: {src_node} -[{relation}]-> {dst_node}")
                        
                    elif len(parsed) == 2:  # ë…ë¦½í˜• ë…¸ë“œ (entity, action)
                        entity, action = parsed
                        
                        # ë…¸ë“œ ID ìƒì„±
                        node_id = f"{entity}:{action}"
                        
                        # ë…ë¦½í˜• ë…¸ë“œ ì¶”ê°€
                        G.add_node(node_id, 
                                  entity=entity, 
                                  action=action,
                                  path=current_path)
                        
                        stats['parsed_lines'].append(f"Line {line_num}: Standalone node {node_id}")
                    
                except Exception as e:
                    stats['parse_errors'].append(f"Line {line_num}: {str(e)}")
            else:
                # íŒŒì‹± ì‹¤íŒ¨í•œ ë¼ì¸ ê¸°ë¡ (ì£¼ì„ì´ ì•„ë‹Œ ê²½ìš°ë§Œ)
                if not line.startswith('#') and line.strip():
                    stats['parse_errors'].append(f"Line {line_num}: íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ - {line[:80]}...")
        
        # ê·¸ë˜í”„ì— í†µê³„ ì •ë³´ ì €ì¥
        G.graph['stats'] = stats
        
        return G
    
    def get_root_nodes(self, G: nx.DiGraph) -> List[str]:
        """Root ë…¸ë“œ(ë“¤ì–´ì˜¤ëŠ” ì—£ì§€ê°€ ì—†ëŠ” ë…¸ë“œ) ì°¾ê¸°"""
        return [node for node in G.nodes() if G.in_degree(node) == 0]
    
    def get_leaf_nodes(self, G: nx.DiGraph) -> List[str]:
        """Leaf ë…¸ë“œ(ë‚˜ê°€ëŠ” ì—£ì§€ê°€ ì—†ëŠ” ë…¸ë“œ) ì°¾ê¸°"""
        return [node for node in G.nodes() if G.out_degree(node) == 0]
    
    def get_paths_from_root_to_leaf(self, G: nx.DiGraph) -> List[List[str]]:
        """Rootì—ì„œ Leafê¹Œì§€ì˜ ëª¨ë“  ê²½ë¡œ ì°¾ê¸°"""
        roots = self.get_root_nodes(G)
        leaves = self.get_leaf_nodes(G)
        
        all_paths = []
        for root in roots:
            for leaf in leaves:
                try:
                    paths = list(nx.all_simple_paths(G, root, leaf))
                    all_paths.extend(paths)
                except nx.NetworkXNoPath:
                    continue
        
        return all_paths
    
    def analyze_graph(self, G: nx.DiGraph) -> Dict:
        """ê·¸ë˜í”„ ë¶„ì„ ì •ë³´ ìƒì„±"""
        analysis = {
            'num_nodes': G.number_of_nodes(),
            'num_edges': G.number_of_edges(),
            'root_nodes': self.get_root_nodes(G),
            'leaf_nodes': self.get_leaf_nodes(G),
            'is_dag': nx.is_directed_acyclic_graph(G),
            'num_components': nx.number_weakly_connected_components(G),
            'paths_info': G.graph.get('stats', {}).get('paths', []),
            'longest_path_length': 0
        }
        
        # ìµœì¥ ê²½ë¡œ ì°¾ê¸°
        if analysis['is_dag'] and G.number_of_nodes() > 0:
            try:
                longest = nx.dag_longest_path(G)
                analysis['longest_path_length'] = len(longest) - 1 if longest else 0
            except:
                analysis['longest_path_length'] = 0
        
        return analysis
    
    def to_json(self, G: nx.DiGraph) -> str:
        """ê·¸ë˜í”„ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        data = {
            'nodes': [
                {
                    'id': node,
                    'entity': G.nodes[node].get('entity', ''),
                    'action': G.nodes[node].get('action', ''),
                    'path': G.nodes[node].get('path', '')
                }
                for node in G.nodes()
            ],
            'edges': [
                {
                    'source': edge[0],
                    'target': edge[1],
                    'relation': G.edges[edge].get('relation', ''),
                    'path': G.edges[edge].get('path', '')
                }
                for edge in G.edges()
            ],
            'analysis': self.analyze_graph(G)
        }
        return json.dumps(data, ensure_ascii=False, indent=2)
    
    def visualize_paths(self, G: nx.DiGraph) -> str:
        """ê²½ë¡œë³„ë¡œ êµ¬ì¡°í™”ëœ í…ìŠ¤íŠ¸ ì¶œë ¥"""
        output = []
        paths_dict = {}
        
        # ê²½ë¡œë³„ë¡œ ì—£ì§€ ê·¸ë£¹í™”
        for edge in G.edges():
            path = G.edges[edge].get('path', 'Unknown')
            if path not in paths_dict:
                paths_dict[path] = []
            paths_dict[path].append(edge)
        
        # ê²½ë¡œë³„ ì¶œë ¥
        for path, edges in paths_dict.items():
            if path and path != 'Unknown':
                output.append(f"\n[{path}]")
            for edge in edges:
                relation = G.edges[edge].get('relation', '')
                output.append(f"  {edge[0]} -{relation}-> {edge[1]}")
        
        return '\n'.join(output)


def extract_dag(parser:DAGParser, msg: str, llm_model):
    """
    DAG ì¶”ì¶œ ë©”ì¸ í•¨ìˆ˜
    
    ë©”ì‹œì§€ì—ì„œ ì—”í‹°í‹° ê°„ì˜ ê´€ê³„ë¥¼ DAG(Directed Acyclic Graph) í˜•íƒœë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Args:
        parser (DAGParser): DAG íŒŒì‹±ì„ ìœ„í•œ íŒŒì„œ ê°ì²´
        msg (str): ë¶„ì„í•  MMS ë©”ì‹œì§€ í…ìŠ¤íŠ¸
        llm_model: ì‚¬ìš©í•  LLM ëª¨ë¸ (Langchain í˜¸í™˜)
        
    Returns:
        dict: {
            'dag_section': str,     # íŒŒì‹±ëœ DAG í…ìŠ¤íŠ¸ í‘œí˜„
            'dag': nx.DiGraph,      # NetworkX ê·¸ë˜í”„ ê°ì²´  
            'dag_raw': str          # LLM ì›ë³¸ ì‘ë‹µ
        }
        
    Process:
        1. LLMì„ í†µí•´ ì—”í‹°í‹° ê´€ê³„ ì¶”ì¶œ
        2. DAG ì„¹ì…˜ íŒŒì‹±
        3. NetworkX ê·¸ë˜í”„ êµ¬ì¡° ìƒì„±
        4. ê²°ê³¼ ë°˜í™˜
    """
    
    logger.info("ğŸš€ DAG ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤ ì‹œì‘")
    logger.info(f"ğŸ“ ì…ë ¥ ë©”ì‹œì§€ ê¸¸ì´: {len(msg)}ì")
    logger.info(f"ğŸ¤– ì‚¬ìš© LLM ëª¨ë¸: {llm_model}")
    
    prompt = f"""
## ì‘ì—… ëª©í‘œ
í†µì‹ ì‚¬ ê´‘ê³  ë©”ì‹œì§€ì—ì„œ **í•µì‹¬ í–‰ë™ íë¦„**ì„ ì¶”ì¶œí•˜ì—¬ ê°„ê²°í•œ DAG(Directed Acyclic Graph) í˜•ì‹ìœ¼ë¡œ í‘œí˜„

## í•µì‹¬ ì›ì¹™
1. **ìµœì†Œ ê²½ë¡œ ì›ì¹™**: ë™ì¼í•œ ê²°ê³¼ë¥¼ ì–»ëŠ” ê°€ì¥ ì§§ì€ ê²½ë¡œë§Œ í‘œí˜„
2. **í•µì‹¬ íë¦„ ìš°ì„ **: ë¶€ê°€ì  ì„¤ëª…ë³´ë‹¤ ì£¼ìš” í–‰ë™ ì—°ì‡„ì— ì§‘ì¤‘
3. **ì¤‘ë³µ ì œê±°**: ì˜ë¯¸ê°€ ê²¹ì¹˜ëŠ” ë…¸ë“œëŠ” í•˜ë‚˜ë¡œ í†µí•©

## ì¶œë ¥ í˜•ì‹
```
(ê°œì²´ëª…:ê¸°ëŒ€í–‰ë™) -[ê´€ê³„ë™ì‚¬]-> (ê°œì²´ëª…:ê¸°ëŒ€í–‰ë™)
ë˜ëŠ”
(ê°œì²´ëª…:ê¸°ëŒ€í–‰ë™)
```

## ê°œì²´ëª… ì¹´í…Œê³ ë¦¬
### í•„ìˆ˜ ì¶”ì¶œ ëŒ€ìƒ
- **ì œí’ˆ/ì„œë¹„ìŠ¤**: êµ¬ì²´ì  ì œí’ˆëª…, ì„œë¹„ìŠ¤ëª…, ìš”ê¸ˆì œëª…
- **í•µì‹¬ í˜œíƒ**: ê¸ˆì „ì  í˜œíƒ, ì‚¬ì€í’ˆ, í• ì¸
- **í–‰ë™ ì¥ì†Œ**: ì˜¨/ì˜¤í”„ë¼ì¸ ì±„ë„ (í•„ìš” ì‹œë§Œ)

### ì¶”ì¶œ ì œì™¸ ëŒ€ìƒ
- ê´‘ê³  ëŒ€ìƒì (ì˜ˆ: "ì•„ì´í° ê³ ê°ë‹˜")
- ì¼ì •/ê¸°ê°„ ì •ë³´
- ë¶€ê°€ ì„¤ëª… ê¸°ëŠ¥ (í•µì‹¬ íë¦„ê³¼ ë¬´ê´€í•œ ê²½ìš°)
- ë²•ì  ê³ ì§€ì‚¬í•­

## ê¸°ëŒ€ í–‰ë™ (10ê°œ í‘œì¤€ ë™ì‚¬)
`êµ¬ë§¤, ê°€ì…, ì‚¬ìš©, ë°©ë¬¸, ì°¸ì—¬, ë“±ë¡, ë‹¤ìš´ë¡œë“œ, í™•ì¸, ìˆ˜ë ¹, ì ë¦½`

## ê´€ê³„ ë™ì‚¬ ìš°ì„ ìˆœìœ„
### 1ìˆœìœ„: ì¡°ê±´ë¶€ ê´€ê³„
- `ê°€ì…í•˜ë©´`, `êµ¬ë§¤í•˜ë©´`, `ì‚¬ìš©í•˜ë©´`
- `ê°€ì…í›„`, `êµ¬ë§¤í›„`, `ì‚¬ìš©í›„`

### 2ìˆœìœ„: ê²°ê³¼ ê´€ê³„
- `ë°›ë‹¤`, `ìˆ˜ë ¹í•˜ë‹¤`, `ì ë¦½í•˜ë‹¤`

### 3ìˆœìœ„: ê²½ë¡œ ê´€ê³„ (í•„ìš” ì‹œë§Œ)
- `í†µí•´`, `ì´ìš©í•˜ì—¬`

## DAG êµ¬ì„± ì „ëµ
### Step 1: ëª¨ë“  ê°€ì¹˜ ì œì•ˆ ì‹ë³„
ê´‘ê³ ì—ì„œ ì œì‹œí•˜ëŠ” **ëª¨ë“  ë…ë¦½ì  ê°€ì¹˜**ë¥¼ íŒŒì•…
- **ì¦‰ê°ì  í˜œíƒ**: ê¸ˆì „ì  ë³´ìƒ, ì‚¬ì€í’ˆ ë“±
- **ì„œë¹„ìŠ¤ ê°€ì¹˜**: ì œí’ˆ/ì„œë¹„ìŠ¤ ìì²´ì˜ ê¸°ëŠ¥ê³¼ í˜œíƒ
ì˜ˆ: "ë„¤ì´ë²„í˜ì´ 5000ì›" + "AI í†µí™” ê¸°ëŠ¥ ë¬´ë£Œ ì´ìš©"

### Step 2: ë…ë¦½ ê²½ë¡œ êµ¬ì„±
ê° ê°€ì¹˜ ì œì•ˆë³„ë¡œ ë³„ë„ ê²½ë¡œ ìƒì„±:
1. **í˜œíƒ íšë“ ê²½ë¡œ**: ê°€ì… â†’ ì‚¬ìš© â†’ ë³´ìƒ
2. **ì„œë¹„ìŠ¤ ì²´í—˜ ê²½ë¡œ**: ê°€ì… â†’ ê²½í—˜ â†’ ê¸°ëŠ¥ í™œìš©

### Step 3: ì„¸ë¶€ ê¸°ëŠ¥ í‘œí˜„
ì£¼ìš” ê¸°ëŠ¥ë“¤ì´ ëª…ì‹œëœ ê²½ìš° ë¶„ê¸° êµ¬ì¡°ë¡œ í‘œí˜„:
- í†µí•© ê°€ëŠ¥í•œ ê¸°ëŠ¥ì€ í•˜ë‚˜ë¡œ (ì˜ˆ: AIí†µí™”ë…¹ìŒ/ìš”ì•½ â†’ "AIí†µí™”ê¸°ëŠ¥")
- ë…ë¦½ì  ê¸°ëŠ¥ì€ ë³„ë„ë¡œ (ì˜ˆ: AIìŠ¤íŒ¸í•„í„°ë§)

## ë¶„ì„ í”„ë¡œì„¸ìŠ¤ (í•„ìˆ˜ ë‹¨ê³„)
### Step 1: ë©”ì‹œì§€ ì´í•´
- ì „ì²´ ë©”ì‹œì§€ë¥¼ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½
- ê´‘ê³ ì£¼ì˜ ì˜ë„ íŒŒì•…
- **ì•”ì‹œëœ í–‰ë™ ì‹ë³„**: ëª…ì‹œë˜ì§€ ì•Šì•˜ì§€ë§Œ í•„ìˆ˜ì ì¸ í–‰ë™ (ì˜ˆ: ë§¤ì¥ ë°©ë¬¸)

### Step 2: ê°€ì¹˜ ì œì•ˆ ì‹ë³„
- ì¦‰ê°ì  í˜œíƒ (ê¸ˆì „, ì‚¬ì€í’ˆ ë“±)
- ì„œë¹„ìŠ¤ ê°€ì¹˜ (ê¸°ëŠ¥, í¸ì˜ì„± ë“±)
- ë¶€ê°€ í˜œíƒ (ìˆë‹¤ë©´)

### Step 3: Root Node ê²°ì •
- **ì‚¬ìš©ìì˜ ì²« ë²ˆì§¸ í–‰ë™ì€ ë¬´ì—‡ì¸ê°€?**
- ë§¤ì¥ ì£¼ì†Œ/ì—°ë½ì²˜ê°€ ìˆë‹¤ë©´ â†’ ë°©ë¬¸ì´ ì‹œì‘ì 
- ì˜¨ë¼ì¸ ë§í¬ê°€ ìˆë‹¤ë©´ â†’ ì ‘ì†ì´ ì‹œì‘ì 
- ì•± ê´€ë ¨ ë‚´ìš©ì´ë¼ë©´ â†’ ë‹¤ìš´ë¡œë“œê°€ ì‹œì‘ì 

### Step 4: ê´€ê³„ ë¶„ì„
- Root Nodeë¶€í„° ì‹œì‘í•˜ëŠ” ì „ì²´ íë¦„
- ê° í–‰ë™ ê°„ ì¸ê³¼ê´€ê³„ ê²€ì¦
- ì¡°ê±´ë¶€ ê´€ê³„ ëª…í™•í™”
- ì‹œê°„ì  ìˆœì„œ í™•ì¸

### Step 5: DAG êµ¬ì„±
- ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ë…¸ë“œì™€ ì—£ì§€ ê²°ì •
- ì¤‘ë³µ ì œê±° ë° í†µí•©

### Step 6: ìê¸° ê²€ì¦ ë° ìˆ˜ì •
- **í‰ê°€**: ì´ˆê¸° DAGë¥¼ ì•„ë˜ ê¸°ì¤€ì— ë”°ë¼ ê²€í† 
  - Root Nodeê°€ ëª…í™•íˆ ì‹ë³„ë˜ì—ˆëŠ”ê°€? (ë°©ë¬¸/ì ‘ì†/ë‹¤ìš´ë¡œë“œ ë“±)
  - ëª¨ë“  ë…ë¦½ì  ê°€ì¹˜ ì œì•ˆì´ í¬í•¨ë˜ì—ˆëŠ”ê°€? (ì¦‰ê°ì  í˜œíƒê³¼ ì„œë¹„ìŠ¤ ê°€ì¹˜)
  - ì£¼ìš” ê¸°ëŠ¥ë“¤ì´ ì ì ˆíˆ ê·¸ë£¹í™”ë˜ì—ˆëŠ”ê°€? (ì¤‘ë³µ ì œê±° ì—¬ë¶€)
  - ê° ê²½ë¡œê°€ ëª…í™•í•œ ê°€ì¹˜ë¥¼ ì „ë‹¬í•˜ëŠ”ê°€?
  - ì „ì²´ êµ¬ì¡°ê°€ ê°„ê²°í•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ê°€?
  - ê´€ê³„ ë™ì‚¬ê°€ ìš°ì„ ìˆœìœ„ì— ë§ê²Œ ì‚¬ìš©ë˜ì—ˆëŠ”ê°€? (ì¡°ê±´ë¶€ > ê²°ê³¼ > ê²½ë¡œ)
- **ë¬¸ì œ ì‹ë³„**: ìœ„ ê¸°ì¤€ ì¤‘ ì¶©ì¡±ë˜ì§€ ì•Šì€ í•­ëª©ì„ ëª…ì‹œí•˜ê³ , ê·¸ ì´ìœ ë¥¼ ì„¤ëª…
- **ìˆ˜ì •**: ì‹ë³„ëœ ë¬¸ì œë¥¼ í•´ê²°í•œ ìˆ˜ì •ëœ DAGë¥¼ ìƒì„±

### Step 7: ìµœì¢… ê²€ì¦
- ìˆ˜ì •ëœ DAGê°€ ëª¨ë“  ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ”ì§€ ì¬í™•ì¸
- ë§Œì•½ ë¬¸ì œê°€ ë‚¨ì•„ìˆë‹¤ë©´, ì¶”ê°€ ìˆ˜ì • ìˆ˜í–‰ (ìµœëŒ€ 2íšŒ ë°˜ë³µ)
- ìµœì¢…ì ìœ¼ë¡œ ëª¨ë“  ê¸°ì¤€ì´ ì¶©ì¡±ë˜ì—ˆìŒì„ í™•ì¸

## ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ ëª¨ë“  ì„¹ì…˜ í¬í•¨)
### 1. ë©”ì‹œì§€ ë¶„ì„
```
[ë©”ì‹œì§€ ìš”ì•½ ë° í•µì‹¬ ì˜ë„]
[ì‹ë³„ëœ ê°€ì¹˜ ì œì•ˆ ëª©ë¡]
```

### 2. ì´ˆê¸° DAG
```
[ì´ˆê¸° DAG êµ¬ì¡°]
```

### 3. ìê¸° ê²€ì¦ ê²°ê³¼
```
[í‰ê°€ ê¸°ì¤€ë³„ ê²€í†  ê²°ê³¼]
[ì‹ë³„ëœ ë¬¸ì œì  ë° ì´ìœ ]
```

### 4. ìˆ˜ì •ëœ DAG
```
[ìˆ˜ì •ëœ DAG êµ¬ì¡°]
```

### 5. ìµœì¢… ê²€ì¦ ë° ì¶”ì¶œ ê·¼ê±°
```
[ìµœì¢… DAGê°€ ëª¨ë“  ê¸°ì¤€ì„ ì¶©ì¡±í•˜ëŠ” ì´ìœ ]
[ë…¸ë“œ/ì—£ì§€ ì„ íƒì˜ ë…¼ë¦¬ì  ê·¼ê±°]
```

## ì‹¤í–‰ ì§€ì¹¨
1. ìœ„ 7ë‹¨ê³„ ë¶„ì„ í”„ë¡œì„¸ìŠ¤ë¥¼ **ìˆœì„œëŒ€ë¡œ** ìˆ˜í–‰
2. ê° ë‹¨ê³„ì—ì„œ ë°œê²¬í•œ ë‚´ìš©ì„ **ëª…ì‹œì ìœ¼ë¡œ** ê¸°ë¡
3. DAG êµ¬ì„± ì „ **ì¶©ë¶„í•œ ë¶„ì„** ìˆ˜í–‰
4. ì´ˆê¸° DAG ìƒì„± í›„ **ë°˜ë“œì‹œ ìê¸° ê²€ì¦ ë° ìˆ˜ì •** ìˆ˜í–‰
5. ìµœì¢… ì¶œë ¥ì— **ëª¨ë“  ì„¹ì…˜** í¬í•¨
6. **ì¤‘ìš”**: ë¶„ì„ ê³¼ì •ì„ ìƒëµí•˜ì§€ ë§ê³ , ì‚¬ê³  ê³¼ì •ê³¼ ìˆ˜ì • ì´ìœ ë¥¼ íˆ¬ëª…í•˜ê²Œ ë³´ì—¬ì£¼ì„¸ìš”

## ì˜ˆì‹œ ë¶„ì„
### ì˜ëª»ëœ ì˜ˆì‹œ (í•µì‹¬ íë¦„ë§Œ ì¶”ì¶œ)
```
(ì—ì´ë‹·:ê°€ì…) -[ê°€ì…í›„]-> (AIì „í™”ì„œë¹„ìŠ¤:ì‚¬ìš©)
(AIì „í™”ì„œë¹„ìŠ¤:ì‚¬ìš©) -[ì‚¬ìš©í•˜ë©´]-> (ë„¤ì´ë²„í˜ì´5000ì›:ìˆ˜ë ¹)
```
â†’ ë¬¸ì œ: ì„œë¹„ìŠ¤ ìì²´ì˜ ê°€ì¹˜(AI ê¸°ëŠ¥ë“¤)ê°€ ëˆ„ë½ë¨

### ì˜¬ë°”ë¥¸ ì˜ˆì‹œ (ì™„ì „í•œ ê°€ì¹˜ í‘œí˜„ - Root Node í¬í•¨)
```
# ë§¤ì¥ ë°©ë¬¸ë¶€í„° ì‹œì‘í•˜ëŠ” ê²½ë¡œ
(ì œì´ìŠ¤ëŒ€ë¦¬ì :ë°©ë¬¸) -[ë°©ë¬¸í•˜ì—¬]-> (ê°¤ëŸ­ì‹œS21:êµ¬ë§¤)
(ê°¤ëŸ­ì‹œS21:êµ¬ë§¤) -[êµ¬ë§¤ì‹œ]-> (5GXí”„ë¼ì„ìš”ê¸ˆì œ:ê°€ì…)
(5GXí”„ë¼ì„ìš”ê¸ˆì œ:ê°€ì…) -[ê°€ì…í•˜ë©´]-> (ì§€ì›ê¸ˆ45ë§Œì›+15%:ìˆ˜ë ¹)

# ì˜¨ë¼ì¸ ì‹œì‘ ê²½ë¡œ ì˜ˆì‹œ
(Të‹¤ì´ë ‰íŠ¸ìƒµ:ì ‘ì†) -[ì ‘ì†í•˜ì—¬]-> (ê°¤ëŸ­ì‹œS24:êµ¬ë§¤)
(ê°¤ëŸ­ì‹œS24:êµ¬ë§¤) -[êµ¬ë§¤ì‹œ]-> (ì‚¬ì€í’ˆ:ìˆ˜ë ¹)
```
â†’ ì¥ì : ì‚¬ìš©ìì˜ ì²« í–‰ë™(Root Node)ë¶€í„° ëª…í™•íˆ í‘œí˜„

## message:
{msg}
"""
    
    logger.info("ğŸ¤– LLMì— DAG ì¶”ì¶œ ìš”ì²­ ì¤‘...")
    logger.info(f"ğŸ“ í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)}ì")
    
    # Step 1: LLMì„ í†µí•œ ì—”í‹°í‹° ê´€ê³„ ì¶”ì¶œ
    try:
        dag_raw = llm_model.invoke(prompt).content
        logger.info(f"ğŸ“ LLM ì‘ë‹µ ê¸¸ì´: {len(dag_raw)}ì")
        logger.info(f"ğŸ“„ LLM ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {dag_raw[:200]}...")
    except Exception as e:
        logger.error(f"âŒ LLM í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise

    # Step 2: DAG ì„¹ì…˜ ì¶”ì¶œ ë° ì •ë¦¬
    # LLM ì‘ë‹µì—ì„œ ì‹¤ì œ DAG êµ¬ì¡° ë¶€ë¶„ë§Œ ì¶”ì¶œ
    logger.info("ğŸ” DAG ì„¹ì…˜ ì¶”ì¶œ ì¤‘...")
    dag_section = parser.extract_dag_section(dag_raw)
    logger.info(f"ğŸ“„ ì¶”ì¶œëœ DAG ì„¹ì…˜ ê¸¸ì´: {len(dag_section)}ì")
    
    # Step 3: NetworkX ê·¸ë˜í”„ êµ¬ì¡° ìƒì„±
    # í…ìŠ¤íŠ¸ DAGë¥¼ ì‹¤ì œ ê·¸ë˜í”„ ê°ì²´ë¡œ ë³€í™˜
    logger.info("ğŸ”— DAG íŒŒì‹± ì¤‘...")
    dag = parser.parse_dag(dag_section)
    logger.info(f"ğŸ“Š íŒŒì‹±ëœ DAG - ë…¸ë“œ ìˆ˜: {dag.number_of_nodes()}, ì—£ì§€ ìˆ˜: {dag.number_of_edges()}")
    
    # Step 4: ê²°ê³¼ ê²€ì¦ ë° ë¡œê¹…
    if dag.number_of_nodes() > 0:
        logger.info(f"ğŸ¯ DAG ë…¸ë“œ ëª©ë¡: {list(dag.nodes())}")
        logger.info(f"ğŸ”— DAG ì—£ì§€ ëª©ë¡: {list(dag.edges())}")
    else:
        logger.warning("âš ï¸ DAGì— ë…¸ë“œê°€ ì—†ìŠµë‹ˆë‹¤")

    logger.info("âœ… DAG ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")
    
    # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
    return {
        'dag_section': dag_section,  # í…ìŠ¤íŠ¸ í˜•íƒœì˜ DAG í‘œí˜„
        'dag': dag,                  # NetworkX DiGraph ê°ì²´
        'dag_raw': dag_raw           # LLM ì›ë³¸ ì‘ë‹µ (ë””ë²„ê¹…ìš©)
    }

    # root_nodes = [node for node in dag.nodes() if dag.in_degree(node) == 0]
    # for root in root_nodes:
    #     node_data = dag.nodes[root]
    #     print(f"  {root} | {node_data}")

    # paths, roots, leaves = get_root_to_leaf_paths(dag)

    # for i, path in enumerate(paths):
    #     print(f"\nPath {i+1}:")
    #     for j, node in enumerate(path):
    #         if j < len(path) - 1:
    #             edge_data = dag.get_edge_data(node, path[j+1])
    #             relation = edge_data['relation'] if edge_data else ''
    #             print(f"  {node}")
    #             print(f"    --[{relation}]-->")
    #         else:
    #             print(f"  {node}")
                

###############################################################################
# 7) ë©”ì¸ ì¶”ì¶œ í•¨ìˆ˜ (ê¸°ì¡´ ì¸í„°í˜ì´ìŠ¤ ìœ ì§€ + ê°œì„  ê¸°ëŠ¥ ì¶”ê°€)
###############################################################################
def dag_finder(num_msgs=50, llm_model_nm='ax', save_dag_image=True):

    if llm_model_nm == 'ax':
        llm_model = llm_ax
    elif llm_model_nm == 'gem':
        llm_model = llm_gem
    elif llm_model_nm == 'cld':
        llm_model = llm_cld
    elif llm_model_nm == 'gen':
        llm_model = llm_gen
    elif llm_model_nm == 'gpt':
        llm_model = llm_gpt

    # ì¶œë ¥ì„ íŒŒì¼ì— ì €ì¥í•˜ê¸° ìœ„í•œ ì„¤ì •
    output_file = "./logs/dag_extraction_output.txt"

    line_break_patterns = {"__":"\n", "â– ":"\nâ– ", "â–¶":"\nâ–¶", "_":"\n"}
    
    # ê°œì„ ëœ íŒŒì„œ ì´ˆê¸°í™”
    parser = DAGParser() 
    with open(output_file, 'a', encoding='utf-8') as f:
        # ì‹¤í–‰ ì‹œì‘ ì‹œì  ê¸°ë¡
        from datetime import datetime
        start_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        f.write(f"\n{'='*80}\n")
        f.write(f"DAG ì¶”ì¶œ ì‹¤í–‰ ì‹œì‘: {start_time}\n")
        f.write(f"{'='*80}\n\n")
        
        for msg in random.sample(mms_pdf.query("msg.str.contains('')")['msg'].unique().tolist(), num_msgs):
            try:
                for pattern, replacement in line_break_patterns.items():
                    msg = msg.replace(pattern, replacement)
                
                # ë©”ì‹œì§€ ì¶œë ¥
                msg_header = "==="*15+" Message "+"==="*15
                print(msg_header)
                f.write(msg_header + "\n")
                print(msg)
                f.write(msg + "\n")
                
                # DAG ì¶œë ¥
                dag_header = "==="*15+f" DAG ({llm_model_nm.upper()}) "+"==="*15
                print(dag_header)
                f.write(dag_header + "\n")
                extract_dag_result = extract_dag(parser, msg, llm_model)

                dag_raw = extract_dag_result['dag_raw']
                dag_section = extract_dag_result['dag_section']
                dag = extract_dag_result['dag']

                print(dag_raw)
                f.write(dag_raw + "\n")

                # íŒŒì„œ ì„ íƒ ë° ì²˜ë¦¬
                if parser:
                    try:                    
                        # ë””ë²„ê¹…ì„ ìœ„í•´ dag_section ë‚´ìš© í™•ì¸
                        print("=== DAG Section Debug ===")
                        print(f"DAG Section Length: {len(dag_section)}")
                        print("DAG Section Content:")
                        print(dag_section)
                        print("=" * 50)

                        # ë¼ì¸ë³„ë¡œ í™•ì¸
                        lines = dag_section.strip().split('\n')
                        print(f"Total lines: {len(lines)}")
                        for i, line in enumerate(lines, 1):
                            line = line.strip()
                            if line:
                                print(f"Line {i}: '{line}'")
                        print("=" * 50)

                        # íŒŒì‹± ê³¼ì • ë””ë²„ê¹…
                        dag = parser.parse_dag(dag_section)

                        # íŒŒì‹± ê²°ê³¼ í™•ì¸
                        print("=== Parse Results ===")
                        print(f"Nodes: {dag.number_of_nodes()}")
                        print(f"Edges: {dag.number_of_edges()}")

                        # íŒŒì‹± í†µê³„ í™•ì¸
                        if dag.graph.get('stats'):
                            stats = dag.graph['stats']
                            print(f"Parsed lines: {len(stats['parsed_lines'])}")
                            print(f"Parse errors: {len(stats['parse_errors'])}")
                            
                            if stats['parse_errors']:
                                print("Parse Errors:")
                                for error in stats['parse_errors']:
                                    print(f"  - {error}")
                                    
                            if stats['parsed_lines']:
                                print("Successfully parsed lines:")
                                for parsed in stats['parsed_lines']:
                                    print(f"  + {parsed}")
                        
                        # ë¶„ì„ ì •ë³´ ì¶œë ¥
                        analysis = parser.analyze_graph(dag)
                        analysis_header = "==="*15+" Enhanced Analysis "+"==="*15
                        print(analysis_header)
                        f.write(analysis_header + "\n")
                        
                        analysis_info = f"""ê·¸ë˜í”„ ë¶„ì„:
- ë…¸ë“œ ìˆ˜: {analysis['num_nodes']}
- ì—£ì§€ ìˆ˜: {analysis['num_edges']}  
- Root ë…¸ë“œ: {analysis['root_nodes']}
- Leaf ë…¸ë“œ: {analysis['leaf_nodes']}
- DAG ì—¬ë¶€: {analysis['is_dag']}
- ìµœì¥ ê²½ë¡œ ê¸¸ì´: {analysis['longest_path_length']}"""
                        print(analysis_info)
                        f.write(analysis_info + "\n")
                        
                        # íŒŒì‹± ì—ëŸ¬ê°€ ìˆë‹¤ë©´ ì¶œë ¥
                        if dag.graph['stats'].get('parse_errors'):
                            error_info = "\níŒŒì‹± ì—ëŸ¬:"
                            print(error_info)
                            f.write(error_info + "\n")
                            for error in dag.graph['stats']['parse_errors'][:3]:  # ì²˜ìŒ 3ê°œë§Œ
                                error_line = f"  âœ— {error}"
                                print(error_line)
                                f.write(error_line + "\n")
                                
                    except Exception as e:
                        print(f"Enhanced parser ì‹¤íŒ¨, ê¸°ë³¸ íŒŒì„œë¡œ ì „í™˜: {e}")
                        f.write(f"Enhanced parser ì‹¤íŒ¨, ê¸°ë³¸ íŒŒì„œë¡œ ì „í™˜: {e}\n")
                        # ê¸°ë³¸ íŒŒì„œë¡œ í´ë°±
                        nodes, edges = parse_block(re.sub(r'^```|```$', '', dag_raw.strip()))
                        dag = build_dag(nodes, edges)
                else:
                    # ê¸°ë³¸ íŒŒì„œ ì‚¬ìš©
                    nodes, edges = parse_block(re.sub(r'^```|```$', '', dag_raw.strip()))
                    dag = build_dag(nodes, edges)

                # Root Nodes ì¶œë ¥
                root_header = "==="*15+" Root Nodes "+"==="*15
                print(root_header)
                f.write(root_header + "\n")
                root_nodes = [node for node in dag.nodes() if dag.in_degree(node) == 0]
                for root in root_nodes:
                    node_data = dag.nodes[root]
                    root_info = f"  {root} | {node_data}"
                    print(root_info)
                    f.write(root_info + "\n")

                # Paths ì¶œë ¥
                paths_header = "==="*15+" Paths "+"==="*15
                print(paths_header)
                f.write(paths_header + "\n")
                paths, roots, leaves = get_root_to_leaf_paths(dag)

                for i, path in enumerate(paths):
                    path_info = f"\nPath {i+1}:"
                    print(path_info)
                    f.write(path_info + "\n")
                    for j, node in enumerate(path):
                        if j < len(path) - 1:
                            edge_data = dag.get_edge_data(node, path[j+1])
                            relation = edge_data['relation'] if edge_data else ''
                            node_info = f"  {node}"
                            relation_info = f"    --[{relation}]-->"
                            print(node_info)
                            print(relation_info)
                            f.write(node_info + "\n")
                            f.write(relation_info + "\n")
                        else:
                            final_node = f"  {node}"
                            print(final_node)
                            f.write(final_node + "\n")

                separator = "\n" + "#"*100 + "\n"
                print(separator)
                f.write(separator)

            except Exception as e:
                print(f"Error: {e}")
                f.write(f"Error: {e}\n")
                continue
    
    print(f"ì¶œë ¥ì´ íŒŒì¼ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_file}")

    if save_dag_image:
        create_dag_diagram(dag, filename=f'dag_{sha256_hash(msg)}')
        print(f"DAG ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {f'dag_{sha256_hash(msg)}.png'}")

if __name__ == "__main__":
    import argparse
    
    parser_arg = argparse.ArgumentParser(description='DAG ì¶”ì¶œê¸°')
    parser_arg.add_argument('--num_msgs', type=int, default=50, help='ì¶”ì¶œí•  ë©”ì‹œì§€ ìˆ˜')
    parser_arg.add_argument('--llm_model', type=str, default='ax', help='ì‚¬ìš©í•  LLM ëª¨ë¸')
    parser_arg.add_argument('--save_dag_image', type=bool, default=True, help='DAG ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€')
    args = parser_arg.parse_args()
    dag_finder(num_msgs=args.num_msgs, llm_model_nm=args.llm_model, save_dag_image=args.save_dag_image)