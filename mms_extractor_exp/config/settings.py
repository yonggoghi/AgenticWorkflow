"""
MMS Extractor Configuration Settings
=====================================

ğŸ“‹ ê°œìš”
-------
MMS Extractor ì‹œìŠ¤í…œì˜ ëª¨ë“  ì„¤ì •ì„ ê´€ë¦¬í•˜ëŠ” ì¤‘ì•™ ì„¤ì • ëª¨ë“ˆì…ë‹ˆë‹¤.
Dataclass ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¡°í™”ë˜ì–´ íƒ€ì… ì•ˆì „ì„±ê³¼ IDE ì§€ì›ì„ ì œê³µí•©ë‹ˆë‹¤.

ğŸ”— ì˜ì¡´ì„±
---------
**ì‚¬ìš©ë˜ëŠ” ê³³:**
- `core.mms_extractor`: MMSExtractor ì´ˆê¸°í™” ì‹œ ì„¤ì • ë¡œë“œ
- `utils.llm_factory`: LLM ëª¨ë¸ ì„¤ì •
- `services.*`: ê° ì„œë¹„ìŠ¤ì˜ ì„ê³„ê°’ ë° ê²½ë¡œ ì„¤ì •
- `apps.*`: API/CLI ì• í”Œë¦¬ì¼€ì´ì…˜ ì„¤ì •

ğŸ—ï¸ ì„¤ì • ê·¸ë£¹
------------

### 1. API_CONFIG (APIConfig)
**ëª©ì **: LLM API í‚¤ ë° ì—”ë“œí¬ì¸íŠ¸ ê´€ë¦¬

**í™˜ê²½ë³€ìˆ˜:**
- `CUSTOM_API_KEY`: ì»¤ìŠ¤í…€ LLM API í‚¤
- `CUSTOM_BASE_URL`: ì»¤ìŠ¤í…€ LLM API URL
- `OPENAI_API_KEY`: OpenAI API í‚¤
- `ANTHROPIC_API_KEY`: Anthropic API í‚¤

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from config.settings import API_CONFIG

# API í‚¤ ì ‘ê·¼
api_key = API_CONFIG.llm_api_key
api_url = API_CONFIG.llm_api_url
```

---

### 2. MODEL_CONFIG (ModelConfig)
**ëª©ì **: AI ëª¨ë¸ ì„¤ì • ë° íŒŒë¼ë¯¸í„° ê´€ë¦¬

**ì£¼ìš” ì„¤ì •:**
- `embedding_model`: ì„ë² ë”© ëª¨ë¸ (ko-sbert-nli)
- `llm_model`: í™œì„± LLM ëª¨ë¸ (ax, gpt, gemini ë“±)
- `llm_max_tokens`: ìµœëŒ€ í† í° ìˆ˜ (ê¸°ë³¸ 4000)
- `temperature`: ìƒì„± ì˜¨ë„ (ê¸°ë³¸ 0.0)
- `model_loading_mode`: ëª¨ë¸ ë¡œë”© ì „ëµ (auto/local/remote)

**ëª¨ë¸ ë¡œë”© ëª¨ë“œ:**
| ëª¨ë“œ | ì„¤ëª… | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|------|------|--------------|
| **auto** | ë¡œì»¬ ìš°ì„ , ì—†ìœ¼ë©´ ë‹¤ìš´ë¡œë“œ | ì¼ë°˜ì ì¸ ì‚¬ìš© (ê¸°ë³¸ê°’) |
| **local** | ë¡œì»¬ë§Œ ì‚¬ìš©, ì—†ìœ¼ë©´ ì‹¤íŒ¨ | ì˜¤í”„ë¼ì¸ í™˜ê²½ |
| **remote** | í•­ìƒ ë‹¤ìš´ë¡œë“œ | ìµœì‹  ëª¨ë¸ ê°•ì œ ì‚¬ìš© |

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from config.settings import MODEL_CONFIG

# ëª¨ë¸ ì„¤ì • ì ‘ê·¼
llm_model = MODEL_CONFIG.llm_model  # 'skt/ax4'
max_tokens = MODEL_CONFIG.llm_max_tokens  # 4000
temperature = MODEL_CONFIG.temperature  # 0.0

# ë¡œë”© ëª¨ë“œ í™•ì¸
mode_desc = MODEL_CONFIG.get_loading_mode_description()
```

---

### 3. PROCESSING_CONFIG (ProcessingConfig)
**ëª©ì **: ì—”í‹°í‹° ì¶”ì¶œ ë° ë§¤ì¹­ ë™ì‘ ì œì–´

**ì„ê³„ê°’ ì„¤ì •:**
```python
# ì—”í‹°í‹° ì¸ì‹ ì„ê³„ê°’
entity_fuzzy_threshold: 0.5           # Fuzzy ë§¤ì¹­
entity_similarity_threshold: 0.2      # Sequence ìœ ì‚¬ë„
entity_combined_similarity_threshold: 0.2  # ê²°í•© ìœ ì‚¬ë„
entity_high_similarity_threshold: 1.0 # ìµœì¢… í•„í„°ë§
entity_llm_fuzzy_threshold: 0.6       # LLM ê¸°ë°˜ ì¶”ì¶œ

# ë§¤ì¥ ë§¤ì¹­ ì„ê³„ê°’
store_matching_threshold: 0.5
similarity_threshold_for_store: 0.6
similarity_threshold_for_store_secondary: 0.3
```

**ì¶”ì¶œ ëª¨ë“œ:**
| ì„¤ì • | ì˜µì…˜ | ì„¤ëª… |
|------|------|------|
| `product_info_extraction_mode` | rag/llm/nlp | ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì „ëµ |
| `entity_extraction_mode` | llm/logic | ì—”í‹°í‹° ë§¤ì¹­ ì „ëµ |

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from config.settings import PROCESSING_CONFIG

# ì„ê³„ê°’ ì ‘ê·¼
fuzzy_threshold = PROCESSING_CONFIG.entity_fuzzy_threshold
extraction_mode = PROCESSING_CONFIG.entity_extraction_mode

# Chain of Thought ê°€ì ¸ì˜¤ê¸°
cot = PROCESSING_CONFIG.chain_of_thought

# ì¶”ì¶œ ê°€ì´ë“œ ìƒì„±
guide = PROCESSING_CONFIG.get_extraction_guide(
    candidate_items=['ì•„ì´í° 17', 'ê°¤ëŸ­ì‹œ']
)
```

---

### 4. METADATA_CONFIG (METADATAConfig)
**ëª©ì **: ë°ì´í„° íŒŒì¼ ê²½ë¡œ ê´€ë¦¬

**í™˜ê²½ë³€ìˆ˜:**
- `ALIAS_RULE_PATH`: ë³„ì¹­ ê·œì¹™ CSV
- `STOP_ITEM_PATH`: ë¶ˆìš©ì–´ CSV
- `OFFER_DATA_PATH`: ìƒí’ˆ ì •ë³´ CSV
- `ORG_INFO_PATH`: ì¡°ì§ ì •ë³´ CSV
- `PGM_INFO_PATH`: í”„ë¡œê·¸ë¨ ë¶„ë¥˜ CSV
- `MMS_MSG_PATH`: MMS ë©”ì‹œì§€ ìƒ˜í”Œ CSV

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from config.settings import METADATA_CONFIG

# íŒŒì¼ ê²½ë¡œ ì ‘ê·¼
alias_path = METADATA_CONFIG.alias_rules_path
offer_path = METADATA_CONFIG.offer_data_path
```

---

### 5. EMBEDDING_CONFIG (EmbeddingConfig)
**ëª©ì **: ì„ë² ë”© ë° ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ê´€ë¦¬

**ìºì‹œ íŒŒì¼:**
- `item_embeddings_path`: ìƒí’ˆ ì„ë² ë”© (.npz)
- `org_all_embeddings_path`: ì¡°ì§ ì „ì²´ ì„ë² ë”©
- `org_nm_embeddings_path`: ì¡°ì§ëª… ì„ë² ë”©

**ëª¨ë¸ ê²½ë¡œ:**
- `local_model_base_path`: ë¡œì»¬ ëª¨ë¸ ê¸°ë³¸ ê²½ë¡œ
- `ko_sbert_model_path`: í•œêµ­ì–´ SBERT ëª¨ë¸ ê²½ë¡œ

---

### 6. STORAGE_CONFIG (StorageConfig)
**ëª©ì **: DAG ì´ë¯¸ì§€ ì €ì¥ ë° URL ê´€ë¦¬

**ì €ì¥ ëª¨ë“œ:**
| ëª¨ë“œ | ì„¤ëª… | URL í˜•ì‹ |
|------|------|---------|
| **local** | API ì„œë²„ì—ì„œ ì œê³µ | `http://{server_ip}:8000/dag_images/{filename}` |
| **nas** | NAS ì„œë²„ì—ì„œ ì œê³µ | `http://172.27.7.58/dag_images/{filename}` |

**í™˜ê²½ë³€ìˆ˜:**
- `DAG_STORAGE_MODE`: ì €ì¥ ëª¨ë“œ (local/nas)
- `LOCAL_BASE_URL`: ë¡œì»¬ ì„œë²„ URL (ìë™ ê°ì§€ ê°€ëŠ¥)
- `LOCAL_PORT`: ë¡œì»¬ ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ 8000)
- `NAS_BASE_URL`: NAS ì„œë²„ URL
- `NAS_URL_PATH`: NAS URL ê²½ë¡œ

**ì‚¬ìš© ì˜ˆì‹œ:**
```python
from config.settings import STORAGE_CONFIG

# DAG ì´ë¯¸ì§€ URL ìƒì„±
dag_url = STORAGE_CONFIG.get_dag_image_url('dag_12345.png')
# local ëª¨ë“œ: http://192.168.1.100:8000/dag_images/dag_12345.png
# nas ëª¨ë“œ: http://172.27.7.58/dag_images/dag_12345.png

# ì €ì¥ ë””ë ‰í† ë¦¬
dag_dir = STORAGE_CONFIG.get_dag_images_dir()  # 'dag_images'

# ëª¨ë“œ ì„¤ëª…
desc = STORAGE_CONFIG.get_storage_description()
```

---

## ğŸ’¡ ì „ì²´ ì‚¬ìš© ì˜ˆì‹œ

```python
from config.settings import (
    API_CONFIG,
    MODEL_CONFIG,
    PROCESSING_CONFIG,
    METADATA_CONFIG,
    EMBEDDING_CONFIG,
    STORAGE_CONFIG
)

# 1. LLM ì´ˆê¸°í™”
from utils.llm_factory import LLMFactory

factory = LLMFactory(
    api_config=API_CONFIG,
    model_config=MODEL_CONFIG
)
llm = factory.create_model(MODEL_CONFIG.llm_model)

# 2. ë°ì´í„° ë¡œë“œ
from services.item_data_loader import ItemDataLoader

loader = ItemDataLoader(data_source='local')
item_df, alias_df = loader.load_and_prepare_items(
    offer_data_path=METADATA_CONFIG.offer_data_path,
    alias_rules_path=METADATA_CONFIG.alias_rules_path,
    excluded_domains=PROCESSING_CONFIG.excluded_domain_codes_for_items,
    user_entities=PROCESSING_CONFIG.user_defined_entities
)

# 3. ì—”í‹°í‹° ì¶”ì¶œ ì„¤ì •
extraction_mode = PROCESSING_CONFIG.entity_extraction_mode
fuzzy_threshold = PROCESSING_CONFIG.entity_fuzzy_threshold

# 4. DAG ì´ë¯¸ì§€ URL ìƒì„±
dag_url = STORAGE_CONFIG.get_dag_image_url('dag_example.png')
```

---

## âš™ï¸ í™˜ê²½ë³€ìˆ˜ ìš°ì„ ìˆœìœ„

ëª¨ë“  ì„¤ì •ì€ ë‹¤ìŒ ìš°ì„ ìˆœìœ„ë¡œ ê²°ì •ë©ë‹ˆë‹¤:
1. **í™˜ê²½ë³€ìˆ˜** (`.env` íŒŒì¼ ë˜ëŠ” ì‹œìŠ¤í…œ í™˜ê²½ë³€ìˆ˜)
2. **ê¸°ë³¸ê°’** (dataclass í•„ë“œ ê¸°ë³¸ê°’)

### .env íŒŒì¼ ì˜ˆì‹œ
```bash
# API ì„¤ì •
CUSTOM_API_KEY=your_api_key_here
CUSTOM_BASE_URL=https://api.platform.a15t.com/v1

# ëª¨ë¸ ì„¤ì •
LLM_MODEL=skt/ax4
MODEL_LOADING_MODE=auto

# ì²˜ë¦¬ ì„¤ì •
ENTITY_EXTRACTION_MODE=llm
PRODUCT_INFO_EXTRACTION_MODE=llm

# ì €ì¥ ì„¤ì •
DAG_STORAGE_MODE=local
LOCAL_PORT=8000
```

---

## ğŸ“ ì°¸ê³ ì‚¬í•­

- ëª¨ë“  ì„¤ì • í´ë˜ìŠ¤ëŠ” `@dataclass` ë°ì½”ë ˆì´í„° ì‚¬ìš©
- `__post_init__` ë©”ì„œë“œë¡œ ì´ˆê¸°í™” í›„ ê²€ì¦ ìˆ˜í–‰
- í™˜ê²½ë³€ìˆ˜ëŠ” `os.getenv()`ë¡œ ì•ˆì „í•˜ê²Œ ë¡œë“œ
- ê¸€ë¡œë²Œ ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ë¡œ ì œê³µ (API_CONFIG, MODEL_CONFIG ë“±)
- íƒ€ì… íŒíŠ¸ë¡œ IDE ìë™ì™„ì„± ì§€ì›

"""
import os
import socket
from dataclasses import dataclass
from typing import List
from pathlib import Path

# Set environment variable to suppress tokenizer warnings
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# Load environment variables from .env file if it exists
try:
    from dotenv import load_dotenv
    env_path = Path(__file__).parent.parent / '.env'
    if env_path.exists():
        load_dotenv(env_path)
except ImportError:
    # dotenv not available, skip loading .env file
    pass


def get_server_ip() -> str:
    """Get the server's IP address dynamically.
    
    Returns:
        str: Server's IP address (e.g., '192.168.1.100')
    """
    try:
        # Create a socket connection to get the actual network IP
        # We don't actually connect, just use it to determine the IP
        s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        s.connect(("8.8.8.8", 80))  # Google DNS, doesn't actually send data
        ip = s.getsockname()[0]
        s.close()
        return ip
    except Exception:
        # Fallback to hostname-based resolution
        try:
            return socket.gethostbyname(socket.gethostname())
        except Exception:
            # Ultimate fallback
            return "127.0.0.1"


@dataclass
class APIConfig:
    """API configuration settings for various LLM services."""
    
    # Custom LLM API configuration (e.g., local or hosted models)
    llm_api_key: str = os.getenv("CUSTOM_API_KEY", "")  # API key for custom LLM service
    llm_api_url: str = os.getenv("CUSTOM_BASE_URL", "https://api.platform.a15t.com/v1")  # Base URL for custom LLM API
    
    # OpenAI API configuration
    openai_api_key: str = os.getenv("OPENAI_API_KEY", "")  # OpenAI API key for GPT models
    
    # Anthropic API configuration  
    anthropic_api_key: str = os.getenv("ANTHROPIC_API_KEY", "")  # Anthropic API key for Claude models

@dataclass
class METADATAConfig:
    """Data file path configuration settings.
    These paths point to various CSV/data files used by the system.
    """
    
    # Alias rules file for item name variations
    alias_rules_path: str = os.getenv("ALIAS_RULE_PATH", "./data/alias_rules.csv")  # CSV file containing item name aliases and variations
    
    # Stop words file for filtering unwanted terms
    stop_items_path: str = os.getenv("STOP_ITEM_PATH", "./data/stop_words.csv")  # CSV file with words to exclude from entity extraction
    
    # Main item/offer information database
    offer_data_path: str = os.getenv("OFFER_DATA_PATH", "./data/offer_master_data.csv")  # Main CSV file with item/offer information (DB schema compatible)
    
    # Organization/store information database
    org_info_path: str = os.getenv("ORG_INFO_PATH", "./data/offer_master_data.csv")  # CSV file with organization/store details (Korean encoding)
    
    # Program classification information
    pgm_info_path: str = os.getenv("PGM_INFO_PATH", "./data/pgm_tag_ext_250516.csv")  # CSV file with program classification tags and clues
    
    # MMS message samples for testing
    mms_msg_path: str = os.getenv("MMS_MSG_PATH", "./data/mms_data_250408.csv")  # CSV file with sample MMS messages for testing

@dataclass
class EmbeddingConfig:
    """Embedding and model file path configuration settings.
    These paths point to pre-computed embeddings and model files.
    """
    
    # Pre-computed embedding cache files (NumPy .npz format)
    item_embeddings_path: str = os.getenv("ITEM_EMBEDDINGS_PATH", "./data/item_embeddings_250527.npz")  # Cached embeddings for item names
    org_all_embeddings_path: str = os.getenv("ORG_ALL_EMBEDDINGS_PATH", "./data/org_all_embeddings_250605.npz")  # Cached embeddings for organization info (name + address)
    org_nm_embeddings_path: str = os.getenv("ORG_NM_EMBEDDINGS_PATH", "./data/org_nm_embeddings_250605.npz")  # Cached embeddings for organization names only
    
    # Local model storage paths
    local_model_base_path: str = os.getenv("LOCAL_MODEL_BASE_PATH", "./models")  # Base directory for storing local models
    ko_sbert_model_path: str = os.getenv("KO_SBERT_MODEL_PATH", "./models/ko-sbert-nli")  # Path to Korean SBERT model for embeddings
    
@dataclass
class ModelConfig:
    """Model configuration settings for various AI models used in the system."""
    
    # Embedding model configuration
    embedding_model: str = "jhgan/ko-sbert-nli"  # Hugging Face model ID for Korean sentence embeddings
    local_embedding_model_path: str = os.getenv("LOCAL_EMBEDDING_MODEL_PATH", "./models/ko-sbert-nli")  # Local path for embedding model
    model_loading_mode: str = os.getenv("MODEL_LOADING_MODE", "auto")  # Model loading strategy: 'auto', 'local', 'remote'
    disable_embedding: bool = os.getenv("DISABLE_EMBEDDING", "false").lower() == "true"  # Disable embedding model for server environments
    
    # LLM model specifications
    gemma_model: str = "skt/gemma3-12b-it"  # Gemma model ID for Korean language processing
    gemini_model: str = "gcp/gemini-2.5-flash" 
    claude_model: str = "amazon/anthropic/claude-sonnet-4-20250514"  # Anthropic Claude model for advanced reasoning
    ax_model: str = "skt/ax4"
    gpt_model: str = "azure/openai/gpt-4o-2024-08-06"  # OpenAI GPT-4o model for high-quality reasoning  
    
    # Active LLM selection
    llm_model: str = os.getenv("LLM_MODEL", "skt/ax4")  # Currently active LLM: 'gemma', 'ax', or 'claude'
    
    # LLM generation parameters
    llm_max_tokens: int = 4000  # Maximum tokens for LLM responses
    temperature: float = 0.0  # Temperature for LLM generation (0.0 = deterministic, 1.0 = creative)
    llm_seed: int = 42  # Seed for LLM generation
    
    def __post_init__(self):
        """Validate model loading mode after initialization."""
        valid_modes = ['auto', 'local', 'remote']
        if self.model_loading_mode not in valid_modes:
            raise ValueError(f"model_loading_mode must be one of {valid_modes}, got: {self.model_loading_mode}")
    
    def get_loading_mode_description(self) -> str:
        """Get human-readable description of current loading mode."""
        descriptions = {
            'auto': 'Automatically use local model if available, otherwise download from internet',
            'local': 'Only use local models, fail if not found (offline mode)',
            'remote': 'Always download from internet, ignore local models'
        }
        return descriptions.get(self.model_loading_mode, 'Unknown mode')

@dataclass
class StorageConfig:
    """Storage configuration for DAG images and other files."""
    
    # DAG image storage mode: 'local' or 'nas'
    # This controls URL generation, not file storage location
    dag_storage_mode: str = "local"  # Will be overridden in __post_init__
    
    # Storage path (single directory for all modes)
    dag_images_dir: str = "dag_images"  # DAG images directory (can be symlink to NAS)
    
    # Server URL configuration
    local_base_url: str = ""  # Will be overridden in __post_init__
    local_port: int = 8000  # Will be overridden in __post_init__
    nas_base_url: str = "http://172.27.7.58"  # Will be overridden in __post_init__
    nas_url_path: str = "/dag_images"  # Will be overridden in __post_init__
    
    def __post_init__(self):
        """Validate storage mode and auto-detect server IP if needed."""
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ê°’ì„ ì½ì–´ì„œ ë®ì–´ì“°ê¸° (ëŸ°íƒ€ì„ ê²°ì •)
        self.dag_storage_mode = os.getenv("DAG_STORAGE_MODE", "local")
        self.local_base_url = os.getenv("LOCAL_BASE_URL", "")
        self.local_port = int(os.getenv("LOCAL_PORT", "8000"))
        self.nas_base_url = os.getenv("NAS_BASE_URL", "http://172.27.7.58")
        self.nas_url_path = os.getenv("NAS_URL_PATH", "/dag_images")
        
        # Validate storage mode
        valid_modes = ['local', 'nas']
        if self.dag_storage_mode not in valid_modes:
            raise ValueError(f"dag_storage_mode must be one of {valid_modes}, got: {self.dag_storage_mode}")
        
        # Auto-detect local server IP if LOCAL_BASE_URL not set
        if not self.local_base_url:
            server_ip = get_server_ip()
            self.local_base_url = f"http://{server_ip}:{self.local_port}"
    
    def get_dag_images_dir(self) -> str:
        """Get the DAG images directory (same for all storage modes)."""
        return self.dag_images_dir
    
    def get_storage_description(self) -> str:
        """Get human-readable description of current storage mode."""
        descriptions = {
            'local': 'API server provides images (URL: API server IP)',
            'nas': 'NAS server provides images (URL: NAS server IP)'
        }
        return descriptions.get(self.dag_storage_mode, 'Unknown mode')
    
    def get_dag_image_url(self, filename: str) -> str:
        """Get the DAG image URL based on storage mode.
        
        Args:
            filename: DAG image filename (e.g., 'dag_xxx.png')
        
        Returns:
            str: Full URL to access the DAG image
        """
        if self.dag_storage_mode == 'nas':
            # Use NAS server absolute URL (NAS IP address)
            return f"{self.nas_base_url.rstrip('/')}{self.nas_url_path.rstrip('/')}/{filename}"
        else:
            # Use API server absolute URL (fixed server address)
            return f"{self.local_base_url.rstrip('/')}/dag_images/{filename}"

@dataclass
class ProcessingConfig:
    """Processing configuration settings that control the behavior of entity extraction and matching."""
    
    # Similarity thresholds for matching
    similarity_threshold: float = 0.7  # Minimum similarity score for entity matching (0.0-1.0)
    similarity_threshold_for_store: float = 0.6  # Minimum similarity score for entity matching (0.0-1.0)
    similarity_threshold_for_store_secondary: float = 0.3  # Minimum similarity score for entity matching (0.0-1.0)
    fuzzy_threshold: float = 0.4  # Minimum fuzzy matching score for initial filtering (0.0-1.0)
    combined_similarity_threshold: float = 0.4  # Minimum threshold for combined similarity scores (s1, s2)
    high_similarity_threshold: float = 1.1  # Minimum high similarity score for final entity filtering (0.0-2.0)
    
    # Processing parameters
    num_candidate_programs: int = 5  # Number of candidate programs to consider for classification
    batch_size: int = 100  # Batch size for parallel processing operations
    n_jobs: int = 6  # Number of parallel jobs for similarity calculations
    
    excluded_domain_codes_for_items: List[str] = None # Domain codes to exclude from item processing (e.g., ['R'] for agency domains)

    # User-defined entities that should always be recognized
    user_defined_entities: List[str] = None  # Custom entities to add to the recognition vocabulary
    
    # Processing mode configurations
    product_info_extraction_mode: str = 'llm'  # Product extraction strategy: 'rag', 'llm', 'nlp'
    entity_extraction_mode: str = 'llm'  # Entity matching strategy: 'llm', 'logic'
    
    # === Threshold Settings (ì„ê³„ê°’ ì„¤ì •) ===
    # Entity Recognition Thresholds (ì—”í‹°í‹° ì¸ì‹ ì„ê³„ê°’)
    entity_fuzzy_threshold: float = 0.5  # Fuzzy matching threshold for entity recognition
    entity_similarity_threshold: float = 0.2  # Sequence similarity threshold
    entity_combined_similarity_threshold: float = 0.2  # Combined similarity threshold
    entity_high_similarity_threshold: float = 1.0  # High similarity threshold for filtering
    entity_llm_fuzzy_threshold: float = 0.6  # Fuzzy threshold for LLM-based entity extraction
    
    # Store Matching Thresholds (ë§¤ì¥ ë§¤ì¹­ ì„ê³„ê°’)
    store_matching_threshold: float = 0.5  # Threshold for store name matching
    
    # Parallel Processing Thresholds (ë³‘ë ¬ ì²˜ë¦¬ ì„ê³„ê°’)
    parallel_fuzzy_threshold: float = 0.5  # Default threshold for parallel fuzzy similarity

    # ì—”í‹°í‹° ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ëŠ” ì´ì œ prompts ë””ë ‰í† ë¦¬ì—ì„œ ê´€ë¦¬ë©ë‹ˆë‹¤.
    # prompts.DETAILED_ENTITY_EXTRACTION_PROMPT ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
    entity_extraction_prompt: str = None  # Deprecated: Use prompts.DETAILED_ENTITY_EXTRACTION_PROMPT instead
    
    def __post_init__(self):
        """Initialize default values and validate configuration after creation."""
        # Set default excluded domain codes if none provided
        if self.excluded_domain_codes_for_items is None:
            self.excluded_domain_codes_for_items = ['R']  # 'R' represents agency/dealer domain codes
        
        # Set default user-defined entities if none provided
        if self.user_defined_entities is None:
            self.user_defined_entities = [
                'AIA Vitality',  # Insurance/health program
                'ë¶€ìŠ¤íŠ¸ íŒŒí¬ ê±´ëŒ€ì…êµ¬',  # Specific location/venue
                'Boost Park ê±´ëŒ€ì…êµ¬'  # English variant of the above
            ]
        
        # Validate product_info_extraction_mode
        valid_modes = ['rag', 'llm', 'nlp']
        if self.product_info_extraction_mode not in valid_modes:
            raise ValueError(f"product_info_extraction_mode must be one of {valid_modes}")
        
        # Validate entity_extraction_mode
        valid_entity_modes = ['llm', 'logic']
        if self.entity_extraction_mode not in valid_entity_modes:
            raise ValueError(f"entity_extraction_mode must be one of {valid_entity_modes}")
            

    @property
    def chain_of_thought(self) -> str:
        """Get processing chain of thought based on extraction mode.
        
        Returns:
            str: Step-by-step processing instructions for the chosen mode
        """
        if self.product_info_extraction_mode == 'nlp':
            return """1. ê´‘ê³  ëª©ì ì„ ë¨¼ì € íŒŒì•…í•œë‹¤.
2. íŒŒì•…ëœ ëª©ì ì— ê¸°ë°˜í•˜ì—¬ Product ì •ë³´ë¥¼ ì¶”ì¶œí•œë‹¤.
3. ì£¼ì–´ì§„ name ì •ë³´ì— ê¸°ë°˜í•˜ì—¬, positionê³¼ action í•„ë“œì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•œë‹¤.
4. ì¶”ì¶œëœ ìƒí’ˆ ì •ë³´ë¥¼ ê³ ë ¤í•˜ì—¬ ì±„ë„ ì •ë³´ë¥¼ ì œê³µí•œë‹¤."""
        else:
            return """1. ê´‘ê³  ëª©ì ì„ ë¨¼ì € íŒŒì•…í•œë‹¤.
2. íŒŒì•…ëœ ëª©ì ì— ê¸°ë°˜í•˜ì—¬ Main ìƒí’ˆì„ ì¶”ì¶œí•œë‹¤.
3. ì¶”ì¶œí•œ Main ìƒí’ˆì— ê´€ë ¨ë˜ëŠ” Sub ìƒí’ˆì„ ì¶”ì¶œí•œë‹¤.
4. ì¶”ì¶œëœ ìƒí’ˆ ì •ë³´ë¥¼ ê³ ë ¤í•˜ì—¬ ì±„ë„ ì •ë³´ë¥¼ ì œê³µí•œë‹¤."""

    def get_extraction_guide(self, candidate_items: List[str] = None) -> str:
        """Get extraction guidelines based on current mode and available candidate items.
        
        Args:
            candidate_items: List of candidate item names to guide extraction
            
        Returns:
            str: Extraction guidelines for the current configuration
        """
        base_guide = "* ìƒí’ˆ ì¶”ì¶œì‹œ ì •í™•ë„(precision) ë³´ë‹¤ëŠ” ì¬í˜„ìœ¨(recall)ì— ì¤‘ì‹¬ì„ ë‘ì–´ë¼."
        
        if self.product_info_extraction_mode == 'rag' and candidate_items:
            return f"""{base_guide}
* í›„ë³´ ìƒí’ˆ ì´ë¦„ ëª©ë¡ì— í¬í•¨ëœ ìƒí’ˆ ì´ë¦„ì€ ì°¸ê³ í•˜ì—¬ Product ì •ë³´ë¥¼ ì¶”ì¶œí•˜ë¼."""
        elif self.product_info_extraction_mode == 'nlp':
            return "* Product ì •ë³´ì—ì„œ position, action í•„ë“œì˜ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ë¼."
        else:
            return base_guide

# Global configuration instances
# These are singleton instances that can be imported and used throughout the application
API_CONFIG = APIConfig()  # API keys and endpoints
MODEL_CONFIG = ModelConfig()  # AI model configurations
PROCESSING_CONFIG = ProcessingConfig()  # Processing behavior settings
METADATA_CONFIG = METADATAConfig()  # Data file paths
EMBEDDING_CONFIG = EmbeddingConfig()  # Embedding and model file paths
STORAGE_CONFIG = StorageConfig()  # Storage configuration for DAG images
DATABASE_CONFIG = DatabaseConfig()  # Database table names and queries