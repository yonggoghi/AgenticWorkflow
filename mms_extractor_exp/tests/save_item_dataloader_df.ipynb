{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save ItemDataLoader DataFrame\n",
    "\n",
    "This notebook loads item data using ItemDataLoader and saves the resulting DataFrames to CSV files for testing and inspection purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add project root to path\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0, project_root)\n",
    "os.chdir(project_root)\n",
    "\n",
    "import pandas as pd\n",
    "from services.item_data_loader import ItemDataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize ItemDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = ItemDataLoader(data_source='local')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Items\n",
    "\n",
    "If `load_and_prepare_items()` fails due to pandas version issues, we'll load step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    item_df, alias_df = loader.load_and_prepare_items()\n",
    "    print(f\"Successfully loaded: item_df={item_df.shape}, alias_df={alias_df.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error with load_and_prepare_items: {e}\")\n",
    "    print(\"Loading step by step...\")\n",
    "    \n",
    "    # Step 1: Load raw data\n",
    "    raw_data = loader.load_raw_data()\n",
    "    print(f\"Raw data: {raw_data.shape}\")\n",
    "    \n",
    "    # Step 2: Normalize columns\n",
    "    normalized_data = loader.normalize_columns(raw_data)\n",
    "    print(f\"Normalized: {normalized_data.shape}\")\n",
    "    \n",
    "    # Step 3: Filter by domain\n",
    "    filtered_data = loader.filter_by_domain(normalized_data)\n",
    "    print(f\"Filtered: {filtered_data.shape}\")\n",
    "    \n",
    "    # Step 4: Load alias rules\n",
    "    alias_pdf = loader.load_alias_rules()\n",
    "    print(f\"Alias rules: {alias_pdf.shape}\")\n",
    "    \n",
    "    # Step 5: Skip expand_build_aliases if it fails (uses problematic query)\n",
    "    try:\n",
    "        alias_pdf = loader.expand_build_aliases(alias_pdf, filtered_data)\n",
    "    except Exception as e2:\n",
    "        print(f\"Skipping expand_build_aliases: {e2}\")\n",
    "    \n",
    "    # Step 6: Create bidirectional aliases\n",
    "    alias_pdf = loader.create_bidirectional_aliases(alias_pdf)\n",
    "    print(f\"After bidirectional: {alias_pdf.shape}\")\n",
    "    \n",
    "    # Step 7: Apply cascading alias rules\n",
    "    with_aliases = loader.apply_cascading_alias_rules(filtered_data, alias_pdf)\n",
    "    print(f\"After cascading: {with_aliases.shape}\")\n",
    "    \n",
    "    # Step 8: Add user defined entities\n",
    "    with_user_entities = loader.add_user_defined_entities(with_aliases, None)\n",
    "    \n",
    "    # Step 9: Add domain name column\n",
    "    with_domain_names = loader.add_domain_name_column(with_user_entities)\n",
    "    \n",
    "    # Step 10: Filter test items\n",
    "    item_df = loader.filter_test_items(with_domain_names)\n",
    "    alias_df = alias_pdf\n",
    "    \n",
    "    print(f\"Final: item_df={item_df.shape}, alias_df={alias_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Inspect Item DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Item DataFrame Shape: {item_df.shape}\")\n",
    "print(f\"Columns: {list(item_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_df[['item_nm', 'item_id', 'item_nm_alias', 'item_dmn']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inspect Alias DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Alias DataFrame Shape: {alias_df.shape}\")\n",
    "print(f\"Columns: {list(alias_df.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Inspect Raw Alias DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if loader.alias_pdf_raw is not None:\n",
    "    print(f\"Raw Alias DataFrame Shape: {loader.alias_pdf_raw.shape}\")\n",
    "    display(loader.alias_pdf_raw.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save DataFrames to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'tests/item_data_output'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save item DataFrame\n",
    "item_output_path = os.path.join(output_dir, 'item_df.csv')\n",
    "item_df.to_csv(item_output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"Saved Item DataFrame: {item_output_path}\")\n",
    "\n",
    "# Save alias DataFrame\n",
    "alias_output_path = os.path.join(output_dir, 'alias_df.csv')\n",
    "alias_df.to_csv(alias_output_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"Saved Alias DataFrame: {alias_output_path}\")\n",
    "\n",
    "# Save raw alias DataFrame\n",
    "if loader.alias_pdf_raw is not None:\n",
    "    raw_alias_path = os.path.join(output_dir, 'alias_raw_df.csv')\n",
    "    loader.alias_pdf_raw.to_csv(raw_alias_path, index=False, encoding='utf-8-sig')\n",
    "    print(f\"Saved Raw Alias DataFrame: {raw_alias_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Query Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all aliases for a specific item\n",
    "item_name = 'iPhone 17'\n",
    "item_aliases = item_df[item_df['item_nm'].str.contains(item_name, case=False, na=False)]\n",
    "print(f\"Aliases for '{item_name}':\")\n",
    "item_aliases[['item_nm', 'item_nm_alias', 'item_dmn']].drop_duplicates()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
