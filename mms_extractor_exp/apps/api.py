#!/usr/bin/env python3
"""
MMS ì¶”ì¶œê¸° REST API ì„œë¹„ìŠ¤ (MMS Extractor API Service)
================================================================

ğŸ¯ ê°œìš”
-------
ì´ ëª¨ë“ˆì€ MMS ê´‘ê³  í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œìŠ¤í…œì„ RESTful API ì„œë¹„ìŠ¤ë¡œ ì œê³µí•˜ëŠ”
ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ì›¹ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. Flask ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ë˜ì–´ ê³ ì„±ëŠ¥ê³¼ í™•ì¥ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.

ğŸ”— ì˜ì¡´ì„±
---------
**ì‚¬ìš©í•˜ëŠ” ëª¨ë“ˆ:**
- `core.mms_extractor`: MMSExtractor ë©”ì¸ ì—”ì§„
- `config.settings`: API, ëª¨ë¸, ì²˜ë¦¬ ì„¤ì •
- `flask`: ì›¹ í”„ë ˆì„ì›Œí¬
- `flask_cors`: CORS ì§€ì›

**ì•„í‚¤í…ì²˜:**
```
Client Request
    â†“
Flask API Server (api.py)
    â†“
global_extractor (MMSExtractor)
    â†“
WorkflowEngine â†’ 9 Steps
    â†“
JSON Response
```

ğŸš€ í•µì‹¬ ê¸°ëŠ¥
-----------
â€¢ **ë‹¨ì¼ ë©”ì‹œì§€ ì²˜ë¦¬**: `POST /extract` - ì‹¤ì‹œê°„ ë©”ì‹œì§€ ë¶„ì„
â€¢ **ë°°ì¹˜ ì²˜ë¦¬**: `POST /extract/batch` - ëŒ€ëŸ‰ ë©”ì‹œì§€ ì¼ê´„ ì²˜ë¦¬
â€¢ **DAG ì¶”ì¶œ**: `POST /dag` - ì—”í‹°í‹° ê´€ê³„ ê·¸ë˜í”„ ìƒì„±
â€¢ **ì„œë¹„ìŠ¤ ëª¨ë‹ˆí„°ë§**: `GET /health`, `GET /status` - ì„œë¹„ìŠ¤ ìƒíƒœ ë° ì„±ëŠ¥ ì§€í‘œ
â€¢ **ëª¨ë¸ ê´€ë¦¬**: `GET /models` - ì‚¬ìš© ê°€ëŠ¥í•œ LLM ëª¨ë¸ ëª©ë¡
â€¢ **ë‹¤ì¤‘ LLM ì§€ì›**: OpenAI GPT, Anthropic Claude, Gemini, AX ë“±
â€¢ **ì‹¤ì‹œê°„ ì„¤ì •**: ëŸ°íƒ€ì„ ì¤‘ ì„¤ì • ë³€ê²½ ì§€ì›

ğŸ“Š ì„±ëŠ¥ íŠ¹ì§•
-----------
â€¢ **ê³ ì„±ëŠ¥**: ì „ì—­ ì¶”ì¶œê¸° ì¬ì‚¬ìš©ìœ¼ë¡œ ì´ˆê¸°í™” ì˜¤ë²„í—¤ë“œ ì œê±°
â€¢ **í™•ì¥ì„±**: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ì§€ì›
â€¢ **ì•ˆì •ì„±**: í¬ê´„ì ì¸ ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹…
â€¢ **ë³´ì•ˆ**: CORS ì„¤ì • ë° ì…ë ¥ ê²€ì¦

ğŸš€ ì‚¬ìš©ë²•
---------
```bash
# ê¸°ë³¸ ì„œë¹„ìŠ¤ ì‹œì‘
python api.py --host 0.0.0.0 --port 8000

# íŠ¹ì • LLM ëª¨ë¸ë¡œ ì‹œì‘
python api.py --llm-model ax --port 8080

# ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ ì„¤ì •
python api.py --entity-matching-mode llm

# ë°ì´í„° ì†ŒìŠ¤ ì§€ì •
python api.py --data-source db

# í…ŒìŠ¤íŠ¸ ëª¨ë“œ
python api.py --test --message "ìƒ˜í”Œ MMS í…ìŠ¤íŠ¸"
```

ğŸ—ï¸ API ì—”ë“œí¬ì¸íŠ¸
--------------

### ë©”ì¸ ì¶”ì¶œ API
- **POST /extract**: ë‹¨ì¼ ë©”ì‹œì§€ ë¶„ì„
  - Request: `{"message": "...", "llm_model": "ax", ...}`
  - Response: `{"success": true, "result": {...}, "metadata": {...}}`

- **POST /extract/batch**: ë°°ì¹˜ ë©”ì‹œì§€ ë¶„ì„
  - Request: `{"messages": ["...", "..."], ...}`
  - Response: `{"success": true, "results": [...], "summary": {...}}`

### DAG ì¶”ì¶œ API
- **POST /dag**: Entity DAG ì¶”ì¶œ
  - Request: `{"message": "...", "llm_models": ["ax", "gpt"]}`
  - Response: `{"dag_section": "...", "entities": [...], ...}`

- **GET /dag_images/<filename>**: DAG ì´ë¯¸ì§€ íŒŒì¼ ì œê³µ

### Quick Extractor API
- **POST /quick/extract**: ì œëª©/ìˆ˜ì‹ ê±°ë¶€ ë²ˆí˜¸ ì¶”ì¶œ (ë‹¨ì¼)
- **POST /quick/extract/batch**: ì œëª©/ìˆ˜ì‹ ê±°ë¶€ ë²ˆí˜¸ ì¶”ì¶œ (ë°°ì¹˜)

### ëª¨ë‹ˆí„°ë§ API
- **GET /health**: ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
  - Response: `{"status": "healthy", "service": "MMS Extractor API", ...}`

- **GET /status**: ìƒì„¸ ì„±ëŠ¥ ì§€í‘œ
- **GET /models**: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡
  - Response: `{"available_llm_models": ["ax", "gpt", ...], ...}`

ğŸ“ˆ ëª¨ë‹ˆí„°ë§
-----------
- **ë¡œê¹…**: íšŒì „ ë¡œê·¸ íŒŒì¼ (api_server.log, 5MB x 10ê°œ)
- **ì„±ëŠ¥ ë©”íŠ¸ë¦­ìŠ¤**: ì²˜ë¦¬ ì‹œê°„, ì„±ê³µ/ì‹¤íŒ¨ìœ¨
- **ì—ëŸ¬ ì¶”ì **: ìƒì„¸ ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤
- **ìì› ì‚¬ìš©ëŸ‰**: ë©”ëª¨ë¦¬, CPU ëª¨ë‹ˆí„°ë§

ğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ
-----------
```python
import requests

# 1. ë‹¨ì¼ ë©”ì‹œì§€ ì¶”ì¶œ
response = requests.post('http://localhost:8000/extract', json={
    "message": "ì•„ì´í° 17 êµ¬ë§¤ ì‹œ ìµœëŒ€ 22ë§Œì› ìºì‹œë°±",
    "llm_model": "ax",
    "entity_matching_mode": "llm"
})
result = response.json()

# 2. ë°°ì¹˜ ì²˜ë¦¬
response = requests.post('http://localhost:8000/extract/batch', json={
    "messages": ["ë©”ì‹œì§€1", "ë©”ì‹œì§€2", "ë©”ì‹œì§€3"],
    "llm_model": "ax"
})
results = response.json()

# 3. DAG ì¶”ì¶œ
response = requests.post('http://localhost:8000/dag', json={
    "message": "T world ì•± ì ‘ì† í›„ í€´ì¦ˆ ì°¸ì—¬í•˜ë©´ ì˜¬ë¦¬ë¸Œì˜ ê¸°í”„í‹°ì½˜ íšë“",
    "llm_models": ["ax", "gpt"]
})
dag_result = response.json()

# 4. í—¬ìŠ¤ì²´í¬
response = requests.get('http://localhost:8000/health')
health = response.json()
```

ğŸ“ ì°¸ê³ ì‚¬í•­
----------
- ì „ì—­ ì¶”ì¶œê¸°ëŠ” ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì´ˆê¸°í™”ë¨
- ëŸ°íƒ€ì„ ì„¤ì • ë³€ê²½ì€ ë°ì´í„° ì¬ë¡œë”© ì—†ì´ ê°€ëŠ¥
- MongoDB ì €ì¥ì€ ì„ íƒì  (save_to_mongodb íŒŒë¼ë¯¸í„°)
- DAG ì´ë¯¸ì§€ëŠ” ./dag_images/ ë””ë ‰í† ë¦¬ì— ì €ì¥
- í”„ë¡¬í”„íŠ¸ëŠ” ìŠ¤ë ˆë“œ ë¡œì»¬ ì €ì¥ì†Œì— ìºì‹œë¨

"""
# =============================================================================
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# =============================================================================
import sys
import os
# Add parent directory to path to allow imports from core
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import json
import logging
import time
import argparse
import warnings
import atexit
from pathlib import Path
from flask import Flask, request, jsonify, send_from_directory
from flask_cors import CORS
from config import settings

# =============================================================================
# ê²½ê³  ë©”ì‹œì§€ ì–µì œ (ë¡œê·¸ ë…¸ì´ì¦ˆ ê°ì†Œ)
# =============================================================================
# joblibê³¼ multiprocessing ê´€ë ¨ ê²½ê³  ì–µì œ
warnings.filterwarnings("ignore", category=UserWarning, module="joblib")
warnings.filterwarnings("ignore", category=UserWarning, module="multiprocessing") 
warnings.filterwarnings("ignore", message=".*resource_tracker.*")
warnings.filterwarnings("ignore", message=".*leaked.*")

# =============================================================================
# ê²½ë¡œ ì„¤ì • ë° ëª¨ë“ˆ ì„í¬íŠ¸ ì¤€ë¹„
# =============================================================================
# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€ (ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸ë¥¼ ìœ„í•´)
current_dir = Path(__file__).parent.absolute()
sys.path.insert(0, str(current_dir))

# =============================================================================
# í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸ (ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)
# =============================================================================
# MMS ì¶”ì¶œê¸° ë° ì„¤ì • ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from core.mms_extractor import MMSExtractor, process_message_worker, process_messages_batch, save_result_to_mongodb_if_enabled
    from config.settings import API_CONFIG, MODEL_CONFIG, PROCESSING_CONFIG
    # Lazy import for DAG extractor
    from core.entity_dag_extractor import DAGParser, extract_dag, llm_ax, llm_gem, llm_cld, llm_gen, llm_gpt
    from quick_extractor import MessageInfoExtractor  # Quick Extractor ì„í¬íŠ¸
except ImportError as e:
    print(f"âŒ ëª¨ë“ˆ ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
    print("ğŸ“ mms_extractor.pyê°€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
    print("ğŸ“ config/ ë””ë ‰í† ë¦¬ì™€ ì„¤ì • íŒŒì¼ë“¤ì„ í™•ì¸í•˜ì„¸ìš”")
    print("ğŸ“ quick_extractor.pyê°€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
    sys.exit(1)

# Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)
CORS(app)  # CORS í™œì„±í™” (í¬ë¡œìŠ¤ ì˜¤ë¦¬ì§„ ìš”ì²­ í—ˆìš©)

def cleanup_resources():
    """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ í•¨ìˆ˜ - í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ í˜¸ì¶œ"""
    try:
        import gc
        import multiprocessing
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
        gc.collect()
        
        # ë©€í‹°í”„ë¡œì„¸ì‹± ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        if hasattr(multiprocessing, 'active_children'):
            for child in multiprocessing.active_children():
                try:
                    child.terminate()
                    child.join(timeout=1)
                except:
                    pass
                    
        print("ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
    except Exception as e:
        print(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
atexit.register(cleanup_resources)

# ë¡œê¹… ì„¤ì • - ì½˜ì†”ê³¼ íŒŒì¼ ëª¨ë‘ì— ì¶œë ¥
import logging.handlers

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
log_dir = Path(__file__).parent.parent / 'logs'
log_dir.mkdir(exist_ok=True)

# API ì „ìš© ë¡œê·¸ íŒŒì¼ ê²½ë¡œ - ì‹¤ì‹œê°„ API ìš”ì²­/ì‘ë‹µ ë¡œê·¸
log_file = log_dir / 'api_server.log'

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# í¬ë§·í„° ì„¤ì • - ëª¨ë“ˆëª… í¬í•¨í•˜ì—¬ ë¡œê·¸ ì¶œì²˜ ëª…í™•í™”
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# ì½˜ì†” í•¸ë“¤ëŸ¬
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(formatter)

# API ì „ìš© íŒŒì¼ í•¸ë“¤ëŸ¬ (íšŒì „ ë¡œê·¸ - 5MBì”© ìµœëŒ€ 10ê°œ íŒŒì¼, ì§§ì€ ë³´ì¡´ê¸°ê°„)
file_handler = logging.handlers.RotatingFileHandler(
    log_file, 
    maxBytes=5*1024*1024,   # 5MB (API ë¡œê·¸ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì‘ìŒ)
    backupCount=10,         # ë” ë§ì€ íŒŒì¼ ë³´ì¡´ (ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ìš©)
    encoding='utf-8'
)
file_handler.setLevel(logging.INFO)
file_handler.setFormatter(formatter)

# ë£¨íŠ¸ ë¡œê±°ì—ë§Œ í•¸ë“¤ëŸ¬ ì¶”ê°€í•˜ì—¬ ëª¨ë“  í•˜ìœ„ ë¡œê±°ì˜ ë¡œê·¸ë¥¼ ì²˜ë¦¬
root_logger = logging.getLogger()
root_logger.setLevel(logging.INFO)
root_logger.addHandler(console_handler)
root_logger.addHandler(file_handler)

# ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
root_logger.handlers = [console_handler, file_handler]

# ê°œë³„ ë¡œê±°ë“¤ì€ ë£¨íŠ¸ ë¡œê±°ë¡œ ì „íŒŒí•˜ë„ë¡ ì„¤ì • (í•¸ë“¤ëŸ¬ ì¤‘ë³µ ë“±ë¡ ë°©ì§€)
logger.setLevel(logging.INFO)
mms_logger = logging.getLogger('mms_extractor')
mms_logger.setLevel(logging.INFO)

# ì „íŒŒ ì„¤ì • í™•ì¸ (ê¸°ë³¸ê°’ì´ Trueì´ë¯€ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •)
logger.propagate = True
mms_logger.propagate = True

# ì „ì—­ ì¶”ì¶œê¸° ì¸ìŠ¤í„´ìŠ¤ - ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¡œë“œ
global_extractor = None

# ì „ì—­ Quick Extractor ì¸ìŠ¤í„´ìŠ¤ (ì œëª©/ìˆ˜ì‹ ê±°ë¶€ ë²ˆí˜¸ ì¶”ì¶œìš©)
global_quick_extractor = None

# CLIì—ì„œ ì„¤ì •ëœ ë°ì´í„° ì†ŒìŠ¤ (ì „ì—­ ë³€ìˆ˜)
CLI_DATA_SOURCE = 'local'

def initialize_global_extractor(offer_info_data_src='db'):
    """
    ì „ì—­ ì¶”ì¶œê¸° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì´ˆê¸°í™”
    
    ì´ í•¨ìˆ˜ëŠ” ë¬´ê±°ìš´ ë°ì´í„° ë¡œë”© ì‘ì—…(ìƒí’ˆ ì •ë³´, ì„ë² ë”© ëª¨ë¸ ë“±)ì„ 
    ì„œë²„ ì‹œì‘ ì‹œ ë¯¸ë¦¬ ìˆ˜í–‰í•˜ì—¬ API ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤.
    
    Args:
        offer_info_data_src: ìƒí’ˆ ì •ë³´ ë°ì´í„° ì†ŒìŠ¤ ('local' ë˜ëŠ” 'db')
    
    Returns:
        MMSExtractor: ì´ˆê¸°í™”ëœ ì¶”ì¶œê¸° ì¸ìŠ¤í„´ìŠ¤
    """
    global global_extractor
    
    if global_extractor is None:
        logger.info(f"ë°ì´í„° ì†ŒìŠ¤ë¡œ ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì¤‘: {offer_info_data_src}")
        
        # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¶”ì¶œê¸° ì´ˆê¸°í™” (CLIì™€ ë™ì¼í•œ ê¸°ë³¸ê°’ ì‚¬ìš©)
        global_extractor = MMSExtractor(
            model_path='./models/ko-sbert-nli',      # ì„ë² ë”© ëª¨ë¸ ê²½ë¡œ
            data_dir='./data',                       # ë°ì´í„° ë””ë ‰í† ë¦¬
            offer_info_data_src=offer_info_data_src, # ìƒí’ˆ ì •ë³´ ì†ŒìŠ¤
            llm_model='gemini',                      # ê¸°ë³¸ LLM: Gemini (CLIì™€ ë™ì¼)
            product_info_extraction_mode='llm',      # ê¸°ë³¸ ìƒí’ˆ ì¶”ì¶œ ëª¨ë“œ: LLM (CLIì™€ ë™ì¼)
            entity_extraction_mode='llm',            # ê¸°ë³¸ ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ: LLM (CLIì™€ ë™ì¼)
            extract_entity_dag=True,
            entity_extraction_context_mode='dag'     # ê¸°ë³¸ ì»¨í…ìŠ¤íŠ¸ ëª¨ë“œ: DAG
        )
        
        logger.info("ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    return global_extractor

def initialize_quick_extractor(use_llm=False, llm_model='ax'):
    """
    ì „ì—­ Quick Extractor ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ˆê¸°í™”
    
    Args:
        use_llm: LLM ì‚¬ìš© ì—¬ë¶€
        llm_model: ì‚¬ìš©í•  LLM ëª¨ë¸ ('ax', 'gpt', 'claude', 'gemini' ë“±)
    
    Returns:
        MessageInfoExtractor: ì´ˆê¸°í™”ëœ Quick Extractor ì¸ìŠ¤í„´ìŠ¤
    """
    global global_quick_extractor
    
    if global_quick_extractor is None:
        logger.info(f"Quick Extractor ì´ˆê¸°í™” ì¤‘... (LLM: {use_llm}, ëª¨ë¸: {llm_model})")
        
        # Quick Extractor ì´ˆê¸°í™” (csv_pathëŠ” APIì—ì„œ í•„ìš” ì—†ìŒ)
        global_quick_extractor = MessageInfoExtractor(
            csv_path=None,
            use_llm=use_llm,
            llm_model=llm_model
        )
        
        logger.info("Quick Extractor ì´ˆê¸°í™” ì™„ë£Œ")
    
    return global_quick_extractor

def get_configured_quick_extractor(use_llm=False, llm_model='ax'):
    """
    ëŸ°íƒ€ì„ ì„¤ì •ìœ¼ë¡œ Quick Extractor êµ¬ì„±
    
    Args:
        use_llm: LLM ì‚¬ìš© ì—¬ë¶€
        llm_model: ì‚¬ìš©í•  LLM ëª¨ë¸
    
    Returns:
        MessageInfoExtractor: êµ¬ì„±ëœ Quick Extractor ì¸ìŠ¤í„´ìŠ¤
    """
    if global_quick_extractor is None:
        return initialize_quick_extractor(use_llm, llm_model)
    
    # LLM ì„¤ì •ì´ ë³€ê²½ëœ ê²½ìš° ì¬ì´ˆê¸°í™”
    if use_llm != global_quick_extractor.use_llm or llm_model != global_quick_extractor.llm_model_name:
        logger.info(f"Quick Extractor ì¬ì„¤ì • ì¤‘... (LLM: {use_llm}, ëª¨ë¸: {llm_model})")
        return initialize_quick_extractor(use_llm, llm_model)
    
    return global_quick_extractor

def get_configured_extractor(llm_model='gemini', product_info_extraction_mode='llm', entity_matching_mode='llm', entity_llm_model='ax', extract_entity_dag=True, entity_extraction_context_mode='dag'):
    """
    ëŸ°íƒ€ì„ ì„¤ì •ìœ¼ë¡œ ì „ì—­ ì¶”ì¶œê¸° êµ¬ì„±
    
    ë°ì´í„° ì¬ë¡œë”© ì—†ì´ LLM ëª¨ë¸ê³¼ ì²˜ë¦¬ ëª¨ë“œë§Œ ë³€ê²½í•˜ì—¬ 
    API ìš”ì²­ë³„ë¡œ ë‹¤ë¥¸ ì„¤ì •ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    Args:
        llm_model: ë©”ì¸ í”„ë¡¬í”„íŠ¸ì— ì‚¬ìš©í•  LLM ëª¨ë¸ ('gemma', 'ax', 'claude', 'gpt', 'gemini')
        product_info_extraction_mode: ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ëª¨ë“œ ('nlp', 'llm', 'rag')
        entity_matching_mode: ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ ('logic', 'llm')
        entity_llm_model: ì—”í‹°í‹° ì¶”ì¶œì— ì‚¬ìš©í•  LLM ëª¨ë¸ ('gemma', 'ax', 'claude', 'gpt', 'gemini')
        entity_extraction_context_mode: ì—”í‹°í‹° ì¶”ì¶œ ì»¨í…ìŠ¤íŠ¸ ëª¨ë“œ ('dag', 'pairing', 'none')
    
    Returns:
        MMSExtractor: êµ¬ì„±ëœ ì¶”ì¶œê¸° ì¸ìŠ¤í„´ìŠ¤
    
    Raises:
        RuntimeError: ì „ì—­ ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°
    """
    if global_extractor is None:
        raise RuntimeError("ì „ì—­ ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. initialize_global_extractor()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
    
    # í˜„ì¬ ì„¤ì •ê³¼ ë¹„êµí•˜ì—¬ ë³€ê²½ëœ ê²½ìš°ë§Œ ì—…ë°ì´íŠ¸
    current_llm_model = getattr(global_extractor, 'llm_model_name', None)
    llm_model_changed = current_llm_model != llm_model
    
    # ë°ì´í„° ì¬ë¡œë”© ì—†ì´ ëŸ°íƒ€ì„ ì„¤ì •ë§Œ ì—…ë°ì´íŠ¸
    global_extractor.llm_model_name = llm_model
    global_extractor.entity_llm_model_name = entity_llm_model
    global_extractor.product_info_extraction_mode = product_info_extraction_mode
    global_extractor.entity_extraction_mode = entity_matching_mode
    global_extractor.extract_entity_dag = extract_entity_dag
    global_extractor.entity_extraction_context_mode = entity_extraction_context_mode
    
    # ResultBuilderì˜ llm_modelë„ ì—…ë°ì´íŠ¸
    if hasattr(global_extractor, 'result_builder'):
        global_extractor.result_builder.llm_model = entity_llm_model
    
    # LLM ëª¨ë¸ì´ ì‹¤ì œë¡œ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ ì¬ì´ˆê¸°í™”
    if llm_model_changed:
        logger.info(f"LLM ëª¨ë¸ì´ {current_llm_model} -> {llm_model}ë¡œ ë³€ê²½ë¨. ì¬ì´ˆê¸°í™” ì¤‘...")
        global_extractor._initialize_llm()
    
    return global_extractor

@app.route('/health', methods=['GET'])
def health_check():
    """
    ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸
    
    ì„œë¹„ìŠ¤ê°€ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê°„ë‹¨í•œ í—¬ìŠ¤ì²´í¬ APIì…ë‹ˆë‹¤.
    ë¡œë“œë°¸ëŸ°ì„œë‚˜ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    
    Returns:
        JSON: ì„œë¹„ìŠ¤ ìƒíƒœ ì •ë³´
            - status: ì„œë¹„ìŠ¤ ìƒíƒœ ("healthy")
            - service: ì„œë¹„ìŠ¤ ì´ë¦„
            - version: ë²„ì „ ì •ë³´
            - model: ì‚¬ìš© ì¤‘ì¸ ê¸°ë³¸ ëª¨ë¸
            - timestamp: ì‘ë‹µ ì‹œê°„
    """
    return jsonify({
        "status": "healthy",
        "service": "MMS Extractor API",
        "version": "2.0.0",
        "model": "skt/gemma3-12b-it",
        "timestamp": time.time()
    })

@app.route('/models', methods=['GET'])
def list_models():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë° ì„¤ì • ì˜µì…˜ ëª©ë¡ ì¡°íšŒ
    
    í´ë¼ì´ì–¸íŠ¸ê°€ APIì—ì„œ ì§€ì›í•˜ëŠ” ëª¨ë“  ì˜µì…˜ì„ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ 
    ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ê³¼ ì„¤ì •ê°’ë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        JSON: ì‚¬ìš© ê°€ëŠ¥í•œ ì„¤ì • ì˜µì…˜ë“¤
            - available_llm_models: ì§€ì›í•˜ëŠ” LLM ëª¨ë¸ ëª©ë¡
            - available_data_sources: ì§€ì›í•˜ëŠ” ë°ì´í„° ì†ŒìŠ¤
            - available_product_info_extraction_modes: ìƒí’ˆ ì¶”ì¶œ ëª¨ë“œ
            - available_entity_matching_modes: ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ
            - features: ì£¼ìš” ê¸°ëŠ¥ ëª©ë¡
    """
    return jsonify({
        "available_llm_models": ["gemma", "ax", "claude", "gemini"],
        "default_llm_model": "ax",
        "available_data_sources": ["local", "db"],
        "default_data_source": "local",
        "available_product_info_extraction_modes": ["nlp", "llm", "rag"],
        "default_product_info_extraction_mode": "nlp",
        "available_entity_matching_modes": ["logic", "llm"],
        "default_entity_matching_mode": "logic",
        "features": [
            "Korean morphological analysis (Kiwi)",      # í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„
            "Embedding-based similarity search",         # ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
            "Entity extraction and matching",            # ì—”í‹°í‹° ì¶”ì¶œ ë° ë§¤ì¹­
            "Program classification",                     # í”„ë¡œê·¸ë¨ ë¶„ë¥˜
            "Multiple LLM support (Gemma, GPT, Claude)" # ë‹¤ì¤‘ LLM ì§€ì›
        ]
    })

@app.route('/extract', methods=['POST'])
def extract_message():
    """
    ë‹¨ì¼ MMS ë©”ì‹œì§€ ì •ë³´ ì¶”ì¶œ API
    
    í•˜ë‚˜ì˜ MMS ë©”ì‹œì§€ì—ì„œ ìƒí’ˆëª…, ì±„ë„ ì •ë³´, ê´‘ê³  ëª©ì  ë“±ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Request Body (JSON):
        - message (required): ì¶”ì¶œí•  MMS ë©”ì‹œì§€ í…ìŠ¤íŠ¸
        - llm_model (optional): ì‚¬ìš©í•  LLM ëª¨ë¸ (ê¸°ë³¸ê°’: 'ax')
        - offer_info_data_src (optional): ë°ì´í„° ì†ŒìŠ¤ (ê¸°ë³¸ê°’: CLI ì„¤ì •ê°’)
        - product_info_extraction_mode (optional): ìƒí’ˆ ì¶”ì¶œ ëª¨ë“œ (ê¸°ë³¸ê°’: 'nlp')
        - entity_matching_mode (optional): ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ (ê¸°ë³¸ê°’: 'logic')
        - extract_entity_dag (optional): ì—”í‹°í‹° DAG ì¶”ì¶œ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
                                         Trueì¼ ê²½ìš° ë©”ì‹œì§€ì—ì„œ ì—”í‹°í‹° ê°„ ê´€ê³„ë¥¼ DAG í˜•íƒœë¡œ ì¶”ì¶œí•˜ê³ 
                                         ì‹œê°ì  ë‹¤ì´ì–´ê·¸ë¨ë„ í•¨ê»˜ ìƒì„±í•©ë‹ˆë‹¤.
        - result_type (optional): ì¶”ì¶œ ê²°ê³¼ íƒ€ì… (ê¸°ë³¸ê°’: 'ext')
        - save_to_mongodb (optional): MongoDB ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
    
    Returns:
        JSON: ì¶”ì¶œ ê²°ê³¼
            - success: ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
            - result: ì¶”ì¶œëœ ì •ë³´ (title, purpose, product, channel, pgm)
                     extract_entity_dag=Trueì¸ ê²½ìš° entity_dag í•„ë“œë„ í¬í•¨
            - metadata: ì²˜ë¦¬ ë©”íƒ€ë°ì´í„° (ì²˜ë¦¬ ì‹œê°„, ì‚¬ìš©ëœ ì„¤ì •, DAG ì¶”ì¶œ ì—¬ë¶€ ë“±)
    
    HTTP Status Codes:
        - 200: ì„±ê³µ
        - 400: ì˜ëª»ëœ ìš”ì²­ (í•„ìˆ˜ í•„ë“œ ëˆ„ë½, ì˜ëª»ëœ íŒŒë¼ë¯¸í„° ë“±)
        - 500: ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜
    """
    try:
        # ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
        if global_extractor is None:
            return jsonify({"error": "ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."}), 500
        
        # ìš”ì²­ ë°ì´í„° ê²€ì¦
        if not request.is_json:
            return jsonify({"error": "Content-Typeì€ application/jsonì´ì–´ì•¼ í•©ë‹ˆë‹¤"}), 400
        
        data = request.get_json()
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if 'message' not in data:
            return jsonify({"error": "í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: 'message'"}), 400
        
        message = data['message']
        if not message or not message.strip():
            return jsonify({"error": "ë©”ì‹œì§€ëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 400
        
        # ì„ íƒì  íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ê¸°ë³¸ê°’ ì‚¬ìš©)
        data_source = data.get('data_source', CLI_DATA_SOURCE)
        offer_info_data_src = data.get('offer_info_data_src', CLI_DATA_SOURCE)
        llm_model = data.get('llm_model', settings.ModelConfig.llm_model)
        entity_llm_model = data.get('entity_llm_model', 'ax')
        product_info_extraction_mode = data.get('product_info_extraction_mode', settings.ProcessingConfig.product_info_extraction_mode)
        entity_matching_mode = data.get('entity_matching_mode', settings.ProcessingConfig.entity_extraction_mode)
        extract_entity_dag = data.get('extract_entity_dag', True)
        entity_extraction_context_mode = data.get('entity_extraction_context_mode', 'dag')
        save_to_mongodb = data.get('save_to_mongodb', True)
        result_type = data.get('result_type', 'ext')
        message_id = data.get('message_id', '#')  # ë©”ì‹œì§€ ID (ê¸°ë³¸ê°’: '#')

        data['save_to_mongodb'] = save_to_mongodb
        data['result_type'] = result_type
        data['processing_mode'] = 'single'
        
        # DAG ì¶”ì¶œ ìš”ì²­ ë¡œê¹…
        if extract_entity_dag:
            logger.info(f"ğŸ¯ DAG ì¶”ì¶œ ìš”ì²­ë¨ - LLM: {llm_model}, ë©”ì‹œì§€ ê¸¸ì´: {len(message)}ì")
        
        # ë©”ì‹œì§€ ID ë¡œê¹…
        if message_id != '#':
            logger.info(f"ğŸ“‹ ë©”ì‹œì§€ ID: {message_id}")
        
        # íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì¦
        valid_sources = ['local', 'db']
        if offer_info_data_src not in valid_sources:
            return jsonify({"error": f"ì˜ëª»ëœ offer_info_data_srcì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_sources}"}), 400
            
        valid_llm_models = ['gemma', 'ax', 'claude', 'gemini']
        if llm_model not in valid_llm_models:
            return jsonify({"error": f"ì˜ëª»ëœ llm_modelì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_llm_models}"}), 400
            
        valid_product_modes = ['nlp', 'llm', 'rag']
        if product_info_extraction_mode not in valid_product_modes:
            return jsonify({"error": f"ì˜ëª»ëœ product_info_extraction_modeì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_product_modes}"}), 400
            
        valid_entity_modes = ['logic', 'llm']
        if entity_matching_mode not in valid_entity_modes:
            return jsonify({"error": f"ì˜ëª»ëœ entity_matching_modeì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_entity_modes}"}), 400
        
        # DAG ì¶”ì¶œ ê¸°ëŠ¥ í™œì„±í™”
        # extract_entity_dag=Trueì¸ ê²½ìš°:
        # 1. ë©”ì‹œì§€ì—ì„œ ì—”í‹°í‹° ê°„ ê´€ê³„ë¥¼ DAG(Directed Acyclic Graph) í˜•íƒœë¡œ ì¶”ì¶œ
        # 2. NetworkXë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ êµ¬ì¡° ìƒì„±
        # 3. Graphvizë¥¼ í†µí•´ ì‹œê°ì  ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± (./dag_images/ ë””ë ‰í† ë¦¬ì— ì €ì¥)
        # 4. ê²°ê³¼ì˜ entity_dag í•„ë“œì— DAG í…ìŠ¤íŠ¸ í‘œí˜„ í¬í•¨
        
        # êµ¬ì„±ëœ ì¶”ì¶œê¸°ë¡œ ë©”ì‹œì§€ ì²˜ë¦¬ (í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ í¬í•¨)
        start_time = time.time()
        extractor = get_configured_extractor(llm_model, product_info_extraction_mode, entity_matching_mode, entity_llm_model, extract_entity_dag, entity_extraction_context_mode)
        
        logger.info(f"ë°ì´í„° ì†ŒìŠ¤ë¡œ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘: {offer_info_data_src}")
        
        # í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ë¥¼ ìœ„í•œ ìŠ¤ë ˆë“œ ë¡œì»¬ ì €ì¥ì†Œ ì´ˆê¸°í™”
        import threading
        current_thread = threading.current_thread()
        current_thread.stored_prompts = {}
        
        # DAG ì¶”ì¶œ ì—¬ë¶€ì— ë”°ë¼ ë³‘ë ¬ ì²˜ë¦¬ ë˜ëŠ” ë‹¨ì¼ ì²˜ë¦¬
        if extract_entity_dag:
            logger.info("DAG ì¶”ì¶œê³¼ í•¨ê»˜ ìˆœì°¨ ì²˜ë¦¬ ì‹œì‘")
            result = process_message_worker(extractor, message, extract_dag=True, message_id=message_id)
        else:
            result = extractor.process_message(message, message_id=message_id)
            result['ext_result']['entity_dag'] = []
            result['raw_result']['entity_dag'] = []  # DAG ì¶”ì¶œí•˜ì§€ ì•Šì€ ê²½ìš° ë¹ˆ ë°°ì—´

        if save_to_mongodb:
            logger.info("MongoDB ì €ì¥ ì¤‘...")
            saved_id = save_result_to_mongodb_if_enabled(message, result, data, extractor)
            if saved_id:
                logger.info("MongoDB ì €ì¥ ì™„ë£Œ!")

        if result_type == 'raw':
            result = result.get('raw_result', {})
        else:
            result = result.get('ext_result', {})
            
        processing_time = time.time() - start_time
        
        # ìº¡ì²˜ëœ í”„ë¡¬í”„íŠ¸ë“¤ ê°€ì ¸ì˜¤ê¸°
        captured_prompts = getattr(current_thread, 'stored_prompts', {})
        logger.info(f"ì¶”ì¶œ ê³¼ì •ì—ì„œ ìº¡ì²˜ëœ í”„ë¡¬í”„íŠ¸: {len(captured_prompts)}ê°œ")
        
        # DAG ì¶”ì¶œ ê²°ê³¼ ê²€ì¦ ë° ë¡œê¹…
        # entity_dag í•„ë“œëŠ” ì¶”ì¶œëœ ì—”í‹°í‹° ê°„ì˜ ê´€ê³„ë¥¼ í…ìŠ¤íŠ¸ë¡œ í‘œí˜„í•œ ê²ƒ
        # ì˜ˆ: "(ê³ ê°:ê°€ì…) -[í•˜ë©´]-> (í˜œíƒ:ìˆ˜ë ¹)"
        if extract_entity_dag and 'entity_dag' in result:
            dag_length = len(result['entity_dag']) if result['entity_dag'] else 0
            if dag_length > 0:
                logger.info(f"âœ… DAG ì¶”ì¶œ ì„±ê³µ - ê¸¸ì´: {dag_length}ì")
                logger.info(f"DAG ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {result['entity_dag'][:100]}...")
            else:
                logger.warning("âš ï¸ DAG ì¶”ì¶œ ìš”ì²­ë˜ì—ˆìœ¼ë‚˜ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
        
        # ì„±ê³µ ì‘ë‹µ ë°˜í™˜ (í”„ë¡¬í”„íŠ¸ í¬í•¨)
        response = {
            "success": True,
            "result": result,
            "metadata": {
                "llm_model": llm_model,
                "offer_info_data_src": offer_info_data_src,
                "product_info_extraction_mode": product_info_extraction_mode,
                "entity_matching_mode": entity_matching_mode,
                "extract_entity_dag": extract_entity_dag,
                "processing_time_seconds": round(processing_time, 3),
                "timestamp": time.time(),
                "message_length": len(message)
            },
            "prompts": {
                "success": True,
                "prompts": captured_prompts,
                "settings": {
                    "llm_model": llm_model,
                    "offer_info_data_src": offer_info_data_src,
                    "product_info_extraction_mode": product_info_extraction_mode,
                    "entity_matching_mode": entity_matching_mode,
                    "extract_entity_dag": extract_entity_dag
                },
                "message_info": {
                    "length": len(message),
                    "preview": message[:200] + "..." if len(message) > 200 else message
                },
                "timestamp": time.time()
            }
        }
        
        logger.info(f"ì¶”ì¶œ ì™„ë£Œ: {processing_time:.3f}ì´ˆ")
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({
            "success": False,
            "error": str(e),
            "timestamp": time.time()
        }), 500

@app.route('/extract/batch', methods=['POST'])
def extract_batch():
    """
    ë‹¤ì¤‘ MMS ë©”ì‹œì§€ ë°°ì¹˜ ì²˜ë¦¬ API
    
    ì—¬ëŸ¬ ê°œì˜ MMS ë©”ì‹œì§€ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.
    ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë‚˜ ë°°ì¹˜ ì‘ì—…ì— ìœ ìš©í•©ë‹ˆë‹¤.
    
    Request Body (JSON):
        - messages (required): ì²˜ë¦¬í•  ë©”ì‹œì§€ ë°°ì—´ (ìµœëŒ€ 100ê°œ)
        - llm_model (optional): ì‚¬ìš©í•  LLM ëª¨ë¸
        - offer_info_data_src (optional): ë°ì´í„° ì†ŒìŠ¤
        - product_info_extraction_mode (optional): ìƒí’ˆ ì¶”ì¶œ ëª¨ë“œ
        - entity_matching_mode (optional): ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ
        - extract_entity_dag (optional): ì—”í‹°í‹° DAG ì¶”ì¶œ ì—¬ë¶€ (ê¸°ë³¸ê°’: True)
        - max_workers (optional): ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸ê°’: CPU ì½”ì–´ ìˆ˜)
    
    Returns:
        JSON: ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼
            - success: ì „ì²´ ë°°ì¹˜ ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
            - results: ê° ë©”ì‹œì§€ë³„ ì²˜ë¦¬ ê²°ê³¼ ë°°ì—´
            - summary: ì²˜ë¦¬ ìš”ì•½ (ì´ ê°œìˆ˜, ì„±ê³µ/ì‹¤íŒ¨ ê°œìˆ˜)
            - metadata: ë°°ì¹˜ ì²˜ë¦¬ ë©”íƒ€ë°ì´í„°
    
    HTTP Status Codes:
        - 200: ì„±ê³µ (ê°œë³„ ë©”ì‹œì§€ ì‹¤íŒ¨ê°€ ìˆì–´ë„ ë°°ì¹˜ ìì²´ëŠ” ì„±ê³µ)
        - 400: ì˜ëª»ëœ ìš”ì²­
        - 500: ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜
    """
    try:
        # ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
        if global_extractor is None:
            return jsonify({"error": "ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."}), 500
        
        if not request.is_json:
            return jsonify({"error": "Content-Typeì€ application/jsonì´ì–´ì•¼ í•©ë‹ˆë‹¤"}), 400
        
        data = request.get_json()
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if 'messages' not in data:
            return jsonify({"error": "í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: 'messages'"}), 400
        
        messages = data['messages']
        if not isinstance(messages, list):
            return jsonify({"error": "'messages' í•„ë“œëŠ” ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤"}), 400
        
        if len(messages) > 100:  # ë°°ì¹˜ í¬ê¸° ì œí•œ
            return jsonify({"error": "ë°°ì¹˜ë‹¹ ìµœëŒ€ 100ê°œ ë©”ì‹œì§€ê¹Œì§€ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤"}), 400
        
        # ì„ íƒì  íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        offer_info_data_src = data.get('offer_info_data_src', CLI_DATA_SOURCE)
        llm_model = data.get('llm_model', settings.ModelConfig.llm_model)
        entity_llm_model = data.get('entity_llm_model', 'ax')
        product_info_extraction_mode = data.get('product_info_extraction_mode', settings.ProcessingConfig.product_info_extraction_mode)
        entity_matching_mode = data.get('entity_matching_mode', settings.ProcessingConfig.entity_extraction_mode)
        extract_entity_dag = data.get('extract_entity_dag', True)
        entity_extraction_context_mode = data.get('entity_extraction_context_mode', 'dag')
        max_workers = data.get('max_workers', None)
        save_to_mongodb = data.get('save_to_mongodb', True)
        result_type = data.get('result_type', 'ext')

        data['save_to_mongodb'] = save_to_mongodb
        data['result_type'] = result_type
        data['processing_mode'] = 'batch'
        
        # íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì¦
        valid_sources = ['local', 'db']
        if offer_info_data_src not in valid_sources:
            return jsonify({"error": f"ì˜ëª»ëœ offer_info_data_srcì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_sources}"}), 400
            
        valid_llm_models = ['gemma', 'ax', 'claude', 'gemini']
        if llm_model not in valid_llm_models:
            return jsonify({"error": f"ì˜ëª»ëœ llm_modelì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_llm_models}"}), 400
            
        valid_product_modes = ['nlp', 'llm', 'rag']
        if product_info_extraction_mode not in valid_product_modes:
            return jsonify({"error": f"ì˜ëª»ëœ product_info_extraction_modeì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_product_modes}"}), 400
            
        valid_entity_modes = ['logic', 'llm']
        if entity_matching_mode not in valid_entity_modes:
            return jsonify({"error": f"ì˜ëª»ëœ entity_matching_modeì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_entity_modes}"}), 400
        
        # êµ¬ì„±ëœ ì¶”ì¶œê¸° ê°€ì ¸ì˜¤ê¸°
        extractor = get_configured_extractor(llm_model, product_info_extraction_mode, entity_matching_mode, entity_llm_model, extract_entity_dag, entity_extraction_context_mode)
        
        # DAG ì¶”ì¶œ ìš”ì²­ ë¡œê¹…
        if extract_entity_dag:
            logger.info(f"ğŸ¯ ë°°ì¹˜ DAG ì¶”ì¶œ ìš”ì²­ë¨ - {len(messages)}ê°œ ë©”ì‹œì§€, ì›Œì»¤: {max_workers}")
        
        # ë©€í‹°í”„ë¡œì„¸ìŠ¤ ë°°ì¹˜ ì²˜ë¦¬
        start_time = time.time()
        
        # í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ë¥¼ ìœ„í•œ ìŠ¤ë ˆë“œ ë¡œì»¬ ì €ì¥ì†Œ ì´ˆê¸°í™”
        import threading
        current_thread = threading.current_thread()
        current_thread.stored_prompts = {}
        
        # ë¹ˆ ë©”ì‹œì§€ í•„í„°ë§ ë° message_id ì¶”ì¶œ
        valid_messages = []
        message_ids = []
        message_indices = []
        for i, msg_item in enumerate(messages):
            # ë©”ì‹œì§€ê°€ ë¬¸ìì—´ì´ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ì¼ ìˆ˜ ìˆìŒ
            if isinstance(msg_item, dict):
                message = msg_item.get('message', '')
                message_id = msg_item.get('message_id', '#')
            else:
                message = msg_item
                message_id = '#'
            
            if message and message.strip():
                valid_messages.append(message)
                message_ids.append(message_id)
                message_indices.append(i)
        
        logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(valid_messages)}/{len(messages)}ê°œ ìœ íš¨í•œ ë©”ì‹œì§€")
        
        # MongoDB ì €ì¥ ì¹´ìš´í„° ì´ˆê¸°í™”
        saved_count = 0
        
        try:
            # ê° ë©”ì‹œì§€ë¥¼ message_idì™€ í•¨ê»˜ ì²˜ë¦¬
            batch_results = []
            for message, message_id in zip(valid_messages, message_ids):
                if extract_entity_dag:
                    result = process_message_worker(
                        extractor, 
                        message, 
                        extract_dag=True,
                        message_id=message_id
                    )
                else:
                    result = extractor.process_message(message, message_id=message_id)
                    result['ext_result']['entity_dag'] = []
                    result['raw_result']['entity_dag'] = []
                
                batch_results.append(result)
            
            # ê²°ê³¼ë¥¼ ì›ë˜ ì¸ë±ìŠ¤ì™€ ë§¤í•‘ ë° MongoDB ì €ì¥
            results = []
            valid_result_idx = 0
            
            for i, msg_item in enumerate(messages):
                # ë©”ì‹œì§€ê°€ ë¬¸ìì—´ì´ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ì¼ ìˆ˜ ìˆìŒ
                if isinstance(msg_item, dict):
                    message_text = msg_item.get('message', '')
                else:
                    message_text = msg_item
                
                if not message_text or not message_text.strip():
                    results.append({
                        "index": i,
                        "success": False,
                        "error": "ë¹ˆ ë©”ì‹œì§€ì…ë‹ˆë‹¤"
                    })
                else:
                    if valid_result_idx < len(batch_results):
                        batch_result = batch_results[valid_result_idx]

                        # result_typeì— ë”°ë¼ ê²°ê³¼ ì„ íƒ
                        if result_type == 'raw':
                            result_data = batch_result.get('raw_result', {})
                        else:
                            result_data = batch_result.get('ext_result', {})

                        # print("=" * 50 + " batch_result " + "=" * 50)
                        # print(batch_result)
                        # print("=" * 50 + " batch_result " + "=" * 50)
                        
                        if result_data.get('error'):
                            results.append({
                                "index": i,
                                "success": False,
                                "error": result_data['error']
                            })
                        else:
                            # MongoDB ì €ì¥ (ë°°ì¹˜ ì²˜ë¦¬ì—ì„œëŠ” ê° ë©”ì‹œì§€ë³„ë¡œ ì €ì¥)
                            if save_to_mongodb:
                                try:
                                    saved_id = save_result_to_mongodb_if_enabled(message_text, batch_result, data, extractor)
                                    if saved_id:
                                        saved_count += 1
                                        logger.debug(f"ë©”ì‹œì§€ {i} MongoDB ì €ì¥ ì™„ë£Œ (ID: {saved_id[:8]}...)")
                                except Exception as e:
                                    logger.warning(f"ë©”ì‹œì§€ {i} MongoDB ì €ì¥ ì‹¤íŒ¨: {str(e)}")
                                
                            results.append({
                                "index": i,
                                "success": True,
                                "result": result_data
                            })
                        valid_result_idx += 1
                    else:
                        results.append({
                            "index": i,
                            "success": False,
                            "error": "ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ë¶€ì¡±"
                        })
            
            if save_to_mongodb and saved_count > 0:
                logger.info(f"MongoDB ì €ì¥ ì™„ë£Œ: {saved_count}/{len(valid_messages)}ê°œ ë©”ì‹œì§€")
        
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ëª¨ë“  ë©”ì‹œì§€ë¥¼ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
            results = []
            for i, message in enumerate(messages):
                results.append({
                    "index": i,
                    "success": False,
                    "error": f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                })
        
        processing_time = time.time() - start_time
        
        # ìº¡ì²˜ëœ í”„ë¡¬í”„íŠ¸ë“¤ ê°€ì ¸ì˜¤ê¸°
        captured_prompts = getattr(current_thread, 'stored_prompts', {})
        logger.info(f"ë°°ì¹˜ ì¶”ì¶œ ê³¼ì •ì—ì„œ ìº¡ì²˜ëœ í”„ë¡¬í”„íŠ¸: {len(captured_prompts)}ê°œ")
        
        # ì„±ê³µ/ì‹¤íŒ¨ ê°œìˆ˜ ì§‘ê³„
        successful = sum(1 for r in results if r["success"])
        failed = len(results) - successful
        
        response = {
            "success": True,
            "results": results,
            "summary": {
                "total_messages": len(messages),
                "successful": successful,
                "failed": failed,
                "saved_to_mongodb": saved_count if save_to_mongodb else 0
            },
            "metadata": {
                "llm_model": llm_model,
                "offer_info_data_src": offer_info_data_src,
                "product_info_extraction_mode": product_info_extraction_mode,
                "entity_matching_mode": entity_matching_mode,
                "extract_entity_dag": extract_entity_dag,
                "max_workers": max_workers,
                "processing_time_seconds": round(processing_time, 3),
                "timestamp": time.time()
            },
            "prompts": {
                "success": True,
                "prompts": captured_prompts,
                "settings": {
                    "llm_model": llm_model,
                    "offer_info_data_src": offer_info_data_src,
                    "product_info_extraction_mode": product_info_extraction_mode,
                    "entity_matching_mode": entity_matching_mode,
                    "extract_entity_dag": extract_entity_dag
                },
                "batch_info": {
                    "total_messages": len(messages),
                    "successful": successful,
                    "failed": failed
                },
                "timestamp": time.time()
            }
        }
        
        logger.info(f"ë°°ì¹˜ ì¶”ì¶œ ì™„ë£Œ: {successful}/{len(messages)}ê°œ ì„±ê³µ, {processing_time:.3f}ì´ˆ ì†Œìš”")
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"ë°°ì¹˜ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({
            "success": False,
            "error": str(e),
            "timestamp": time.time()
        }), 500

@app.route('/status', methods=['GET'])
def get_status():
    """
    API ìƒíƒœ ë° ì¶”ì¶œê¸° ì •ë³´ ì¡°íšŒ
    
    í˜„ì¬ ì„œë²„ì˜ ìƒíƒœì™€ ì¶”ì¶œê¸°ì˜ ì„¤ì • ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    ë””ë²„ê¹…ì´ë‚˜ ëª¨ë‹ˆí„°ë§ ëª©ì ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    
    Returns:
        JSON: ì„œë²„ ë° ì¶”ì¶œê¸° ìƒíƒœ ì •ë³´
            - status: ì„œë²„ ì‹¤í–‰ ìƒíƒœ
            - extractor: ì¶”ì¶œê¸° ìƒíƒœ ì •ë³´
                - initialized: ì´ˆê¸°í™” ì—¬ë¶€
                - data_source: í˜„ì¬ ë°ì´í„° ì†ŒìŠ¤
                - current_llm_model: í˜„ì¬ LLM ëª¨ë¸
                - current_product_mode: í˜„ì¬ ìƒí’ˆ ì¶”ì¶œ ëª¨ë“œ
                - current_entity_mode: í˜„ì¬ ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ
            - timestamp: ì‘ë‹µ ì‹œê°„
    """
    global global_extractor
    
    # ì¶”ì¶œê¸° ìƒíƒœ ì •ë³´ ìˆ˜ì§‘
    extractor_status = {
        "initialized": global_extractor is not None,
        "data_source": CLI_DATA_SOURCE if global_extractor else None,
        "current_llm_model": global_extractor.llm_model_name if global_extractor else None,
        "current_product_mode": global_extractor.product_info_extraction_mode if global_extractor else None,
        "current_entity_mode": global_extractor.entity_extraction_mode if global_extractor else None
    }
    
    return jsonify({
        "status": "running",
        "extractor": extractor_status,
        "timestamp": time.time()
    })

@app.route('/prompts', methods=['POST'])
def get_prompts():
    """
    ì‹¤ì œ ì¶”ì¶œ ê³¼ì •ì—ì„œ ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸ë“¤ì„ ë°˜í™˜í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    
    ì‹¤ì œ ì¶”ì¶œì„ ìˆ˜í–‰í•˜ê³  ê·¸ ê³¼ì •ì—ì„œ LLMì— ì „ì†¡ëœ í”„ë¡¬í”„íŠ¸ë“¤ì„ ìº¡ì²˜í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        if not global_extractor:
            return jsonify({
                "success": False,
                "error": "ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 500
        
        # ìš”ì²­ ë°ì´í„° íŒŒì‹±
        data = request.get_json()
        if not data:
            return jsonify({
                "success": False,
                "error": "JSON ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400
        
        message = data.get('message', '')
        if not message:
            return jsonify({
                "success": False,
                "error": "ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400
        
        # ì„¤ì • íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        llm_model = data.get('llm_model', 'ax')
        offer_info_data_src = data.get('offer_info_data_src', 'db')
        product_info_extraction_mode = data.get('product_info_extraction_mode', 'llm')
        entity_matching_mode = data.get('entity_matching_mode', 'logic')
        extract_entity_dag = data.get('extract_entity_dag', True)
        
        # ì¶”ì¶œê¸° ì„¤ì • ì—…ë°ì´íŠ¸
        extractor = get_configured_extractor(llm_model, product_info_extraction_mode, entity_matching_mode, extract_entity_dag)
        
        # ì‹¤ì œ ì¶”ì¶œ ìˆ˜í–‰ (í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ë¥¼ ìœ„í•´)
        import threading
        current_thread = threading.current_thread()
        current_thread.stored_prompts = {}  # í”„ë¡¬í”„íŠ¸ ì €ì¥ì†Œ ì´ˆê¸°í™”
        
        logger.info(f"í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ì‹œì‘ - ìŠ¤ë ˆë“œ ID: {current_thread.ident}")
        
        # ì¶”ì¶œ ìˆ˜í–‰
        if extract_entity_dag:
            result = process_message_worker(extractor, message, extract_dag=True)['extracted_result']
        else:
            result = extractor.process_message(message)['extracted_result']
        
        # ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ë“¤ ê°€ì ¸ì˜¤ê¸°
        stored_prompts = getattr(current_thread, 'stored_prompts', {})
        
        logger.info(f"í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ì™„ë£Œ - ìŠ¤ë ˆë“œ ID: {current_thread.ident}")
        logger.info(f"ì‹¤ì œ stored_prompts ë‚´ìš©: {stored_prompts}")
        
        logger.info(f"í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ìƒíƒœ: {len(stored_prompts)}ê°œ í”„ë¡¬í”„íŠ¸")
        logger.info(f"í”„ë¡¬í”„íŠ¸ í‚¤ë“¤: {list(stored_prompts.keys())}")
        
        # í”„ë¡¬í”„íŠ¸ê°€ ì—†ì–´ë„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ (ì¼ë¶€ ëª¨ë“œì—ì„œëŠ” íŠ¹ì • í”„ë¡¬í”„íŠ¸ë§Œ ìƒì„±ë¨)
        # if not stored_prompts:
        #     return jsonify({
        #         "success": False,
        #         "error": "í”„ë¡¬í”„íŠ¸ê°€ ìº¡ì²˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
        #         "prompts": {},
        #         "settings": {...}
        #     }), 200
        
        # ì‘ë‹µ êµ¬ì„±
        response = {
            "success": True,
            "prompts": stored_prompts,
            "settings": {
                "llm_model": llm_model,
                "offer_info_data_src": offer_info_data_src,
                "product_info_extraction_mode": product_info_extraction_mode,
                "entity_matching_mode": entity_matching_mode,
                "extract_entity_dag": extract_entity_dag
            },
            "message_info": {
                "length": len(message),
                "preview": message[:200] + "..." if len(message) > 200 else message
            },
            "timestamp": time.time(),
            "extraction_result": result  # ì¶”ì¶œ ê²°ê³¼ë„ í•¨ê»˜ ë°˜í™˜ (ì°¸ê³ ìš©)
        }
        
        logger.info(f"ì‹¤ì œ í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ì™„ë£Œ: {len(stored_prompts)}ê°œ í”„ë¡¬í”„íŠ¸")
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({
            "success": False,
            "error": str(e),
            "timestamp": time.time()
        }), 500

@app.route('/dag', methods=['POST'])
def extract_dag_endpoint():
    """
    Entity DAG ì¶”ì¶œ API
    
    MMS ë©”ì‹œì§€ì—ì„œ ì—”í‹°í‹° ê°„ì˜ ê´€ê³„ë¥¼ ë¶„ì„í•˜ì—¬ DAG(Directed Acyclic Graph) í˜•íƒœë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Request Body (JSON):
        - message (required): ë¶„ì„í•  MMS ë©”ì‹œì§€ í…ìŠ¤íŠ¸
        - llm_model (optional): ì‚¬ìš©í•  LLM ëª¨ë¸ (ê¸°ë³¸ê°’: 'ax')
                                ì„ íƒ ê°€ëŠ¥: 'ax', 'gem', 'cld', 'gen', 'gpt'
        - save_dag_image (optional): DAG ì´ë¯¸ì§€ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
    
    Returns:
        JSON: DAG ì¶”ì¶œ ê²°ê³¼
            - success: ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
            - result: DAG ì¶”ì¶œ ê²°ê³¼
                - dag_section: íŒŒì‹±ëœ DAG í…ìŠ¤íŠ¸
                - dag_raw: LLM ì›ë³¸ ì‘ë‹µ
                - dag_json: NetworkX ê·¸ë˜í”„ë¥¼ JSONìœ¼ë¡œ ë³€í™˜
                - analysis: ê·¸ë˜í”„ ë¶„ì„ ì •ë³´ (ë…¸ë“œ ìˆ˜, ì—£ì§€ ìˆ˜, root/leaf ë…¸ë“œ ë“±)
            - metadata: ì²˜ë¦¬ ë©”íƒ€ë°ì´í„° (ì²˜ë¦¬ ì‹œê°„, ì‚¬ìš©ëœ ì„¤ì • ë“±)
    
    HTTP Status Codes:
        - 200: ì„±ê³µ
        - 400: ì˜ëª»ëœ ìš”ì²­ (í•„ìˆ˜ í•„ë“œ ëˆ„ë½, ì˜ëª»ëœ íŒŒë¼ë¯¸í„° ë“±)
        - 500: ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜
    
    Example Request:
        ```json
        {
            "message": "SKí…”ë ˆì½¤ ê°€ì…í•˜ì‹œë©´ ZEMí°ì„ ë“œë¦½ë‹ˆë‹¤",
            "llm_model": "ax",
            "save_dag_image": true
        }
        ```
    """
    try:
        # ìš”ì²­ ë°ì´í„° ê²€ì¦
        if not request.is_json:
            return jsonify({"error": "Content-Typeì€ application/jsonì´ì–´ì•¼ í•©ë‹ˆë‹¤"}), 400
        
        data = request.get_json()
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if 'message' not in data:
            return jsonify({"error": "í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: 'message'"}), 400
        
        message = data['message']
        if not message or not message.strip():
            return jsonify({"error": "ë©”ì‹œì§€ëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 400
        
        # ì„ íƒì  íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        llm_model_name = data.get('llm_model', 'ax')
        save_dag_image = data.get('save_dag_image', False)
        message_id = data.get('message_id', '#')  # ë©”ì‹œì§€ ID (ê¸°ë³¸ê°’: '#')
        
        # íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì¦
        valid_llm_models = ['ax', 'gem', 'cld', 'gen', 'gpt']
        if llm_model_name not in valid_llm_models:
            return jsonify({"error": f"ì˜ëª»ëœ llm_modelì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_llm_models}"}), 400
        
        # LLM ëª¨ë¸ ë§¤í•‘
        llm_model_map = {
            'ax': llm_ax,
            'gem': llm_gem,
            'cld': llm_cld,
            'gen': llm_gen,
            'gpt': llm_gpt
        }
        llm_model = llm_model_map[llm_model_name]
        
        logger.info(f"ğŸ¯ DAG ì¶”ì¶œ ìš”ì²­ - LLM: {llm_model_name}, ë©”ì‹œì§€ ê¸¸ì´: {len(message)}ì")
        
        # ë©”ì‹œì§€ ID ë¡œê¹…
        if message_id != '#':
            logger.info(f"ğŸ“‹ ë©”ì‹œì§€ ID: {message_id}")
        
        # DAG íŒŒì„œ ì´ˆê¸°í™”
        parser = DAGParser()
        
        # DAG ì¶”ì¶œ ì‹¤í–‰
        start_time = time.time()
        result = extract_dag(parser, message, llm_model)
        processing_time = time.time() - start_time
        
        # NetworkX ê·¸ë˜í”„ë¥¼ JSONìœ¼ë¡œ ë³€í™˜
        dag = result['dag']
        dag_json = parser.to_json(dag)
        analysis = parser.analyze_graph(dag)
        
        # ì´ë¯¸ì§€ ì €ì¥ (ì„ íƒ ì‚¬í•­)
        dag_image_url = None
        dag_image_path = None
        if save_dag_image:
            try:
                from utils import create_dag_diagram, sha256_hash
                from config import settings
                
                dag_hash = sha256_hash(message)
                dag_image_filename = f'dag_{message_id}_{dag_hash}.png'
                
                # ì„¤ì •ì— ë”°ë¼ ì €ì¥ ìœ„ì¹˜ ê²°ì • (ì¬ìƒì„±ëœ STORAGE_CONFIG ì‚¬ìš©)
                dag_dir = settings.STORAGE_CONFIG.get_dag_images_dir()
                output_dir = f'./{dag_dir}'
                
                # DAG ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± ë° ì €ì¥ (output_dir ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬)
                create_dag_diagram(dag, filename=f'dag_{message_id}_{dag_hash}', output_dir=output_dir)
                
                # HTTP URL ìƒì„± (ìŠ¤í† ë¦¬ì§€ ëª¨ë“œì— ë”°ë¼ URL ê²°ì •)
                # - local ëª¨ë“œ: API ì„œë²„ ê³ ì • ì£¼ì†Œ ì‚¬ìš© (http://skt-tosaipoc01:8000)
                # - nas ëª¨ë“œ: NAS ì„œë²„ ì ˆëŒ€ IP ì£¼ì†Œ ì‚¬ìš© (http://172.27.7.58)
                dag_image_url = settings.STORAGE_CONFIG.get_dag_image_url(dag_image_filename)
                
                # ì‹¤ì œ ë¡œì»¬ ê²½ë¡œ (ì €ì¥ëœ ì‹¤ì œ ê²½ë¡œ)
                dag_image_path = str(Path(__file__).parent / dag_dir / dag_image_filename)
                
                logger.info(f"ğŸ“Š DAG ì´ë¯¸ì§€ ì €ì¥ë¨: {dag_image_path} ({settings.STORAGE_CONFIG.dag_storage_mode} ëª¨ë“œ)")
                logger.info(f"ğŸŒ DAG ì´ë¯¸ì§€ URL: {dag_image_url}")
            except Exception as e:
                logger.warning(f"âš ï¸ DAG ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # MongoDB ì €ì¥ (ì„ íƒ ì‚¬í•­)
        save_to_mongodb = data.get('save_to_mongodb', False)
        if save_to_mongodb:
            try:
                # save_result_to_mongodb_if_enabled í•¨ìˆ˜ê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ êµ¬ì„±
                # ext_resultì™€ raw_resultì— DAG ì •ë³´ í¬í•¨
                dag_list = sorted([d for d in result['dag_section'].split('\n') if d!=''])
                
                mock_result = {
                    'ext_result': {
                        'message_id': message_id,
                        'entity_dag': dag_list,
                        'dag_json': json.loads(dag_json),
                        'dag_analysis': analysis
                    },
                    'raw_result': {
                        'message_id': message_id,
                        'dag_raw': result['dag_raw']
                    },
                    'processing_time': processing_time
                }
                
                # ê°€ì§œ args ê°ì²´ ìƒì„± (í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ë§ì¶”ê¸° ìœ„í•¨)
                mock_args = {
                    'save_to_mongodb': True,
                    'llm_model': llm_model_name,
                    'processing_mode': 'api_dag',
                    'user_id': 'API_USER'
                }
                
                logger.info("MongoDB ì €ì¥ ì¤‘...")
                saved_id = save_result_to_mongodb_if_enabled(message, mock_result, mock_args)
                if saved_id:
                    logger.info(f"MongoDB ì €ì¥ ì™„ë£Œ! ID: {saved_id}")
            except Exception as e:
                logger.error(f"MongoDB ì €ì¥ ì‹¤íŒ¨: {e}")
        
        # ì‘ë‹µ êµ¬ì„±
        response = {
            "success": True,
            "result": {
                "message_id": message_id,  # message_id ì¶”ê°€
                "dag_section": result['dag_section'],
                "dag_raw": result['dag_raw'],
                "dag_json": json.loads(dag_json),
                "analysis": analysis,
                "dag_image_url": dag_image_url,  # HTTP URL (ì™¸ë¶€ ì‹œìŠ¤í…œìš©)
                "dag_image_path": dag_image_path  # ë¡œì»¬ ê²½ë¡œ (ë‚´ë¶€ ì°¸ì¡°ìš©)
            },
            "metadata": {
                "llm_model": llm_model_name,
                "processing_time_seconds": round(processing_time, 3),
                "timestamp": time.time(),
                "message_length": len(message),
                "save_dag_image": save_dag_image
            }
        }
        
        logger.info(f"âœ… DAG ì¶”ì¶œ ì™„ë£Œ: {processing_time:.3f}ì´ˆ, ë…¸ë“œ: {analysis['num_nodes']}, ì—£ì§€: {analysis['num_edges']}")
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"âŒ DAG ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({
            "success": False,
            "error": str(e),
            "timestamp": time.time()
        }), 500

# =============================================================================
# Quick Extractor API ì—”ë“œí¬ì¸íŠ¸ (ì œëª© ë° ìˆ˜ì‹ ê±°ë¶€ ë²ˆí˜¸ ì¶”ì¶œ)
# =============================================================================

@app.route('/quick/extract', methods=['POST'])
def quick_extract():
    """
    ë‹¨ì¼ ë©”ì‹œì§€ì—ì„œ ì œëª©ê³¼ ìˆ˜ì‹ ê±°ë¶€ ì „í™”ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•˜ëŠ” API
    
    Request Body (JSON):
    {
        "message": "ë©”ì‹œì§€ í…ìŠ¤íŠ¸",
        "method": "textrank|tfidf|first_bracket|llm",  // ì„ íƒì‚¬í•­, ê¸°ë³¸ê°’: textrank
        "llm_model": "ax|gpt|claude|gemini",            // LLM ë°©ë²• ì‚¬ìš© ì‹œ ì„ íƒì‚¬í•­, ê¸°ë³¸ê°’: ax
        "use_llm": false                                 // LLM ì‚¬ìš© ì—¬ë¶€, ê¸°ë³¸ê°’: false
    }
    
    Response (JSON):
    {
        "success": true,
        "data": {
            "title": "ì¶”ì¶œëœ ì œëª©",
            "unsubscribe_phone": "1504",
            "message": "ì „ì²´ ë©”ì‹œì§€ ë‚´ìš©..."
        },
        "metadata": {
            "method": "textrank",
            "message_length": 188,
            "processing_time_seconds": 0.123
        }
    }
    """
    try:
        # ìš”ì²­ ì‹œì‘ ì‹œê°„
        start_time = time.time()
        
        # ìš”ì²­ ë°ì´í„° íŒŒì‹±
        data = request.get_json()
        if not data:
            return jsonify({
                "success": False,
                "error": "ìš”ì²­ ë³¸ë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì „ì†¡í•˜ì„¸ìš”."
            }), 400
        
        # í•„ìˆ˜ íŒŒë¼ë¯¸í„° ê²€ì¦
        message = data.get('message')
        if not message:
            return jsonify({
                "success": False,
                "error": "'message' í•„ë“œëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤."
            }), 400
        
        # ì„ íƒì  íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’ ì„¤ì •)
        method = data.get('method', 'textrank')
        use_llm = data.get('use_llm', method == 'llm')
        llm_model = data.get('llm_model', 'ax')
        message_id = data.get('message_id', '#')  # ë©”ì‹œì§€ ID (ê¸°ë³¸ê°’: '#')
        
        # ë©”ì„œë“œ ê²€ì¦
        valid_methods = ['textrank', 'tfidf', 'first_bracket', 'llm']
        if method not in valid_methods:
            return jsonify({
                "success": False,
                "error": f"ìœ íš¨í•˜ì§€ ì•Šì€ method: {method}. ì‚¬ìš© ê°€ëŠ¥: {', '.join(valid_methods)}"
            }), 400
        
        # Quick Extractor êµ¬ì„± ë° ê°€ì ¸ì˜¤ê¸°
        extractor = get_configured_quick_extractor(use_llm=use_llm, llm_model=llm_model)
        
        # ë©”ì‹œì§€ ì²˜ë¦¬
        logger.info(f"ğŸ“ Quick Extract ì‹œì‘: method={method}, use_llm={use_llm}, llm_model={llm_model}")
        result = extractor.process_single_message(message, method=method)
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = time.time() - start_time
        
        # ë©”íƒ€ë°ì´í„°ì— ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
        result['metadata']['processing_time_seconds'] = round(processing_time, 3)
        result['metadata']['timestamp'] = time.time()
        
        # message_id ì¶”ê°€
        result['data']['message_id'] = message_id
        
        logger.info(f"âœ… Quick Extract ì™„ë£Œ: {processing_time:.3f}ì´ˆ, ì œëª©={result['data']['title'][:50]}...")
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"âŒ Quick Extract ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({
            "success": False,
            "error": str(e),
            "timestamp": time.time()
        }), 500

@app.route('/quick/extract/batch', methods=['POST'])
def quick_extract_batch():
    """
    ì—¬ëŸ¬ ë©”ì‹œì§€ì—ì„œ ì œëª©ê³¼ ìˆ˜ì‹ ê±°ë¶€ ì „í™”ë²ˆí˜¸ë¥¼ ì¼ê´„ ì¶”ì¶œí•˜ëŠ” API
    
    Request Body (JSON):
    {
        "messages": ["ë©”ì‹œì§€1", "ë©”ì‹œì§€2", ...],
        "method": "textrank|tfidf|first_bracket|llm",  // ì„ íƒì‚¬í•­, ê¸°ë³¸ê°’: textrank
        "llm_model": "ax|gpt|claude|gemini",            // LLM ë°©ë²• ì‚¬ìš© ì‹œ ì„ íƒì‚¬í•­, ê¸°ë³¸ê°’: ax
        "use_llm": false                                 // LLM ì‚¬ìš© ì—¬ë¶€, ê¸°ë³¸ê°’: false
    }
    
    Response (JSON):
    {
        "success": true,
        "data": {
            "results": [
                {
                    "msg_id": 0,
                    "title": "ì¶”ì¶œëœ ì œëª©",
                    "unsubscribe_phone": "1504",
                    "message": "ì „ì²´ ë©”ì‹œì§€ ë‚´ìš©..."
                },
                ...
            ],
            "statistics": {
                "total_messages": 10,
                "with_unsubscribe_phone": 8,
                "extraction_rate": 80.0
            }
        },
        "metadata": {
            "method": "textrank",
            "processing_time_seconds": 1.234,
            "avg_time_per_message": 0.123
        }
    }
    """
    try:
        # ìš”ì²­ ì‹œì‘ ì‹œê°„
        start_time = time.time()
        
        # ìš”ì²­ ë°ì´í„° íŒŒì‹±
        data = request.get_json()
        if not data:
            return jsonify({
                "success": False,
                "error": "ìš”ì²­ ë³¸ë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. JSON í˜•ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì „ì†¡í•˜ì„¸ìš”."
            }), 400
        
        # í•„ìˆ˜ íŒŒë¼ë¯¸í„° ê²€ì¦
        messages = data.get('messages')
        if not messages:
            return jsonify({
                "success": False,
                "error": "'messages' í•„ë“œëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤."
            }), 400
        
        if not isinstance(messages, list):
            return jsonify({
                "success": False,
                "error": "'messages'ëŠ” ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤."
            }), 400
        
        if len(messages) == 0:
            return jsonify({
                "success": False,
                "error": "ìµœì†Œ 1ê°œ ì´ìƒì˜ ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤."
            }), 400
        
        # ì„ íƒì  íŒŒë¼ë¯¸í„° (ê¸°ë³¸ê°’ ì„¤ì •)
        method = data.get('method', 'textrank')
        use_llm = data.get('use_llm', method == 'llm')
        llm_model = data.get('llm_model', 'ax')
        
        # ë©”ì„œë“œ ê²€ì¦
        valid_methods = ['textrank', 'tfidf', 'first_bracket', 'llm']
        if method not in valid_methods:
            return jsonify({
                "success": False,
                "error": f"ìœ íš¨í•˜ì§€ ì•Šì€ method: {method}. ì‚¬ìš© ê°€ëŠ¥: {', '.join(valid_methods)}"
            }), 400
        
        # Quick Extractor êµ¬ì„± ë° ê°€ì ¸ì˜¤ê¸°
        extractor = get_configured_quick_extractor(use_llm=use_llm, llm_model=llm_model)
        
        # ë°°ì¹˜ ë©”ì‹œì§€ ì²˜ë¦¬
        logger.info(f"ğŸ“ Quick Extract Batch ì‹œì‘: {len(messages)}ê°œ ë©”ì‹œì§€, method={method}, use_llm={use_llm}")
        
        results = []
        msg_processing_times = []
        
        for idx, msg_item in enumerate(messages):
            # ë©”ì‹œì§€ê°€ ë¬¸ìì—´ì´ê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ì¼ ìˆ˜ ìˆìŒ
            if isinstance(msg_item, dict):
                message = msg_item.get('message', '')
                message_id = msg_item.get('message_id', '#')
            else:
                message = msg_item
                message_id = '#'
            
            msg_start_time = time.time()
            result = extractor.process_single_message(message, method=method)
            msg_processing_time = time.time() - msg_start_time
            
            # ê²°ê³¼ì— ë©”ì‹œì§€ IDì™€ ì²˜ë¦¬ ì‹œê°„ ì¶”ê°€
            message_result = {
                'msg_id': idx,
                'message_id': message_id,  # message_id ì¶”ê°€
                'title': result['data']['title'],
                'unsubscribe_phone': result['data']['unsubscribe_phone'],
                'message': result['data']['message'],
                'processing_time_seconds': round(msg_processing_time, 3)
            }
            results.append(message_result)
            msg_processing_times.append(msg_processing_time)
        
        # í†µê³„ ê³„ì‚°
        total = len(results)
        with_phone = sum(1 for r in results if r.get('unsubscribe_phone'))
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = time.time() - start_time
        avg_time = sum(msg_processing_times) / total if total > 0 else 0
        min_time = min(msg_processing_times) if msg_processing_times else 0
        max_time = max(msg_processing_times) if msg_processing_times else 0
        
        # ì‘ë‹µ êµ¬ì„±
        response = {
            'success': True,
            'data': {
                'results': results,
                'statistics': {
                    'total_messages': total,
                    'with_unsubscribe_phone': with_phone,
                    'extraction_rate': round(with_phone / total * 100, 2) if total > 0 else 0,
                    'total_processing_time_seconds': round(sum(msg_processing_times), 3),
                    'avg_processing_time_seconds': round(avg_time, 3),
                    'min_processing_time_seconds': round(min_time, 3),
                    'max_processing_time_seconds': round(max_time, 3)
                }
            },
            'metadata': {
                'method': method,
                'total_time_seconds': round(processing_time, 3),
                'timestamp': time.time()
            }
        }
        
        logger.info(f"âœ… Quick Extract Batch ì™„ë£Œ: {processing_time:.3f}ì´ˆ, {total}ê°œ ë©”ì‹œì§€ ì²˜ë¦¬")
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"âŒ Quick Extract Batch ì˜¤ë¥˜: {e}")
        import traceback
        logger.error(traceback.format_exc())
        return jsonify({
            "success": False,
            "error": str(e),
            "timestamp": time.time()
        }), 500

@app.route('/dag_images/<path:filename>', methods=['GET'])
def serve_dag_image(filename):
    """
    DAG ì´ë¯¸ì§€ íŒŒì¼ ì œê³µ ì—”ë“œí¬ì¸íŠ¸
    
    ì™¸ë¶€ ì‹œìŠ¤í…œì—ì„œ HTTPë¥¼ í†µí•´ DAG ì´ë¯¸ì§€ì— ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    ì„¤ì •ì— ë”°ë¼ ë¡œì»¬ ë˜ëŠ” NAS ë””ë ‰í† ë¦¬ì—ì„œ íŒŒì¼ì„ ì œê³µí•©ë‹ˆë‹¤.
    
    Parameters:
    -----------
    filename : str
        ì´ë¯¸ì§€ íŒŒì¼ëª… (ì˜ˆ: dag_abc123.png)
    
    Returns:
    --------
    file : ì´ë¯¸ì§€ íŒŒì¼
    """
    try:
        from config import settings
        
        # DAG ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ (ìŠ¤í† ë¦¬ì§€ ëª¨ë“œì™€ ê´€ê³„ì—†ì´ ë™ì¼)
        dag_dir = settings.STORAGE_CONFIG.get_dag_images_dir()
        dag_images_dir = Path(__file__).parent / dag_dir
        
        logger.info(f"ğŸ“Š DAG ì´ë¯¸ì§€ ìš”ì²­: {filename} (from {dag_dir})")
        
        return send_from_directory(dag_images_dir, filename)
    except FileNotFoundError:
        logger.warning(f"âš ï¸ DAG ì´ë¯¸ì§€ ì—†ìŒ: {filename}")
        return jsonify({
            "success": False,
            "error": "Image not found"
        }), 404
    except Exception as e:
        logger.error(f"âŒ DAG ì´ë¯¸ì§€ ì œê³µ ì˜¤ë¥˜: {e}")
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.errorhandler(404)
def not_found(error):
    """404 ì—ëŸ¬ í•¸ë“¤ëŸ¬ - ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì—”ë“œí¬ì¸íŠ¸ ì ‘ê·¼ ì‹œ"""
    return jsonify({"error": "ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 404

@app.errorhandler(500)
def internal_error(error):
    """500 ì—ëŸ¬ í•¸ë“¤ëŸ¬ - ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ ë°œìƒ ì‹œ"""
    return jsonify({"error": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"}), 500

def main():
    """
    ë©”ì¸ í•¨ìˆ˜ - CLI ì‚¬ìš©ì„ ìœ„í•œ ì§„ì…ì 
    
    ì»¤ë§¨ë“œë¼ì¸ ì¸ìë¥¼ íŒŒì‹±í•˜ê³  ì„œë²„ë¥¼ ì‹œì‘í•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸ ëª¨ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    CLI ì˜µì…˜:
        --host: ë°”ì¸ë”©í•  í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: 0.0.0.0)
        --port: ë°”ì¸ë”©í•  í¬íŠ¸ (ê¸°ë³¸ê°’: 8000)
        --debug: ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”
        --test: í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰
        --message: í…ŒìŠ¤íŠ¸í•  ë©”ì‹œì§€ (í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œ ì‚¬ìš©)
        --offer-data-source: ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ
        --product-info-extraction-mode: ìƒí’ˆ ì¶”ì¶œ ëª¨ë“œ ì„ íƒ
        --entity-matching-mode: ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ ì„ íƒ
        --llm-model: ì‚¬ìš©í•  LLM ëª¨ë¸ ì„ íƒ
    
    ì‚¬ìš© ì˜ˆì‹œ:
        # ì„œë²„ ëª¨ë“œ
        python api.py --host 0.0.0.0 --port 8000
        
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
        python api.py --test --message "í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€" --llm-model gpt
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©
        python api.py --offer-data-source db
    """
    global CLI_DATA_SOURCE
    
    # ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì„œ ì„¤ì •
    parser = argparse.ArgumentParser(description='MMS ì¶”ì¶œê¸° API ì„œë²„')
    parser.add_argument('--host', default='0.0.0.0', help='ë°”ì¸ë”©í•  í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ')
    parser.add_argument('--port', type=int, default=8000, help='ë°”ì¸ë”©í•  í¬íŠ¸ ë²ˆí˜¸')
    parser.add_argument('--debug', action='store_true', help='ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”')
    parser.add_argument('--test', action='store_true', help='í…ŒìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤í–‰')
    parser.add_argument('--message', type=str, help='í…ŒìŠ¤íŠ¸í•  ë©”ì‹œì§€')
    parser.add_argument('--offer-data-source', choices=['local', 'db'], default='db',
                       help='ë°ì´í„° ì†ŒìŠ¤ (local: CSV íŒŒì¼, db: ë°ì´í„°ë² ì´ìŠ¤)')
    parser.add_argument('--product-info-extraction-mode', choices=['nlp', 'llm' ,'rag'], default='nlp',
                       help='ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ëª¨ë“œ (nlp: í˜•íƒœì†Œë¶„ì„, llm: LLM ê¸°ë°˜, rag: ê²€ìƒ‰ì¦ê°•ìƒì„±)')
    parser.add_argument('--entity-matching-mode', choices=['logic', 'llm'], default='llm',
                       help='ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ (logic: ë¡œì§ ê¸°ë°˜, llm: LLM ê¸°ë°˜)')
    parser.add_argument('--llm-model', choices=['gem', 'ax', 'cld', 'gen', 'gpt'], default='ax',
                       help='ì‚¬ìš©í•  LLM ëª¨ë¸ (gem: Gemma, ax: ax, cld: Claude, gen: Gemini, gpt: GPT)')
    parser.add_argument('--log-level', choices=['DEBUG', 'INFO', 'WARNING', 'ERROR'], default='INFO',
                       help='ë¡œê·¸ ë ˆë²¨ ì„¤ì • (DEBUG: ìƒì„¸, INFO: ì¼ë°˜, WARNING: ê²½ê³ , ERROR: ì˜¤ë¥˜ë§Œ)')
    parser.add_argument('--extract-entity-dag', action='store_true', default=False, help='Entity DAG extraction (default: False)')
    parser.add_argument('--storage', choices=['local', 'nas'], default='local',
                       help='DAG ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜ (local: ë¡œì»¬ ë””ìŠ¤í¬, nas: NAS ì„œë²„)')
    
    args = parser.parse_args()
    
    # ë¡œê·¸ ë ˆë²¨ ì„¤ì • - ë£¨íŠ¸ ë¡œê±°ì™€ ëª¨ë“  í•¸ë“¤ëŸ¬ì— ì ìš©
    log_level = getattr(logging, args.log_level)
    root_logger.setLevel(log_level)
    for handler in root_logger.handlers:
        handler.setLevel(log_level)
    logger.setLevel(log_level)
    mms_logger.setLevel(log_level)
    
    logger.info(f"ë¡œê·¸ ë ˆë²¨ ì„¤ì •: {args.log_level}")
    
    # DAG ì €ì¥ ëª¨ë“œ ì„¤ì •
    logger.info(f"ğŸ”§ --storage ì˜µì…˜: {args.storage}")
    os.environ['DAG_STORAGE_MODE'] = args.storage
    logger.info(f"ğŸ”§ í™˜ê²½ë³€ìˆ˜ DAG_STORAGE_MODE ì„¤ì •: {os.environ.get('DAG_STORAGE_MODE')}")
    
    # STORAGE_CONFIG ì¬ìƒì„± (í™˜ê²½ë³€ìˆ˜ ì ìš©)
    from config.settings import StorageConfig
    from config import settings
    settings.STORAGE_CONFIG = StorageConfig()
    STORAGE_CONFIG = settings.STORAGE_CONFIG
    
    logger.info(f"ğŸ“ DAG ì €ì¥ ëª¨ë“œ: {STORAGE_CONFIG.dag_storage_mode} - {STORAGE_CONFIG.get_storage_description()}")
    logger.info(f"ğŸ“‚ DAG ì €ì¥ ê²½ë¡œ: {STORAGE_CONFIG.get_dag_images_dir()}")
    if STORAGE_CONFIG.dag_storage_mode == 'local':
        logger.info(f"ğŸŒ ë¡œì»¬ ì„œë²„ URL: {STORAGE_CONFIG.local_base_url}")
    else:
        logger.info(f"ğŸŒ NAS ì„œë²„ URL: {STORAGE_CONFIG.nas_base_url}")
    
    # ì „ì—­ CLI ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •
    CLI_DATA_SOURCE = args.offer_data_source
    logger.info(f"CLI ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •: {CLI_DATA_SOURCE}")
    
    # ì§€ì •ëœ ë°ì´í„° ì†ŒìŠ¤ë¡œ ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™”
    logger.info("ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì¤‘...")
    initialize_global_extractor(CLI_DATA_SOURCE)
    
    if args.test:
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰
        logger.info("í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œ ì‹¤í–‰ ì¤‘...")
        
        # ì œê³µëœ ë©”ì‹œì§€ ë˜ëŠ” ê¸°ë³¸ ìƒ˜í”Œ ë©”ì‹œì§€ ì‚¬ìš©
        message = args.message or """
        [SKí…”ë ˆì½¤] ZEMí° í¬ì¼“ëª¬ì—ë””ì…˜3 ì•ˆë‚´
        (ê´‘ê³ )[SKT] ìš°ë¦¬ ì•„ì´ ì²« ë²ˆì§¸ ìŠ¤ë§ˆíŠ¸í°, ZEM í‚¤ì¦ˆí°__#04 ê³ ê°ë‹˜, ì•ˆë…•í•˜ì„¸ìš”!
        ìš°ë¦¬ ì•„ì´ ìŠ¤ë§ˆíŠ¸í° ê³ ë¯¼ ì¤‘ì´ì…¨ë‹¤ë©´, ìë…€ ìŠ¤ë§ˆíŠ¸í° ê´€ë¦¬ ì•± ZEMì´ ì„¤ì¹˜ëœ SKTë§Œì˜ ì•ˆì „í•œ í‚¤ì¦ˆí°,
        ZEMí° í¬ì¼“ëª¬ì—ë””ì…˜3ìœ¼ë¡œ ìš°ë¦¬ ì•„ì´ ì·¨í–¥ì„ ì €ê²©í•´ ë³´ì„¸ìš”!
        """
        
        try:
            logger.info(f"ì¶”ì¶œê¸° ì„¤ì •: llm_model={args.llm_model}, product_mode={args.product_info_extraction_mode}, entity_mode={args.entity_matching_mode}, dag_extract={args.extract_entity_dag}")
            extractor = get_configured_extractor(args.llm_model, args.product_info_extraction_mode, args.entity_matching_mode, args.extract_entity_dag)
            
            if not message.strip():
                logger.info("í…ìŠ¤íŠ¸ê°€ ì œê³µë˜ì§€ ì•Šì•„ ìƒ˜í”Œ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤...")
            
            logger.info("ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘...")
            
            # DAG ì¶”ì¶œ ì—¬ë¶€ì— ë”°ë¼ ë³‘ë ¬ ì²˜ë¦¬ ë˜ëŠ” ë‹¨ì¼ ì²˜ë¦¬
            if args.extract_entity_dag:
                logger.info("DAG ì¶”ì¶œê³¼ í•¨ê»˜ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘")
                result = process_message_worker(extractor, message, extract_dag=True)
            else:
                result = extractor.process_message(message)
                result['entity_dag'] = []
            
            print("\n" + "="*60)
            print("ì¶”ì¶œ ê²°ê³¼:")
            print("="*60)
            print(json.dumps(result, ensure_ascii=False, indent=2))
            print("="*60)
            
            logger.info("ì²˜ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
        except Exception as e:
            logger.error(f"âŒ ì˜¤ë¥˜: {e}")
            sys.exit(1)
    else:
        # ì„œë²„ ëª¨ë“œ ì‹¤í–‰
        logger.info(f"íŒŒì‹±ëœ ì¸ì: host={args.host}, port={args.port}, debug={args.debug}")
        logger.info("âœ… ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ, ìš”ì²­ ì²˜ë¦¬ ì¤€ë¹„ë¨")
        logger.info(f"MMS ì¶”ì¶œê¸° API ì„œë²„ë¥¼ {args.host}:{args.port}ì—ì„œ ì‹œì‘í•©ë‹ˆë‹¤")
        logger.info("ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸:")
        logger.info("  GET  /health - í—¬ìŠ¤ì²´í¬")
        logger.info("  GET  /models - ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡")
        logger.info("  GET  /status - ì„œë²„ ìƒíƒœ ì¡°íšŒ")
        logger.info("  POST /extract - ë‹¨ì¼ ë©”ì‹œì§€ ì¶”ì¶œ")
        logger.info("  POST /extract/batch - ë‹¤ì¤‘ ë©”ì‹œì§€ ë°°ì¹˜ ì¶”ì¶œ")
        logger.info("  POST /dag - Entity DAG ì¶”ì¶œ")
        
        # Flask ì„¤ì • ì ìš©
        app.config['DEBUG'] = args.debug
        
        try:
            # ì„œë²„ ì‹œì‘ (ë¦¬ë¡œë” ë¹„í™œì„±í™”, ìŠ¤ë ˆë”© í™œì„±í™”)
            app.run(host=args.host, port=args.port, debug=args.debug, use_reloader=False, threaded=True)
        except Exception as e:
            logger.error(f"ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
            sys.exit(1)

if __name__ == "__main__":
    main()
