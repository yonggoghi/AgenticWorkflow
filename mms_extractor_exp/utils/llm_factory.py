"""
LLM Factory - LLM ëª¨ë¸ ì´ˆê¸°í™” ì „ë‹´ í´ë˜ìŠ¤
============================================

ğŸ“‹ ê°œìš”
-------
ìˆœí™˜ ì˜ì¡´ì„±ì„ ì œê±°í•˜ê³  LLM ì´ˆê¸°í™” ë¡œì§ì„ ì¤‘ì•™í™”í•©ë‹ˆë‹¤.
ë‹¤ì–‘í•œ LLM ëª¨ë¸ì„ ì¼ê´€ëœ ì¸í„°í˜ì´ìŠ¤ë¡œ ìƒì„±í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.

ğŸ”— ì˜ì¡´ì„±
---------
**ì‚¬ìš©í•˜ëŠ” ëª¨ë“ˆ:**
- `langchain_openai.ChatOpenAI`: LLM ëª¨ë¸ ì¸í„°í˜ì´ìŠ¤
- `config.settings`: API ë° ëª¨ë¸ ì„¤ì • (API_CONFIG, MODEL_CONFIG)
- `os`: í™˜ê²½ë³€ìˆ˜ ì ‘ê·¼

**ì‚¬ìš©ë˜ëŠ” ê³³:**
- `core.mms_extractor`: MMSExtractor ì´ˆê¸°í™” ì‹œ LLM ìƒì„±
- `services.result_builder`: ResultBuilderì—ì„œ ë™ì  LLM ìƒì„±
- `services.entity_recognizer`: ë©€í‹°ëª¨ë¸ ì—”í‹°í‹° ì¶”ì¶œ

ğŸ—ï¸ ì£¼ìš” ê¸°ëŠ¥
------------
- **ë‹¨ì¼/ë³µìˆ˜ LLM ëª¨ë¸ ìƒì„±**: í•˜ë‚˜ ë˜ëŠ” ì—¬ëŸ¬ ëª¨ë¸ì„ ë™ì‹œì— ì´ˆê¸°í™”
- **ëª¨ë¸ëª… ë§¤í•‘ ê´€ë¦¬**: ì§§ì€ ë³„ì¹­(ax, gpt ë“±)ì„ ì‹¤ì œ ëª¨ë¸ëª…ìœ¼ë¡œ ë³€í™˜
- **ì¼ê´€ëœ ì„¤ì • ì ìš©**: temperature, seed, max_tokens í†µì¼

ğŸ“Š ì§€ì› ëª¨ë¸ ë§¤í•‘
----------------

| ë³„ì¹­ | ì‹¤ì œ ëª¨ë¸ëª… | ì œê³µì‚¬ | ìš©ë„ |
|------|------------|--------|------|
| **ax** | skt/ax4 | SK Telecom | ê¸°ë³¸ ì¶”ì¶œ ëª¨ë¸ (ë¹ ë¦„) |
| **gpt** | azure/openai/gpt-4o-2024-08-06 | OpenAI | ê³ í’ˆì§ˆ ì¶”ì¶œ |
| **gen** | gcp/gemini-2.5-flash | Google | ë¹ ë¥¸ ì²˜ë¦¬ |
| **cld** | amazon/anthropic/claude-sonnet-4 | Anthropic | ë³µì¡í•œ ì¶”ë¡  |
| **gem** | gemma-7b | Google | ê²½ëŸ‰ ëª¨ë¸ |

### ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ
- **ë¹ ë¥¸ ì²˜ë¦¬**: ax, gen
- **ë†’ì€ ì •í™•ë„**: gpt, cld
- **ë¹„ìš© íš¨ìœ¨**: gem, gen
- **ë©€í‹°ëª¨ë¸ ì•™ìƒë¸”**: [ax, gpt, gen]

ğŸ’¡ ì‚¬ìš© ì˜ˆì‹œ
-----------
```python
from utils.llm_factory import LLMFactory

# 1. ê¸°ë³¸ ì‚¬ìš© (config.settings ìë™ ë¡œë“œ)
factory = LLMFactory()

# ë‹¨ì¼ ëª¨ë¸ ìƒì„±
llm = factory.create_model('ax')
response = llm.invoke("ê´‘ê³  ë©”ì‹œì§€ ë¶„ì„...")

# 2. ë³µìˆ˜ ëª¨ë¸ ìƒì„± (ë©€í‹°ëª¨ë¸ ì•™ìƒë¸”)
llms = factory.create_models(['ax', 'gpt', 'gen'])
for llm in llms:
    response = llm.invoke("...")

# 3. ì»¤ìŠ¤í…€ ì„¤ì • ì‚¬ìš©
from config.settings import API_CONFIG, MODEL_CONFIG

factory = LLMFactory(
    api_config=API_CONFIG,
    model_config=MODEL_CONFIG
)
llm = factory.create_model('cld')

# 4. í™˜ê²½ë³€ìˆ˜ë§Œ ì‚¬ìš© (config ì—†ì´)
factory = LLMFactory(api_config=None, model_config=None)
llm = factory.create_model('ax')  # í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ
```

âš™ï¸ ì„¤ì • ìš°ì„ ìˆœìœ„
---------------
1. **API í‚¤**: `api_config.llm_api_key` â†’ `OPENAI_API_KEY` â†’ `LLM_API_KEY`
2. **API URL**: `api_config.llm_api_url` â†’ `LLM_BASE_URL`
3. **ëª¨ë¸ ì„¤ì •**: `model_config` â†’ ê¸°ë³¸ê°’ (max_tokens=4000, seed=42)

ğŸ“ ì°¸ê³ ì‚¬í•­
----------
- ëª¨ë“  ëª¨ë¸ì€ temperature=0.0 (ê²°ì •ë¡ ì  ì¶œë ¥)
- ì‹¤íŒ¨í•œ ëª¨ë¸ì€ ìë™ìœ¼ë¡œ ê±´ë„ˆë›°ê³  ë¡œê·¸ ê¸°ë¡
- ëª¨ë¸ëª… ë§¤í•‘ì€ `__init__`ì—ì„œ ì„¤ì • ê°€ëŠ¥
- í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•´ MMSExtractorì˜ `_initialize_multiple_llm_models` ìœ ì§€

ì‘ì„±ì: MMS ë¶„ì„íŒ€
ìµœì¢… ìˆ˜ì •: 2024-12
ë²„ì „: 2.1.0
"""

import logging
import os
from typing import List, Optional
from langchain_openai import ChatOpenAI

logger = logging.getLogger(__name__)


class LLMFactory:
    """
    LLM ëª¨ë¸ ìƒì„± Factory í´ë˜ìŠ¤
    
    ì±…ì„:
        - LLM ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° ì´ˆê¸°í™”
        - ëª¨ë¸ëª… ë³„ì¹­ ê´€ë¦¬ (ax, gpt, gen ë“±)
        - API í‚¤ ë° ì„¤ì • ê´€ë¦¬
        - ë©€í‹°ëª¨ë¸ ìƒì„± ì§€ì›
    
    í˜‘ë ¥ ê°ì²´:
        - **ChatOpenAI**: LangChain OpenAI ì¸í„°í˜ì´ìŠ¤
        - **config.settings**: API ë° ëª¨ë¸ ì„¤ì • ì œê³µ
    
    Attributes:
        api_config: API ì„¤ì • ê°ì²´ (llm_api_key, llm_api_url)
        model_config: ëª¨ë¸ ì„¤ì • ê°ì²´ (max_tokens, seed, ëª¨ë¸ëª…)
        model_mapping (Dict[str, str]): ë³„ì¹­ â†’ ì‹¤ì œ ëª¨ë¸ëª… ë§¤í•‘
    """
    
    def __init__(self, api_config=None, model_config=None):
        """
        LLMFactory ì´ˆê¸°í™”
        
        Args:
            api_config: API ì„¤ì • ê°ì²´ (ì„ íƒì‚¬í•­, Noneì´ë©´ config.settingsì—ì„œ ë¡œë“œ)
            model_config: ëª¨ë¸ ì„¤ì • ê°ì²´ (ì„ íƒì‚¬í•­, Noneì´ë©´ config.settingsì—ì„œ ë¡œë“œ)
        """
        # Config ë¡œë“œ
        if api_config is None or model_config is None:
            try:
                from config.settings import API_CONFIG, MODEL_CONFIG
                self.api_config = api_config or API_CONFIG
                self.model_config = model_config or MODEL_CONFIG
            except ImportError:
                logger.warning("ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                self.api_config = None
                self.model_config = None
        else:
            self.api_config = api_config
            self.model_config = model_config
        
        # ëª¨ë¸ëª… ë§¤í•‘
        self.model_mapping = {
            "cld": self._get_config_value('anthropic_model', 'amazon/anthropic/claude-sonnet-4-20250514'),
            "ax": self._get_config_value('ax_model', 'skt/ax4'),
            "gpt": self._get_config_value('gpt_model', 'azure/openai/gpt-4o-2024-08-06'),
            "gen": self._get_config_value('gemini_model', 'gcp/gemini-2.5-flash'),
            "gem": self._get_config_value('gemma_model', 'gemma-7b'),
        }
    
    def _get_config_value(self, attr_name: str, default_value: str) -> str:
        """ì„¤ì • ê°’ì„ ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸°"""
        if self.model_config:
            return getattr(self.model_config, attr_name, default_value)
        return default_value
    
    def create_model(self, model_name: str) -> ChatOpenAI:
        """
        ë‹¨ì¼ LLM ëª¨ë¸ ìƒì„±
        
        Args:
            model_name: ëª¨ë¸ ì´ë¦„ (ì˜ˆ: 'ax', 'gpt', 'gen', 'cld', 'gem')
        
        Returns:
            ChatOpenAI: ì´ˆê¸°í™”ëœ LLM ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        
        Raises:
            Exception: ëª¨ë¸ ìƒì„± ì‹¤íŒ¨ ì‹œ
        """
        actual_model_name = self.model_mapping.get(model_name, model_name)
        
        # API í‚¤ ë° URL ê°€ì ¸ì˜¤ê¸°
        if self.api_config:
            api_key = getattr(self.api_config, 'llm_api_key', os.getenv('OPENAI_API_KEY'))
            api_base = getattr(self.api_config, 'llm_api_url', None)
        else:
            api_key = os.getenv('OPENAI_API_KEY') or os.getenv('LLM_API_KEY')
            api_base = os.getenv('LLM_BASE_URL')
        
        # ëª¨ë¸ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        if self.model_config:
            max_tokens = getattr(self.model_config, 'llm_max_tokens', 4000)
            seed = getattr(self.model_config, 'llm_seed', 42)
        else:
            max_tokens = 4000
            seed = 42
        
        model_kwargs = {
            "temperature": 0.0,
            "openai_api_key": api_key,
            "openai_api_base": api_base,
            "model": actual_model_name,
            "max_tokens": max_tokens,
            "seed": seed
        }
        
        llm_model = ChatOpenAI(**model_kwargs)
        logger.info(f"âœ… LLM ëª¨ë¸ ìƒì„± ì™„ë£Œ: {model_name} ({actual_model_name})")
        return llm_model
    
    def create_models(self, model_names: List[str]) -> List[ChatOpenAI]:
        """
        ë³µìˆ˜ì˜ LLM ëª¨ë¸ ìƒì„±
        
        Args:
            model_names: ëª¨ë¸ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (ì˜ˆ: ['ax', 'gpt', 'gen'])
        
        Returns:
            List[ChatOpenAI]: ì´ˆê¸°í™”ëœ LLM ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë¦¬ìŠ¤íŠ¸
            
        Note:
            ì‹¤íŒ¨í•œ ëª¨ë¸ì€ ê±´ë„ˆë›°ê³  ì„±ê³µí•œ ëª¨ë¸ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
        """
        llm_models = []
        
        for model_name in model_names:
            try:
                llm_model = self.create_model(model_name)
                llm_models.append(llm_model)
            except Exception as e:
                logger.error(f"âŒ LLM ëª¨ë¸ ìƒì„± ì‹¤íŒ¨: {model_name} - {e}")
                continue
        
        logger.info(f"âœ… ì´ {len(llm_models)}ê°œ LLM ëª¨ë¸ ìƒì„± ì™„ë£Œ")
        return llm_models
