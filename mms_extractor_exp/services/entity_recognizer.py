"""
MMS Extractor - Entity Recognizer Service
==========================================

ðŸ“‹ ê°œìš”
-------
ì´ ì„œë¹„ìŠ¤ëŠ” MMS ë©”ì‹œì§€ì—ì„œ ìƒí’ˆ/ì„œë¹„ìŠ¤ ì—”í‹°í‹°ë¥¼ ì¶”ì¶œí•˜ê³  ë°ì´í„°ë² ì´ìŠ¤ì™€ ë§¤ì¹­í•˜ëŠ”
í•µì‹¬ ë¡œì§ì„ ë‹´ë‹¹í•©ë‹ˆë‹¤. MMSExtractorë¡œë¶€í„° ë¶„ë¦¬ë˜ì–´ ë…ë¦½ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ ë° ìž¬ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.

ðŸ”— ì˜ì¡´ì„±
---------
**ì‚¬ìš©í•˜ëŠ” ëª¨ë“ˆ:**
- `utils`: ìœ ì‚¬ë„ ê³„ì‚° (parallel_fuzzy_similarity, parallel_seq_similarity)
- `prompts`: ì—”í‹°í‹° ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
- `config.settings`: ìž„ê³„ê°’ ë° ì²˜ë¦¬ ì„¤ì • (PROCESSING_CONFIG)
- `Kiwi`: í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„
- `LangChain`: LLM ëª¨ë¸ ì¸í„°íŽ˜ì´ìŠ¤

**ì‚¬ìš©ë˜ëŠ” ê³³:**
- `core.mms_workflow_steps.EntityExtractionStep`: ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ì—ì„œ ì‚¬ìš©
- `core.mms_extractor`: MMSExtractor ì´ˆê¸°í™” ì‹œ ìƒì„±

ðŸ—ï¸ ì—”í‹°í‹° ì¶”ì¶œ ëª¨ë“œ ë¹„êµ
------------------------

| ëª¨ë“œ | ë°©ë²• | ì†ë„ | ì •í™•ë„ | ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤ |
|------|------|------|--------|--------------|
| **Kiwi** | í˜•íƒœì†Œ ë¶„ì„ + Fuzzy/Sequence ë§¤ì¹­ | ë¹ ë¦„ | ì¤‘ê°„ | ëª…í™•í•œ ìƒí’ˆëª…, ë¹ ë¥¸ ì²˜ë¦¬ í•„ìš” |
| **Logic** | Fuzzy + Sequence ìœ ì‚¬ë„ ì¡°í•© | ì¤‘ê°„ | ì¤‘ê°„ | í›„ë³´ ì—”í‹°í‹° ëª©ë¡ì´ ìžˆì„ ë•Œ |
| **LLM** | 2ë‹¨ê³„ LLM ì¶”ì¶œ + í•„í„°ë§ | ëŠë¦¼ | ë†’ìŒ | ë³µìž¡í•œ ë¬¸ë§¥, ë†’ì€ ì •í™•ë„ í•„ìš” |

### LLM ëª¨ë“œ ìƒì„¸ íë¦„
```
1ë‹¨ê³„: ì´ˆê¸° ì¶”ì¶œ
  â”œâ”€ DAG/PAIRING/SIMPLE í”„ë¡¬í”„íŠ¸ ì„ íƒ (context_mode)
  â”œâ”€ ë©€í‹°ëª¨ë¸ ë³‘ë ¬ ì‹¤í–‰ (ìµœëŒ€ 3ê°œ)
  â””â”€ ì—”í‹°í‹° + ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ

2ë‹¨ê³„: ì •ì œ ë° í•„í„°ë§
  â”œâ”€ N-gram í™•ìž¥
  â”œâ”€ ìƒí’ˆ DBì™€ Fuzzy/Sequence ë§¤ì¹­
  â”œâ”€ ë°°ì¹˜ ë‹¨ìœ„ë¡œ LLM ìž¬ê²€ì¦
  â””â”€ ìµœì¢… ì—”í‹°í‹° ëª©ë¡ ë°˜í™˜
```

ðŸ—ï¸ ì£¼ìš” ì»´í¬ë„ŒíŠ¸
----------------
- **EntityRecognizer**: ì—”í‹°í‹° ì¶”ì¶œ ë° ë§¤ì¹­ ì„œë¹„ìŠ¤ í´ëž˜ìŠ¤
  - `extract_entities_hybrid()`: í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì¶œ (Kiwi + Fuzzy + Sequence)
  - `extract_entities_with_fuzzy_matching()`: í¼ì§€ ë§¤ì¹­ ê¸°ë°˜ ì¶”ì¶œ
  - `extract_entities_with_llm()`: LLM ê¸°ë°˜ ì¶”ì¶œ (2ë‹¨ê³„)
  - `map_products_with_similarity()`: ìœ ì‚¬ë„ ê¸°ë°˜ ìƒí’ˆ ë§¤í•‘

ðŸ’¡ ì‚¬ìš© ì˜ˆì‹œ
-----------
```python
from services.entity_recognizer import EntityRecognizer

# ì´ˆê¸°í™”
recognizer = EntityRecognizer(
    kiwi=kiwi_instance,
    item_pdf_all=product_dataframe,
    stop_item_names=['ê´‘ê³ ', 'ì´ë²¤íŠ¸'],
    llm_model=llm_instance,
    entity_extraction_mode='llm'
)

# Kiwi ê¸°ë°˜ ì¶”ì¶œ
entities, candidates, extra_df = recognizer.extract_entities_hybrid(
    "ì•„ì´í° 17 êµ¬ë§¤ ì‹œ ìºì‹œë°± ì œê³µ"
)

# LLM ê¸°ë°˜ ì¶”ì¶œ (DAG ì»¨í…ìŠ¤íŠ¸ ëª¨ë“œ)
similarity_df = recognizer.extract_entities_with_llm(
    msg_text="ì•„ì´í° 17 êµ¬ë§¤ ì‹œ ìºì‹œë°± ì œê³µ",
    rank_limit=50,
    llm_models=[llm1, llm2],
    context_mode='dag'
)

# ìƒí’ˆ ë§¤í•‘
products = recognizer.map_products_with_similarity(
    similarities_fuzzy=similarity_df,
    json_objects=llm_response
)
```

ðŸ“Š ìœ ì‚¬ë„ ê³„ì‚° ì•Œê³ ë¦¬ì¦˜
---------------------
**Fuzzy Similarity**: RapidFuzz ê¸°ë°˜ ë¬¸ìžì—´ ìœ ì‚¬ë„
- ìž„ê³„ê°’: `PROCESSING_CONFIG.fuzzy_threshold` (ê¸°ë³¸ 0.5)
- ìš©ë„: ì´ˆê¸° í›„ë³´ í•„í„°ë§

**Sequence Similarity**: ì‹œí€€ìŠ¤ ë§¤ì¹­ (s1, s2)
- s1: ì •ê·œí™” ë°©ì‹ 1
- s2: ì •ê·œí™” ë°©ì‹ 2
- Combined: s1 + s2 (ìž„ê³„ê°’: 1.0)

**ìµœì¢… ì ìˆ˜**: 
```
final_sim = sim_s1 + sim_s2
í•„í„°: final_sim >= high_similarity_threshold (ê¸°ë³¸ 1.0)
```

ðŸ“ ì°¸ê³ ì‚¬í•­
----------
- LLM ëª¨ë“œëŠ” context_modeì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
  - 'dag': HYBRID_DAG_EXTRACTION_PROMPT (ì‚¬ìš©ìž í–‰ë™ ê²½ë¡œ)
  - 'pairing': HYBRID_PAIRING_EXTRACTION_PROMPT (í˜œíƒ ë§¤í•‘)
  - 'ont': ONTOLOGY_PROMPT (íŒ”ëž€í‹°ì–´ ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ JSON ì¶”ì¶œ)
  - 'none': SIMPLE_ENTITY_EXTRACTION_PROMPT (ë‹¨ìˆœ ì¶”ì¶œ)
- ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™” (joblib Parallel)
- ë©”ì‹œì§€ ê¸¸ì´ì— ë”°ë¼ ë°°ì¹˜ í¬ê¸° ìžë™ ì¡°ì •
- Stop words í•„í„°ë§ìœ¼ë¡œ ë…¸ì´ì¦ˆ ì œê±°

"""


import logging
import traceback
import re
import json
from typing import List, Tuple, Dict, Optional, Any
import pandas as pd
from langchain_core.prompts import PromptTemplate
from joblib import Parallel, delayed

# Utility imports
from utils import (
    log_performance,
    validate_text_input,
    safe_execute,
    parallel_fuzzy_similarity,
    parallel_seq_similarity,
    filter_text_by_exc_patterns,
    filter_specific_terms,
    extract_ngram_candidates,
    convert_df_to_json_list,
    select_most_comprehensive
)

# Prompt imports
from prompts import (
    SIMPLE_ENTITY_EXTRACTION_PROMPT,
    HYBRID_DAG_EXTRACTION_PROMPT,
    CONTEXT_BASED_ENTITY_EXTRACTION_PROMPT,
    build_context_based_entity_extraction_prompt,
    HYBRID_PAIRING_EXTRACTION_PROMPT,
    ONTOLOGY_PROMPT
)

# Config imports
try:
    from config.settings import PROCESSING_CONFIG
except ImportError:
    logging.warning("Config file not found. Using defaults.")
    class PROCESSING_CONFIG:        # ìž„ê³„ê°’ ì„¤ì • (configì—ì„œ ë¡œë“œ)
        # If config.settings is not found, these are the default values.
        # The original instruction's intent to import PROCESSING_CONFIG inside this block
        # would cause an infinite ImportError loop.
        # Assuming the intent is to define default entity-specific thresholds
        # if the main config is not available.
        fuzzy_threshold = 0.5
        n_jobs = 4
        batch_size = 100
        similarity_threshold = 0.2
        combined_similarity_threshold = 0.2
        high_similarity_threshold = 1.0
        entity_fuzzy_threshold = 0.5
        entity_similarity_threshold = 0.2
        entity_combined_similarity_threshold = 0.2
        entity_high_similarity_threshold = 1.0
        entity_llm_fuzzy_threshold = 0.6  # LLM-based entity extraction threshold

logger = logging.getLogger(__name__)


class EntityRecognizer:
    """
    ì—”í‹°í‹° ì¶”ì¶œ ë° ë§¤ì¹­ ì„œë¹„ìŠ¤ í´ëž˜ìŠ¤
    
    ì±…ìž„:
        - MMS ë©”ì‹œì§€ì—ì„œ ìƒí’ˆ/ì„œë¹„ìŠ¤ ì—”í‹°í‹° ì¶”ì¶œ
        - ì¶”ì¶œëœ ì—”í‹°í‹°ë¥¼ ìƒí’ˆ ë°ì´í„°ë² ì´ìŠ¤ì™€ ë§¤ì¹­
        - ë‹¤ì–‘í•œ ì¶”ì¶œ ëª¨ë“œ ì§€ì› (Kiwi, Logic, LLM)
        - ìœ ì‚¬ë„ ê¸°ë°˜ í›„ë³´ í•„í„°ë§ ë° ëž­í‚¹
    
    í˜‘ë ¥ ê°ì²´:
        - **Kiwi**: í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„ (NNP íƒœê·¸ ì¶”ì¶œ)
        - **LLM Model**: ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œ
        - **ItemDataLoader**: ìƒí’ˆ ë°ì´í„° ì œê³µ (item_pdf_all)
        - **Parallel (joblib)**: ë³‘ë ¬ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ìµœì í™”
    
    ë°ì´í„° íë¦„:
        ```
        MMS ë©”ì‹œì§€
            â†“
        [Kiwi/Logic/LLM ì¶”ì¶œ]
            â†“
        í›„ë³´ ì—”í‹°í‹° ëª©ë¡
            â†“
        [Fuzzy + Sequence ìœ ì‚¬ë„ ê³„ì‚°]
            â†“
        ìœ ì‚¬ë„ DataFrame
            â†“
        [ìž„ê³„ê°’ í•„í„°ë§ + ëž­í‚¹]
            â†“
        ìµœì¢… ë§¤ì¹­ ê²°ê³¼
        ```
    
    Attributes:
        kiwi: Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ì¸ìŠ¤í„´ìŠ¤
        item_pdf_all (pd.DataFrame): ì „ì²´ ìƒí’ˆ ì •ë³´ (item_nm, item_nm_alias, item_id ë“±)
        stop_item_names (List[str]): ì œì™¸í•  ë¶ˆìš©ì–´ ëª©ë¡
        llm_model: LangChain LLM ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤
        alias_pdf_raw (pd.DataFrame): ë³„ì¹­ ê·œì¹™ (ì„ íƒì‚¬í•­)
        entity_extraction_mode (str): ì¶”ì¶œ ëª¨ë“œ ('llm', 'nlp', 'logic')
        exc_tag_patterns (List): Kiwi ì œì™¸ íƒœê·¸ íŒ¨í„´
    """

    def __init__(self, kiwi, item_pdf_all: pd.DataFrame, stop_item_names: List[str], 
                 llm_model, alias_pdf_raw: pd.DataFrame = None, entity_extraction_mode: str = 'llm'):
        """
        Initialize the EntityRecognizer service.

        Args:
            kiwi: Initialized Kiwi instance
            item_pdf_all: DataFrame containing all item information
            stop_item_names: List of stop words/items to ignore
            llm_model: Initialized LLM model instance
            alias_pdf_raw: DataFrame containing alias rules (optional)
            entity_extraction_mode: Mode of entity extraction ('llm', 'nlp', 'logic')
        """
        self.kiwi = kiwi
        self.item_pdf_all = item_pdf_all
        self.stop_item_names = stop_item_names
        self.llm_model = llm_model
        self.alias_pdf_raw = alias_pdf_raw
        self.entity_extraction_mode = entity_extraction_mode
        
        # Exclusion patterns for Kiwi
        self.exc_tag_patterns = [
            ['SN', 'NNB'], ['W_SERIAL'], ['JKO'], ['W_URL'], ['W_EMAIL'],
            ['XSV', 'EC'], ['VV', 'EC'], ['VCP', 'ETM'], ['XSA', 'ETM'],
            ['VV', 'ETN'], ['SSO'], ['SSC'], ['SW'], ['SF'], ['SP'], 
            ['SS'], ['SE'], ['SO'], ['SB'], ['SH'], ['W_HASHTAG']
        ]

    @log_performance
    def extract_entities_hybrid(self, mms_msg: str) -> Tuple[List[str], List[str], pd.DataFrame]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì—”í‹°í‹° ì¶”ì¶œ (Kiwi í˜•íƒœì†Œ ë¶„ì„ + Fuzzy Matching + Sequence Similarity)"""
        try:
            logger.info("=== Kiwi Entity Extraction Started ===")
            mms_msg = validate_text_input(mms_msg)
            logger.info(f"Message length: {len(mms_msg)} chars")
            
            if self.item_pdf_all.empty:
                logger.error("Item data is empty! Cannot extract entities.")
                return [], [], pd.DataFrame()
            
            if 'item_nm_alias' not in self.item_pdf_all.columns:
                logger.error("item_nm_alias column missing! Cannot extract entities.")
                return [], [], pd.DataFrame()
            
            unique_aliases = self.item_pdf_all['item_nm_alias'].unique()
            logger.info(f"Number of aliases to match: {len(unique_aliases)}")
            
            # Sentence splitting
            sentences = sum(self.kiwi.split_into_sents(
                re.split(r"_+", mms_msg), return_tokens=True, return_sub_sents=True
            ), [])
            
            sentences_all = []
            for sent in sentences:
                if sent.subs:
                    sentences_all.extend(sent.subs)
                else:
                    sentences_all.append(sent)
            
            # Filter sentences
            sentence_list = [
                filter_text_by_exc_patterns(sent, self.exc_tag_patterns) 
                for sent in sentences_all
            ]
            
            # Tokenize and extract NNPs
            result_msg = self.kiwi.tokenize(mms_msg, normalize_coda=True, z_coda=False, split_complex=False)
            
            entities_from_kiwi = [
                token.form for token in result_msg 
                if token.tag == 'NNP' and 
                   token.form not in self.stop_item_names + ['-'] and 
                   len(token.form) >= 2 and 
                   not token.form.lower() in self.stop_item_names
            ]
            entities_from_kiwi = [e for e in filter_specific_terms(entities_from_kiwi) if e in unique_aliases]
            
            logger.info(f"Entities from Kiwi (filtered): {list(set(entities_from_kiwi))}")

            # Fuzzy matching
            logger.info("Starting fuzzy matching...")
            similarities_fuzzy = safe_execute(
                parallel_fuzzy_similarity,
                sentence_list, 
                unique_aliases,
                threshold=getattr(PROCESSING_CONFIG, 'fuzzy_threshold', 0.5),
                text_col_nm='sent', 
                item_col_nm='item_nm_alias',
                n_jobs=getattr(PROCESSING_CONFIG, 'n_jobs', 4),
                batch_size=30,
                default_return=pd.DataFrame()
            )
            
            if similarities_fuzzy.empty:
                logger.warning("Fuzzy matching result empty. Using Kiwi results only.")
                cand_item_list = list(entities_from_kiwi) if entities_from_kiwi else []
                
                if cand_item_list:
                    extra_item_pdf = self.item_pdf_all.query("item_nm_alias in @cand_item_list")[
                        ['item_nm','item_nm_alias','item_id']
                    ].groupby(["item_nm"])['item_id'].apply(list).reset_index()
                else:
                    extra_item_pdf = pd.DataFrame()
                
                return entities_from_kiwi, cand_item_list, extra_item_pdf

            # Sequence similarity
            logger.info("Starting sequence similarity calculation...")
            similarities_seq = safe_execute(
                parallel_seq_similarity,
                sent_item_pdf=similarities_fuzzy,
                text_col_nm='sent',
                item_col_nm='item_nm_alias',
                n_jobs=getattr(PROCESSING_CONFIG, 'n_jobs', 4),
                batch_size=getattr(PROCESSING_CONFIG, 'batch_size', 100),
                default_return=pd.DataFrame()
            )
            
            # Filter by threshold
            similarity_threshold = getattr(PROCESSING_CONFIG, 'similarity_threshold', 0.2)
            cand_items = similarities_seq.query(
                "sim >= @similarity_threshold and "
                "item_nm_alias.str.contains('', case=False) and "
                "item_nm_alias not in @self.stop_item_names"
            )
            
            # Add Kiwi entities
            entities_from_kiwi_pdf = self.item_pdf_all.query("item_nm_alias in @entities_from_kiwi")[
                ['item_nm','item_nm_alias']
            ]
            entities_from_kiwi_pdf['sim'] = 1.0

            # Merge results
            cand_item_pdf = pd.concat([cand_items, entities_from_kiwi_pdf])
            
            if not cand_item_pdf.empty:
                cand_item_array = cand_item_pdf.sort_values('sim', ascending=False).groupby([
                    "item_nm_alias"
                ])['sim'].max().reset_index(name='final_sim').sort_values(
                    'final_sim', ascending=False
                ).query("final_sim >= 0.2")['item_nm_alias'].unique()
                
                cand_item_list = list(cand_item_array) if hasattr(cand_item_array, '__iter__') else []
                
                if cand_item_list:
                    extra_item_pdf = self.item_pdf_all.query("item_nm_alias in @cand_item_list")[
                        ['item_nm','item_nm_alias','item_id']
                    ].groupby(["item_nm"])['item_id'].apply(list).reset_index()
                else:
                    extra_item_pdf = pd.DataFrame()
            else:
                cand_item_list = []
                extra_item_pdf = pd.DataFrame()

            return entities_from_kiwi, cand_item_list, extra_item_pdf
            
        except Exception as e:
            logger.error(f"Kiwi entity extraction failed: {e}")
            logger.error(f"Details: {traceback.format_exc()}")
            return [], [], pd.DataFrame()

    def extract_entities_with_fuzzy_matching(self, cand_entities: List[str], threshold_for_fuzzy: float = 0.5) -> pd.DataFrame:
        """í¼ì§€ ìœ ì‚¬ë„ + ì‹œí€€ìŠ¤ ìœ ì‚¬ë„ ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œ"""
        try:
            if not cand_entities:
                return pd.DataFrame()
            
            similarities_fuzzy = safe_execute(
                parallel_fuzzy_similarity,
                cand_entities,
                self.item_pdf_all['item_nm_alias'].unique(),
                threshold=threshold_for_fuzzy,
                text_col_nm='item_name_in_msg',
                item_col_nm='item_nm_alias',
                n_jobs=getattr(PROCESSING_CONFIG, 'n_jobs', 4),
                batch_size=30,
                default_return=pd.DataFrame()
            )
            
            if similarities_fuzzy.empty:
                return pd.DataFrame()
            
            cand_entities_sim = self._calculate_combined_similarity(similarities_fuzzy)
            return cand_entities_sim
            
        except Exception as e:
            logger.error(f"Logic-based extraction failed: {e}")
            return pd.DataFrame()

    def _calculate_combined_similarity(self, similarities_fuzzy: pd.DataFrame) -> pd.DataFrame:
        """Calculate combined similarity (s1 + s2)"""
        try:
            sim_s1 = safe_execute(
                parallel_seq_similarity,
                sent_item_pdf=similarities_fuzzy,
                text_col_nm='item_name_in_msg',
                item_col_nm='item_nm_alias',
                n_jobs=getattr(PROCESSING_CONFIG, 'n_jobs', 4),
                batch_size=30,
                normalization_value='s1',
                default_return=pd.DataFrame()
            ).rename(columns={'sim': 'sim_s1'})
            
            sim_s2 = safe_execute(
                parallel_seq_similarity,
                sent_item_pdf=similarities_fuzzy,
                text_col_nm='item_name_in_msg',
                item_col_nm='item_nm_alias',
                n_jobs=getattr(PROCESSING_CONFIG, 'n_jobs', 4),
                batch_size=30,
                normalization_value='s2',
                default_return=pd.DataFrame()
            ).rename(columns={'sim': 'sim_s2'})
            
            if not sim_s1.empty and not sim_s2.empty:
                combined = sim_s1.merge(sim_s2, on=['item_name_in_msg', 'item_nm_alias'])
                filtered = combined.query("(sim_s1>=@PROCESSING_CONFIG.combined_similarity_threshold and sim_s2>=@PROCESSING_CONFIG.combined_similarity_threshold)")
                
                if filtered.empty:
                    return pd.DataFrame()
                    
                combined = filtered.groupby(['item_name_in_msg', 'item_nm_alias']).agg({
                    'sim_s1': 'sum',
                    'sim_s2': 'sum'
                }).reset_index()
                combined['sim'] = combined['sim_s1'] + combined['sim_s2']
                return combined
            else:
                return pd.DataFrame()
                
        except Exception as e:
            logger.error(f"Combined similarity calculation failed: {e}")
            return pd.DataFrame()

    def _parse_entity_response(self, response: str) -> List[str]:
        """Parse entities from LLM response"""
        try:
            lines = response.split('\n')
            for line in lines:
                line_stripped = line.strip()
                line_upper = line_stripped.upper()
                
                if line_upper.startswith('REASON:'):
                    continue
                
                if line_upper.startswith('ENTITY:'):
                    entity_part = line_stripped[line_upper.find('ENTITY:') + 7:].strip()
                    
                    if not entity_part or entity_part.lower() in ['none', 'empty', 'ì—†ìŒ', 'null']:
                        return []
                    
                    if len(entity_part) > 200:
                        continue
                    
                    entities = [e.strip() for e in entity_part.split(',') if e.strip()]
                    return [e for e in entities if len(e) <= 100 and not (e.startswith('"') and not e.endswith('"'))]
            
            entity_pattern = r'ENTITY:\s*([^\n]*?)(?:\n|$)'
            entity_matches = list(re.finditer(entity_pattern, response, re.IGNORECASE))
            
            if entity_matches:
                last_match = entity_matches[-1]
                entity_text = last_match.group(1).strip()
                if entity_text and entity_text.lower() not in ['none', 'empty', 'ì—†ìŒ', 'null']:
                    if len(entity_text) <= 200:
                        return [e.strip() for e in entity_text.split(',') if e.strip() and len(e.strip()) <= 100]
            
            for line in reversed(lines):
                line_stripped = line.strip()
                if not line_stripped or line_stripped.upper().startswith('REASON:') or len(line_stripped) > 200:
                    continue
                
                if ',' in line_stripped:
                    entities = [e.strip() for e in line_stripped.split(',') if e.strip() and len(e.strip()) <= 100]
                    if entities and all(len(e) <= 100 for e in entities):
                        return entities
                elif len(line_stripped) <= 100:
                    return [line_stripped]
            
            return []
            
        except Exception as e:
            logger.error(f"Entity parsing failed: {e}")
            return []

    def _parse_ontology_response(self, response: str) -> dict:
        """
        Parse ontology JSON response from LLM.

        Args:
            response: LLM response (expected JSON format)

        Returns:
            dict with keys:
              - 'entities': List[str] - entity IDs
              - 'entity_types': Dict[str, str] - {id: type} mapping
              - 'relationships': List[dict] - [{source, target, type}, ...]
              - 'dag_text': str - user_action_path.dag
              - 'raw_json': dict - original parsed JSON
        """
        try:
            # JSON ì¶”ì¶œ (ì½”ë“œ ë¸”ë¡ ì²˜ë¦¬)
            json_str = response.strip()
            if json_str.startswith('```'):
                json_str = re.sub(r'^```(?:json)?\n?', '', json_str)
                json_str = re.sub(r'\n?```$', '', json_str)

            data = json.loads(json_str)

            # entities ì¶”ì¶œ
            entities = [e.get('id', '') for e in data.get('entities', []) if e.get('id')]

            # entity_types ë§¤í•‘
            entity_types = {e.get('id'): e.get('type', 'Unknown')
                           for e in data.get('entities', []) if e.get('id')}

            # relationships ì¶”ì¶œ
            relationships = data.get('relationships', [])

            # DAG í…ìŠ¤íŠ¸ ì¶”ì¶œ
            dag_text = data.get('user_action_path', {}).get('dag', '')

            return {
                'entities': entities,
                'entity_types': entity_types,
                'relationships': relationships,
                'dag_text': dag_text,
                'raw_json': data
            }
        except json.JSONDecodeError as e:
            logger.warning(f"Ontology JSON parsing failed: {e}")
            # Fallback: ê¸°ì¡´ íŒŒì‹± ë¡œì§ ì‚¬ìš©
            return {
                'entities': self._parse_entity_response(response),
                'entity_types': {},
                'relationships': [],
                'dag_text': '',
                'raw_json': {}
            }

    def _calculate_optimal_batch_size(self, msg_text: str, base_size: int = 50) -> int:
        """Calculate optimal batch size based on message length"""
        msg_length = len(msg_text)
        if msg_length < 500:
            return min(base_size * 2, 100)
        elif msg_length < 1000:
            return base_size
        else:
            return max(base_size // 2, 25)

    @log_performance
    def extract_entities_with_llm(self, msg_text: str, rank_limit: int = 50, llm_models: List = None, 
                                external_cand_entities: List[str] = [], context_mode: str = 'dag') -> pd.DataFrame:
        """
        LLM-based entity extraction with multi-model support and configurable context mode.

        Args:
            msg_text: Message text to extract entities from
            rank_limit: Maximum rank for entity candidates
            llm_models: List of LLM models to use (defaults to self.llm_model)
            external_cand_entities: External candidate entities to include
            context_mode: Context extraction mode - 'dag', 'pairing', 'ont', or 'none' (default: 'dag')
                - 'dag': HYBRID_DAG_EXTRACTION_PROMPT (ì‚¬ìš©ìž í–‰ë™ ê²½ë¡œ)
                - 'pairing': HYBRID_PAIRING_EXTRACTION_PROMPT (í˜œíƒ ë§¤í•‘)
                - 'ont': ONTOLOGY_PROMPT (íŒ”ëž€í‹°ì–´ ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ JSON ì¶”ì¶œ)
                - 'none': SIMPLE_ENTITY_EXTRACTION_PROMPT (ë‹¨ìˆœ ì¶”ì¶œ)

        Returns:
            DataFrame with extracted entities and similarity scores
        """

        try:
            logger.info("=== LLM Entity Extraction Started ===")
            logger.info(f"Context mode: {context_mode}")
            msg_text = validate_text_input(msg_text)
            
            if llm_models is None:
                llm_models = [self.llm_model]
            
            # Validate context_mode
            if context_mode not in ['dag', 'pairing', 'none', 'ont']:
                logger.warning(f"Invalid context_mode '{context_mode}', defaulting to 'dag'")
                context_mode = 'dag'
            
            # Select prompt based on context_mode
            if context_mode == 'dag':
                first_stage_prompt = HYBRID_DAG_EXTRACTION_PROMPT
                context_keyword = 'DAG'
            elif context_mode == 'pairing':
                first_stage_prompt = HYBRID_PAIRING_EXTRACTION_PROMPT
                context_keyword = 'PAIRING'
            elif context_mode == 'ont':
                first_stage_prompt = ONTOLOGY_PROMPT
                context_keyword = 'ONT'
            else:  # 'none'
                first_stage_prompt = SIMPLE_ENTITY_EXTRACTION_PROMPT
                context_keyword = None
            
            # Internal function for parallel execution
            def get_entities_and_context_by_llm(args_dict):
                llm_model, prompt = args_dict['llm_model'], args_dict['prompt']
                extract_context = args_dict.get('extract_context', True)
                context_kw = args_dict.get('context_keyword', None)
                is_ontology_mode = args_dict.get('is_ontology_mode', False)
                model_name = getattr(llm_model, 'model_name', 'Unknown')

                try:
                    # Log the prompt being sent to LLM
                    prompt_res_log_list = []
                    prompt_res_log_list.append(f"[{model_name}] Sending prompt to LLM:")
                    prompt_res_log_list.append("="*100)
                    prompt_res_log_list.append(prompt)
                    prompt_res_log_list.append("="*100)

                    response = llm_model.invoke(f"""

                    {prompt}

                    """).content

                    # Log the response received from LLM
                    prompt_res_log_list.append(f"[{model_name}] Received response from LLM:")
                    prompt_res_log_list.append("-"*100)
                    prompt_res_log_list.append(response)
                    prompt_res_log_list.append("-"*100)

                    logger.debug("\n".join(prompt_res_log_list))

                    # Ontology mode: use JSON parsing
                    if is_ontology_mode:
                        parsed = self._parse_ontology_response(response)
                        cand_entity_list = [e for e in parsed['entities']
                                          if e not in self.stop_item_names and len(e) >= 2]

                        # Build rich context with Entity Types, Relationships, and DAG
                        entity_types = parsed.get('entity_types', {})
                        relationships = parsed.get('relationships', [])
                        dag_text = parsed['dag_text']

                        # Format entity types: Name(Type), ...
                        entity_type_str = ", ".join([f"{k}({v})" for k, v in entity_types.items()]) if entity_types else ""

                        # Format relationships: Source -[TYPE]-> Target
                        rel_lines = []
                        for rel in relationships:
                            src = rel.get('source', '')
                            tgt = rel.get('target', '')
                            rel_type = rel.get('type', '')
                            if src and tgt and rel_type:
                                rel_lines.append(f"  - {src} -[{rel_type}]-> {tgt}")
                        relationships_str = "\n".join(rel_lines) if rel_lines else ""

                        # Combine all parts into context_text
                        context_parts = []
                        if entity_type_str:
                            context_parts.append(f"Entities: {entity_type_str}")
                        if relationships_str:
                            context_parts.append(f"Relationships:\n{relationships_str}")
                        if dag_text:
                            context_parts.append(f"DAG: {dag_text}")
                        context_text = "\n".join(context_parts)

                        logger.info(f"[{model_name}] Extracted {len(cand_entity_list)} entities (ONT mode): {cand_entity_list}")
                        logger.info(f"[{model_name}] Entity types: {entity_types}")
                        logger.info(f"[{model_name}] Relationships: {len(relationships)} found")
                        return {
                            "entities": cand_entity_list,
                            "context_text": context_text,
                            "entity_types": entity_types,
                            "relationships": relationships
                        }

                    # Standard mode: use regex parsing
                    cand_entity_list_raw = self._parse_entity_response(response)
                    cand_entity_list = [e for e in cand_entity_list_raw if e not in self.stop_item_names and len(e) >= 2]

                    logger.info(f"[{model_name}] Extracted {len(cand_entity_list)} entities: {cand_entity_list}")

                    context_text = ""
                    if extract_context and context_kw:
                        context_match = re.search(rf'{context_kw}:\s*(.*)', response, re.DOTALL | re.IGNORECASE)
                        if context_match:
                            context_text = context_match.group(1).strip()
                            logger.info(f"[{model_name}] Extracted {context_kw} text ({len(context_text)} chars)")
                        else:
                            logger.debug(f"[{model_name}] No {context_kw} found in response")

                    return {"entities": cand_entity_list, "context_text": context_text}
                except Exception as e:
                    logger.error(f"LLM extraction failed for {model_name}: {e}")
                    return {"entities": [], "context_text": ""}

            def get_entities_only_by_llm(args_dict):
                result = get_entities_and_context_by_llm(args_dict)
                return result['entities']

            # 1. First Stage: Extract entities and context
            batches = []
            for llm_model in llm_models:
                prompt = f"{first_stage_prompt}\n\n## message:\n{msg_text}"
                batches.append({
                    "prompt": prompt,
                    "llm_model": llm_model,
                    "extract_context": (context_mode != 'none'),
                    "context_keyword": context_keyword,
                    "is_ontology_mode": (context_mode == 'ont')
                })
            
            n_jobs = min(len(batches), 3)
            with Parallel(n_jobs=n_jobs, backend='threading') as parallel:
                batch_results_dicts = parallel(delayed(get_entities_and_context_by_llm)(args) for args in batches)
            
            all_entities = []
            all_contexts = []
            for result_dict in batch_results_dicts:
                all_entities.extend(result_dict['entities'])
                if result_dict['context_text']:
                    all_contexts.append(result_dict['context_text'])
            
            combined_context = "\n".join(all_contexts)
            
            if external_cand_entities:
                all_entities.extend(external_cand_entities)
            
            cand_entity_list = list(set(all_entities))
            
            # N-gram expansion
            cand_entity_list = list(set(sum([[c['text'] for c in extract_ngram_candidates(cand_entity, min_n=2, max_n=len(cand_entity.split())) if c['start_idx']<=0] if len(cand_entity.split())>=4 else [cand_entity] for cand_entity in cand_entity_list], [])))
            
            if not cand_entity_list:
                return pd.DataFrame()
            
            # Match with products
            cand_entities_sim = self._match_entities_with_products(cand_entity_list, rank_limit)
            
            if cand_entities_sim.empty:
                return pd.DataFrame()
            
            # 2. Second Stage: Filtering
            entities_in_message = cand_entities_sim['item_name_in_msg'].unique()
            cand_entities_voca_all = cand_entities_sim['item_nm_alias'].unique()
            optimal_batch_size = self._calculate_optimal_batch_size(msg_text, base_size=10)
            
            second_stage_llm = llm_models[0] if llm_models else self.llm_model
            
            batches = []
            for i in range(0, len(cand_entities_voca_all), optimal_batch_size):
                cand_entities_voca = cand_entities_voca_all[i:i+optimal_batch_size]
                
                # Build context section based on mode
                if context_mode == 'none' or not combined_context:
                    context_section = ""
                else:
                    context_label = f"{context_keyword} Context (User Action Paths)" if context_keyword else "Context"
                    context_section = f"\n## {context_label}:\n{combined_context}\n"
                
                # Build dynamic prompt based on context_keyword
                second_stage_prompt = build_context_based_entity_extraction_prompt(context_keyword)
                
                prompt = f"""
                {second_stage_prompt}
                
                ## message:                
                {msg_text}
                
                {context_section}
                
                ## entities in message:
                {', '.join(entities_in_message)}

                ## candidate entities in vocabulary:
                {', '.join(cand_entities_voca)}
                """
                batches.append({
                    "prompt": prompt, 
                    "llm_model": second_stage_llm, 
                    "extract_context": False,
                    "context_keyword": None
                })
            
            n_jobs = min(len(batches), 3)
            with Parallel(n_jobs=n_jobs, backend='threading') as parallel:
                batch_results = parallel(delayed(get_entities_only_by_llm)(args) for args in batches)
            
            cand_entity_list = list(set(sum(batch_results, [])))
            
            cand_entities_sim = cand_entities_sim.query("item_nm_alias in @cand_entity_list")
            
            return cand_entities_sim
            
        except Exception as e:
            logger.error(f"LLM entity extraction failed: {e}")
            logger.error(traceback.format_exc())
            return pd.DataFrame()

    def _match_entities_with_products(self, cand_entity_list: List[str], rank_limit: int) -> pd.DataFrame:
        """Match candidate entities with product database"""
        try:
            # print(cand_entity_list)
            # LLM ê¸°ë°˜ ì—”í‹°í‹° ì¶”ì¶œì„ ìœ„í•œ Fuzzy ìœ ì‚¬ë„ ê³„ì‚°
            similarities_fuzzy = parallel_fuzzy_similarity(
                cand_entity_list,
                self.item_pdf_all['item_nm_alias'].unique(),
                threshold=getattr(PROCESSING_CONFIG, 'entity_llm_fuzzy_threshold', 0.6),
                text_col_nm='item_name_in_msg',
                item_col_nm='item_nm_alias',
                n_jobs=6,
                batch_size=30
            )
            
            if similarities_fuzzy.empty:
                return pd.DataFrame()
            
            similarities_fuzzy = similarities_fuzzy[
                ~similarities_fuzzy['item_nm_alias'].isin(self.stop_item_names)
            ]
            
            sim_s1 = parallel_seq_similarity(
                sent_item_pdf=similarities_fuzzy,
                text_col_nm='item_name_in_msg',
                item_col_nm='item_nm_alias',
                n_jobs=6,
                batch_size=30,
                normalization_value='s1'
            ).rename(columns={'sim': 'sim_s1'})
            
            sim_s2 = parallel_seq_similarity(
                sent_item_pdf=similarities_fuzzy,
                text_col_nm='item_name_in_msg',
                item_col_nm='item_nm_alias',
                n_jobs=6,
                batch_size=30,
                normalization_value='s2'
            ).rename(columns={'sim': 'sim_s2'})
            
            cand_entities_sim = sim_s1.merge(sim_s2, on=['item_name_in_msg', 'item_nm_alias'])
            
            if cand_entities_sim.empty:
                return pd.DataFrame()
            
            cand_entities_sim = cand_entities_sim.query("(sim_s1>=@PROCESSING_CONFIG.combined_similarity_threshold and sim_s2>=@PROCESSING_CONFIG.combined_similarity_threshold)")
            
            cand_entities_sim = cand_entities_sim.groupby(['item_name_in_msg', 'item_nm_alias'])[['sim_s1', 'sim_s2']].apply(
                lambda x: x['sim_s1'].sum() + x['sim_s2'].sum()
            ).reset_index(name='sim')
            
            cand_entities_sim = cand_entities_sim.query("sim >= @PROCESSING_CONFIG.high_similarity_threshold").copy()
            
            if cand_entities_sim.empty:
                return pd.DataFrame()
            
            cand_entities_sim["rank"] = cand_entities_sim.groupby('item_name_in_msg')['sim'].rank(
                method='dense', ascending=False
            )
            cand_entities_sim = cand_entities_sim.query(f"rank <= {rank_limit}").sort_values(
                ['item_name_in_msg', 'rank'], ascending=[True, True]
            )
            
            if 'item_dmn_nm' in self.item_pdf_all.columns:
                cand_entities_sim = cand_entities_sim.merge(
                    self.item_pdf_all[['item_nm_alias', 'item_dmn_nm']].drop_duplicates(),
                    on='item_nm_alias',
                    how='left'
                )


            # print(cand_entities_sim['item_nm_alias'].unique())
            
            return cand_entities_sim
            
        except Exception as e:
            logger.error(f"Entity-product matching failed: {e}")
            return pd.DataFrame()

    def map_products_to_entities(self, similarities_fuzzy: pd.DataFrame, json_objects: Dict = None) -> List[Dict]:
        """ìœ ì‚¬ë„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒí’ˆì„ ì—”í‹°í‹°ì— ë§¤í•‘"""
        try:
            logger.info("ðŸ” [map_products_to_entities] Started")
            logger.info(f"   - Input similarities_fuzzy shape: {similarities_fuzzy.shape}")
            
            # Filter high similarity items
            high_sim_threshold = getattr(PROCESSING_CONFIG, 'high_similarity_threshold', 1.0)
            
            high_sim_items = similarities_fuzzy.query('sim >= @high_sim_threshold')['item_nm_alias'].unique()
            
            before_filter = len(similarities_fuzzy)
            filtered_similarities = similarities_fuzzy[
                (similarities_fuzzy['item_nm_alias'].isin(high_sim_items)) &
                (~similarities_fuzzy['item_nm_alias'].str.contains('test', case=False)) &
                (~similarities_fuzzy['item_name_in_msg'].isin(self.stop_item_names))
            ]
            after_filter = len(filtered_similarities)
            logger.info(f"   - Filtering: {before_filter} -> {after_filter}")
            
            if filtered_similarities.empty:
                logger.warning("   âš ï¸ filtered_similarities is empty -> returning empty list")
                return []
            
            # Merge with product info
            merged_items = self.item_pdf_all.merge(filtered_similarities, on=['item_nm_alias'])
            
            if merged_items.empty:
                logger.warning("   âš ï¸ merged_items is empty -> returning empty list")
                return []
            
            product_tag = convert_df_to_json_list(merged_items)
            logger.info(f"   âœ… product_tag count: {len(product_tag)}")
            
            # Add expected_action to each product
            if json_objects:
                action_mapping = self._create_action_mapping(json_objects)
                
                for product in product_tag:
                    # New schema: item_name_in_msg is a list
                    item_names_in_msg = product.get('item_name_in_msg', [])
                    found_actions = []
                    for item_name in item_names_in_msg:
                        if item_name in action_mapping:
                            found_actions.append(action_mapping[item_name])
                    product['expected_action'] = list(dict.fromkeys(found_actions)) if found_actions else ['ê¸°íƒ€']
            
            return product_tag
            
        except Exception as e:
            logger.error(f"âŒ [map_products_with_similarity] Failed: {e}")
            logger.error(f"   Details: {traceback.format_exc()}")
            return []

    def _create_action_mapping(self, json_objects: Dict) -> Dict[str, str]:
        """Create product name to action mapping from LLM response"""
        try:
            action_mapping = {}
            product_data = json_objects.get('product', [])
            
            if isinstance(product_data, list):
                for item in product_data:
                    if isinstance(item, dict) and 'name' in item and 'action' in item:
                        action_mapping[item['name']] = item['action']
            elif isinstance(product_data, dict):
                if 'items' in product_data:
                    items = product_data.get('items', [])
                    for item in items:
                        if isinstance(item, dict) and 'name' in item and 'action' in item:
                            action_mapping[item['name']] = item['action']
                elif 'type' in product_data and product_data.get('type') == 'array':
                    logger.debug("Schema definition detected, skipping action mapping")
                else:
                    if 'name' in product_data and 'action' in product_data:
                        action_mapping[product_data['name']] = product_data['action']
            
            return action_mapping
            
        except Exception as e:
            logger.error(f"Action mapping creation failed: {e}")
            return {}
