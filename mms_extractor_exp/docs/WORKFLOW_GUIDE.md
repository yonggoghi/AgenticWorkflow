# MMS Extractor - Workflow ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨

1. [Workflow ê°œìš”](#workflow-ê°œìš”)
2. [ë‹¨ê³„ë³„ ìƒì„¸ ê°€ì´ë“œ](#ë‹¨ê³„ë³„-ìƒì„¸-ê°€ì´ë“œ)
3. [ìƒíƒœ ê´€ë¦¬](#ìƒíƒœ-ê´€ë¦¬)
4. [ì—ëŸ¬ ì²˜ë¦¬](#ì—ëŸ¬-ì²˜ë¦¬)
5. [ì»¤ìŠ¤í„°ë§ˆì´ì§•](#ì»¤ìŠ¤í„°ë§ˆì´ì§•)

---

## Workflow ê°œìš”

MMS ExtractorëŠ” 11ë‹¨ê³„ì˜ Workflowë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ê° ë‹¨ê³„ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë˜ê³  `WorkflowState`ë¥¼ í†µí•´ ë°ì´í„°ë¥¼ ì£¼ê³ ë°›ìŠµë‹ˆë‹¤. ê° ë‹¨ê³„ëŠ” `should_execute()` ë©”ì„œë“œë¥¼ í†µí•´ ì¡°ê±´ë¶€ë¡œ ìŠ¤í‚µë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### Workflow ìˆœì„œë„

```mermaid
graph TD
    START([ë©”ì‹œì§€ ì…ë ¥]) --> STEP1[1. InputValidation<br/>ì…ë ¥ ê²€ì¦]
    STEP1 --> STEP2[2. EntityExtraction<br/>ì—”í‹°í‹° ì¶”ì¶œ]
    STEP2 --> STEP3[3. ProgramClassification<br/>í”„ë¡œê·¸ë¨ ë¶„ë¥˜]
    STEP3 --> STEP4[4. ContextPreparation<br/>ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„]
    STEP4 --> STEP5[5. LLMExtraction<br/>LLM ì¶”ì¶œ]
    STEP5 --> STEP6[6. ResponseParsing<br/>ì‘ë‹µ íŒŒì‹±]
    STEP6 --> STEP7[7. EntityMatching<br/>ì—”í‹°í‹° ë§¤ì¹­]
    STEP7 --> STEP8[8. ResultConstruction<br/>ê²°ê³¼ êµ¬ì„±]
    STEP8 --> STEP9[9. Validation<br/>ê²°ê³¼ ê²€ì¦]
    STEP9 --> DECISION{DAG ì¶”ì¶œ<br/>í™œì„±í™”?}
    DECISION -->|Yes| STEP10[10. DAGExtraction<br/>DAG ì¶”ì¶œ]
    DECISION -->|No| END([ì¶”ì¶œ ì™„ë£Œ])
    STEP10 --> END

    style START fill:#f9f,stroke:#333
    style END fill:#9f9,stroke:#333
    style DECISION fill:#ff9,stroke:#333
```

### ì „ì²´ ì²˜ë¦¬ ì‹œê°„

| ë‹¨ê³„ | í‰ê·  ì†Œìš” ì‹œê°„ | ë¹„ê³  |
|------|---------------|------|
| 1-3ë‹¨ê³„ | 1-2ì´ˆ | ë¡œì»¬ ì²˜ë¦¬ (bigram ìµœì í™” ì ìš©) |
| 4ë‹¨ê³„ | 1-2ì´ˆ | RAG ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± |
| 5ë‹¨ê³„ | 5-15ì´ˆ | **LLM API í˜¸ì¶œ (ë³‘ëª©)** |
| 6-8ë‹¨ê³„ | 1-5ì´ˆ | ì‘ë‹µ íŒŒì‹± + ì—”í‹°í‹° ì¶”ì¶œ + ë§¤ì¹­ |
| 9-10ë‹¨ê³„ | 1-2ì´ˆ | ê²°ê³¼ êµ¬ì„± + ê²€ì¦ |
| 11ë‹¨ê³„ | 5-10ì´ˆ | LLM API í˜¸ì¶œ (ì„ íƒì ) |
| **ì „ì²´** | **10-25ì´ˆ** | DAG í¬í•¨ ì‹œ |

---

## ë‹¨ê³„ë³„ ìƒì„¸ ê°€ì´ë“œ

### 1. InputValidationStep

**ëª©ì **: ì…ë ¥ ë©”ì‹œì§€ ê²€ì¦ ë° ì „ì²˜ë¦¬

**ì…ë ¥**:
- `state.mms_msg`: ì›ë³¸ MMS ë©”ì‹œì§€ (str)
- `state.extractor`: MMSExtractor ì¸ìŠ¤í„´ìŠ¤

**ì²˜ë¦¬ ë¡œì§**:
```python
1. ë©”ì‹œì§€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
2. í…ìŠ¤íŠ¸ ì •ê·œí™” (ê³µë°± ì œê±°, ì†Œë¬¸ì ë³€í™˜ ë“±)
3. ì¶”ì¶œê¸° ì„¤ì • ë¡œê¹…
```

**ì¶œë ¥**:
- `state.msg`: ì „ì²˜ë¦¬ëœ ë©”ì‹œì§€ (str)

**ì—ëŸ¬ ì²˜ë¦¬**:
- ë¹ˆ ë©”ì‹œì§€ â†’ `state.is_fallback = True`
- ì—ëŸ¬ ë©”ì‹œì§€ â†’ `state.error_message`

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
# ì •ìƒ ì¼€ì´ìŠ¤
state.mms_msg = "[ê´‘ê³ ] ì•„ì´í° êµ¬ë§¤ ì‹œ ìµœëŒ€ 20ë§Œì› í• ì¸"
# â†’ state.msg = "[ê´‘ê³ ] ì•„ì´í° êµ¬ë§¤ ì‹œ ìµœëŒ€ 20ë§Œì› í• ì¸"

# ì—ëŸ¬ ì¼€ì´ìŠ¤
state.mms_msg = ""
# â†’ state.is_fallback = True
# â†’ state.error_message = "ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
```

---

### 2. EntityExtractionStep

**ëª©ì **: Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ë˜ëŠ” LLMì„ ì‚¬ìš©í•œ ì—”í‹°í‹° ì¶”ì¶œ

**ì…ë ¥**:
- `state.msg`: ì „ì²˜ë¦¬ëœ ë©”ì‹œì§€
- `state.extractor.entity_recognizer`: EntityRecognizer ì„œë¹„ìŠ¤

**ì²˜ë¦¬ ë¡œì§**:
```python
if entity_extraction_mode == 'logic':
    # Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ì‚¬ìš©
    entities = recognizer.extract_entities_hybrid(msg)
elif entity_extraction_mode == 'llm':
    # LLM ê¸°ë°˜ ì¶”ì¶œ
    entities = recognizer.extract_entities_with_llm(msg)
```

**ì¶œë ¥**:
- `state.entities_from_kiwi`: ì¶”ì¶œëœ ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸
  ```python
  [
      {
          "item_nm": "ì•„ì´í°17",
          "item_id": "PROD123",
          "item_name_in_msg": "ì•„ì´í°",
          "similarity": 0.95
      },
      ...
  ]
  ```

**í˜‘ë ¥ ê°ì²´**:
- `EntityRecognizer`: ì—”í‹°í‹° ì¶”ì¶œ ë° ë§¤ì¹­
- `Kiwi`: í˜•íƒœì†Œ ë¶„ì„ (logic ëª¨ë“œ)
- `LLM`: ì—”í‹°í‹° ì¶”ì¶œ (llm ëª¨ë“œ)

**ì£¼ì˜ì‚¬í•­**:
- Kiwi ëª¨ë“œ: ì‚¬ì „ì— ë“±ë¡ëœ ìƒí’ˆë§Œ ì¶”ì¶œ ê°€ëŠ¥
- LLM ëª¨ë“œ: ë” ìœ ì—°í•˜ì§€ë§Œ API ë¹„ìš© ë°œìƒ

---

### 3. ProgramClassificationStep

**ëª©ì **: ë©”ì‹œì§€ë¥¼ í”„ë¡œê·¸ë¨ ì¹´í…Œê³ ë¦¬ë¡œ ë¶„ë¥˜

**ì…ë ¥**:
- `state.msg`: ì „ì²˜ë¦¬ëœ ë©”ì‹œì§€
- `state.extractor.program_classifier`: ProgramClassifier ì„œë¹„ìŠ¤

**ì²˜ë¦¬ ë¡œì§**:
```python
1. ë©”ì‹œì§€ ì„ë² ë”© ìƒì„±
2. í”„ë¡œê·¸ë¨ í´ë£¨ ì„ë² ë”©ê³¼ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
3. ìƒìœ„ Nê°œ í›„ë³´ í”„ë¡œê·¸ë¨ ì„ íƒ
```

**ì¶œë ¥**:
- `state.pgm_info`: í”„ë¡œê·¸ë¨ ë¶„ë¥˜ ì •ë³´
  ```python
  {
      "pgm_cand_info": "í”„ë¡œê·¸ë¨1 : í´ë£¨1\ní”„ë¡œê·¸ë¨2 : í´ë£¨2",
      "similarities": [0.85, 0.72, ...],
      "pgm_pdf_tmp": DataFrame
  }
  ```

**í˜‘ë ¥ ê°ì²´**:
- `ProgramClassifier`: í”„ë¡œê·¸ë¨ ë¶„ë¥˜
- `SentenceTransformer`: ì„ë² ë”© ëª¨ë¸

**ì„±ëŠ¥ ìµœì í™” (2026-02-09)**:
- Bigram pre-filteringìœ¼ë¡œ Fuzzy Matching ëŒ€ìƒ 94.7% ê°ì†Œ (904K â†’ 48K)
- 100K ë¯¸ë§Œ ë¹„êµ ì‹œ ë‹¨ì¼ í”„ë¡œì„¸ìŠ¤ë¡œ joblib IPC ì˜¤ë²„í—¤ë“œ ì œê±°
- Step 2 ì „ì²´: 16.2ì´ˆ â†’ 1.5ì´ˆ (11x ê°œì„ )

**ì„±ëŠ¥**:
- í‰ê·  ì²˜ë¦¬ ì‹œê°„: 0.5-1ì´ˆ
- ì„ë² ë”© ìºì‹±ìœ¼ë¡œ ìµœì í™”

---

### 4. ContextPreparationStep

**ëª©ì **: RAG (Retrieval-Augmented Generation) ì»¨í…ìŠ¤íŠ¸ ì¤€ë¹„

**ì…ë ¥**:
- `state.msg`: ì „ì²˜ë¦¬ëœ ë©”ì‹œì§€
- `state.entities_from_kiwi`: ì¶”ì¶œëœ ì—”í‹°í‹°
- `state.pgm_info`: í”„ë¡œê·¸ë¨ ì •ë³´

**ì²˜ë¦¬ ë¡œì§**:
```python
# RAG ì»¨í…ìŠ¤íŠ¸ëŠ” ContextPreparationStepì—ì„œ ìë™ìœ¼ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤
# - ê´‘ê³  ë¶„ë¥˜ ì •ë³´ (_build_ad_classification_rag_context)
# - ì œí’ˆ ì •ë³´ (_build_product_rag_context)
# - NLP ëª¨ë“œ ì œí’ˆ ìš”ì†Œ (_build_nlp_product_element)
```

**ì¶œë ¥**:
- `state.rag_context`: RAG ì»¨í…ìŠ¤íŠ¸ (str)
  ```
  [ìƒí’ˆ ì •ë³´]
  - ì•„ì´í°17 (ID: PROD123): ìµœì‹  ìŠ¤ë§ˆíŠ¸í°
  - ê°¤ëŸ­ì‹œS25 (ID: PROD456): ì‚¼ì„± í”Œë˜ê·¸ì‹­
  
  [í”„ë¡œê·¸ë¨ ì •ë³´]
  - ë‹¨ë§ í• ì¸ í”„ë¡œê·¸ë¨: ìµœëŒ€ 20ë§Œì› í• ì¸
  ```

**ì»¨í…ìŠ¤íŠ¸ ëª¨ë“œ**:
- `dag`: DAG í˜•ì‹ ì»¨í…ìŠ¤íŠ¸ (ê¸°ë³¸)
- `pairing`: í˜ì–´ë§ í˜•ì‹ ì»¨í…ìŠ¤íŠ¸
- `none`: ì»¨í…ìŠ¤íŠ¸ ì—†ìŒ
- `ont`: ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ì»¨í…ìŠ¤íŠ¸ (ì—”í‹°í‹° íƒ€ì…, ê´€ê³„ í¬í•¨)
- `typed`: 6-type ì—”í‹°í‹° ì¶”ì¶œ (Product, Store, Program, Channel, Purpose, Other)

---

### 5. LLMExtractionStep

**ëª©ì **: LLMì„ ì‚¬ìš©í•œ ì •ë³´ ì¶”ì¶œ

**ì…ë ¥**:
- `state.msg`: ì „ì²˜ë¦¬ëœ ë©”ì‹œì§€
- `state.rag_context`: RAG ì»¨í…ìŠ¤íŠ¸
- `state.pgm_info`: í”„ë¡œê·¸ë¨ ì •ë³´

**ì²˜ë¦¬ ë¡œì§**:
```python
1. í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ë©”ì‹œì§€ + ì»¨í…ìŠ¤íŠ¸ + ì§€ì‹œì‚¬í•­)
2. LLM API í˜¸ì¶œ
3. ì‘ë‹µ ìˆ˜ì‹ 
```

**ì¶œë ¥**:
- `state.llm_response`: LLM ì‘ë‹µ (str, JSON í˜•ì‹)

**í”„ë¡¬í”„íŠ¸ êµ¬ì¡°**:
```
ì‹œìŠ¤í…œ ë©”ì‹œì§€: ì—­í•  ì •ì˜
â†“
RAG ì»¨í…ìŠ¤íŠ¸: ì°¸ì¡° ì •ë³´
â†“
í”„ë¡œê·¸ë¨ ì •ë³´: ë¶„ë¥˜ ê²°ê³¼
â†“
ë©”ì‹œì§€: ë¶„ì„ ëŒ€ìƒ
â†“
ì§€ì‹œì‚¬í•­: ì¶”ì¶œ ìš”êµ¬ì‚¬í•­
```

**ì„±ëŠ¥**:
- **í‰ê·  ì²˜ë¦¬ ì‹œê°„: 5-15ì´ˆ** (ê°€ì¥ í° ë³‘ëª©)
- ëª¨ë¸ë³„ ì°¨ì´:
  - AX: 5-8ì´ˆ
  - GPT-4: 8-12ì´ˆ
  - Claude: 10-15ì´ˆ

---

### 6. ResponseParsingStep

**ëª©ì **: LLM ì‘ë‹µì„ JSON ê°ì²´ë¡œ íŒŒì‹±

**ì…ë ¥**:
- `state.llm_response`: LLM ì‘ë‹µ (str)

**ì²˜ë¦¬ ë¡œì§**:
```python
1. JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` ì œê±°)
2. JSON íŒŒì‹±
3. ë°°ì—´ ì—¬ë¶€ í™•ì¸ ë° ì •ê·œí™”
```

**ì¶œë ¥**:
- `state.json_objects`: íŒŒì‹±ëœ JSON ê°ì²´ ë¦¬ìŠ¤íŠ¸
  ```python
  [
      {
          "title": "ì œëª©",
          "product": [...],
          "channel": [...],
          ...
      }
  ]
  ```

**ì—ëŸ¬ ì²˜ë¦¬**:
- JSON íŒŒì‹± ì‹¤íŒ¨ â†’ ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
- ì˜ëª»ëœ í˜•ì‹ â†’ ë¡œê·¸ ê¸°ë¡ í›„ ê³„ì† ì§„í–‰

---

### 7. EntityContextExtractionStep

**ëª©ì **: ë©”ì‹œì§€ì—ì„œ ì—”í‹°í‹°ì™€ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ (Stage 1)

**ì¡°ê±´ë¶€ ìŠ¤í‚µ**: `should_execute()` â†’ `has_error` ë˜ëŠ” `entity_matching_mode='logic'`ì´ë©´ ìŠ¤í‚µ

**âš ï¸ ì¤‘ìš”**: `--entity-matching-mode logic` ì‚¬ìš© ì‹œ ì´ ë‹¨ê³„ëŠ” **ì™„ì „íˆ ê±´ë„ˆëœë‹ˆë‹¤** (`--extraction-engine` ì„¤ì • ë¬´ì‹œ)

**ì…ë ¥**:
- `state.msg`: ì›ë³¸ ë©”ì‹œì§€
- `state.entities_from_kiwi`: Kiwi ì¶”ì¶œ ì—”í‹°í‹°
- `state.json_objects`: íŒŒì‹±ëœ JSON ê°ì²´ (product items)
- `extraction_engine`: ì¶”ì¶œ ì—”ì§„ ('default' ë˜ëŠ” 'langextract')
- `use_external_candidates`: ì™¸ë¶€ í›„ë³´ ì—”í‹°í‹° ì‚¬ìš© ì—¬ë¶€

**ì²˜ë¦¬ ë¡œì§ (ë‘ ê°€ì§€ ë°©ì‹)**:

**A. langextract ë°©ì‹** (extraction_engine='langextract'):
```python
1. extract_mms_entities(msg) í˜¸ì¶œ
2. 6-type ì—”í‹°í‹° ì¶”ì¶œ (Product, Store, Program, Channel, Purpose, Other)
3. Channel/Purpose ì œì™¸, 2ê¸€ì ì´ìƒë§Œ í¬í•¨
4. state.extracted_entities ì„¤ì •:
   {
       'entities': [...],
       'context_text': "product1(Product), store1(Store), ..."
       'entity_types': {},
       'relationships': []
   }
```

**B. default ë°©ì‹** (extraction_engine='default'):
```python
1. ì™¸ë¶€ í›„ë³´ êµ¬ì„± (use_external_candidates=Trueì¼ ë•Œ):
   - external_cand = entities_from_kiwi + primary_llm_extracted_entities
2. entity_recognizer._extract_entities_stage1() í˜¸ì¶œ
   - context_modeì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (dag, ont, typed, pairing, none)
3. state.extracted_entities ì„¤ì •:
   {
       'entities': [...],
       'context_text': "...",
       'entity_types': {...},  # ont/typed ëª¨ë“œë§Œ
       'relationships': [...]  # ont ëª¨ë“œë§Œ
   }
```

**ì¶œë ¥**:
- `state.extracted_entities`: ì¶”ì¶œëœ ì—”í‹°í‹° ë° ì»¨í…ìŠ¤íŠ¸
  ```python
  {
      'entities': ['ì•„ì´í°17', 'ê°¤ëŸ­ì‹œS25'],
      'context_text': "ì•„ì´í°17(Product), ê°¤ëŸ­ì‹œS25(Product)",
      'entity_types': {...},  # ont/typed ëª¨ë“œë§Œ
      'relationships': [...]  # ont ëª¨ë“œë§Œ
  }
  ```

**í˜‘ë ¥ ê°ì²´**:
- `lx_extractor.extract_mms_entities`: LangExtract ê¸°ë°˜ ì¶”ì¶œ (langextract ì—”ì§„)
- `entity_recognizer._extract_entities_stage1`: LLM ê¸°ë°˜ ì¶”ì¶œ (default ì—”ì§„)

**CLI ì˜µì…˜**:
```bash
# Default engine + LLM mode (Step 7 runs)
python apps/cli.py --message "ê´‘ê³  ë©”ì‹œì§€" --entity-matching-mode llm

# LangExtract engine + LLM mode (Step 7 runs with langextract)
python apps/cli.py --extraction-engine langextract --entity-matching-mode llm --message "ê´‘ê³  ë©”ì‹œì§€"

# Logic mode (Step 7 SKIPPED - extraction-engine ignored!)
python apps/cli.py --entity-matching-mode logic --message "ê´‘ê³  ë©”ì‹œì§€"

# Disable external candidates
python apps/cli.py --no-external-candidates --message "ê´‘ê³  ë©”ì‹œì§€"
```

**íŒŒë¼ë¯¸í„° ìš°ì„ ìˆœìœ„**:
- `--entity-matching-mode=logic` â†’ Step 7 ìŠ¤í‚µ, `--extraction-engine` ë¬´ì‹œë¨
- `--entity-matching-mode=llm` â†’ Step 7 ì‹¤í–‰, `--extraction-engine`ì— ë”°ë¼ langextract/default ì„ íƒ

---

### 8. VocabularyFilteringStep

**ëª©ì **: Stage 1ì—ì„œ ì¶”ì¶œí•œ ì—”í‹°í‹°ë¥¼ ìƒí’ˆ DBì™€ ë§¤ì¹­í•˜ì—¬ item_id ë¶€ì—¬ (Stage 2)

**ì¡°ê±´ë¶€ ìŠ¤í‚µ**: `should_execute()` â†’ `has_error`, `is_fallback`, ë˜ëŠ” ì¶”ì¶œëœ ì—”í‹°í‹° ì—†ìœ¼ë©´ ìŠ¤í‚µ

**ì…ë ¥**:
- `state.extracted_entities`: Step 7ì—ì„œ ì¶”ì¶œí•œ ì—”í‹°í‹° ë° ì»¨í…ìŠ¤íŠ¸
- `state.msg`: ì›ë³¸ ë©”ì‹œì§€
- `state.json_objects`: íŒŒì‹±ëœ JSON ê°ì²´
- `entity_extraction_mode`: ë§¤ì¹­ ëª¨ë“œ ('logic' ë˜ëŠ” 'llm')

**ì²˜ë¦¬ ë¡œì§ (ë‘ ê°€ì§€ ëª¨ë“œ)**:

**A. logic ëª¨ë“œ**:
```python
1. Kiwi ì—”í‹°í‹° + product items ê²°í•©
2. entity_recognizer.extract_entities_with_fuzzy_matching() í˜¸ì¶œ
3. fuzzy + sequence ìœ ì‚¬ë„ ê³„ì‚°
4. ìƒìœ„ ë§¤ì¹­ ê²°ê³¼ ë°˜í™˜
```

**B. llm ëª¨ë“œ**:
```python
1. extracted_entitiesì—ì„œ entities, context_text ì¶”ì¶œ
2. entity_recognizer._filter_with_vocabulary() í˜¸ì¶œ
   - ìƒí’ˆ DBì™€ ìœ ì‚¬ë„ ë§¤ì¹­
   - ì–´íœ˜ í•„í„°ë§ í”„ë¡¬í”„íŠ¸ ìƒì„±
   - LLMìœ¼ë¡œ ìµœì¢… í•„í„°ë§
3. alias type í•„í„°ë§ (non-expansion íƒ€ì… ì œê±°)
4. entity_recognizer.map_products_to_entities() í˜¸ì¶œ
5. ë§¤ì¹­ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ fallback (item_id='#')
```

**ì¶œë ¥**:
- `state.matched_products`: ë§¤ì¹­ëœ ìƒí’ˆ ë¦¬ìŠ¤íŠ¸
  ```python
  [
      {
          "item_nm": "ì•„ì´í°17",
          "item_id": ["PROD_IP17_001"],
          "item_name_in_msg": ["ì•„ì´í° 17"],
          "expected_action": ["ê¸°ë³€"]
      }
  ]
  ```

**í˜‘ë ¥ ê°ì²´**:
- `entity_recognizer._filter_with_vocabulary`: LLM ê¸°ë°˜ í•„í„°ë§ (llm ëª¨ë“œ)
- `entity_recognizer.extract_entities_with_fuzzy_matching`: ìœ ì‚¬ë„ ê¸°ë°˜ ë§¤ì¹­ (logic ëª¨ë“œ)
- `entity_recognizer.map_products_to_entities`: ìƒí’ˆ-ì—”í‹°í‹° ë§¤í•‘

---

### 9. ResultConstructionStep

**ëª©ì **: ë§¤ì¹­ëœ ìƒí’ˆ ê¸°ë°˜ìœ¼ë¡œ ìµœì¢… ê²°ê³¼ ì¡°ë¦½

**ì…ë ¥**:
- `state.matched_products`: ë§¤ì¹­ëœ ìƒí’ˆ (Step 7 ì¶œë ¥)
- `state.json_objects`: íŒŒì‹±ëœ JSON ê°ì²´
- `state.msg`: ì›ë³¸ ë©”ì‹œì§€
- `state.pgm_info`: í”„ë¡œê·¸ë¨ ì •ë³´

**ì²˜ë¦¬ ë¡œì§**:
```python
1. ResultBuilder.assemble_result() í˜¸ì¶œ
2. ì±„ë„ ì •ë³´ ì¶”ì¶œ ë° ë³´ê°•
3. í”„ë¡œê·¸ë¨ ë§¤í•‘
4. Offer ê°ì²´ ìƒì„±
5. entity_dag, message_id ì²¨ë¶€
```

**ì¶œë ¥**:
- `state.final_result`: ìµœì¢… ì¶”ì¶œ ê²°ê³¼
  ```python
  {
      "ext_result": {
          "title": "ì œëª©",
          "product": [...],
          "channel": [...],
          "pgm": [...],
          "offer": {...}
      },
      "raw_result": {...},
      "metadata": {...}
  }
  ```

**í˜‘ë ¥ ê°ì²´**:
- `ResultBuilder`: ê²°ê³¼ ì¡°ë¦½ (`assemble_result()`)
- `StoreMatcher`: ë§¤ì¥ ë§¤ì¹­
- `SchemaTransformer`: ìŠ¤í‚¤ë§ˆ ë³€í™˜

---

### 10. ValidationStep

**ëª©ì **: ì¶”ì¶œ ê²°ê³¼ ê²€ì¦

**ì…ë ¥**:
- `state.final_result`: ìµœì¢… ê²°ê³¼

**ì²˜ë¦¬ ë¡œì§**:
```python
1. í•„ìˆ˜ í•„ë“œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
2. ë°ì´í„° íƒ€ì… ê²€ì¦
3. ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ ê²€ì¦
```

**ê²€ì¦ í•­ëª©**:
- âœ… `ext_result` í•„ë“œ ì¡´ì¬
- âœ… `product`, `channel` ë°°ì—´ íƒ€ì…
- âœ… ê° ìƒí’ˆì— `item_nm`, `item_id` ì¡´ì¬

**ì¶œë ¥**:
- ê²€ì¦ í†µê³¼ â†’ ìƒíƒœ ìœ ì§€
- ê²€ì¦ ì‹¤íŒ¨ â†’ ê²½ê³  ë¡œê·¸ (ê³„ì† ì§„í–‰)

---

### 11. DAGExtractionStep (ì„ íƒì )

**ëª©ì **: ì—”í‹°í‹° ê°„ ê´€ê³„ë¥¼ DAG (Directed Acyclic Graph)ë¡œ ì¶”ì¶œ

**ì…ë ¥**:
- `state.msg`: ì›ë³¸ ë©”ì‹œì§€
- `state.extractor.extract_entity_dag`: DAG ì¶”ì¶œ í™œì„±í™” ì—¬ë¶€

**ì²˜ë¦¬ ë¡œì§**:
```python
if extract_entity_dag:
    1. DAG ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    2. LLM API í˜¸ì¶œ
    3. DAG í…ìŠ¤íŠ¸ íŒŒì‹±
    4. NetworkX ê·¸ë˜í”„ ìƒì„±
    5. Graphviz ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
```

**ì¶œë ¥**:
- `state.entity_dag`: DAG ì—£ì§€ ë¦¬ìŠ¤íŠ¸
  ```python
  [
      "(ì•„ì´í°17:êµ¬ë§¤) -[íšë“]-> (ìºì‹œë°±:ì œê³µ)",
      "(T world:ì ‘ì†) -[ì°¸ì—¬]-> (ì´ë²¤íŠ¸:ì§„í–‰)"
  ]
  ```

**ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±**:
- ì €ì¥ ìœ„ì¹˜: `./dag_images/dag_{message_id}.png`
- í˜•ì‹: PNG ì´ë¯¸ì§€

**ì„±ëŠ¥**:
- í‰ê·  ì²˜ë¦¬ ì‹œê°„: 5-10ì´ˆ
- ì„ íƒì  ê¸°ëŠ¥ì´ë¯€ë¡œ ë¹„í™œì„±í™” ê°€ëŠ¥
- ëª¨ë“  context modeì—ì„œ ë™ì¼í•˜ê²Œ fresh LLM callë¡œ DAG ì¶”ì¶œ

---

## ìƒíƒœ ê´€ë¦¬

### WorkflowState êµ¬ì¡°

```python
@dataclass
class WorkflowState:
    # === ì…ë ¥ ë°ì´í„° ===
    mms_msg: str                    # ì›ë³¸ ë©”ì‹œì§€
    extractor: 'MMSExtractor'       # ì¶”ì¶œê¸° ì¸ìŠ¤í„´ìŠ¤
    message_id: str = '#'           # ë©”ì‹œì§€ ID
    
    # === ì¤‘ê°„ ê²°ê³¼ (ë‹¨ê³„ë³„ ì¶œë ¥) ===
    msg: str = ""                   # ì „ì²˜ë¦¬ëœ ë©”ì‹œì§€ (Step 1)
    entities_from_kiwi: List = field(default_factory=list)  # ì—”í‹°í‹° (Step 2)
    pgm_info: Dict = field(default_factory=dict)  # í”„ë¡œê·¸ë¨ ì •ë³´ (Step 3)
    rag_context: str = ""           # RAG ì»¨í…ìŠ¤íŠ¸ (Step 4)
    llm_response: str = ""          # LLM ì‘ë‹µ (Step 5)
    json_objects: List[Dict] = field(default_factory=list)  # íŒŒì‹± ê²°ê³¼ (Step 6)
    matched_products: List[Dict] = field(default_factory=list)  # ë§¤ì¹­ëœ ìƒí’ˆ (Step 7)
    final_result: Dict = field(default_factory=dict)  # ìµœì¢… ê²°ê³¼ (Step 8)
    entity_dag: List[str] = field(default_factory=list)  # DAG (Step 10)
    
    # === ë©”íƒ€ë°ì´í„° ===
    is_fallback: bool = False       # í´ë°± ì—¬ë¶€
    error_message: str = ""         # ì—ëŸ¬ ë©”ì‹œì§€
    processing_time: float = 0.0    # ì²˜ë¦¬ ì‹œê°„
    
    # === í—¬í¼ ë©”ì„œë“œ ===
    def set(self, key: str, value: Any):
        """ìƒíƒœ í•„ë“œ ì„¤ì •"""
        setattr(self, key, value)

    def get(self, key: str, default=None) -> Any:
        """ìƒíƒœ í•„ë“œ ì¡°íšŒ"""
        return getattr(self, key, default)

    def has_error(self) -> bool:
        """ì—ëŸ¬ ì—¬ë¶€ í™•ì¸"""
        return bool(self.error_message)
```

### ìƒíƒœ ì „ë‹¬ íë¦„

```
ì´ˆê¸° ìƒíƒœ ìƒì„±
    â†“
Step 1: msg ì„¤ì •
    â†“
Step 2: entities_from_kiwi ì„¤ì • (ìŠ¤í‚µ ê°€ëŠ¥: --skip-entity-extraction)
    â†“
Step 3: pgm_info ì„¤ì •
    â†“
Step 4: rag_context ì„¤ì •
    â†“
Step 5: llm_response ì„¤ì •
    â†“
Step 6: json_objects ì„¤ì •
    â†“
Step 7: matched_products ì„¤ì • (ìŠ¤í‚µ ê°€ëŠ¥: ì—ëŸ¬/í´ë°±/ìƒí’ˆì—†ìŒ)
    â†“
Step 8: final_result ì„¤ì •
    â†“
Step 9: ê²€ì¦ (ìƒíƒœ ë³€ê²½ ì—†ìŒ)
    â†“
Step 10: entity_dag ì„¤ì • (ì„ íƒì )
    â†“
ìµœì¢… ìƒíƒœ ë°˜í™˜
```

---

## ì—ëŸ¬ ì²˜ë¦¬

### ì—ëŸ¬ ì²˜ë¦¬ ì „ëµ

ê° ë‹¨ê³„ëŠ” ë…ë¦½ì ìœ¼ë¡œ ì—ëŸ¬ë¥¼ ì²˜ë¦¬í•˜ë©°, ì¹˜ëª…ì ì´ì§€ ì•Šì€ ì—ëŸ¬ëŠ” ë¡œê·¸ ê¸°ë¡ í›„ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.

#### 1. ì…ë ¥ ê²€ì¦ ì—ëŸ¬
```python
# InputValidationStep
if not msg or msg.strip() == "":
    state.is_fallback = True
    state.error_message = "ë©”ì‹œì§€ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
    return state  # í´ë°± ëª¨ë“œë¡œ ê³„ì† ì§„í–‰
```

#### 2. LLM API ì—ëŸ¬
```python
# LLMExtractionStep
try:
    response = llm.invoke(prompt)
except Exception as e:
    logger.error(f"LLM API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
    state.llm_response = "{}"  # ë¹ˆ JSON ë°˜í™˜
    state.is_fallback = True
    return state
```

#### 3. íŒŒì‹± ì—ëŸ¬
```python
# ResponseParsingStep
try:
    json_objects = json.loads(response)
except json.JSONDecodeError as e:
    logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
    state.json_objects = []  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    return state
```

### í´ë°± ëª¨ë“œ

`state.is_fallback = True`ì¸ ê²½ìš°:
- ìµœì†Œí•œì˜ ê²°ê³¼ ë°˜í™˜
- ë©”íƒ€ë°ì´í„°ì— ì—ëŸ¬ ì •ë³´ í¬í•¨
- ì‚¬ìš©ìì—ê²Œ ì¬ì‹œë„ ê¶Œì¥

---

## ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ìƒˆë¡œìš´ ë‹¨ê³„ ì¶”ê°€

**ì˜ˆì‹œ**: ê°ì • ë¶„ì„ ë‹¨ê³„ ì¶”ê°€

#### 1. Step í´ë˜ìŠ¤ êµ¬í˜„
```python
# core/mms_workflow_steps.py
class SentimentAnalysisStep(WorkflowStep):
    """ê°ì • ë¶„ì„ ë‹¨ê³„"""
    
    def __init__(self, sentiment_analyzer):
        self.analyzer = sentiment_analyzer
    
    def execute(self, state: WorkflowState) -> WorkflowState:
        logger.info("ğŸ­ ê°ì • ë¶„ì„ ì‹œì‘")
        
        # ê°ì • ë¶„ì„ ìˆ˜í–‰
        sentiment = self.analyzer.analyze(state.msg)
        
        # ìƒíƒœ ì—…ë°ì´íŠ¸
        state.set("sentiment", sentiment)
        
        logger.info(f"âœ… ê°ì • ë¶„ì„ ì™„ë£Œ: {sentiment}")
        return state
```

#### 2. ì„œë¹„ìŠ¤ ìƒì„± (ì„ íƒì )
```python
# services/sentiment_analyzer.py
class SentimentAnalyzer:
    """ê°ì • ë¶„ì„ ì„œë¹„ìŠ¤"""
    
    def analyze(self, text: str) -> Dict[str, float]:
        # ê°ì • ë¶„ì„ ë¡œì§
        return {
            "positive": 0.7,
            "negative": 0.2,
            "neutral": 0.1
        }
```

#### 3. MMSExtractorì— ë“±ë¡
```python
# core/mms_extractor.py __init__
from services.sentiment_analyzer import SentimentAnalyzer

# ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
self.sentiment_analyzer = SentimentAnalyzer()

# Workflowì— ë‹¨ê³„ ì¶”ê°€ (Step 3ê³¼ 4 ì‚¬ì´ì— ì‚½ì…)
self.workflow_engine.add_step(
    SentimentAnalysisStep(self.sentiment_analyzer),
    position=3  # Step 3 ë‹¤ìŒì— ì‚½ì…
)
```

### ë‹¨ê³„ ìˆœì„œ ë³€ê²½

```python
# ê¸°ë³¸ ìˆœì„œ
steps = [
    InputValidationStep(),
    EntityExtractionStep(),
    ProgramClassificationStep(),
    # ...
]

# ìˆœì„œ ë³€ê²½ (ì˜ˆ: í”„ë¡œê·¸ë¨ ë¶„ë¥˜ë¥¼ ì—”í‹°í‹° ì¶”ì¶œ ì „ì—)
steps = [
    InputValidationStep(),
    ProgramClassificationStep(),  # ìˆœì„œ ë³€ê²½
    EntityExtractionStep(),
    # ...
]
```

### ë‹¨ê³„ ë¹„í™œì„±í™”

```python
# ë°©ë²• 1: ë‹¨ê³„ë¥¼ ë“±ë¡í•˜ì§€ ì•ŠìŒ
if not extract_entity_dag:
    # DAGExtractionStep ì¶”ê°€í•˜ì§€ ì•ŠìŒ
    pass

# ë°©ë²• 2: should_execute() ì˜¤ë²„ë¼ì´ë“œë¡œ ì¡°ê±´ë¶€ ìŠ¤í‚µ
class EntityExtractionStep(WorkflowStep):
    def should_execute(self, state: WorkflowState) -> bool:
        if self.skip_entity_extraction:
            return False  # ì›Œí¬í”Œë¡œìš° íˆìŠ¤í† ë¦¬ì— "skipped"ë¡œ ê¸°ë¡
        return not state.has_error()
```

---

## ëª¨ë²” ì‚¬ë¡€

### 1. ë¡œê¹…
ê° ë‹¨ê³„ëŠ” ì‹œì‘ê³¼ ì™„ë£Œë¥¼ ëª…í™•íˆ ë¡œê¹…í•©ë‹ˆë‹¤:
```python
logger.info("ğŸš€ [ë‹¨ê³„ëª…] ì‹œì‘")
# ì²˜ë¦¬ ë¡œì§
logger.info("âœ… [ë‹¨ê³„ëª…] ì™„ë£Œ")
```

### 2. ì—ëŸ¬ ì²˜ë¦¬
ì¹˜ëª…ì ì´ì§€ ì•Šì€ ì—ëŸ¬ëŠ” ë¡œê·¸ í›„ ê³„ì† ì§„í–‰:
```python
try:
    result = process()
except Exception as e:
    logger.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
    result = default_value
```

### 3. ìƒíƒœ ì—…ë°ì´íŠ¸
ëª…ì‹œì ìœ¼ë¡œ ìƒíƒœë¥¼ ì—…ë°ì´íŠ¸:
```python
state.set("field_name", value)
# ë˜ëŠ”
state.field_name = value
```

### 4. íƒ€ì… íŒíŠ¸
ëª¨ë“  ë©”ì„œë“œì— íƒ€ì… íŒíŠ¸ ì¶”ê°€:
```python
def execute(self, state: WorkflowState) -> WorkflowState:
    ...
```

---

*ì‘ì„±ì¼: 2025-12-16*
*ìµœì¢… ì—…ë°ì´íŠ¸: 2026-02-11*
*ë²„ì „: 1.4*
*ì‘ì„±ì: ì‹ ìš©ìš± with Google Antigravity*
