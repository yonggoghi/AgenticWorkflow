# Extraction Engine Workflow Analysis

**Date**: 2026-02-11
**Purpose**: Comprehensive analysis of `--extraction-engine` argument flow through the entire MMS Extractor workflow

---

## Overview

The `--extraction-engine` argument controls which entity extraction approach is used in **Step 7 (EntityMatchingStep)**:
- **`default`**: Standard 10-step pipeline with LLM-based entity extraction
- **`langextract`**: Google langextract-based pre-extraction in Step 7 Stage 1

---

## 1. CLI Entry Point (apps/cli.py)

### Argument Definition (Line 102-103)
```python
parser.add_argument('--extraction-engine',
                   choices=['default', 'langextract'],
                   default='default',
                   help='ì¶”ì¶œ ì—”ì§„ ì„ íƒ (default: 10-step pipeline, langextract: Google langextract ê¸°ë°˜)')
```

### Auto-Configuration Logic (Lines 132-136)
```python
# When using langextract engine, force entity_extraction_context_mode to 'typed'
entity_extraction_context_mode = args.entity_extraction_context_mode
if args.extraction_engine == 'langextract':
    entity_extraction_context_mode = 'typed'
    logger.info("langextract ì—”ì§„ ì„ íƒ: entity_extraction_context_modeë¥¼ 'typed'ë¡œ ê°•ì œ ì„¤ì •")
```

**Key Point**: When `--extraction-engine langextract` is used:
- `entity_extraction_context_mode` is FORCED to `'typed'`
- This overrides any `--entity-extraction-context-mode` CLI argument

### MMSExtractor Initialization (Lines 141-152)
```python
extractor = MMSExtractor(
    offer_info_data_src=args.offer_data_source,
    product_info_extraction_mode=args.product_info_extraction_mode,
    entity_extraction_mode=args.entity_matching_mode,
    llm_model=args.llm_model,
    entity_llm_model=args.entity_llm_model,
    extract_entity_dag=args.extract_entity_dag,
    entity_extraction_context_mode=entity_extraction_context_mode,  # â† 'typed' if langextract
    skip_entity_extraction=args.skip_entity_extraction,
    use_external_candidates=not args.no_external_candidates,
    extraction_engine=args.extraction_engine,  # â† Passed to MMSExtractor
)
```

---

## 2. MMSExtractor Initialization (core/mms_extractor.py)

### Constructor Signature (Line 352)
```python
def __init__(self, ...,
             extraction_engine='default'):  # â† New parameter
```

### Storing Configuration (Lines 387-393)
```python
self._set_default_config(
    model_path, data_dir, product_info_extraction_mode,
    entity_extraction_mode, offer_info_data_src, llm_model, entity_llm_model,
    extract_entity_dag, entity_extraction_context_mode,
    skip_entity_extraction, use_external_candidates,
    extraction_engine  # â† Stored in self.extraction_engine
)
```

### Instance Variable (Line 503)
```python
self.extraction_engine = extraction_engine  # â† Stored for later use
```

---

## 3. Workflow Step Registration (core/mms_extractor.py)

### EntityMatchingStep Registration (Lines 456-466)
```python
self.workflow_engine.add_step(EntityMatchingStep(
    entity_recognizer=self.entity_recognizer,
    alias_pdf_raw=self.alias_pdf_raw,
    stop_item_names=self.stop_item_names,
    entity_extraction_mode=self.entity_extraction_mode,
    llm_factory=self.llm_factory,
    llm_model=self.entity_llm_model_name,
    entity_extraction_context_mode=self.entity_extraction_context_mode,  # â† 'typed' if langextract
    use_external_candidates=self.use_external_candidates,
    extraction_engine=self.extraction_engine,  # â† CRITICAL: Passed to step
))
```

**Key Point**: The `extraction_engine` parameter is passed to EntityMatchingStep during workflow initialization.

---

## 4. EntityMatchingStep Execution (core/mms_workflow_steps.py)

### Constructor (Lines 628-642)
```python
class EntityMatchingStep(WorkflowStep):
    def __init__(self, entity_recognizer, alias_pdf_raw: pd.DataFrame,
                 stop_item_names: List[str], entity_extraction_mode: str,
                 llm_factory=None, llm_model: str = 'ax',
                 entity_extraction_context_mode: str = 'dag',
                 use_external_candidates: bool = True,
                 extraction_engine: str = 'default'):  # â† Stored
        # ... other assignments ...
        self.extraction_engine = extraction_engine  # â† Instance variable
```

### Conditional Skip Logic (Lines 644-656)
```python
def should_execute(self, state: WorkflowState) -> bool:
    if state.has_error():
        return False

    # âœ… SPECIAL CASE: langextract extracts entities independently of the main prompt,
    # so it should run even when is_fallback (main JSON parse failed)
    if state.is_fallback and self.extraction_engine != 'langextract':
        return False  # â† Skip if fallback UNLESS using langextract

    json_objects = state.json_objects
    product_items = json_objects.get('product', [])
    # ... check for entities ...
    has_entities = len(product_items) > 0 or len(state.entities_from_kiwi) > 0

    # âœ… SPECIAL CASE: Always run if using langextract (even without entities)
    return has_entities or self.extraction_engine == 'langextract'
```

**Key Points**:
1. **Fallback resilience**: langextract runs even when `is_fallback=True`
2. **Entity-less execution**: langextract runs even when no entities are found in previous steps
3. **Rationale**: langextract is independent of main prompt, so it can extract entities from scratch

### Stage 1: LangExtract Pre-Extraction (Lines 679-705)
```python
def execute(self, state: WorkflowState) -> WorkflowState:
    # ... stage preparation ...

    # âœ… CONDITIONAL: Only runs if extraction_engine='langextract'
    pre_extracted = None
    if self.extraction_engine == 'langextract':
        try:
            from core.lx_extractor import extract_mms_entities
            logger.info("ğŸ”— langextract ì—”ì§„ìœ¼ë¡œ Stage 1 ì—”í‹°í‹° ì¶”ì¶œ ì‹œì‘...")

            # Call langextract
            doc = extract_mms_entities(msg, model_id=self.llm_model)

            # Extract entities (excluding Channel, Purpose)
            entities = []
            type_pairs = []
            for ext in (doc.extractions or []):
                name = ext.extraction_text
                if ext.extraction_class in ('Channel', 'Purpose'):
                    continue
                if name not in self.stop_item_names and len(name) >= 2:
                    entities.append(name)
                    type_pairs.append(f"{name}({ext.extraction_class})")

            # Create pre_extracted context
            pre_extracted = {
                'entities': entities,
                'context_text': ", ".join(type_pairs)
            }
            logger.info(f"âœ… langextract Stage 1 ì™„ë£Œ: {len(entities)}ê°œ ì—”í‹°í‹° ì¶”ì¶œ")
        except Exception as e:
            logger.error(f"âŒ langextract ì¶”ì¶œ ì‹¤íŒ¨, ê¸°ë³¸ ëª¨ë“œë¡œ í´ë°±: {e}")
            pre_extracted = None
```

**Prompts Used in Stage 1**:
- **NOT** `prompts/entity_extraction_prompt.py` (HYBRID_DAG, PAIRING, ONT, TYPED, SIMPLE)
- **INSTEAD**: `core/lx_extractor.py` uses:
  - `MMS_PROMPT_DESCRIPTION` (defined in lx_extractor.py)
  - `prompts/lx_examples.build_mms_examples()` (few-shot examples)
  - `config/lx_schemas.get_class_description_text()` (entity type definitions)

### Stage 2: Entity Matching (Lines 706-776)
```python
    # Stage 2: Entity matching based on mode
    if self.entity_extraction_mode == 'logic':
        # Logic-based fuzzy matching
        cand_entities = list(set(entities_from_kiwi + [item.get('name', '') ...]))
        similarities_fuzzy = self.entity_recognizer.extract_entities_with_fuzzy_matching(cand_entities)
    else:
        # âœ… LLM-based matching with pre_extracted context
        llm_result = self.entity_recognizer.extract_entities_with_llm(
            msg,
            llm_models=default_llm_models,
            rank_limit=100,
            external_cand_entities=external_cand,
            context_mode=self.entity_extraction_context_mode,  # â† 'typed' if langextract
            pre_extracted=pre_extracted,  # â† CRITICAL: Passed to entity_recognizer
        )

        if isinstance(llm_result, dict):
            similarities_fuzzy = llm_result.get('similarities_df', pd.DataFrame())
        else:
            similarities_fuzzy = llm_result
```

---

## 5. EntityRecognizer Processing (services/entity_recognizer.py)

### extract_entities_with_llm Method (Lines 594-596)
```python
def extract_entities_with_llm(self, msg_text: str, rank_limit: int = 50, llm_models: List = None,
                            external_cand_entities: List[str] = [], context_mode: str = 'dag',
                            pre_extracted: dict = None) -> pd.DataFrame:  # â† Receives pre_extracted
```

### Pre-Extracted Path (Lines 628-710)
```python
    # âœ… CRITICAL BRANCH: Pre-extracted entities skip Stage 1 entirely
    if pre_extracted:
        logger.info("=== Using pre-extracted entities (Stage 1 skipped) ===")
        cand_entity_list = list(pre_extracted['entities'])
        combined_context = pre_extracted.get('context_text', '')
        context_keyword = 'TYPED'  # â† langextract always uses typed context

        # ... normalization, n-gram expansion ...

        # Match with products
        cand_entities_sim = self._match_entities_with_products(cand_entity_list, rank_limit)

        # âœ… Stage 2 ONLY: Vocabulary filtering using LLM
        # Uses build_context_based_entity_extraction_prompt('TYPED')
        second_stage_prompt = build_context_based_entity_extraction_prompt(context_keyword)

        prompt = f"""
        {second_stage_prompt}

        ## message:
        {msg_text}

        ## TYPED Context (Entity Types):
        {combined_context}  # â† Uses langextract type annotations

        ## entities in message:
        {', '.join(entities_in_message)}

        ## candidate entities in vocabulary:
        {', '.join(cand_entities_voca)}
        """

        # Call LLM for Stage 2 filtering only
        response = llm_model.invoke(prompt).content

        return cand_entities_sim  # â† Filtered results
```

**Key Points**:
1. **Stage 1 SKIPPED**: No `HYBRID_DAG_EXTRACTION_PROMPT`, `ONTOLOGY_PROMPT`, etc.
2. **Stage 2 ONLY**: Uses `build_context_based_entity_extraction_prompt('TYPED')`
3. **Context**: Uses langextract's type annotations (e.g., "ì•„ì´í°17(Product), ì„ì§€ë¡œì (Store)")

### Default Path (Lines 712+)
```python
    # âœ… Standard path (when pre_extracted is None)

    # Select prompt based on context_mode
    if context_mode == 'dag':
        first_stage_prompt = HYBRID_DAG_EXTRACTION_PROMPT
        context_keyword = 'DAG'
    elif context_mode == 'pairing':
        first_stage_prompt = HYBRID_PAIRING_EXTRACTION_PROMPT
        context_keyword = 'PAIRING'
    elif context_mode == 'ont':
        first_stage_prompt = ONTOLOGY_PROMPT
        context_keyword = 'ONT'
    elif context_mode == 'typed':
        first_stage_prompt = TYPED_ENTITY_EXTRACTION_PROMPT
        context_keyword = 'TYPED'
    else:  # 'none'
        first_stage_prompt = SIMPLE_ENTITY_EXTRACTION_PROMPT
        context_keyword = None

    # Stage 1: Extract entities with context
    # Stage 2: Filter entities from vocabulary
    # ... full 2-stage LLM extraction ...
```

---

## Complete Workflow Trace

### Scenario 1: `--extraction-engine default`

```
User Command:
  python apps/cli.py --message "ê´‘ê³ " --extraction-engine default

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLI (apps/cli.py)                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ args.extraction_engine = 'default'                          â”‚
â”‚ entity_extraction_context_mode = args.entity_extraction_   â”‚
â”‚                                  context_mode (e.g., 'dag') â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MMSExtractor.__init__()                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ self.extraction_engine = 'default'                          â”‚
â”‚ self.entity_extraction_context_mode = 'dag'                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Workflow Step Registration                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ EntityMatchingStep(                                         â”‚
â”‚   extraction_engine='default',                              â”‚
â”‚   entity_extraction_context_mode='dag'                      â”‚
â”‚ )                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 7: EntityMatchingStep.execute()                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ… should_execute() checks:                                 â”‚
â”‚    - has_error? No â†’ Continue                               â”‚
â”‚    - is_fallback? Yes â†’ SKIP (because extraction_engine    â”‚
â”‚                               != 'langextract')             â”‚
â”‚                                                              â”‚
â”‚ OR if not fallback:                                         â”‚
â”‚    - has_entities? â†’ Continue                               â”‚
â”‚                                                              â”‚
â”‚ Stage 1: SKIPPED (extraction_engine != 'langextract')       â”‚
â”‚   pre_extracted = None                                      â”‚
â”‚                                                              â”‚
â”‚ Stage 2: entity_recognizer.extract_entities_with_llm(       â”‚
â”‚   pre_extracted=None  â† NULL                                â”‚
â”‚ )                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EntityRecognizer.extract_entities_with_llm()                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ if pre_extracted:  â† FALSE, skip this branch                â”‚
â”‚                                                              â”‚
â”‚ âœ… DEFAULT PATH (lines 712+):                               â”‚
â”‚   - Select prompt: HYBRID_DAG_EXTRACTION_PROMPT             â”‚
â”‚   - Stage 1: Extract entities + DAG context (LLM call 1)    â”‚
â”‚   - Stage 2: Filter vocabulary (LLM call 2)                 â”‚
â”‚                                                              â”‚
â”‚ Result: 2 LLM calls in entity extraction                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Scenario 2: `--extraction-engine langextract`

```
User Command:
  python apps/cli.py --message "ê´‘ê³ " --extraction-engine langextract

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CLI (apps/cli.py)                                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ args.extraction_engine = 'langextract'                      â”‚
â”‚ âœ… AUTO-CONFIG:                                             â”‚
â”‚   entity_extraction_context_mode = 'typed' (FORCED!)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MMSExtractor.__init__()                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ self.extraction_engine = 'langextract'                      â”‚
â”‚ self.entity_extraction_context_mode = 'typed'               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Workflow Step Registration                                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ EntityMatchingStep(                                         â”‚
â”‚   extraction_engine='langextract',                          â”‚
â”‚   entity_extraction_context_mode='typed'                    â”‚
â”‚ )                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Step 7: EntityMatchingStep.execute()                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ… should_execute() checks:                                 â”‚
â”‚    - has_error? No â†’ Continue                               â”‚
â”‚    - is_fallback? Yes â†’ CONTINUE (because extraction_engine â”‚
â”‚                                   == 'langextract')         â”‚
â”‚    - OR: Always TRUE if extraction_engine=='langextract'    â”‚
â”‚                                                              â”‚
â”‚ âœ… Stage 1: LANGEXTRACT PRE-EXTRACTION                      â”‚
â”‚   - Call: lx_extractor.extract_mms_entities(msg)            â”‚
â”‚   - Prompt: MMS_PROMPT_DESCRIPTION + lx_examples            â”‚
â”‚   - Result: pre_extracted = {                               â”‚
â”‚       'entities': ['ì•„ì´í°17', 'ì„ì§€ë¡œì ', ...],            â”‚
â”‚       'context_text': "ì•„ì´í°17(Product), ì„ì§€ë¡œì (Store)"  â”‚
â”‚     }                                                        â”‚
â”‚   - LLM call: 1 (via langextract)                           â”‚
â”‚                                                              â”‚
â”‚ Stage 2: entity_recognizer.extract_entities_with_llm(       â”‚
â”‚   pre_extracted=pre_extracted  â† POPULATED                  â”‚
â”‚ )                                                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EntityRecognizer.extract_entities_with_llm()                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ âœ… if pre_extracted:  â† TRUE, use this branch               â”‚
â”‚                                                              â”‚
â”‚   PRE-EXTRACTED PATH (lines 628-710):                       â”‚
â”‚   - SKIP Stage 1 (no HYBRID_DAG/ONT/PAIRING prompts)        â”‚
â”‚   - Use pre_extracted entities directly                     â”‚
â”‚   - Match with products                                     â”‚
â”‚   - Stage 2 ONLY: Vocabulary filtering (LLM call 2)         â”‚
â”‚     Prompt: build_context_based_entity_extraction_prompt    â”‚
â”‚             ('TYPED') + pre_extracted context               â”‚
â”‚                                                              â”‚
â”‚ Result: 1 LLM call in entity extraction (Stage 2 only)      â”‚
â”‚         + 1 LLM call from langextract (Stage 1)             â”‚
â”‚         = 2 total LLM calls (same as default)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Key Differences: Default vs LangExtract

| Aspect | `--extraction-engine default` | `--extraction-engine langextract` |
|--------|-------------------------------|-----------------------------------|
| **Step 7 Stage 1** | Skipped (no pre-extraction) | âœ… Runs langextract extraction |
| **Prompts Used (Stage 1)** | None | `MMS_PROMPT_DESCRIPTION` + `lx_examples` |
| **LLM Calls (Stage 1)** | 0 | 1 (langextract) |
| **EntityRecognizer Path** | Default path (lines 712+) | Pre-extracted path (lines 628-710) |
| **EntityRecognizer Stage 1** | âœ… Runs (HYBRID_DAG/ONT/etc.) | âŒ SKIPPED |
| **EntityRecognizer Stage 2** | âœ… Runs (vocabulary filtering) | âœ… Runs (vocabulary filtering) |
| **LLM Calls (EntityRecognizer)** | 2 (Stage 1 + Stage 2) | 1 (Stage 2 only) |
| **Total LLM Calls (Step 7)** | 2 | 2 (1 langextract + 1 filtering) |
| **Entity Types** | Extracted by LLM in Stage 1 | âœ… Explicitly typed (Product, Store, etc.) |
| **Context Mode** | User-specified (dag/pairing/ont/typed/none) | âœ… FORCED to 'typed' |
| **Fallback Resilience** | âŒ Skips if `is_fallback=True` | âœ… Runs even if `is_fallback=True` |
| **Entity-less Execution** | âŒ Skips if no entities found | âœ… Runs even without entities |

---

## Prompt Usage Summary

### Default Engine Prompts (from `prompts/entity_extraction_prompt.py`)
- âœ… Used in EntityRecognizer Stage 1:
  - `HYBRID_DAG_EXTRACTION_PROMPT` (if context_mode='dag')
  - `HYBRID_PAIRING_EXTRACTION_PROMPT` (if context_mode='pairing')
  - `ONTOLOGY_PROMPT` (if context_mode='ont')
  - `TYPED_ENTITY_EXTRACTION_PROMPT` (if context_mode='typed')
  - `SIMPLE_ENTITY_EXTRACTION_PROMPT` (if context_mode='none')
- âœ… Used in EntityRecognizer Stage 2:
  - `build_context_based_entity_extraction_prompt(context_keyword)`

### LangExtract Engine Prompts
- âœ… Stage 1 (lx_extractor.py):
  - `MMS_PROMPT_DESCRIPTION` (custom prompt for Korean MMS)
  - `prompts/lx_examples.build_mms_examples()` (few-shot examples)
  - `config/lx_schemas.get_class_description_text()` (entity type definitions)
- âœ… Stage 2 (entity_recognizer.py):
  - `build_context_based_entity_extraction_prompt('TYPED')` ONLY
  - Uses `pre_extracted['context_text']` for entity type annotations

**Critical Finding**: LangExtract does NOT use `prompts/entity_extraction_prompt.py` at all in Stage 1!

---

## Architecture Impact

### Current (Single Step with Two Stages)
- **Pros**:
  - All entity extraction in one place
  - Simpler workflow (10 steps)
- **Cons**:
  - Mixed responsibilities (extraction + matching)
  - Complex conditional logic in `should_execute()`
  - Hidden Stage 1 (not visible in workflow logs)
  - Different prompt systems mixed in one step

### Proposed (Split into Two Steps)
- **Pros**:
  - Clear separation: Step 7A = Extraction, Step 7B = Matching
  - Simple `should_execute()` per step
  - Explicit workflow visibility
  - Better observability (separate timing per step)
- **Cons**:
  - 10 â†’ 11 steps
  - +1 class, +1 state field

**Recommendation**: Split is justified given the distinct purposes and prompt systems used.

---

## Conclusion

The `--extraction-engine` parameter fundamentally changes how Step 7 operates:

1. **Flow Control**: Determines whether Stage 1 pre-extraction runs
2. **Prompt Selection**: Completely different prompt systems (entity_extraction_prompt.py vs lx_extractor prompts)
3. **Context Mode**: Forces 'typed' mode when langextract is used
4. **Resilience**: langextract runs even in fallback/entity-less scenarios
5. **LLM Call Pattern**: Same total (2 calls), but different stages execute

This bi-modal behavior (with/without Stage 1) is a strong indicator that **splitting into two steps** would improve clarity and maintainability.

---

*Analysis Date: 2026-02-11*
*Next Steps: Decide whether to split Step 7 into two separate workflow steps*
