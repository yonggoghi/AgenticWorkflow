# Step 7 ë¦¬íŒ©í† ë§ ì˜µì…˜ - Stage 1/2 ì™„ì „ ë¶„ë¦¬

**Date**: 2026-02-11
**Goal**: Stage 1ì˜ ë‘ ê°€ì§€ ë°©ì‹ (langextract, entity_extraction_prompt.py)ì„ ëª¨ë‘ EntityMatchingStepì—ì„œ ë…ë¦½

---

## í˜„ì¬ êµ¬ì¡°ì˜ ë¬¸ì œì 

### EntityMatchingStepì˜ ë³µì¡í•œ ì±…ì„
```
[EntityMatchingStep]
â”œâ”€ Stage 1 Option A: langextract (ì¡°ê±´ë¶€)
â”œâ”€ Stage 1 Option B: entity_extraction_prompt.py (entity_recognizer ë‚´ë¶€, ì¡°ê±´ë¶€)
â””â”€ Stage 2: vocabulary filtering (í•­ìƒ)
```

**ë¬¸ì œ**:
1. EntityMatchingStepì´ "ì‚¬ì „ ì¶”ì¶œ" + "ë§¤ì¹­" + "í•„í„°ë§" ì„¸ ê°€ì§€ ì±…ì„
2. entity_recognizer ë‚´ë¶€ì— Stage 1 ë¡œì§ì´ ìˆ¨ì–´ìˆìŒ
3. ê´€ì°°ì„± ë‚®ìŒ: Stage 1ì˜ ë‘ ë°©ì‹ì„ êµ¬ë¶„í•˜ê¸° ì–´ë ¤ì›€

---

## ëª©í‘œ

### Stage 1ê³¼ Stage 2ë¥¼ ëª…í™•íˆ ë¶„ë¦¬

**Stage 1: Entity + Context ì¶”ì¶œ**
- ë°©ì‹ A: langextract
- ë°©ì‹ B: entity_extraction_prompt.py

**Stage 2: Vocabulary Filtering**
- fuzzy matching + LLM filtering

**ìš”êµ¬ì‚¬í•­**:
- âœ… Stage 1ì˜ ë‘ ë°©ì‹ì„ ë™ì¼í•œ ìˆ˜ì¤€ìœ¼ë¡œ ë…ë¦½
- âœ… Stage 2ëŠ” Stage 1ì˜ êµ¬í˜„ ë°©ì‹ê³¼ ë¬´ê´€í•˜ê²Œ ë™ì‘
- âœ… ëª…í™•í•œ ë‹¨ì¼ ì±…ì„
- âœ… ë†’ì€ ê´€ì°°ì„±

---

## ì˜µì…˜ 1: 3-Step ë¶„ë¦¬ (ê¶Œì¥)

### êµ¬ì¡°
```
Step 7: EntityContextExtractionStep (ìƒˆë¡œ ì¶”ê°€)
  - Stage 1 í†µí•© (langextract + entity_extraction_prompt.py)
  - ì¶œë ¥: state.extracted_entities = {entities, context_text}

Step 8: VocabularyFilteringStep (ìƒˆë¡œ ì¶”ê°€)
  - Stage 2ë§Œ ë‹´ë‹¹ (vocabulary filtering)
  - ì…ë ¥: state.extracted_entities
  - ì¶œë ¥: state.matched_products

Step 9: ResultConstructionStep (ê¸°ì¡´ Step 8 â†’ renumber)
```

### ì¥ì 
âœ… **Stage 1ê³¼ Stage 2 ëª…í™•íˆ ë¶„ë¦¬**
âœ… **ë‹¨ì¼ ì±…ì„**: ê° Stepì´ í•˜ë‚˜ì˜ ëª…í™•í•œ ì—­í• 
âœ… **ê´€ì°°ì„± ìµœê³ **:
```
âœ… Step 7: EntityContextExtractionStep (1.8s)
    [langextract: 1.5s] ë˜ëŠ” [entity_extraction_prompt.py: 1.8s]
âœ… Step 8: VocabularyFilteringStep (1.5s)
âœ… Step 9: ResultConstructionStep (1.2s)
```
âœ… **ìœ ì—°ì„±**: ë‚˜ì¤‘ì— Stage 1ì— ìƒˆë¡œìš´ ë°©ì‹ ì¶”ê°€ ê°€ëŠ¥

### ë‹¨ì 
âš ï¸ 10 â†’ 11 steps
âš ï¸ entity_recognizer ë¦¬íŒ©í† ë§ í•„ìš” (Stage 1/2 ë¶„ë¦¬)

### êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

#### Step 7: EntityContextExtractionStep
```python
class EntityContextExtractionStep(WorkflowStep):
    """
    ì—”í‹°í‹° + ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ (Step 7)

    ë‘ ê°€ì§€ ë°©ì‹ ì¤‘ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ì‹¤í–‰:
    - langextract: Google langextract ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©
    - llm: entity_extraction_prompt.pyì˜ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©

    ë°ì´í„° íë¦„:
        ì…ë ¥: state.msg
        ì¶œë ¥: state.extracted_entities = {
            'entities': [...],
            'context_text': "...",
            'context_mode': 'typed' | 'dag' | 'ont' | ...,
            'extraction_method': 'langextract' | 'llm'
        }
    """

    def __init__(self, extraction_engine='default', context_mode='dag',
                 llm_model='ax', entity_recognizer=None):
        self.extraction_engine = extraction_engine
        self.context_mode = context_mode
        self.llm_model = llm_model
        self.entity_recognizer = entity_recognizer

    def should_execute(self, state: WorkflowState) -> bool:
        """ì—ëŸ¬ ì—†ê³ , entity_extraction_mode='llm'ì¼ ë•Œ ì‹¤í–‰"""
        if state.has_error():
            return False
        # logic ëª¨ë“œë©´ ìŠ¤í‚µ (fuzzy matchingë§Œ ì‚¬ìš©)
        return self.entity_recognizer.entity_extraction_mode == 'llm'

    def execute(self, state: WorkflowState) -> WorkflowState:
        logger.info("ğŸ” [Step 7] ì—”í‹°í‹° + ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œì‘...")
        stage_start = time.time()

        if self.extraction_engine == 'langextract':
            # ë°©ì‹ A: langextract
            result = self._extract_with_langextract(state.msg)
        else:
            # ë°©ì‹ B: entity_extraction_prompt.py
            result = self._extract_with_llm(state.msg)

        state.extracted_entities = result

        elapsed = time.time() - stage_start
        logger.info(f"âœ… ì—”í‹°í‹° ì¶”ì¶œ ì™„ë£Œ ({result['extraction_method']}): "
                   f"{len(result['entities'])}ê°œ ì—”í‹°í‹° ({elapsed:.1f}s)")

        return state

    def _extract_with_langextract(self, msg: str) -> dict:
        """langextract ë°©ì‹"""
        from core.lx_extractor import extract_mms_entities

        doc = extract_mms_entities(msg, model_id=self.llm_model)
        entities = []
        type_pairs = []

        for ext in (doc.extractions or []):
            if ext.extraction_class not in ('Channel', 'Purpose'):
                if len(ext.extraction_text) >= 2:
                    entities.append(ext.extraction_text)
                    type_pairs.append(f"{ext.extraction_text}({ext.extraction_class})")

        return {
            'entities': entities,
            'context_text': ", ".join(type_pairs),
            'context_mode': 'typed',
            'extraction_method': 'langextract'
        }

    def _extract_with_llm(self, msg: str) -> dict:
        """entity_extraction_prompt.py ë°©ì‹"""
        # entity_recognizerì˜ Stage 1 ë¡œì§ í˜¸ì¶œ
        result = self.entity_recognizer._extract_entities_stage1(
            msg, context_mode=self.context_mode
        )

        return {
            'entities': result['entities'],
            'context_text': result['context_text'],
            'context_mode': self.context_mode,
            'extraction_method': 'llm'
        }
```

#### Step 8: VocabularyFilteringStep
```python
class VocabularyFilteringStep(WorkflowStep):
    """
    Vocabulary ê¸°ë°˜ ì—”í‹°í‹° í•„í„°ë§ (Step 8)

    Stage 1ì—ì„œ ì¶”ì¶œí•œ ì—”í‹°í‹°ë“¤ì„ DB vocabularyì™€ ë¹„êµí•˜ì—¬ ìµœì¢… ì„ íƒ.

    ë°ì´í„° íë¦„:
        ì…ë ¥:
            - state.extracted_entities (from Step 7)
            - state.json_objects
            - state.entities_from_kiwi
        ì¶œë ¥: state.matched_products
    """

    def __init__(self, entity_recognizer, alias_pdf_raw, stop_item_names,
                 use_external_candidates=True):
        self.entity_recognizer = entity_recognizer
        self.alias_pdf_raw = alias_pdf_raw
        self.stop_item_names = stop_item_names
        self.use_external_candidates = use_external_candidates

    def should_execute(self, state: WorkflowState) -> bool:
        """ì—ëŸ¬ ì—†ê³ , extracted_entities ìˆì„ ë•Œ ì‹¤í–‰"""
        if state.has_error():
            return False
        if state.is_fallback:
            return False

        # Step 7ì—ì„œ ì¶”ì¶œëœ ì—”í‹°í‹°ê°€ ìˆì–´ì•¼ í•¨
        extracted = getattr(state, 'extracted_entities', None)
        if extracted and len(extracted.get('entities', [])) > 0:
            return True

        # ë˜ëŠ” json_objects/kiwiì— ì—”í‹°í‹°ê°€ ìˆì–´ì•¼ í•¨
        product_items = state.json_objects.get('product', [])
        if isinstance(product_items, dict):
            product_items = product_items.get('items', [])

        return len(product_items) > 0 or len(state.entities_from_kiwi) > 0

    def execute(self, state: WorkflowState) -> WorkflowState:
        logger.info("ğŸ” [Step 8] Vocabulary í•„í„°ë§ ì‹œì‘...")
        stage_start = time.time()

        # Get extracted entities from Step 7
        extracted = getattr(state, 'extracted_entities', None)

        if extracted:
            # Step 7ì—ì„œ ì¶”ì¶œí•œ ì—”í‹°í‹° ì‚¬ìš©
            entities = extracted['entities']
            context_text = extracted['context_text']
            context_mode = extracted['context_mode']
        else:
            # Fallback: json_objectsì—ì„œ ì¶”ì¶œ (logic ëª¨ë“œì¼ ë•Œ)
            entities = []
            context_text = ""
            context_mode = 'none'

        # External candidates ì¶”ê°€
        if self.use_external_candidates:
            # ... existing logic ...
            pass

        # entity_recognizerì˜ Stage 2 ë¡œì§ í˜¸ì¶œ
        matched = self.entity_recognizer._filter_with_vocabulary(
            entities=entities,
            context_text=context_text,
            context_mode=context_mode,
            msg=state.msg
        )

        # Product mapping
        state.matched_products = self.entity_recognizer.map_products_to_entities(
            matched, state.json_objects
        )

        elapsed = time.time() - stage_start
        logger.info(f"âœ… Vocabulary í•„í„°ë§ ì™„ë£Œ: {len(state.matched_products)}ê°œ ë§¤ì¹­ ({elapsed:.1f}s)")

        return state
```

#### entity_recognizer ë¦¬íŒ©í† ë§
```python
# services/entity_recognizer.py

class EntityRecognizer:
    def _extract_entities_stage1(self, msg: str, context_mode: str = 'dag') -> dict:
        """
        Stage 1: Entity + Context ì¶”ì¶œ

        ê¸°ì¡´ extract_entities_with_llm()ì˜ Stage 1 ë¶€ë¶„ë§Œ ë¶„ë¦¬.
        Lines 712-925ì˜ ë¡œì§.

        Returns:
            {
                'entities': [...],
                'context_text': "...",
                'entity_types': {...},  # ont ëª¨ë“œì¼ ë•Œë§Œ
                'relationships': [...]   # ont ëª¨ë“œì¼ ë•Œë§Œ
            }
        """
        # ... existing Stage 1 logic (lines 712-925) ...
        pass

    def _filter_with_vocabulary(self, entities: list, context_text: str,
                                context_mode: str, msg: str) -> pd.DataFrame:
        """
        Stage 2: Vocabulary Filtering

        ê¸°ì¡´ extract_entities_with_llm()ì˜ Stage 2 ë¶€ë¶„ë§Œ ë¶„ë¦¬.
        Lines 940-1006ì˜ ë¡œì§.

        Returns:
            DataFrame with filtered entities
        """
        # ... existing Stage 2 logic (lines 940-1006) ...
        pass

    def extract_entities_with_llm(self, msg_text: str, ...):
        """
        ê¸°ì¡´ ë©”ì„œë“œ (backward compatibility ìœ ì§€)

        ë‚´ë¶€ì ìœ¼ë¡œ _extract_entities_stage1 + _filter_with_vocabulary í˜¸ì¶œ
        """
        if pre_extracted:
            # Stage 1 ìŠ¤í‚µ
            result = self._filter_with_vocabulary(
                entities=pre_extracted['entities'],
                context_text=pre_extracted['context_text'],
                context_mode='typed',
                msg=msg_text
            )
        else:
            # Stage 1 + Stage 2
            stage1 = self._extract_entities_stage1(msg_text, context_mode)
            result = self._filter_with_vocabulary(
                entities=stage1['entities'],
                context_text=stage1['context_text'],
                context_mode=context_mode,
                msg=msg_text
            )

        return result
```

### WorkflowState ìˆ˜ì •
```python
@dataclass
class WorkflowState:
    # ... existing fields ...

    # Entity extraction (set by EntityContextExtractionStep)
    extracted_entities: Optional[Dict[str, Any]] = None  # {entities, context_text, context_mode, extraction_method}

    # Entity matching (set by VocabularyFilteringStep)
    matched_products: List[Dict[str, Any]] = field(default_factory=list)
```

### íŒŒì´í”„ë¼ì¸ ìˆœì„œ
```
1. InputValidationStep
2. EntityExtractionStep (Kiwi)
3. ProgramClassificationStep
4. ContextPreparationStep
5. LLMExtractionStep
6. ResponseParsingStep
7. EntityContextExtractionStep (Stage 1: langextract ë˜ëŠ” entity_extraction_prompt.py)
8. VocabularyFilteringStep (Stage 2: vocabulary filtering)
9. ResultConstructionStep
10. ValidationStep
11. DAGExtractionStep
```

**Total: 11 steps**

---

## ì˜µì…˜ 2: 4-Step ë¶„ë¦¬ (ìµœëŒ€ ëª…í™•ì„±)

### êµ¬ì¡°
```
Step 7A: LangExtractStep
  - langextractë§Œ ë‹´ë‹¹
  - ì¡°ê±´: extraction_engine='langextract'

Step 7B: LLMEntityExtractionStep
  - entity_extraction_prompt.pyë§Œ ë‹´ë‹¹
  - ì¡°ê±´: extraction_engine='default' and entity_extraction_mode='llm'

Step 8: VocabularyFilteringStep
  - Stage 2ë§Œ ë‹´ë‹¹

Step 9: ResultConstructionStep
```

### ì¥ì 
âœ… **ìµœëŒ€ ëª…í™•ì„±**: ê° ì¶”ì¶œ ë°©ì‹ì´ ë…ë¦½ëœ Step
âœ… **ë°°íƒ€ì  ì‹¤í–‰ ëª…í™•**: 7Aì™€ 7BëŠ” ì ˆëŒ€ ë™ì‹œ ì‹¤í–‰ ì•ˆ ë¨
âœ… **ìµœê³  ê´€ì°°ì„±**:
```
â­ï¸ Step 7A: LangExtractStep (skipped - extraction_engine=default)
âœ… Step 7B: LLMEntityExtractionStep (1.8s)
âœ… Step 8: VocabularyFilteringStep (1.5s)
```

### ë‹¨ì 
âš ï¸ 10 â†’ 12 steps (ë„ˆë¬´ ë§ìŒ)
âš ï¸ Step 7Aì™€ 7Bê°€ ë°°íƒ€ì  â†’ ê°œë…ì ìœ¼ë¡œ í•˜ë‚˜ì˜ "ì—­í• "ì¸ë° 2ê°œ Step

---

## ì˜µì…˜ 3: 2-Step ë¶„ë¦¬ + entity_recognizer ìº¡ìŠí™” ìœ ì§€

### êµ¬ì¡°
```
Step 7: PreExtractionStep (ì„ íƒì )
  - langextractë§Œ ë‹´ë‹¹
  - ì¡°ê±´: extraction_engine='langextract'
  - ì¶œë ¥: state.pre_extracted

Step 8: EntityMatchingStep (ìˆ˜ì •)
  - entity_recognizer.extract_entities_with_llm() í˜¸ì¶œ
  - pre_extracted ìˆìœ¼ë©´ â†’ Stage 2ë§Œ
  - pre_extracted ì—†ìœ¼ë©´ â†’ Stage 1 (entity_extraction_prompt.py) + Stage 2
```

### ì¥ì 
âœ… **ìµœì†Œ ë³€ê²½**: entity_recognizer ë¦¬íŒ©í† ë§ ë¶ˆí•„ìš”
âœ… **10 â†’ 11 steps**
âœ… **ìº¡ìŠí™” ìœ ì§€**: entity_recognizer ë‚´ë¶€ êµ¬ì¡° ìˆ¨ê¹€

### ë‹¨ì 
âŒ **Stage 1 ë°©ì‹ì˜ ë¹„ëŒ€ì¹­ì„±**: langextractëŠ” Stepìœ¼ë¡œ ë¶„ë¦¬, entity_extraction_prompt.pyëŠ” entity_recognizer ë‚´ë¶€
âŒ **ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ë¯¸ì¶©ì¡±**: "ë™ì¼í•œ ìˆ˜ì¤€ìœ¼ë¡œ ë…ë¦½"ì´ ëª©í‘œì¸ë° ë¹„ëŒ€ì¹­ì 

---

## ë¹„êµí‘œ

| ê¸°ì¤€ | ì˜µì…˜ 1 (3-Step) | ì˜µì…˜ 2 (4-Step) | ì˜µì…˜ 3 (2-Step) |
|------|----------------|----------------|----------------|
| **Steps ìˆ˜** | 11 | 12 | 11 |
| **Stage 1/2 ë¶„ë¦¬** | âœ… ì™„ì „ ë¶„ë¦¬ | âœ… ì™„ì „ ë¶„ë¦¬ | âš ï¸ ë¶€ë¶„ ë¶„ë¦¬ |
| **ë‘ ë°©ì‹ ëŒ€ì¹­ì„±** | âœ… ë™ì¼ Step ë‚´ | âœ… ê°ê° ë…ë¦½ Step | âŒ ë¹„ëŒ€ì¹­ |
| **entity_recognizer ë¦¬íŒ©í† ë§** | í•„ìš” (medium) | í•„ìš” (medium) | ë¶ˆí•„ìš” |
| **ê´€ì°°ì„±** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­ |
| **ë‹¨ì¼ ì±…ì„** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­ |
| **êµ¬í˜„ ë³µì¡ë„** | Medium | Medium | Low |
| **ìœ ì§€ë³´ìˆ˜ì„±** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ |
| **ì‚¬ìš©ì ìš”êµ¬ ì¶©ì¡±** | âœ… | âœ… | âŒ |

---

## ìµœì¢… ê¶Œì¥: ì˜µì…˜ 1 (3-Step ë¶„ë¦¬)

### ì´ìœ 

1. **ì‚¬ìš©ì ìš”êµ¬ì‚¬í•­ ì¶©ì¡±**:
   - Stage 1ì˜ ë‘ ë°©ì‹ì„ ë™ì¼í•œ ìˆ˜ì¤€ìœ¼ë¡œ ë…ë¦½ âœ…
   - EntityContextExtractionStep ë‚´ë¶€ì—ì„œ ë‘ ë°©ì‹ì´ ëŒ€ë“±í•˜ê²Œ ì²˜ë¦¬ë¨

2. **ëª…í™•í•œ Stage 1/2 ë¶„ë¦¬**:
   - EntityContextExtractionStep: Stage 1ë§Œ ë‹´ë‹¹
   - VocabularyFilteringStep: Stage 2ë§Œ ë‹´ë‹¹
   - ì—­í• ì´ ëª…í™•í•¨

3. **í•©ë¦¬ì ì¸ ë³µì¡ë„**:
   - 11 steps (12 stepsì¸ ì˜µì…˜ 2ë³´ë‹¤ ì ìŒ)
   - entity_recognizer ë¦¬íŒ©í† ë§ í•„ìš”í•˜ì§€ë§Œ ê¹”ë”í•œ ì„¤ê³„
   - ë‘ ë°©ì‹ì´ ê°™ì€ Step ì•ˆì— ìˆì–´ì„œ "í•˜ë‚˜ì˜ ì—­í• "ì´ë¼ëŠ” ê°œë… ìœ ì§€

4. **ë†’ì€ ê´€ì°°ì„±**:
   ```
   âœ… Step 7: EntityContextExtractionStep (1.8s)
       - Method: langextract (or llm)
       - Entities: 5ê°œ
       - Context: "ì•„ì´í°17(Product), ì„ì§€ë¡œì (Store)"
   âœ… Step 8: VocabularyFilteringStep (1.5s)
       - Matched: 3ê°œ
   ```

5. **í™•ì¥ì„±**:
   - ë‚˜ì¤‘ì— Stage 1ì— ìƒˆë¡œìš´ ë°©ì‹ ì¶”ê°€ ê°€ëŠ¥
   - ì˜ˆ: OpenAI structured outputs, Anthropic tool use ë“±

---

## êµ¬í˜„ ê³„íš (ì˜µì…˜ 1)

### Phase 1: entity_recognizer ë¦¬íŒ©í† ë§ (2-3ì‹œê°„)

#### 1.1. Stage 1/2 ë¶„ë¦¬
```python
# services/entity_recognizer.py

def _extract_entities_stage1(self, msg: str, context_mode: str = 'dag',
                             llm_models: list = None) -> dict:
    """Stage 1 ë¡œì§ (lines 712-925)"""
    # ... ê¸°ì¡´ ë¡œì§ ...
    return {
        'entities': all_entities,
        'context_text': combined_context,
        'entity_types': all_entity_types,  # ont mode only
        'relationships': all_relationships  # ont mode only
    }

def _filter_with_vocabulary(self, entities: list, context_text: str,
                            context_mode: str, msg: str, rank_limit: int = 5) -> pd.DataFrame:
    """Stage 2 ë¡œì§ (lines 940-1006)"""
    # ... ê¸°ì¡´ ë¡œì§ ...
    return cand_entities_sim

def extract_entities_with_llm(self, msg_text: str, ...):
    """Backward compatibility wrapper"""
    if pre_extracted:
        return self._filter_with_vocabulary(...)
    else:
        stage1 = self._extract_entities_stage1(...)
        return self._filter_with_vocabulary(...)
```

### Phase 2: ìƒˆ Step í´ë˜ìŠ¤ ìƒì„± (2-3ì‹œê°„)

#### 2.1. EntityContextExtractionStep
```python
# core/mms_workflow_steps.py
class EntityContextExtractionStep(WorkflowStep):
    # ... ìœ„ì˜ êµ¬í˜„ ì°¸ì¡° ...
```

#### 2.2. VocabularyFilteringStep
```python
# core/mms_workflow_steps.py
class VocabularyFilteringStep(WorkflowStep):
    # ... ìœ„ì˜ êµ¬í˜„ ì°¸ì¡° ...
```

#### 2.3. WorkflowState ìˆ˜ì •
```python
# core/workflow_core.py
@dataclass
class WorkflowState:
    # ... existing ...
    extracted_entities: Optional[Dict[str, Any]] = None
    matched_products: List[Dict[str, Any]] = field(default_factory=list)
```

#### 2.4. MMSExtractor ì—…ë°ì´íŠ¸
```python
# core/mms_extractor.py

# Step 7: EntityContextExtractionStep
self.workflow_engine.add_step(
    EntityContextExtractionStep(
        extraction_engine=self.extraction_engine,
        context_mode=entity_extraction_context_mode,
        llm_model=llm_model,
        entity_recognizer=self.entity_recognizer
    )
)

# Step 8: VocabularyFilteringStep
self.workflow_engine.add_step(
    VocabularyFilteringStep(
        entity_recognizer=self.entity_recognizer,
        alias_pdf_raw=self.alias_pdf_raw,
        stop_item_names=self.stop_item_names,
        use_external_candidates=self.use_external_candidates
    )
)
```

### Phase 3: ë¬¸ì„œ ì—…ë°ì´íŠ¸ (1ì‹œê°„)

1. ARCHITECTURE.md: 10 â†’ 11 steps, Stage 1/2 ë¶„ë¦¬ ì„¤ëª…
2. WORKFLOW_GUIDE.md: Step 7 (EntityContextExtraction) + Step 8 (VocabularyFiltering)
3. EXECUTION_FLOW.md: íë¦„ë„ ì—…ë°ì´íŠ¸
4. QUICK_REFERENCE.md: ë‹¨ê³„ ë²ˆí˜¸ ìˆ˜ì •
5. WORKFLOW_EXECUTIVE_SUMMARY.md: 11 steps ë°˜ì˜
6. WORKFLOW_SUMMARY.md: 11 steps ë°˜ì˜

### Phase 4: í…ŒìŠ¤íŠ¸ (1ì‹œê°„)

```bash
# 1. Default engine (Step 7 uses entity_extraction_prompt.py)
python tests/trace_product_extraction.py \
    --message "í…ŒìŠ¤íŠ¸" \
    --extraction-engine default \
    --entity-matching-mode llm \
    --data-source local

# Expected:
# âœ… Step 7: EntityContextExtractionStep (1.8s) - method: llm
# âœ… Step 8: VocabularyFilteringStep (1.5s)

# 2. LangExtract engine (Step 7 uses langextract)
python tests/trace_product_extraction.py \
    --message "í…ŒìŠ¤íŠ¸" \
    --extraction-engine langextract \
    --entity-matching-mode llm \
    --data-source local

# Expected:
# âœ… Step 7: EntityContextExtractionStep (1.5s) - method: langextract
# âœ… Step 8: VocabularyFilteringStep (1.5s)

# 3. Logic mode (Step 7 skipped)
python tests/trace_product_extraction.py \
    --message "í…ŒìŠ¤íŠ¸" \
    --extraction-engine default \
    --entity-matching-mode logic \
    --data-source local

# Expected:
# â­ï¸ Step 7: EntityContextExtractionStep (skipped - mode: logic)
# â­ï¸ Step 8: VocabularyFilteringStep (skipped - no extracted entities)
```

---

## ì˜ˆìƒ ì†Œìš” ì‹œê°„

| Phase | ì‘ì—… | ì‹œê°„ |
|-------|------|------|
| Phase 1 | entity_recognizer ë¦¬íŒ©í† ë§ | 2-3ì‹œê°„ |
| Phase 2 | ìƒˆ Step í´ë˜ìŠ¤ ìƒì„± | 2-3ì‹œê°„ |
| Phase 3 | ë¬¸ì„œ ì—…ë°ì´íŠ¸ | 1ì‹œê°„ |
| Phase 4 | í…ŒìŠ¤íŠ¸ | 1ì‹œê°„ |
| **Total** | | **6-8ì‹œê°„** |

---

## ê²°ë¡ 

**ì˜µì…˜ 1 (3-Step ë¶„ë¦¬) ê¶Œì¥**

**í•µì‹¬ ì´ì **:
1. âœ… Stage 1ì˜ ë‘ ë°©ì‹ì„ ë™ì¼í•œ ìˆ˜ì¤€ìœ¼ë¡œ ë…ë¦½
2. âœ… Stage 1ê³¼ Stage 2 ëª…í™•íˆ ë¶„ë¦¬
3. âœ… ëª…í™•í•œ ë‹¨ì¼ ì±…ì„
4. âœ… ë†’ì€ ê´€ì°°ì„±
5. âœ… í•©ë¦¬ì ì¸ ë³µì¡ë„ (11 steps)

**ë‹¤ìŒ ë‹¨ê³„**: ì‚¬ìš©ì ìŠ¹ì¸ í›„ Phase 1-4 êµ¬í˜„ ì§„í–‰

---

*ì‘ì„± ë‚ ì§œ: 2026-02-11*
*ì˜ˆìƒ êµ¬í˜„ ì‹œê°„: 6-8ì‹œê°„*
