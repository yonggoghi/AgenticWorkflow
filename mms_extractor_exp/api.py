#!/usr/bin/env python3
"""
MMS ì¶”ì¶œê¸° REST API ì„œë¹„ìŠ¤ (MMS Extractor API Service)
================================================================

ğŸ¯ ê°œìš”
-------
ì´ ëª¨ë“ˆì€ MMS ê´‘ê³  í…ìŠ¤íŠ¸ ë¶„ì„ ì‹œìŠ¤í…œì„ RESTful API ì„œë¹„ìŠ¤ë¡œ ì œê³µí•˜ëŠ”
ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ì›¹ ì„œë¹„ìŠ¤ì…ë‹ˆë‹¤. Flask ê¸°ë°˜ìœ¼ë¡œ êµ¬ì¶•ë˜ì–´ ê³ ì„±ëŠ¥ê³¼ í™•ì¥ì„±ì„ ë³´ì¥í•©ë‹ˆë‹¤.

ğŸš€ í•µì‹¬ ê¸°ëŠ¥
-----------
â€¢ **ë‹¨ì¼ ë©”ì‹œì§€ ì²˜ë¦¬**: `POST /extract` - ì‹¤ì‹œê°„ ë©”ì‹œì§€ ë¶„ì„
â€¢ **ë°°ì¹˜ ì²˜ë¦¬**: `POST /extract/batch` - ëŒ€ëŸ‰ ë©”ì‹œì§€ ì¼ê´„ ì²˜ë¦¬
â€¢ **ì„œë¹„ìŠ¤ ëª¨ë‹ˆí„°ë§**: `GET /health`, `GET /status` - ì„œë¹„ìŠ¤ ìƒíƒœ ë° ì„±ëŠ¥ ì§€í‘œ
â€¢ **ëª¨ë¸ ê´€ë¦¬**: `GET /models` - ì‚¬ìš© ê°€ëŠ¥í•œ LLM ëª¨ë¸ ëª©ë¡
â€¢ **ë‹¤ì¤‘ LLM ì§€ì›**: OpenAI GPT, Anthropic Claude, Gemma ë“±
â€¢ **ì‹¤ì‹œê°„ ì„¤ì •**: ëŸ°íƒ€ì„ ì¤‘ ì„¤ì • ë³€ê²½ ì§€ì›

ğŸ“Š ì„±ëŠ¥ íŠ¹ì§•
-----------
â€¢ **ê³ ì„±ëŠ¥**: ë¹„ë™ê¸° ì²˜ë¦¬ ë° ë©€í‹°í”„ë¡œì„¸ì‹± ì§€ì›
â€¢ **í™•ì¥ì„±**: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ì§€ì›
â€¢ **ì•ˆì •ì„±**: í¬ê´„ì ì¸ ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹…
â€¢ **ë³´ì•ˆ**: CORS ì„¤ì • ë° ì…ë ¥ ê²€ì¦

ğŸš€ ì‚¬ìš©ë²•
---------
```bash
# ê¸°ë³¸ ì„œë¹„ìŠ¤ ì‹œì‘
python api.py --host 0.0.0.0 --port 8000

# íŠ¹ì • LLM ëª¨ë¸ë¡œ ì‹œì‘
python api.py --llm-model gpt-4 --port 8080

# ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ ì„¤ì •
python api.py --entity-matching-mode hybrid

# í…ŒìŠ¤íŠ¸ ëª¨ë“œ
python api.py --test --message "ìƒ˜í”Œ MMS í…ìŠ¤íŠ¸"
```

ğŸ—ï¸ API ì—”ë“œí¬ì¸íŠ¸
--------------
- `POST /extract`: ë‹¨ì¼ ë©”ì‹œì§€ ë¶„ì„
- `POST /extract/batch`: ë°°ì¹˜ ë©”ì‹œì§€ ë¶„ì„
- `GET /health`: ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
- `GET /status`: ìƒì„¸ ì„±ëŠ¥ ì§€í‘œ
- `GET /models`: ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡

ğŸ“ˆ ëª¨ë‹ˆí„°ë§
-----------
- ìš”ì²­/ì‘ë‹µ ë¡œê¹…
- ì„±ëŠ¥ ë©”íŠ¸ë¦­ìŠ¤
- ì—ëŸ¬ ì¶”ì 
- ìì› ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§

ì‘ì„±ì: MMS ë¶„ì„íŒ€
ìµœì¢… ìˆ˜ì •: 2024-09
ë²„ì „: 2.0.0
"""
# =============================================================================
# í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# =============================================================================
import sys
import os
import json
import logging
import time
import argparse
import warnings
import atexit
from pathlib import Path
from flask import Flask, request, jsonify
from flask_cors import CORS
from config import settings

# =============================================================================
# ê²½ê³  ë©”ì‹œì§€ ì–µì œ (ë¡œê·¸ ë…¸ì´ì¦ˆ ê°ì†Œ)
# =============================================================================
# joblibê³¼ multiprocessing ê´€ë ¨ ê²½ê³  ì–µì œ
warnings.filterwarnings("ignore", category=UserWarning, module="joblib")
warnings.filterwarnings("ignore", category=UserWarning, module="multiprocessing") 
warnings.filterwarnings("ignore", message=".*resource_tracker.*")
warnings.filterwarnings("ignore", message=".*leaked.*")

# =============================================================================
# ê²½ë¡œ ì„¤ì • ë° ëª¨ë“ˆ ì„í¬íŠ¸ ì¤€ë¹„
# =============================================================================
# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€ (ë¡œì»¬ ëª¨ë“ˆ ì„í¬íŠ¸ë¥¼ ìœ„í•´)
current_dir = Path(__file__).parent.absolute()
sys.path.insert(0, str(current_dir))

# =============================================================================
# í•µì‹¬ ëª¨ë“ˆ ì„í¬íŠ¸ (ì˜¤ë¥˜ ì²˜ë¦¬ í¬í•¨)
# =============================================================================
# MMS ì¶”ì¶œê¸° ë° ì„¤ì • ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from mms_extractor import MMSExtractor, process_message_with_dag, process_messages_batch
    from config.settings import API_CONFIG, MODEL_CONFIG, PROCESSING_CONFIG
except ImportError as e:
    print(f"âŒ MMSExtractor ì„í¬íŠ¸ ì˜¤ë¥˜: {e}")
    print("ğŸ“ mms_extractor.pyê°€ ê°™ì€ ë””ë ‰í† ë¦¬ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”")
    print("ğŸ“ config/ ë””ë ‰í† ë¦¬ì™€ ì„¤ì • íŒŒì¼ë“¤ì„ í™•ì¸í•˜ì„¸ìš”")
    sys.exit(1)

# Flask ì•± ì´ˆê¸°í™”
app = Flask(__name__)
CORS(app)  # CORS í™œì„±í™” (í¬ë¡œìŠ¤ ì˜¤ë¦¬ì§„ ìš”ì²­ í—ˆìš©)

def cleanup_resources():
    """ë¦¬ì†ŒìŠ¤ ì •ë¦¬ í•¨ìˆ˜ - í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ í˜¸ì¶œ"""
    try:
        import gc
        import multiprocessing
        
        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜ ì‹¤í–‰
        gc.collect()
        
        # ë©€í‹°í”„ë¡œì„¸ì‹± ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        if hasattr(multiprocessing, 'active_children'):
            for child in multiprocessing.active_children():
                try:
                    child.terminate()
                    child.join(timeout=1)
                except:
                    pass
                    
        print("ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
    except Exception as e:
        print(f"ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")

# í”„ë¡œê·¸ë¨ ì¢…ë£Œ ì‹œ ë¦¬ì†ŒìŠ¤ ì •ë¦¬
atexit.register(cleanup_resources)

# ë¡œê¹… ì„¤ì • - ì½˜ì†”ê³¼ íŒŒì¼ ëª¨ë‘ì— ì¶œë ¥
import logging.handlers

# ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
log_dir = Path(__file__).parent / 'logs'
log_dir.mkdir(exist_ok=True)

# API ì „ìš© ë¡œê·¸ íŒŒì¼ ê²½ë¡œ - ì‹¤ì‹œê°„ API ìš”ì²­/ì‘ë‹µ ë¡œê·¸
log_file = log_dir / 'api_server.log'

# ë¡œê±° ì„¤ì •
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)

# í¬ë§·í„° ì„¤ì • - ëª¨ë“ˆëª… í¬í•¨í•˜ì—¬ ë¡œê·¸ ì¶œì²˜ ëª…í™•í™”
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')

# ì½˜ì†” í•¸ë“¤ëŸ¬
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(formatter)

# API ì „ìš© íŒŒì¼ í•¸ë“¤ëŸ¬ (íšŒì „ ë¡œê·¸ - 5MBì”© ìµœëŒ€ 10ê°œ íŒŒì¼, ì§§ì€ ë³´ì¡´ê¸°ê°„)
file_handler = logging.handlers.RotatingFileHandler(
    log_file, 
    maxBytes=5*1024*1024,   # 5MB (API ë¡œê·¸ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì‘ìŒ)
    backupCount=10,         # ë” ë§ì€ íŒŒì¼ ë³´ì¡´ (ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ìš©)
    encoding='utf-8'
)
file_handler.setLevel(logging.INFO)
file_handler.setFormatter(formatter)

# ë£¨íŠ¸ ë¡œê±°ì—ë§Œ í•¸ë“¤ëŸ¬ ì¶”ê°€í•˜ì—¬ ëª¨ë“  í•˜ìœ„ ë¡œê±°ì˜ ë¡œê·¸ë¥¼ ì²˜ë¦¬
root_logger = logging.getLogger()
root_logger.setLevel(logging.INFO)
root_logger.addHandler(console_handler)
root_logger.addHandler(file_handler)

# ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±° (ì¤‘ë³µ ë°©ì§€)
root_logger.handlers = [console_handler, file_handler]

# ê°œë³„ ë¡œê±°ë“¤ì€ ë£¨íŠ¸ ë¡œê±°ë¡œ ì „íŒŒí•˜ë„ë¡ ì„¤ì • (í•¸ë“¤ëŸ¬ ì¤‘ë³µ ë“±ë¡ ë°©ì§€)
logger.setLevel(logging.INFO)
mms_logger = logging.getLogger('mms_extractor')
mms_logger.setLevel(logging.INFO)

# ì „íŒŒ ì„¤ì • í™•ì¸ (ê¸°ë³¸ê°’ì´ Trueì´ë¯€ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •)
logger.propagate = True
mms_logger.propagate = True

# ì „ì—­ ì¶”ì¶œê¸° ì¸ìŠ¤í„´ìŠ¤ - ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ë¡œë“œ
global_extractor = None

# CLIì—ì„œ ì„¤ì •ëœ ë°ì´í„° ì†ŒìŠ¤ (ì „ì—­ ë³€ìˆ˜)
CLI_DATA_SOURCE = 'local'

def initialize_global_extractor(offer_info_data_src='local'):
    """
    ì „ì—­ ì¶”ì¶œê¸° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì„œë²„ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì´ˆê¸°í™”
    
    ì´ í•¨ìˆ˜ëŠ” ë¬´ê±°ìš´ ë°ì´í„° ë¡œë”© ì‘ì—…(ìƒí’ˆ ì •ë³´, ì„ë² ë”© ëª¨ë¸ ë“±)ì„ 
    ì„œë²„ ì‹œì‘ ì‹œ ë¯¸ë¦¬ ìˆ˜í–‰í•˜ì—¬ API ìš”ì²­ ì²˜ë¦¬ ì‹œê°„ì„ ë‹¨ì¶•í•©ë‹ˆë‹¤.
    
    Args:
        offer_info_data_src: ìƒí’ˆ ì •ë³´ ë°ì´í„° ì†ŒìŠ¤ ('local' ë˜ëŠ” 'db')
    
    Returns:
        MMSExtractor: ì´ˆê¸°í™”ëœ ì¶”ì¶œê¸° ì¸ìŠ¤í„´ìŠ¤
    """
    global global_extractor
    
    if global_extractor is None:
        logger.info(f"ë°ì´í„° ì†ŒìŠ¤ë¡œ ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì¤‘: {offer_info_data_src}")
        
        # ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¶”ì¶œê¸° ì´ˆê¸°í™” (ìš”ì²­ ì‹œ ë™ì ìœ¼ë¡œ ë³€ê²½ ê°€ëŠ¥)
        global_extractor = MMSExtractor(
            model_path='./models/ko-sbert-nli',      # ì„ë² ë”© ëª¨ë¸ ê²½ë¡œ
            data_dir='./data',                       # ë°ì´í„° ë””ë ‰í† ë¦¬
            offer_info_data_src=offer_info_data_src, # ìƒí’ˆ ì •ë³´ ì†ŒìŠ¤
            llm_model='ax',                       # ê¸°ë³¸ LLM (ìš”ì²­ë³„ ë³€ê²½ ê°€ëŠ¥)
            product_info_extraction_mode='nlp',     # ê¸°ë³¸ ìƒí’ˆ ì¶”ì¶œ ëª¨ë“œ
            entity_extraction_mode='logic',          # ê¸°ë³¸ ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ
            extract_entity_dag=False
        )
        
        logger.info("ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ")
    
    return global_extractor

def get_configured_extractor(llm_model='ax', product_info_extraction_mode='nlp', entity_matching_mode='logic', extract_entity_dag=False):
    """
    ëŸ°íƒ€ì„ ì„¤ì •ìœ¼ë¡œ ì „ì—­ ì¶”ì¶œê¸° êµ¬ì„±
    
    ë°ì´í„° ì¬ë¡œë”© ì—†ì´ LLM ëª¨ë¸ê³¼ ì²˜ë¦¬ ëª¨ë“œë§Œ ë³€ê²½í•˜ì—¬ 
    API ìš”ì²­ë³„ë¡œ ë‹¤ë¥¸ ì„¤ì •ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    
    Args:
        llm_model: ì‚¬ìš©í•  LLM ëª¨ë¸ ('gemma', 'ax', 'claude', 'gpt', 'gemini')
        product_info_extraction_mode: ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ëª¨ë“œ ('nlp', 'llm', 'rag')
        entity_matching_mode: ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ ('logic', 'llm')
    
    Returns:
        MMSExtractor: êµ¬ì„±ëœ ì¶”ì¶œê¸° ì¸ìŠ¤í„´ìŠ¤
    
    Raises:
        RuntimeError: ì „ì—­ ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš°
    """
    if global_extractor is None:
        raise RuntimeError("ì „ì—­ ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. initialize_global_extractor()ë¥¼ ë¨¼ì € í˜¸ì¶œí•˜ì„¸ìš”.")
    
    # í˜„ì¬ ì„¤ì •ê³¼ ë¹„êµí•˜ì—¬ ë³€ê²½ëœ ê²½ìš°ë§Œ ì—…ë°ì´íŠ¸
    current_llm_model = getattr(global_extractor, 'llm_model_name', None)
    llm_model_changed = current_llm_model != llm_model
    
    # ë°ì´í„° ì¬ë¡œë”© ì—†ì´ ëŸ°íƒ€ì„ ì„¤ì •ë§Œ ì—…ë°ì´íŠ¸
    global_extractor.llm_model_name = llm_model
    global_extractor.product_info_extraction_mode = product_info_extraction_mode
    global_extractor.entity_extraction_mode = entity_matching_mode
    global_extractor.extract_entity_dag = extract_entity_dag
    # LLM ëª¨ë¸ì´ ì‹¤ì œë¡œ ë³€ê²½ëœ ê²½ìš°ì—ë§Œ ì¬ì´ˆê¸°í™”
    if llm_model_changed:
        logger.info(f"LLM ëª¨ë¸ì´ {current_llm_model} -> {llm_model}ë¡œ ë³€ê²½ë¨. ì¬ì´ˆê¸°í™” ì¤‘...")
        global_extractor._initialize_llm()
    
    return global_extractor

@app.route('/health', methods=['GET'])
def health_check():
    """
    ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸
    
    ì„œë¹„ìŠ¤ê°€ ì •ìƒ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ê°„ë‹¨í•œ í—¬ìŠ¤ì²´í¬ APIì…ë‹ˆë‹¤.
    ë¡œë“œë°¸ëŸ°ì„œë‚˜ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì—ì„œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    
    Returns:
        JSON: ì„œë¹„ìŠ¤ ìƒíƒœ ì •ë³´
            - status: ì„œë¹„ìŠ¤ ìƒíƒœ ("healthy")
            - service: ì„œë¹„ìŠ¤ ì´ë¦„
            - version: ë²„ì „ ì •ë³´
            - model: ì‚¬ìš© ì¤‘ì¸ ê¸°ë³¸ ëª¨ë¸
            - timestamp: ì‘ë‹µ ì‹œê°„
    """
    return jsonify({
        "status": "healthy",
        "service": "MMS Extractor API",
        "version": "2.0.0",
        "model": "skt/gemma3-12b-it",
        "timestamp": time.time()
    })

@app.route('/models', methods=['GET'])
def list_models():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ë° ì„¤ì • ì˜µì…˜ ëª©ë¡ ì¡°íšŒ
    
    í´ë¼ì´ì–¸íŠ¸ê°€ APIì—ì„œ ì§€ì›í•˜ëŠ” ëª¨ë“  ì˜µì…˜ì„ í™•ì¸í•  ìˆ˜ ìˆë„ë¡ 
    ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ê³¼ ì„¤ì •ê°’ë“¤ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
    
    Returns:
        JSON: ì‚¬ìš© ê°€ëŠ¥í•œ ì„¤ì • ì˜µì…˜ë“¤
            - available_llm_models: ì§€ì›í•˜ëŠ” LLM ëª¨ë¸ ëª©ë¡
            - available_data_sources: ì§€ì›í•˜ëŠ” ë°ì´í„° ì†ŒìŠ¤
            - available_product_info_extraction_modes: ìƒí’ˆ ì¶”ì¶œ ëª¨ë“œ
            - available_entity_matching_modes: ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ
            - features: ì£¼ìš” ê¸°ëŠ¥ ëª©ë¡
    """
    return jsonify({
        "available_llm_models": ["gemma", "ax", "claude", "gemini"],
        "default_llm_model": "ax",
        "available_data_sources": ["local", "db"],
        "default_data_source": "local",
        "available_product_info_extraction_modes": ["nlp", "llm", "rag"],
        "default_product_info_extraction_mode": "nlp",
        "available_entity_matching_modes": ["logic", "llm"],
        "default_entity_matching_mode": "logic",
        "features": [
            "Korean morphological analysis (Kiwi)",      # í•œêµ­ì–´ í˜•íƒœì†Œ ë¶„ì„
            "Embedding-based similarity search",         # ì„ë² ë”© ê¸°ë°˜ ìœ ì‚¬ë„ ê²€ìƒ‰
            "Entity extraction and matching",            # ì—”í‹°í‹° ì¶”ì¶œ ë° ë§¤ì¹­
            "Program classification",                     # í”„ë¡œê·¸ë¨ ë¶„ë¥˜
            "Multiple LLM support (Gemma, GPT, Claude)" # ë‹¤ì¤‘ LLM ì§€ì›
        ]
    })

@app.route('/extract', methods=['POST'])
def extract_message():
    """
    ë‹¨ì¼ MMS ë©”ì‹œì§€ ì •ë³´ ì¶”ì¶œ API
    
    í•˜ë‚˜ì˜ MMS ë©”ì‹œì§€ì—ì„œ ìƒí’ˆëª…, ì±„ë„ ì •ë³´, ê´‘ê³  ëª©ì  ë“±ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Request Body (JSON):
        - message (required): ì¶”ì¶œí•  MMS ë©”ì‹œì§€ í…ìŠ¤íŠ¸
        - llm_model (optional): ì‚¬ìš©í•  LLM ëª¨ë¸ (ê¸°ë³¸ê°’: 'ax')
        - offer_info_data_src (optional): ë°ì´í„° ì†ŒìŠ¤ (ê¸°ë³¸ê°’: CLI ì„¤ì •ê°’)
        - product_info_extraction_mode (optional): ìƒí’ˆ ì¶”ì¶œ ëª¨ë“œ (ê¸°ë³¸ê°’: 'nlp')
        - entity_matching_mode (optional): ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ (ê¸°ë³¸ê°’: 'logic')
        - extract_entity_dag (optional): ì—”í‹°í‹° DAG ì¶”ì¶œ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
                                         Trueì¼ ê²½ìš° ë©”ì‹œì§€ì—ì„œ ì—”í‹°í‹° ê°„ ê´€ê³„ë¥¼ DAG í˜•íƒœë¡œ ì¶”ì¶œí•˜ê³ 
                                         ì‹œê°ì  ë‹¤ì´ì–´ê·¸ë¨ë„ í•¨ê»˜ ìƒì„±í•©ë‹ˆë‹¤.
    
    Returns:
        JSON: ì¶”ì¶œ ê²°ê³¼
            - success: ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
            - result: ì¶”ì¶œëœ ì •ë³´ (title, purpose, product, channel, pgm)
                     extract_entity_dag=Trueì¸ ê²½ìš° entity_dag í•„ë“œë„ í¬í•¨
            - metadata: ì²˜ë¦¬ ë©”íƒ€ë°ì´í„° (ì²˜ë¦¬ ì‹œê°„, ì‚¬ìš©ëœ ì„¤ì •, DAG ì¶”ì¶œ ì—¬ë¶€ ë“±)
    
    HTTP Status Codes:
        - 200: ì„±ê³µ
        - 400: ì˜ëª»ëœ ìš”ì²­ (í•„ìˆ˜ í•„ë“œ ëˆ„ë½, ì˜ëª»ëœ íŒŒë¼ë¯¸í„° ë“±)
        - 500: ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜
    """
    try:
        # ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
        if global_extractor is None:
            return jsonify({"error": "ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."}), 500
        
        # ìš”ì²­ ë°ì´í„° ê²€ì¦
        if not request.is_json:
            return jsonify({"error": "Content-Typeì€ application/jsonì´ì–´ì•¼ í•©ë‹ˆë‹¤"}), 400
        
        data = request.get_json()
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if 'message' not in data:
            return jsonify({"error": "í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: 'message'"}), 400
        
        message = data['message']
        if not message or not message.strip():
            return jsonify({"error": "ë©”ì‹œì§€ëŠ” ë¹„ì–´ìˆì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 400
        
        # ì„ íƒì  íŒŒë¼ë¯¸í„° ì¶”ì¶œ (ê¸°ë³¸ê°’ ì‚¬ìš©)
        data_source = data.get('data_source', CLI_DATA_SOURCE)
        offer_info_data_src = data.get('offer_info_data_src', CLI_DATA_SOURCE)
        llm_model = data.get('llm_model', settings.ModelConfig.llm_model)
        product_info_extraction_mode = data.get('product_info_extraction_mode', settings.ProcessingConfig.product_info_extraction_mode)
        entity_matching_mode = data.get('entity_matching_mode', settings.ProcessingConfig.entity_extraction_mode)
        extract_entity_dag = data.get('extract_entity_dag', False)
        
        # DAG ì¶”ì¶œ ìš”ì²­ ë¡œê¹…
        if extract_entity_dag:
            logger.info(f"ğŸ¯ DAG ì¶”ì¶œ ìš”ì²­ë¨ - LLM: {llm_model}, ë©”ì‹œì§€ ê¸¸ì´: {len(message)}ì")
        
        # íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì¦
        valid_sources = ['local', 'db']
        if offer_info_data_src not in valid_sources:
            return jsonify({"error": f"ì˜ëª»ëœ offer_info_data_srcì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_sources}"}), 400
            
        valid_llm_models = ['gemma', 'ax', 'claude', 'gemini']
        if llm_model not in valid_llm_models:
            return jsonify({"error": f"ì˜ëª»ëœ llm_modelì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_llm_models}"}), 400
            
        valid_product_modes = ['nlp', 'llm', 'rag']
        if product_info_extraction_mode not in valid_product_modes:
            return jsonify({"error": f"ì˜ëª»ëœ product_info_extraction_modeì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_product_modes}"}), 400
            
        valid_entity_modes = ['logic', 'llm']
        if entity_matching_mode not in valid_entity_modes:
            return jsonify({"error": f"ì˜ëª»ëœ entity_matching_modeì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_entity_modes}"}), 400
        
        # DAG ì¶”ì¶œ ê¸°ëŠ¥ í™œì„±í™”
        # extract_entity_dag=Trueì¸ ê²½ìš°:
        # 1. ë©”ì‹œì§€ì—ì„œ ì—”í‹°í‹° ê°„ ê´€ê³„ë¥¼ DAG(Directed Acyclic Graph) í˜•íƒœë¡œ ì¶”ì¶œ
        # 2. NetworkXë¥¼ ì‚¬ìš©í•˜ì—¬ ê·¸ë˜í”„ êµ¬ì¡° ìƒì„±
        # 3. Graphvizë¥¼ í†µí•´ ì‹œê°ì  ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± (./dag_images/ ë””ë ‰í† ë¦¬ì— ì €ì¥)
        # 4. ê²°ê³¼ì˜ entity_dag í•„ë“œì— DAG í…ìŠ¤íŠ¸ í‘œí˜„ í¬í•¨
        
        # êµ¬ì„±ëœ ì¶”ì¶œê¸°ë¡œ ë©”ì‹œì§€ ì²˜ë¦¬ (í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ í¬í•¨)
        start_time = time.time()
        extractor = get_configured_extractor(llm_model, product_info_extraction_mode, entity_matching_mode, extract_entity_dag)
        
        logger.info(f"ë°ì´í„° ì†ŒìŠ¤ë¡œ ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘: {offer_info_data_src}")
        
        # í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ë¥¼ ìœ„í•œ ìŠ¤ë ˆë“œ ë¡œì»¬ ì €ì¥ì†Œ ì´ˆê¸°í™”
        import threading
        current_thread = threading.current_thread()
        current_thread.stored_prompts = {}
        
        # DAG ì¶”ì¶œ ì—¬ë¶€ì— ë”°ë¼ ë³‘ë ¬ ì²˜ë¦¬ ë˜ëŠ” ë‹¨ì¼ ì²˜ë¦¬
        if extract_entity_dag:
            logger.info("DAG ì¶”ì¶œê³¼ í•¨ê»˜ ìˆœì°¨ ì²˜ë¦¬ ì‹œì‘")
            result = process_message_with_dag(extractor, message, extract_dag=True)['extracted_result']
        else:
            result = extractor.process_message(message)['extracted_result']
            result['entity_dag'] = []  # DAG ì¶”ì¶œí•˜ì§€ ì•Šì€ ê²½ìš° ë¹ˆ ë°°ì—´
            
        processing_time = time.time() - start_time
        
        # ìº¡ì²˜ëœ í”„ë¡¬í”„íŠ¸ë“¤ ê°€ì ¸ì˜¤ê¸°
        captured_prompts = getattr(current_thread, 'stored_prompts', {})
        logger.info(f"ì¶”ì¶œ ê³¼ì •ì—ì„œ ìº¡ì²˜ëœ í”„ë¡¬í”„íŠ¸: {len(captured_prompts)}ê°œ")
        
        # DAG ì¶”ì¶œ ê²°ê³¼ ê²€ì¦ ë° ë¡œê¹…
        # entity_dag í•„ë“œëŠ” ì¶”ì¶œëœ ì—”í‹°í‹° ê°„ì˜ ê´€ê³„ë¥¼ í…ìŠ¤íŠ¸ë¡œ í‘œí˜„í•œ ê²ƒ
        # ì˜ˆ: "(ê³ ê°:ê°€ì…) -[í•˜ë©´]-> (í˜œíƒ:ìˆ˜ë ¹)"
        if extract_entity_dag and 'entity_dag' in result:
            dag_length = len(result['entity_dag']) if result['entity_dag'] else 0
            if dag_length > 0:
                logger.info(f"âœ… DAG ì¶”ì¶œ ì„±ê³µ - ê¸¸ì´: {dag_length}ì")
                logger.info(f"DAG ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°: {result['entity_dag'][:100]}...")
            else:
                logger.warning("âš ï¸ DAG ì¶”ì¶œ ìš”ì²­ë˜ì—ˆìœ¼ë‚˜ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŒ")
        
        # ì„±ê³µ ì‘ë‹µ ë°˜í™˜ (í”„ë¡¬í”„íŠ¸ í¬í•¨)
        response = {
            "success": True,
            "result": result,
            "metadata": {
                "llm_model": llm_model,
                "offer_info_data_src": offer_info_data_src,
                "product_info_extraction_mode": product_info_extraction_mode,
                "entity_matching_mode": entity_matching_mode,
                "extract_entity_dag": extract_entity_dag,
                "processing_time_seconds": round(processing_time, 3),
                "timestamp": time.time(),
                "message_length": len(message)
            },
            "prompts": {
                "success": True,
                "prompts": captured_prompts,
                "settings": {
                    "llm_model": llm_model,
                    "offer_info_data_src": offer_info_data_src,
                    "product_info_extraction_mode": product_info_extraction_mode,
                    "entity_matching_mode": entity_matching_mode,
                    "extract_entity_dag": extract_entity_dag
                },
                "message_info": {
                    "length": len(message),
                    "preview": message[:200] + "..." if len(message) > 200 else message
                },
                "timestamp": time.time()
            }
        }
        
        logger.info(f"ì¶”ì¶œ ì™„ë£Œ: {processing_time:.3f}ì´ˆ")
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({
            "success": False,
            "error": str(e),
            "timestamp": time.time()
        }), 500

@app.route('/extract/batch', methods=['POST'])
def extract_batch():
    """
    ë‹¤ì¤‘ MMS ë©”ì‹œì§€ ë°°ì¹˜ ì²˜ë¦¬ API
    
    ì—¬ëŸ¬ ê°œì˜ MMS ë©”ì‹œì§€ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬í•˜ì—¬ íš¨ìœ¨ì„±ì„ ë†’ì…ë‹ˆë‹¤.
    ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ë‚˜ ë°°ì¹˜ ì‘ì—…ì— ìœ ìš©í•©ë‹ˆë‹¤.
    
    Request Body (JSON):
        - messages (required): ì²˜ë¦¬í•  ë©”ì‹œì§€ ë°°ì—´ (ìµœëŒ€ 100ê°œ)
        - llm_model (optional): ì‚¬ìš©í•  LLM ëª¨ë¸
        - offer_info_data_src (optional): ë°ì´í„° ì†ŒìŠ¤
        - product_info_extraction_mode (optional): ìƒí’ˆ ì¶”ì¶œ ëª¨ë“œ
        - entity_matching_mode (optional): ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ
        - extract_entity_dag (optional): ì—”í‹°í‹° DAG ì¶”ì¶œ ì—¬ë¶€ (ê¸°ë³¸ê°’: False)
        - max_workers (optional): ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ (ê¸°ë³¸ê°’: CPU ì½”ì–´ ìˆ˜)
    
    Returns:
        JSON: ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼
            - success: ì „ì²´ ë°°ì¹˜ ì²˜ë¦¬ ì„±ê³µ ì—¬ë¶€
            - results: ê° ë©”ì‹œì§€ë³„ ì²˜ë¦¬ ê²°ê³¼ ë°°ì—´
            - summary: ì²˜ë¦¬ ìš”ì•½ (ì´ ê°œìˆ˜, ì„±ê³µ/ì‹¤íŒ¨ ê°œìˆ˜)
            - metadata: ë°°ì¹˜ ì²˜ë¦¬ ë©”íƒ€ë°ì´í„°
    
    HTTP Status Codes:
        - 200: ì„±ê³µ (ê°œë³„ ë©”ì‹œì§€ ì‹¤íŒ¨ê°€ ìˆì–´ë„ ë°°ì¹˜ ìì²´ëŠ” ì„±ê³µ)
        - 400: ì˜ëª»ëœ ìš”ì²­
        - 500: ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜
    """
    try:
        # ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ìƒíƒœ í™•ì¸
        if global_extractor is None:
            return jsonify({"error": "ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì„œë²„ ì‹œì‘ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."}), 500
        
        if not request.is_json:
            return jsonify({"error": "Content-Typeì€ application/jsonì´ì–´ì•¼ í•©ë‹ˆë‹¤"}), 400
        
        data = request.get_json()
        
        # í•„ìˆ˜ í•„ë“œ ê²€ì¦
        if 'messages' not in data:
            return jsonify({"error": "í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: 'messages'"}), 400
        
        messages = data['messages']
        if not isinstance(messages, list):
            return jsonify({"error": "'messages' í•„ë“œëŠ” ë°°ì—´ì´ì–´ì•¼ í•©ë‹ˆë‹¤"}), 400
        
        if len(messages) > 100:  # ë°°ì¹˜ í¬ê¸° ì œí•œ
            return jsonify({"error": "ë°°ì¹˜ë‹¹ ìµœëŒ€ 100ê°œ ë©”ì‹œì§€ê¹Œì§€ ì²˜ë¦¬ ê°€ëŠ¥í•©ë‹ˆë‹¤"}), 400
        
        # ì„ íƒì  íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        offer_info_data_src = data.get('offer_info_data_src', CLI_DATA_SOURCE)
        llm_model = data.get('llm_model', settings.ModelConfig.llm_model)
        product_info_extraction_mode = data.get('product_info_extraction_mode', settings.ProcessingConfig.product_info_extraction_mode)
        entity_matching_mode = data.get('entity_matching_mode', settings.ProcessingConfig.entity_extraction_mode)
        extract_entity_dag = data.get('extract_entity_dag', False)
        max_workers = data.get('max_workers', None)
        
        # íŒŒë¼ë¯¸í„° ìœ íš¨ì„± ê²€ì¦
        valid_sources = ['local', 'db']
        if offer_info_data_src not in valid_sources:
            return jsonify({"error": f"ì˜ëª»ëœ offer_info_data_srcì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_sources}"}), 400
            
        valid_llm_models = ['gemma', 'ax', 'claude', 'gemini']
        if llm_model not in valid_llm_models:
            return jsonify({"error": f"ì˜ëª»ëœ llm_modelì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_llm_models}"}), 400
            
        valid_product_modes = ['nlp', 'llm', 'rag']
        if product_info_extraction_mode not in valid_product_modes:
            return jsonify({"error": f"ì˜ëª»ëœ product_info_extraction_modeì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_product_modes}"}), 400
            
        valid_entity_modes = ['logic', 'llm']
        if entity_matching_mode not in valid_entity_modes:
            return jsonify({"error": f"ì˜ëª»ëœ entity_matching_modeì…ë‹ˆë‹¤. ì‚¬ìš© ê°€ëŠ¥: {valid_entity_modes}"}), 400
        
        # êµ¬ì„±ëœ ì¶”ì¶œê¸° ê°€ì ¸ì˜¤ê¸°
        extractor = get_configured_extractor(llm_model, product_info_extraction_mode, entity_matching_mode, extract_entity_dag)
        
        # DAG ì¶”ì¶œ ìš”ì²­ ë¡œê¹…
        if extract_entity_dag:
            logger.info(f"ğŸ¯ ë°°ì¹˜ DAG ì¶”ì¶œ ìš”ì²­ë¨ - {len(messages)}ê°œ ë©”ì‹œì§€, ì›Œì»¤: {max_workers}")
        
        # ë©€í‹°í”„ë¡œì„¸ìŠ¤ ë°°ì¹˜ ì²˜ë¦¬
        start_time = time.time()
        
        # ë¹ˆ ë©”ì‹œì§€ í•„í„°ë§
        valid_messages = []
        message_indices = []
        for i, message in enumerate(messages):
            if message and message.strip():
                valid_messages.append(message)
                message_indices.append(i)
        
        logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì‹œì‘: {len(valid_messages)}/{len(messages)}ê°œ ìœ íš¨í•œ ë©”ì‹œì§€")
        
        try:
            # ë©€í‹°í”„ë¡œì„¸ìŠ¤ ë°°ì¹˜ ì²˜ë¦¬ ì‹¤í–‰
            batch_results = process_messages_batch(
                extractor, 
                valid_messages, 
                extract_dag=extract_entity_dag,
                max_workers=max_workers
            )
            
            # ê²°ê³¼ë¥¼ ì›ë˜ ì¸ë±ìŠ¤ì™€ ë§¤í•‘
            results = []
            valid_result_idx = 0
            
            for i, message in enumerate(messages):
                if not message or not message.strip():
                    results.append({
                        "index": i,
                        "success": False,
                        "error": "ë¹ˆ ë©”ì‹œì§€ì…ë‹ˆë‹¤"
                    })
                else:
                    if valid_result_idx < len(batch_results):
                        batch_result = batch_results[valid_result_idx]
                        if batch_result.get('error'):
                            results.append({
                                "index": i,
                                "success": False,
                                "error": batch_result['error']
                            })
                        else:
                            results.append({
                                "index": i,
                                "success": True,
                                "result": batch_result
                            })
                        valid_result_idx += 1
                    else:
                        results.append({
                            "index": i,
                            "success": False,
                            "error": "ë°°ì¹˜ ì²˜ë¦¬ ê²°ê³¼ ë¶€ì¡±"
                        })
        
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            # ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œ ëª¨ë“  ë©”ì‹œì§€ë¥¼ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
            results = []
            for i, message in enumerate(messages):
                results.append({
                    "index": i,
                    "success": False,
                    "error": f"ë°°ì¹˜ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"
                })
        
        processing_time = time.time() - start_time
        
        # ì„±ê³µ/ì‹¤íŒ¨ ê°œìˆ˜ ì§‘ê³„
        successful = sum(1 for r in results if r["success"])
        failed = len(results) - successful
        
        response = {
            "success": True,
            "results": results,
            "summary": {
                "total_messages": len(messages),
                "successful": successful,
                "failed": failed
            },
            "metadata": {
                "llm_model": llm_model,
                "offer_info_data_src": offer_info_data_src,
                "product_info_extraction_mode": product_info_extraction_mode,
                "entity_matching_mode": entity_matching_mode,
                "extract_entity_dag": extract_entity_dag,
                "max_workers": max_workers,
                "processing_time_seconds": round(processing_time, 3),
                "timestamp": time.time()
            }
        }
        
        logger.info(f"ë°°ì¹˜ ì¶”ì¶œ ì™„ë£Œ: {successful}/{len(messages)}ê°œ ì„±ê³µ, {processing_time:.3f}ì´ˆ ì†Œìš”")
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"ë°°ì¹˜ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({
            "success": False,
            "error": str(e),
            "timestamp": time.time()
        }), 500

@app.route('/status', methods=['GET'])
def get_status():
    """
    API ìƒíƒœ ë° ì¶”ì¶œê¸° ì •ë³´ ì¡°íšŒ
    
    í˜„ì¬ ì„œë²„ì˜ ìƒíƒœì™€ ì¶”ì¶œê¸°ì˜ ì„¤ì • ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    ë””ë²„ê¹…ì´ë‚˜ ëª¨ë‹ˆí„°ë§ ëª©ì ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.
    
    Returns:
        JSON: ì„œë²„ ë° ì¶”ì¶œê¸° ìƒíƒœ ì •ë³´
            - status: ì„œë²„ ì‹¤í–‰ ìƒíƒœ
            - extractor: ì¶”ì¶œê¸° ìƒíƒœ ì •ë³´
                - initialized: ì´ˆê¸°í™” ì—¬ë¶€
                - data_source: í˜„ì¬ ë°ì´í„° ì†ŒìŠ¤
                - current_llm_model: í˜„ì¬ LLM ëª¨ë¸
                - current_product_mode: í˜„ì¬ ìƒí’ˆ ì¶”ì¶œ ëª¨ë“œ
                - current_entity_mode: í˜„ì¬ ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ
            - timestamp: ì‘ë‹µ ì‹œê°„
    """
    global global_extractor
    
    # ì¶”ì¶œê¸° ìƒíƒœ ì •ë³´ ìˆ˜ì§‘
    extractor_status = {
        "initialized": global_extractor is not None,
        "data_source": CLI_DATA_SOURCE if global_extractor else None,
        "current_llm_model": global_extractor.llm_model_name if global_extractor else None,
        "current_product_mode": global_extractor.product_info_extraction_mode if global_extractor else None,
        "current_entity_mode": global_extractor.entity_extraction_mode if global_extractor else None
    }
    
    return jsonify({
        "status": "running",
        "extractor": extractor_status,
        "timestamp": time.time()
    })

@app.route('/prompts', methods=['POST'])
def get_prompts():
    """
    ì‹¤ì œ ì¶”ì¶œ ê³¼ì •ì—ì„œ ì‚¬ìš©ëœ í”„ë¡¬í”„íŠ¸ë“¤ì„ ë°˜í™˜í•˜ëŠ” ì—”ë“œí¬ì¸íŠ¸
    
    ì‹¤ì œ ì¶”ì¶œì„ ìˆ˜í–‰í•˜ê³  ê·¸ ê³¼ì •ì—ì„œ LLMì— ì „ì†¡ëœ í”„ë¡¬í”„íŠ¸ë“¤ì„ ìº¡ì²˜í•˜ì—¬ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    try:
        if not global_extractor:
            return jsonify({
                "success": False,
                "error": "ì¶”ì¶œê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 500
        
        # ìš”ì²­ ë°ì´í„° íŒŒì‹±
        data = request.get_json()
        if not data:
            return jsonify({
                "success": False,
                "error": "JSON ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400
        
        message = data.get('message', '')
        if not message:
            return jsonify({
                "success": False,
                "error": "ë©”ì‹œì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400
        
        # ì„¤ì • íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        llm_model = data.get('llm_model', 'ax')
        offer_info_data_src = data.get('offer_info_data_src', 'local')
        product_info_extraction_mode = data.get('product_info_extraction_mode', 'llm')
        entity_matching_mode = data.get('entity_matching_mode', 'logic')
        extract_entity_dag = data.get('extract_entity_dag', False)
        
        # ì¶”ì¶œê¸° ì„¤ì • ì—…ë°ì´íŠ¸
        extractor = get_configured_extractor(llm_model, product_info_extraction_mode, entity_matching_mode, extract_entity_dag)
        
        # ì‹¤ì œ ì¶”ì¶œ ìˆ˜í–‰ (í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ë¥¼ ìœ„í•´)
        import threading
        current_thread = threading.current_thread()
        current_thread.stored_prompts = {}  # í”„ë¡¬í”„íŠ¸ ì €ì¥ì†Œ ì´ˆê¸°í™”
        
        logger.info(f"í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ì‹œì‘ - ìŠ¤ë ˆë“œ ID: {current_thread.ident}")
        
        # ì¶”ì¶œ ìˆ˜í–‰
        if extract_entity_dag:
            result = process_message_with_dag(extractor, message, extract_dag=True)
        else:
            result = extractor.process_message(message)
        
        # ì €ì¥ëœ í”„ë¡¬í”„íŠ¸ë“¤ ê°€ì ¸ì˜¤ê¸°
        stored_prompts = getattr(current_thread, 'stored_prompts', {})
        
        logger.info(f"í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ì™„ë£Œ - ìŠ¤ë ˆë“œ ID: {current_thread.ident}")
        logger.info(f"ì‹¤ì œ stored_prompts ë‚´ìš©: {stored_prompts}")
        
        logger.info(f"í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ìƒíƒœ: {len(stored_prompts)}ê°œ í”„ë¡¬í”„íŠ¸")
        logger.info(f"í”„ë¡¬í”„íŠ¸ í‚¤ë“¤: {list(stored_prompts.keys())}")
        
        # í”„ë¡¬í”„íŠ¸ê°€ ì—†ì–´ë„ ì„±ê³µìœ¼ë¡œ ì²˜ë¦¬ (ì¼ë¶€ ëª¨ë“œì—ì„œëŠ” íŠ¹ì • í”„ë¡¬í”„íŠ¸ë§Œ ìƒì„±ë¨)
        # if not stored_prompts:
        #     return jsonify({
        #         "success": False,
        #         "error": "í”„ë¡¬í”„íŠ¸ê°€ ìº¡ì²˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
        #         "prompts": {},
        #         "settings": {...}
        #     }), 200
        
        # ì‘ë‹µ êµ¬ì„±
        response = {
            "success": True,
            "prompts": stored_prompts,
            "settings": {
                "llm_model": llm_model,
                "offer_info_data_src": offer_info_data_src,
                "product_info_extraction_mode": product_info_extraction_mode,
                "entity_matching_mode": entity_matching_mode,
                "extract_entity_dag": extract_entity_dag
            },
            "message_info": {
                "length": len(message),
                "preview": message[:200] + "..." if len(message) > 200 else message
            },
            "timestamp": time.time(),
            "extraction_result": result  # ì¶”ì¶œ ê²°ê³¼ë„ í•¨ê»˜ ë°˜í™˜ (ì°¸ê³ ìš©)
        }
        
        logger.info(f"ì‹¤ì œ í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ì™„ë£Œ: {len(stored_prompts)}ê°œ í”„ë¡¬í”„íŠ¸")
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"í”„ë¡¬í”„íŠ¸ ìº¡ì²˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return jsonify({
            "success": False,
            "error": str(e),
            "timestamp": time.time()
        }), 500

@app.errorhandler(404)
def not_found(error):
    """404 ì—ëŸ¬ í•¸ë“¤ëŸ¬ - ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì—”ë“œí¬ì¸íŠ¸ ì ‘ê·¼ ì‹œ"""
    return jsonify({"error": "ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 404

@app.errorhandler(500)
def internal_error(error):
    """500 ì—ëŸ¬ í•¸ë“¤ëŸ¬ - ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ ë°œìƒ ì‹œ"""
    return jsonify({"error": "ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤"}), 500

def main():
    """
    ë©”ì¸ í•¨ìˆ˜ - CLI ì‚¬ìš©ì„ ìœ„í•œ ì§„ì…ì 
    
    ì»¤ë§¨ë“œë¼ì¸ ì¸ìë¥¼ íŒŒì‹±í•˜ê³  ì„œë²„ë¥¼ ì‹œì‘í•˜ê±°ë‚˜ í…ŒìŠ¤íŠ¸ ëª¨ë“œë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.
    
    CLI ì˜µì…˜:
        --host: ë°”ì¸ë”©í•  í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: 0.0.0.0)
        --port: ë°”ì¸ë”©í•  í¬íŠ¸ (ê¸°ë³¸ê°’: 8000)
        --debug: ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”
        --test: í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰
        --message: í…ŒìŠ¤íŠ¸í•  ë©”ì‹œì§€ (í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œ ì‚¬ìš©)
        --offer-data-source: ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ
        --product-info-extraction-mode: ìƒí’ˆ ì¶”ì¶œ ëª¨ë“œ ì„ íƒ
        --entity-matching-mode: ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ ì„ íƒ
        --llm-model: ì‚¬ìš©í•  LLM ëª¨ë¸ ì„ íƒ
    
    ì‚¬ìš© ì˜ˆì‹œ:
        # ì„œë²„ ëª¨ë“œ
        python api.py --host 0.0.0.0 --port 8000
        
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
        python api.py --test --message "í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€" --llm-model gpt
        
        # ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš©
        python api.py --offer-data-source db
    """
    global CLI_DATA_SOURCE
    
    # ì»¤ë§¨ë“œë¼ì¸ ì¸ì íŒŒì„œ ì„¤ì •
    parser = argparse.ArgumentParser(description='MMS ì¶”ì¶œê¸° API ì„œë²„')
    parser.add_argument('--host', default='0.0.0.0', help='ë°”ì¸ë”©í•  í˜¸ìŠ¤íŠ¸ ì£¼ì†Œ')
    parser.add_argument('--port', type=int, default=8000, help='ë°”ì¸ë”©í•  í¬íŠ¸ ë²ˆí˜¸')
    parser.add_argument('--debug', action='store_true', help='ë””ë²„ê·¸ ëª¨ë“œ í™œì„±í™”')
    parser.add_argument('--test', action='store_true', help='í…ŒìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤í–‰')
    parser.add_argument('--message', type=str, help='í…ŒìŠ¤íŠ¸í•  ë©”ì‹œì§€')
    parser.add_argument('--offer-data-source', choices=['local', 'db'], default='local',
                       help='ë°ì´í„° ì†ŒìŠ¤ ì„ íƒ (local: CSV íŒŒì¼, db: ë°ì´í„°ë² ì´ìŠ¤)')
    parser.add_argument('--product-info-extraction-mode', choices=['nlp', 'llm' ,'rag'], default='nlp',
                       help='ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ëª¨ë“œ (nlp: í˜•íƒœì†Œë¶„ì„, llm: LLM ê¸°ë°˜, rag: ê²€ìƒ‰ì¦ê°•ìƒì„±)')
    parser.add_argument('--entity-matching-mode', choices=['logic', 'llm'], default='llm',
                       help='ì—”í‹°í‹° ë§¤ì¹­ ëª¨ë“œ (logic: ë¡œì§ ê¸°ë°˜, llm: LLM ê¸°ë°˜)')
    parser.add_argument('--llm-model', choices=['gem', 'ax', 'cld', 'gen', 'gpt'], default='ax',
                       help='ì‚¬ìš©í•  LLM ëª¨ë¸ (gem: Gemma, ax: ax, cld: Claude, gen: Gemini, gpt: GPT)')
    parser.add_argument('--extract-entity-dag', action='store_true', default=False, help='Entity DAG extraction (default: False)')
    
    args = parser.parse_args()
    
    # ì „ì—­ CLI ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •
    CLI_DATA_SOURCE = args.offer_data_source
    logger.info(f"CLI ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •: {CLI_DATA_SOURCE}")
    
    # ì§€ì •ëœ ë°ì´í„° ì†ŒìŠ¤ë¡œ ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™”
    logger.info("ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì¤‘...")
    initialize_global_extractor(CLI_DATA_SOURCE)
    
    if args.test:
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰
        logger.info("í…ŒìŠ¤íŠ¸ ëª¨ë“œì—ì„œ ì‹¤í–‰ ì¤‘...")
        
        # ì œê³µëœ ë©”ì‹œì§€ ë˜ëŠ” ê¸°ë³¸ ìƒ˜í”Œ ë©”ì‹œì§€ ì‚¬ìš©
        message = args.message or """
        [SKí…”ë ˆì½¤] ZEMí° í¬ì¼“ëª¬ì—ë””ì…˜3 ì•ˆë‚´
        (ê´‘ê³ )[SKT] ìš°ë¦¬ ì•„ì´ ì²« ë²ˆì§¸ ìŠ¤ë§ˆíŠ¸í°, ZEM í‚¤ì¦ˆí°__#04 ê³ ê°ë‹˜, ì•ˆë…•í•˜ì„¸ìš”!
        ìš°ë¦¬ ì•„ì´ ìŠ¤ë§ˆíŠ¸í° ê³ ë¯¼ ì¤‘ì´ì…¨ë‹¤ë©´, ìë…€ ìŠ¤ë§ˆíŠ¸í° ê´€ë¦¬ ì•± ZEMì´ ì„¤ì¹˜ëœ SKTë§Œì˜ ì•ˆì „í•œ í‚¤ì¦ˆí°,
        ZEMí° í¬ì¼“ëª¬ì—ë””ì…˜3ìœ¼ë¡œ ìš°ë¦¬ ì•„ì´ ì·¨í–¥ì„ ì €ê²©í•´ ë³´ì„¸ìš”!
        """
        
        try:
            logger.info(f"ì¶”ì¶œê¸° ì„¤ì •: llm_model={args.llm_model}, product_mode={args.product_info_extraction_mode}, entity_mode={args.entity_matching_mode}, dag_extract={args.extract_entity_dag}")
            extractor = get_configured_extractor(args.llm_model, args.product_info_extraction_mode, args.entity_matching_mode, args.extract_entity_dag)
            
            if not message.strip():
                logger.info("í…ìŠ¤íŠ¸ê°€ ì œê³µë˜ì§€ ì•Šì•„ ìƒ˜í”Œ ë©”ì‹œì§€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤...")
            
            logger.info("ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘...")
            
            # DAG ì¶”ì¶œ ì—¬ë¶€ì— ë”°ë¼ ë³‘ë ¬ ì²˜ë¦¬ ë˜ëŠ” ë‹¨ì¼ ì²˜ë¦¬
            if args.extract_entity_dag:
                logger.info("DAG ì¶”ì¶œê³¼ í•¨ê»˜ ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘")
                result = process_message_with_dag(extractor, message, extract_dag=True)
            else:
                result = extractor.process_message(message)
                result['entity_dag'] = []
            
            print("\n" + "="*60)
            print("ì¶”ì¶œ ê²°ê³¼:")
            print("="*60)
            print(json.dumps(result, ensure_ascii=False, indent=2))
            print("="*60)
            
            logger.info("ì²˜ë¦¬ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
            
        except Exception as e:
            logger.error(f"âŒ ì˜¤ë¥˜: {e}")
            sys.exit(1)
    else:
        # ì„œë²„ ëª¨ë“œ ì‹¤í–‰
        logger.info(f"íŒŒì‹±ëœ ì¸ì: host={args.host}, port={args.port}, debug={args.debug}")
        logger.info("âœ… ì „ì—­ ì¶”ì¶œê¸° ì´ˆê¸°í™” ì™„ë£Œ, ìš”ì²­ ì²˜ë¦¬ ì¤€ë¹„ë¨")
        logger.info(f"MMS ì¶”ì¶œê¸° API ì„œë²„ë¥¼ {args.host}:{args.port}ì—ì„œ ì‹œì‘í•©ë‹ˆë‹¤")
        logger.info("ì‚¬ìš© ê°€ëŠ¥í•œ ì—”ë“œí¬ì¸íŠ¸:")
        logger.info("  GET  /health - í—¬ìŠ¤ì²´í¬")
        logger.info("  GET  /models - ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡")
        logger.info("  GET  /status - ì„œë²„ ìƒíƒœ ì¡°íšŒ")
        logger.info("  POST /extract - ë‹¨ì¼ ë©”ì‹œì§€ ì¶”ì¶œ")
        logger.info("  POST /extract/batch - ë‹¤ì¤‘ ë©”ì‹œì§€ ë°°ì¹˜ ì¶”ì¶œ")
        
        # Flask ì„¤ì • ì ìš©
        app.config['DEBUG'] = args.debug
        
        try:
            # ì„œë²„ ì‹œì‘ (ë¦¬ë¡œë” ë¹„í™œì„±í™”, ìŠ¤ë ˆë”© í™œì„±í™”)
            app.run(host=args.host, port=args.port, debug=args.debug, use_reloader=False, threaded=True)
        except Exception as e:
            logger.error(f"ì„œë²„ ì‹œì‘ ì‹¤íŒ¨: {e}")
            sys.exit(1)

if __name__ == "__main__":
    main()
